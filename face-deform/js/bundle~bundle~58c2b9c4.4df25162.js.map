{"version":3,"sources":["webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/scatter_nd_util.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/zeros_like.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/reverse.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/sqrt.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/transpose.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/sub.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/slice_util.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/print.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/sigmoid.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/squeeze.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/spectral/irfft.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/round.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/pow.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/sum.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/ones.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/not_equal.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/squared_difference.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/step.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/relu6.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/scalar.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/prelu.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/tensor3d.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/reduce_util.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/slice.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/rotate_util.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/selu_util.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/split_util.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/segment_util.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/signal_ops_util.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/signal/hamming_window.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/signal/hann_window.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/signal/frame.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/signal/stft.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/sparse/sparse_fill_empty_rows.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/sparse/sparse_reshape.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/sparse/sparse_segment_mean.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/sparse/sparse_segment_sum.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/string/string_n_grams.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/string/string_split.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/string/string_to_hash_bucket_fast.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/ops.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/profiler.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/operation.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/tensor1d.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/platforms/platform_browser.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/platforms/platform_node.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/nonmax_util.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/where.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/tensor_ops_util.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/stack.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/split.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/zeros.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/relu.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/tensor.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/tensor2d.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/range.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/spectral/ifft.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/real.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/reshape.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/unstack.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/spectral/fft.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/spectral/rfft.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/norm.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/square.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/tile.js"],"names":["validateUpdateShape","shape","indices","updates","sliceDim","rank","batchDim","shapeError","Error","length","d","validateInput","dtype","size","calculateShapes","indicesRank","sliceRank","totalNd","sliceSize","i","safeSliceDim","numUpdates","strides","slice","outputSize","zerosLike","zerosLike_","x","inputs","runKernel","reverse","reverse_","axis","attrs","dims","sqrt","sqrt_","transpose","transpose_","perm","$x","map","s","forEach","clone","sub","sub_","a","b","$a","$b","assertParamsValid","input","begin","inputRank","maskToAxes","mask","axes","push","computeOutShape","end","Math","ceil","stridesWithElidedDims","ellipsisInsertionIndex","numElidedAxes","inputShape","newStrides","splice","pop","unnormalizeAxis","normalizedAxis","getElidedAxes","elidedAxes","getNormalizedAxes","ellipsisAxes","numInterpolatedAxes","beginMask","endMask","ellipsisMask","normalizedBegin","Array","normalizedEnd","normalizedStrides","fullIndex","startIndicesWithElidedDims","stopIndicesWithElidedDims","startForAxis","stopForAxis","stridesForAxis","originalBegin","newIndices","indexOf","originalAxis","originalValue","originalEnd","Number","MAX_SAFE_INTEGER","axisSize","stride","startIndices","start","MIN_SAFE_INTEGER","stopIndices","stop","isSliceContinous","firstNonOneAxis","computeFlatOffset","flatOffset","parseSliceParams","begin_","xRank","size_","fill","concat","sliceInfo","xShape","newAxisMask","shrinkAxisMask","$begin","$end","$strides","expandAxes","newShape","shrinkAxes","outShape","filter","_","nonStrided","every","v","print","verbose","console","log","toString","sigmoid","sigmoid_","squeeze","squeeze_","irfft","irfft_","innerDimensionSize","batch","ret","complexInput","outputShape","realInput","imagInput","realConjugate","imagConjugate","r","temp","dispose","round","round_","pow","pow_","base","exp","$base","$exp","sum","sum_","keepDims","ones","real","imag","values","makeTensor","notEqual","notEqual_","squaredDifference","squaredDifference_","step","step_","alpha","relu6","relu6_","scalar","value","isArray","Uint8Array","prelu","prelu_","tensor3d","inferredShape","PARALLELIZE_THRESHOLD","computeOptimalWindowSize","inSize","floor","slice_","getImageCenter","center","imageHeight","imageWidth","SELU_SCALEALPHA","SELU_SCALE","prepareSplitSize","numOrSizeSplits","splitSizes","numOfNegs","reduce","count","negIndex","total","segOpComputeOptimalWindowSize","numSegments","res","done","aShape","dim","collectGatherOpShapeInfo","batchDims","dimSize","batchSize","outerSize","cosineWindow","windowLength","even","newValues","Float32Array","cosArg","PI","cos","tensor1d","hammingWindow_","hannWindow","hannWindow_","frame_","signal","frameLength","frameStep","padEnd","padValue","output","padLen","pad","tensor2d","reshape","stft_","fftLength","windowFn","framedSignal","windowedSignal","mul","rfft","sparseFillEmptyRows","sparseFillEmptyRows_","denseShape","defaultValue","$indices","$values","$denseShape","$defaultValue","result","outputIndices","outputValues","emptyRowIndicator","reverseIndexMap","sparseReshape","sparseReshape_","inputIndices","$inputIndices","$inputShape","$newShape","sparseSegmentMean","sparseSegmentMean_","data","segmentIds","$data","$segmentIds","sparseSegmentSum","sparseSegmentSum_","stringNGrams","stringNGrams_","dataSplits","separator","nGramWidths","leftPad","rightPad","padWidth","preserveShortSequences","$dataSplits","nGrams","nGramsSplits","stringSplit","stringSplit_","delimiter","skipEmpty","$input","$delimiter","stringToHashBucketFast","stringToHashBucketFast_","numBuckets","fft","ifft","flipLeftRight","resizeNearestNeighbor","resizeBilinear","rotateWithOffset","cropAndResize","nonMaxSuppression","nonMaxSuppressionAsync","nonMaxSuppressionWithScore","nonMaxSuppressionWithScoreAsync","nonMaxSuppressionPadded","nonMaxSuppressionPaddedAsync","threshold","transform","sparse","qr","string","Profiler","backendTimer","logger","this","Logger","kernelName","f","outputs","holdResultWrapperFn","timer","timerAvailable","time","dataSync","Promise","resolve","kernelMs","getBool","then","tensorVals","checkComputationForErrors","timeMs","timing","extraInfo","getExtraProfileInfo","kernelProfile","all","valueContainer","logKernelProfile","vals","num","isNaN","isFinite","warn","name","paddedName","inputShapesDescription","op","keys","Object","opName","fn","endsWith","substring","f2","args","startScope","error","endScope","ex","defineProperty","configurable","PlatformBrowser","path","init","fetch","performance","now","text","encoding","textEncoder","TextEncoder","encode","bytes","TextDecoder","decode","get","setPlatform","registerManager","URL_SCHEME","err","getNodeFetch","systemFetch","PlatformNode","util","requestInits","global","process","hrtime","nonMaxSuppSanityCheck","boxes","scores","maxOutputSize","iouThreshold","scoreThreshold","softNmsSigma","NEGATIVE_INFINITY","numBoxes","min","where","where_","condition","$condition","broadcastShape","t","e","providedSize","inferredSize","inferred","flatDimsDontMatch","stack","stack_","tensors","$tensors","split","split_","attr","zeros","relu","relu_","tensor","range","ifft_","real_","reshape_","unstack","unstack_","fft_","rfft_","adjustedInput","zerosShape","zerosInput","half","realValues","imagValues","realComplexConjugate","imagComplexConjugate","normImpl","p","Infinity","norm","norm_","ord","keepDimsShape","square","square_","tile","tile_","reps"],"mappings":";sJAAA,oKAOO,SAASA,EAAoBC,EAAOC,EAASC,GAChD,MAAMC,EAAYF,EAAQG,KAAO,EAAKH,EAAQD,MAAMC,EAAQG,KAAO,GAAK,EAClEC,EAAYJ,EAAQG,KAAO,EAAKH,EAAQG,KAAO,EAAI,EACnDE,EACF,6FAAwCJ,EAAQF,yBAC5BC,EAAQD,iBAAiBA,gBAC9BG,oBAA2BE,KAC9C,GAAIH,EAAQE,KAAOC,EACf,MAAM,IAAIE,MAAMD,EAAa,kBAAkBD,OAEnD,GAAIL,EAAMQ,OAASL,GAAYD,EAAQE,KAAOC,GAC1C,MAAM,IAAIE,MAAMD,EACZ,0BAA0BH,GAAYD,EAAQE,KAAOC,MAE7D,GAAIH,EAAQE,OAASC,EAAWL,EAAMQ,OAASL,EAC3C,MAAM,IAAII,MAAMD,EAAa,oBAAmBD,EAAWL,EAAMQ,OAASL,IAE9E,IAAK,IAAIM,EAAI,EAAGA,EAAIJ,IAAYI,EAC5B,GAAIP,EAAQF,MAAMS,KAAOR,EAAQD,MAAMS,GACnC,MAAM,IAAIF,MAAMD,EACZ,kBAAkBG,OAAOP,EAAQF,MAAMS,wBAAwBA,OAAOR,EAAQD,MAAMS,QAGhG,IAAK,IAAIA,EAAI,EAAGA,EAAIP,EAAQE,KAAOC,IAAYI,EAC3C,GAAIP,EAAQF,MAAMS,EAAIJ,KAAcL,EAAMS,EAAIN,GAC1C,MAAM,IAAII,MAAMD,EACZ,kBAAkBG,EAAIJ,OAAcH,EAAQF,MAAMS,EAAIJ,gBAAuBI,EAAIJ,OAAcL,EAAMS,EAAIJ,OAWlH,SAASK,EAAcR,EAASD,EAASD,GAC5C,GAAIC,EAAQG,KAAO,EACf,MAAM,IAAIG,MACN,+EAAqBN,EAAQG,SAErC,GAAIF,EAAQE,KAAO,EACf,MAAM,IAAIG,MACN,+EAAqBL,EAAQE,SAErC,GAAsB,UAAlBH,EAAQU,MACR,MAAM,IAAIJ,MAAM,0DAA0DN,EAAQU,SAEtF,GAAIX,EAAMQ,OAAS,EACf,MAAM,IAAID,MAAM,6DAA6DP,KAEjF,GAAqB,IAAjBA,EAAMQ,OAAc,CACpB,GAAqB,IAAjBP,EAAQW,KACR,MAAM,IAAIL,MAAM,sDAAsDN,EAAQD,SAElF,GAAqB,IAAjBE,EAAQU,KACR,MAAM,IAAIL,MAAM,sDAAsDL,EAAQF,SAGtFD,EAAoBC,EAAOC,EAASC,GAWjC,SAASW,EAAgBX,EAASD,EAASD,GAE9C,MAAMc,EAAcb,EAAQD,MAAMQ,OAC5BO,EAAaD,EAAc,EAAKb,EAAQD,MAAMc,EAAc,GAAK,EAIjEE,EAAUhB,EAAMQ,OACtB,IAAIS,EAAY,EAChB,IAAK,IAAIC,EAAIH,EAAWG,EAAIF,IAAWE,EACnCD,GAAajB,EAAMkB,GAEvB,MAAMC,EAAgBJ,EAAY,EAAK,EAAIA,EAI3C,MAAO,CAAEA,YAAWK,WAHD,YAAcnB,EAAQD,OAASmB,EAGlBF,YAAWI,QAF3B,IAAI,YAAerB,EAAMsB,MAAM,EAAGP,IAAa,GAEXQ,WADjC,YAAcvB,M,iCC7FrC,kEAsCO,MAAMwB,EAAY,YAAG,CAAEC,WAL9B,SAAoBC,GAChB,MACMC,EAAS,CAAED,EADN,YAAgBA,EAAG,IAAK,cAEnC,OAAO,IAAOE,UAAU,KAAWD,O,iCCpCvC,kEAyDO,MAAME,EAAU,YAAG,CAAEC,SAN5B,SAAkBJ,EAAGK,GACjB,MACMJ,EAAS,CAAED,EADN,YAAgBA,EAAG,IAAK,YAE7BM,EAAQ,CAAEC,KAAMF,GACtB,OAAO,IAAOH,UAAU,KAASD,EAAQK,O,iCCvD7C,kEAqCO,MAAME,EAAO,YAAG,CAAEC,MALzB,SAAeT,GACX,MACMC,EAAS,CAAED,EADN,YAAgBA,EAAG,IAAK,SAEnC,OAAO,IAAOE,UAAU,KAAMD,O,iCCnClC,yEA0DO,MAAMS,EAAY,YAAG,CAAEC,WAlB9B,SAAoBX,EAAGY,GACnB,MAAMC,EAAK,YAAgBb,EAAG,IAAK,aAUnC,GATY,MAARY,IACAA,EAAOC,EAAGvC,MAAMwC,KAAI,CAACC,EAAGvB,IAAMA,IAAGW,WAErC,IAAYU,EAAGnC,OAASkC,EAAK9B,QAAQ,IAAM,qCAAqC+B,EAAGnC,kCAClDkC,OACjCA,EAAKI,SAAQX,IACT,IAAYA,GAAQ,GAAKA,EAAOQ,EAAGnC,MAAM,IAAM,gDAA+CmC,EAAGnC,KAAO,GACpG,YAAYkC,SAEhBC,EAAGnC,MAAQ,EACX,OAAOmC,EAAGI,QAEd,MAAMhB,EAAS,CAAED,EAAGa,GACdP,EAAQ,CAAEM,QAChB,OAAO,IAAOV,UAAU,KAAWD,EAAQK,O,gCCxD/C,0EAmDO,MAAMY,EAAM,YAAG,CAAEC,KAPxB,SAAcC,EAAGC,GACb,IAAIC,EAAK,YAAgBF,EAAG,IAAK,OAC7BG,EAAK,YAAgBF,EAAG,IAAK,QAChCC,EAAIC,GAAM,YAAeD,EAAIC,GAC9B,MAAMtB,EAAS,CAAEmB,EAAGE,EAAID,EAAGE,GAC3B,OAAO,IAAOrB,UAAU,KAAKD,O,iCCjDjC,ksBAiBO,SAASuB,EAAkBC,EAAOC,EAAOxC,GAC5C,MAAMyC,EAAYF,EAAMnD,MAAMQ,OAC9B,IAAY6C,IAAcD,EAAM5C,QAAQ,IAAM,iBAAiB6C,uBAA+BD,uCAC1DC,QACpC,IAAYA,IAAczC,EAAKJ,QAAQ,IAAM,iBAAiB6C,sBAA8BzC,uCACxDyC,QACpC,IAAK,IAAInC,EAAI,EAAGA,EAAImC,IAAanC,EAC7B,IAAYkC,EAAMlC,GAAKN,EAAKM,IAAMiC,EAAMnD,MAAMkB,IAAI,IAAM,iBAAiBmC,aAAqBnC,aAAaA,OACnGkC,EAAMlC,GAAKN,EAAKM,kCAAkCA,OAAOiC,EAAMnD,MAAMkB,QAI9E,SAASoC,EAAWC,GACvB,MAAMC,EAAO,GACb,IAAIzB,EAAO,EACX,KAAOwB,EAAO,GACC,EAAPA,GACAC,EAAKC,KAAK1B,GAEdwB,GAAQ,EACRxB,IAEJ,OAAOyB,EAGJ,SAASE,EAAgBN,EAAOO,EAAKtC,GACxC,MAAMT,EAAO,GACb,IAAK,IAAImB,EAAO,EAAGA,EAAOqB,EAAM5C,OAAQuB,IACpCnB,EAAKmB,GAAQ6B,KAAKC,MAAMF,EAAI5B,GAAQqB,EAAMrB,IAASV,EAAQU,IAE/D,OAAOnB,EAIJ,SAASkD,EAAsBzC,EAAS0C,EAAwBC,EAAeC,GAClF,MAAMC,EAAa,IAAI7C,GACvB,IAAK,IAAIH,EAAIgD,EAAW1D,OAAQU,EAAI+C,EAAWzD,OAAQU,IACnDgD,EAAWT,KAAK,GAEpB,IAAK,IAAIvC,EAAI,EAAGA,EAAI8C,EAAe9C,IACrB,IAANA,EACAgD,EAAWH,GAA0B,GAGrCG,EAAWC,OAAOJ,EAAwB,EAAgC,GAC1EG,EAAWE,OAGnB,OAAOF,EAEX,SAASG,EAAgBN,EAAwBC,EAAeM,GAC5D,OAAIA,GAAkBP,EACXO,EAEJA,GAAkBN,EAAgB,GAE7C,SAASO,EAAcP,EAAeD,GAClC,MAAMS,EAAa,GACnB,IAAK,IAAItD,EAAI,EAAGA,EAAI8C,EAAe9C,IAC/BsD,EAAWf,KAAKM,EAAyB7C,GAE7C,OAAOsD,EAGJ,SAASC,EAAkBR,EAAYS,EAAcC,EAAqBvB,EAAOO,EAAKtC,EAASuD,EAAWC,EAASC,GACtH,MAAMzB,EAAYY,EAAWzD,OAC7B,IAAIuE,EAAkB,IAAIC,MAAM3B,GAAY4B,EAAgB,IAAID,MAAM3B,GAAY6B,EAAoB,IAAIF,MAAM3B,GAChH,GAAIqB,EAAalE,QAAUmE,EAAsB,EAAG,CAChD,MAAMQ,EAAYT,EAAa,GAGzBV,EAAgBW,EAAsB,EAC5CI,EAAkBK,EAA2BR,EAAWO,EAAWnB,EAAeZ,EAAOa,GACzFgB,EAAgBI,EAA0BR,EAASM,EAAWnB,EAAeL,EAAKM,GAClFiB,EACIpB,EAAsBzC,EAAS8D,EAAWnB,EAAeC,QAG7D,IAAK,IAAIlC,EAAO,EAAGA,EAAOsB,EAAWtB,IACjCgD,EAAgBhD,GAAQuD,EAAaV,EAAWxB,EAAO/B,EAAS4C,EAAYlC,EAAM+C,GAClFG,EAAclD,GACVwD,EAAYV,EAASlB,EAAKtC,EAAS4C,EAAYlC,EAAM+C,GACzDI,EAAkBnD,GAAQyD,EAAenE,EAASU,EAAM+C,GAGhE,MAAO,CACH1B,MAAO2B,EACPpB,IAAKsB,EACL5D,QAAS6D,GAKV,SAASE,EAA2BR,EAAWb,EAAwBC,EAAeyB,EAAexB,GACxG,MAAMyB,EAAa,IAAIzB,GACjBO,EAAaD,EAAcP,EAAeD,GAChD,IAAK,IAAIhC,EAAO,EAAGA,EAAO2D,EAAWlF,OAAQuB,IACzC,GAAIyC,EAAWmB,QAAQ5D,IAAS,EAC5B2D,EAAW3D,GAAQ,MAElB,CACD,MAAM6D,EAAevB,EAAgBN,EAAwBC,EAAejC,GAC5E,IAAI8D,EAAgBJ,EAAcG,GAC9BhB,EAAY,GAAKgB,IACjBC,EAAgB,GAEpBH,EAAW3D,GAAQ8D,EAG3B,OAAOH,EAIJ,SAASL,EAA0BR,EAASd,EAAwBC,EAAe8B,EAAa7B,GACnG,MAAMyB,EAAa,IAAIzB,GACjBO,EAAaD,EAAcP,EAAeD,GAChD,IAAK,IAAIhC,EAAO,EAAGA,EAAO2D,EAAWlF,OAAQuB,IACzC,GAAIyC,EAAWmB,QAAQ5D,IAAS,EAC5B2D,EAAW3D,GAAQgE,OAAOC,qBAEzB,CACD,MAAMJ,EAAevB,EAAgBN,EAAwBC,EAAejC,GAC5E,IAAI8D,EAAgBC,EAAYF,GAC5Bf,EAAU,GAAKe,IACfC,EAAgBE,OAAOC,kBAE3BN,EAAW3D,GAAQ8D,EAG3B,IAAK,IAAI3E,EAAI,EAAGA,EAAIwE,EAAWlF,OAAQU,IAAK,CAExC,MAAM+E,EAAWhC,EAAW/C,GACxBwE,EAAWxE,GAAK,IAChBwE,EAAWxE,IAAM+E,GAErBP,EAAWxE,GAAK,IAAW,EAAGwE,EAAWxE,GAAI+C,EAAW/C,IAE5D,OAAOwE,EAEJ,SAASF,EAAenE,EAASU,EAAM+C,GAC1C,IAAIoB,EAAS7E,EAAQU,GAIrB,OAHI+C,EAAgB,GAAK/C,GAAmB,MAAVmE,KAC9BA,EAAS,GAENA,EAEJ,SAASZ,EAAaV,EAAWuB,EAAc9E,EAAS4C,EAAYlC,EAAM+C,GAE7E,IAAIsB,EAAQD,EAAapE,GACzB,MAAMmE,EAAS7E,EAAQU,IAAS,GAG5B6C,EAAY,GAAK7C,GAAQ+C,EAAe,GAAK/C,GAAiB,MAATqE,KAKjDA,EAJAF,EAAS,EAIDH,OAAOM,iBAIPN,OAAOC,kBAIvB,MAAMC,EAAWhC,EAAWlC,GAM5B,OALIqE,EAAQ,IACRA,GAASH,GAGbG,EAAQ,IAAW,EAAGA,EAAOH,EAAW,GACjCG,EAEJ,SAASb,EAAYV,EAASyB,EAAajF,EAAS4C,EAAYlC,EAAM+C,GAEzE,IAAIyB,EAAOD,EAAYvE,GACvB,MAAMmE,EAAS7E,EAAQU,IAAS,GAG5B8C,EAAW,GAAK9C,GAAS+C,EAAgB,GAAK/C,GAAiB,MAARwE,KAInDA,EAHAL,EAAS,EAGFH,OAAOC,iBAIPD,OAAOM,kBAItB,MAAMJ,EAAWhC,EAAWlC,GAe5B,OAdIwE,EAAO,IACPA,GAAQN,GAORM,EAFAL,EAAS,EAEF,IAAW,EAAGK,EAAMN,GAIpB,KAAY,EAAGM,EAAMN,EAAW,GAEpCM,EAMJ,SAASC,EAAiBxG,EAAOoD,EAAOxC,GAE3C,IAAI6F,EAAkB7F,EAAKJ,OAC3B,IAAK,IAAIU,EAAI,EAAGA,EAAIN,EAAKJ,OAAQU,IAC7B,GAAIN,EAAKM,GAAK,EAAG,CACbuF,EAAkBvF,EAClB,MAGR,IAAK,IAAIA,EAAIuF,EAAkB,EAAGvF,EAAIN,EAAKJ,OAAQU,IAC/C,GAAIkC,EAAMlC,GAAK,GAAKN,EAAKM,KAAOlB,EAAMkB,GAClC,OAAO,EAGf,OAAO,EAEJ,SAASwF,EAAkBtD,EAAO/B,GACrC,IAAIsF,EAAavD,EAAM5C,OAAS,EAAI4C,EAAMA,EAAM5C,OAAS,GAAK,EAC9D,IAAK,IAAIU,EAAI,EAAGA,EAAIkC,EAAM5C,OAAS,EAAGU,IAClCyF,GAAcvD,EAAMlC,GAAKG,EAAQH,GAErC,OAAOyF,EAEJ,SAASC,EAAiBlF,EAAG0B,EAAOxC,GAEvC,IAAIiG,EACJ,MAAMC,EAAQpF,EAAE1B,MAAMQ,OAatB,IAAIuG,EAuBJ,OAlCIF,EADiB,iBAAVzD,EACE,CAACA,KAAU,IAAI4B,MAAM8B,EAAQ,GAAGE,KAAK,IAEzC5D,EAAM5C,OAASsG,EACX1D,EAAM6D,OAAO,IAAIjC,MAAM8B,EAAQ1D,EAAM5C,QAAQwG,KAAK,IAGlD5D,EAAM9B,QAEnBuF,EAAOnE,SAAQjC,IACX,KAAmB,IAAPA,GAAU,IAAM,yDAI5BsG,EADQ,MAARnG,EACQ,IAAIoE,MAAM8B,GAAOE,MAAM,GAEV,iBAATpG,EACJ,CAACA,KAAS,IAAIoE,MAAM8B,EAAQ,GAAGE,MAAM,IAExCpG,EAAKJ,OAASsG,EACXlG,EAAKqG,OAAO,IAAIjC,MAAM8B,EAAQlG,EAAKJ,QAAQwG,MAAM,IAGjDpG,EAEZmG,EAAQA,EAAMvE,KAAI,CAAC/B,EAAGS,IACdT,GAAK,EACEA,GAGP,KAAmB,IAAPA,GAAU,IAClB,qDAAGA,mCAAmCS,OACnCQ,EAAE1B,MAAMkB,GAAK2F,EAAO3F,MAG5B,CAAC2F,EAAQE,GAEb,SAASG,EAAUC,EAAQ/D,EAAOO,EAAKtC,EAASuD,EAAWC,EAASC,EAAcsC,EAAaC,GAElG,IAAIC,EAASlE,EAAM9B,QACfiG,EAAO5D,EAAIrC,QACXkG,EAAWnG,EACA,MAAXA,IACAmG,EAAW,IAAIxC,MAAMsC,EAAO9G,SAEhC,MAAMkE,EAAepB,EAAWwB,GAChC,GAAIJ,EAAalE,OAAS,EACtB,MAAM,IAAID,MAAM,8CAEpB,GAAqB,IAAjBuE,GAAsC,IAAhBsC,EACtB,MAAM,IAAI7G,MAAM,iEAEpB,GAAqB,IAAjBuE,GAAyC,IAAnBuC,EACtB,MAAM,IAAI9G,MAAM,oEAEpB,MAAMoE,EAAsBwC,EAAO3G,OAAS8G,EAAO9G,OAE7CiH,EAAanE,EAAW8D,GACxBM,EAAWP,EAAO7F,QACxBmG,EAAW/E,SAAQX,IACfuF,EAAOvF,GAAQ,EACfwF,EAAKxF,GAAQ,EACb2F,EAASvD,OAAOpC,EAAM,EAAG,MAE7B,MAAQqB,MAAO2B,EAAiBpB,IAAKsB,EAAe5D,QAAS6D,GAAsBT,EAAkBiD,EAAUhD,EAAcC,EAAqB2C,EAAQC,EAAMC,EAAU5C,EAAWC,EAASC,GAC9LwC,EAASvC,EACTwC,EAAOtC,EACPuC,EAAWtC,EACX,MAAMyC,EAAarE,EAAW+D,GAE9BM,EAAWjF,SAAQX,IACfwF,EAAKxF,GAAQuF,EAAOvF,GAAQ,EAC5ByF,EAASzF,GAAQ,KAGrB,MAAMnB,EAAO8C,EAAgB4D,EAAQC,EAAMC,GAErCI,EAAWhH,EAAKiH,QAAO,CAACC,EAAG/F,KAAuC,IAA9B4F,EAAWhC,QAAQ5D,KAE7D,MAAO,CAAEgG,WADUP,EAASQ,OAAMC,GAAW,IAANA,IAClBX,SAAQC,OAAMC,WAAU5G,OAAM8G,WAAUE,c,iCClT1D,SAASM,EAAMxG,EAAGyG,GAAU,GAC/BC,QAAQC,IAAI3G,EAAE4G,SAASH,IA9B3B,mC,iCCAA,kEAqCO,MAAMI,EAAU,YAAG,CAAEC,SAL5B,SAAkB9G,GACd,MACMC,EAAS,CAAED,EADN,YAAgBA,EAAG,IAAK,YAEnC,OAAO,IAAOE,UAAU,KAASD,O,iCCnCrC,kEAuCO,MAAM8G,EAAU,YAAG,CAAEC,SAJ5B,SAAkBhH,EAAGK,GACjB,MAAMQ,EAAK,YAAgBb,EAAG,IAAK,WACnC,OAAO,YAAQa,EAAI,YAAaA,EAAGvC,MAAO+B,GAAM2F,c,iCCrCpD,6HA2EO,MAAMiB,EAAQ,YAAG,CAAEC,OA/B1B,SAAgBzF,GACZ,MAAM0F,EAAqB1F,EAAMnD,MAAMmD,EAAMnD,MAAMQ,OAAS,GACtDsI,EAAQ3F,EAAMvC,KAAOiI,EAC3B,IAAIE,EACJ,GAAIF,GAAsB,EAAG,CACzB,MAAMG,EAAe,YAAQ7F,EAAO,CAAC2F,EAAOD,IAC5CE,EAAM,YAAKC,OAEV,CAGD,MAAMC,EAAc,CAACH,EAAO,GAAKD,EAAqB,IAChDK,EAAY,YAAQ,YAAK/F,GAAQ,CAAC2F,EAAOD,IACzCM,EAAY,YAAQ,YAAKhG,GAAQ,CAAC2F,EAAOD,IACzCO,EAAgB,YAAQ,YAAMF,EAAW,CAAC,EAAG,GAAI,CAACJ,EAAOD,EAAqB,IAAK,GACnFQ,EAAgB,YAAI,YAAQ,YAAMF,EAAW,CAAC,EAAG,GAAI,CAACL,EAAOD,EAAqB,IAAK,GAAI,aAAQ,IACnGS,EAAI,YAAO,CAACJ,EAAWE,GAAgB,GACvClI,EAAI,YAAO,CAACiI,EAAWE,GAAgB,GACvCL,EAAe,YAAQ,YAAQM,EAAGpI,GAAI,CAAC+H,EAAY,GAAIA,EAAY,KACzEF,EAAM,YAAKC,GAIf,GAFAD,EAAM,YAAKA,GAEQ,IAAf5F,EAAM/C,MAAiC,IAAnB+C,EAAMnD,MAAM,GAAU,CAC1C,MAAMuJ,EAAOR,EACPD,EAAQ3F,EAAMnD,MAAM,GAC1B+I,EAAM,YAAQA,EAAK,CAACD,EAAOC,EAAI/I,MAAM,GAAK8I,EAAOC,EAAI/I,MAAM,KAC3DuJ,EAAKC,UAET,OAAOT,M,iCCzEX,kEAsCO,MAAMU,EAAQ,YAAG,CAAEC,OAL1B,SAAgBhI,GACZ,MACMC,EAAS,CAAED,EADN,YAAgBA,EAAG,IAAK,UAEnC,OAAO,IAAOE,UAAU,KAAOD,O,iCCpCnC,0EAwDO,MAAMgI,EAAM,YAAG,CAAEC,KAPxB,SAAcC,EAAMC,GAChB,IAAIC,EAAQ,YAAgBF,EAAM,OAAQ,OACtCG,EAAO,YAAgBF,EAAK,MAAO,QACtCC,EAAOC,GAAQ,YAAeD,EAAOC,GACtC,MAAMrI,EAAS,CAAEmB,EAAGiH,EAAOhH,EAAGiH,GAC9B,OAAO,IAAOpI,UAAU,KAAKD,O,gCCtDjC,0EA4DO,MAAMsI,EAAM,YAAG,CAAEC,KATxB,SAAcxI,EAAGK,EAAO,KAAMoI,GAAW,GACrC,IAAI5H,EAAK,YAAgBb,EAAG,IAAK,OAChB,SAAba,EAAG5B,QACH4B,EAAK,YAAKA,EAAI,UAElB,MAAMZ,EAAS,CAAED,EAAGa,GACdP,EAAQ,CAAED,OAAMoI,YACtB,OAAO,IAAOvI,UAAU,KAAKD,EAAQK,O,iCC1DzC,oEAiCO,SAASoI,EAAKpK,EAAOW,EAAQ,WAChC,GAAc,cAAVA,EAAuB,CACvB,MAAM0J,EAAOD,EAAKpK,EAAO,WACnBsK,EAAO,YAAMtK,EAAO,WAC1B,OAAO,YAAQqK,EAAMC,GAEzB,MAAMC,EAAS,YAAmB,YAAcvK,GAAQW,GACxD,OAAO,IAAO6J,WAAWD,EAAQvK,EAAOW,K,iCCxC5C,kFA4CO,MAAM8J,EAAW,YAAG,CAAEC,UAR7B,SAAmB5H,EAAGC,GAClB,IAAIC,EAAK,YAAgBF,EAAG,IAAK,WAAY,qBACzCG,EAAK,YAAgBF,EAAG,IAAK,WAAY,sBAC5CC,EAAIC,GAAM,YAAeD,EAAIC,GAC9B,YAA2BD,EAAGhD,MAAOiD,EAAGjD,OACxC,MAAM2B,EAAS,CAAEmB,EAAGE,EAAID,EAAGE,GAC3B,OAAO,IAAOrB,UAAU,KAAUD,O,iCC1CtC,kFAuDO,MAAMgJ,EAAoB,YAAG,CAAEC,mBATtC,SAA4B9H,EAAGC,GAC3B,IAAIC,EAAK,YAAgBF,EAAG,IAAK,qBAC7BG,EAAK,YAAgBF,EAAG,IAAK,sBAChCC,EAAIC,GAAM,YAAeD,EAAIC,GAC9B,YAA2BD,EAAGhD,MAAOiD,EAAGjD,OACxC,MAAM2B,EAAS,CAAEmB,EAAGE,EAAID,EAAGE,GAE3B,OAAO,IAAOrB,UAAU,KAAmBD,EAD7B,Q,iCCpDlB,kEAuCO,MAAMkJ,EAAO,YAAG,CAAEC,MANzB,SAAepJ,EAAGqJ,EAAQ,GACtB,MACMpJ,EAAS,CAAED,EADN,YAAgBA,EAAG,IAAK,SAE7BM,EAAQ,CAAE+I,SAChB,OAAO,IAAOnJ,UAAU,KAAMD,EAAQK,O,iCCrC1C,kEAsCO,MAAMgJ,EAAQ,YAAG,CAAEC,OAL1B,SAAgBvJ,GACZ,MACMC,EAAS,CAAED,EADN,YAAgBA,EAAG,IAAK,UAEnC,OAAO,IAAOE,UAAU,KAAOD,O,gCCpCnC,qDAiCO,SAASuJ,EAAOC,EAAOxK,GAC1B,IAAM,YAAawK,IAAoB,WAAVxK,GAAuBqE,MAAMoG,QAAQD,KACpD,cAAVxK,EACA,MAAM,IAAIJ,MAAM,kFAGpB,GAAc,WAAVI,GAAsB,YAAawK,MACjCA,aAAiBE,YACnB,MAAM,IAAI9K,MAAM,6EAKpB,OAAO,YAAW4K,EAFJ,GACQ,GACyBxK,K,iCC9CnD,kEA0CO,MAAM2K,EAAQ,YAAG,CAAEC,OAN1B,SAAgB7J,EAAGqJ,GACf,MAEMpJ,EAAS,CAAED,EAFN,YAAgBA,EAAG,IAAK,SAEXqJ,MADT,YAAgBA,EAAO,QAAS,UAE/C,OAAO,IAAOnJ,UAAU,KAAOD,O,iCCxCnC,4DA0CO,SAAS6J,EAASjB,EAAQvK,EAAOW,GAEpC,GADA,YAAc4J,GACD,MAATvK,GAAkC,IAAjBA,EAAMQ,OACvB,MAAM,IAAID,MAAM,mDAEpB,MAAMkL,EAAgB,YAAWlB,EAAQ5J,GACzC,GAA6B,IAAzB8K,EAAcjL,QAAyC,IAAzBiL,EAAcjL,OAC5C,MAAM,IAAID,MAAM,oEAEpB,GAA6B,IAAzBkL,EAAcjL,QAAyB,MAATR,EAC9B,MAAM,IAAIO,MAAM,2EAGpB,OAAO,YAAWgK,EAAQvK,EAAOyL,EAAe9K,K,iCCvDpD,+EAqBO,MAAM+K,EAAwB,GAC9B,SAASC,EAAyBC,GACrC,OAAIA,GAAUF,EACHE,EAEJ,YAAeA,EAAQhI,KAAKiI,MAAMjI,KAAK1B,KAAK0J,O,gCC1BvD,kEA+DO,MAAMtK,EAAQ,YAAG,CAAEwK,OAT1B,SAAgBpK,EAAG0B,EAAOxC,GACtB,MAAM2B,EAAK,YAAgBb,EAAG,IAAK,QAAS,qBAC5C,GAAgB,IAAZa,EAAGnC,KACH,MAAM,IAAIG,MAAM,kCAEpB,MAAMoB,EAAS,CAAED,EAAGa,GACdP,EAAQ,CAAEoB,QAAOxC,QACvB,OAAO,IAAOgB,UAAU,KAAOD,EAAQK,O,iCC5CpC,SAAS+J,EAAeC,EAAQC,EAAaC,GAGhD,MAAO,CAFSA,GAAgC,iBAAXF,EAAsBA,EAASA,EAAO,IAC3DC,GAAiC,iBAAXD,EAAsBA,EAASA,EAAO,KAnBhF,mC,iCCAA,oEAgBO,MAAMG,EAAkB,mBAClBC,EAAa,oB,iCCjB1B,6CAMO,SAASC,EAAiB3K,EAAG4K,EAAiBvK,EAAO,GACxD,IAAIwK,EAAa,GACjB,GAAiC,iBAAtB,EACP,YAAO7K,EAAE1B,MAAM+B,GAAQuK,GAAoB,GAAG,IAAM,kDACpDC,EACI,IAAIvH,MAAMsH,GAAiBtF,KAAKtF,EAAE1B,MAAM+B,GAAQuK,OAEnD,CACD,MAAME,EAAYF,EAAgBG,QAAO,CAACC,EAAOvB,MAC9B,IAAXA,IACAuB,GAAS,GAENA,IACR,GACH,YAAOF,GAAa,GAAG,IAAM,4DAC7B,MAAMG,EAAWL,EAAgB3G,SAAS,GAG1C,IAAkB,IAAdgH,EAAiB,CACjB,MAAMC,EAAQN,EAAgBG,QAAO,CAAC3J,EAAGC,IAAMA,EAAI,EAAID,EAAIC,EAAID,IAC/DwJ,EAAgBK,GAAYjL,EAAE1B,MAAM+B,GAAQ6K,EAEhD,YAAOlL,EAAE1B,MAAM+B,KAAUuK,EAAgBG,QAAO,CAAC3J,EAAGC,IAAMD,EAAIC,KAAI,IAAM,gEACxEwJ,EAAaD,EAEjB,OAAOC,I,iCC/BX,kMAkBO,SAASM,EAA8BjB,EAAQkB,GAClD,IACIC,EADAC,GAAO,EASX,IAPIpB,GAAU,KACVmB,EAAMnB,EACNoB,GAAO,GAGPD,EAAM,YAAenB,EAAQhI,KAAKiI,MAAMjI,KAAK1B,KAAK0J,MAE9CoB,GACAD,EAAMD,GAAeC,IAAQnB,EAC7BoB,GAAO,EAGPD,EAAM,YAAenB,EAAQmB,EAAM,GAG3C,OAAOA,EAEJ,SAASrJ,EAAgBuJ,EAAQlL,EAAM+K,GAC1C,MAAMlF,EAAW,GACXxH,EAAO6M,EAAOzM,OACpB,IAAK,IAAI0M,EAAM,EAAGA,EAAM9M,EAAM8M,IACtBA,IAAQnL,EACR6F,EAASnE,KAAKwJ,EAAOC,IAGrBtF,EAASnE,KAAKqJ,GAGtB,OAAOlF,EAEJ,SAASuF,EAAyBzL,EAAGzB,EAAS8B,EAAMqL,GACvD,MAAMtM,EAAcb,EAAQD,MAAMQ,OAC5BsG,EAAQpF,EAAE1B,MAAMQ,OACtB,GAAkB,IAAd4M,IACIA,GAAatM,GAAesM,EAAYtM,GACxC,MAAM,IAAIP,MAAM,sCAAsCO,MAAgBA,eAAyBsM,KAMvG,GAHIA,EAAY,IACZA,GAAatM,GAEbsM,EAAYtG,EACZ,MAAM,IAAIvG,MAAM,cAAc6M,uCAChCtG,OAEF,GAAI/E,EAAOqL,EACP,MAAM,IAAI7M,MAAM,cAAc6M,0CAAkDrL,OAEpF,IAAK,IAAIb,EAAI,EAAGA,EAAIkM,IAAalM,EAC7B,GAAIQ,EAAE1B,MAAMkB,KAAOjB,EAAQD,MAAMkB,GAC7B,MAAM,IAAIX,MAAM,WAAWW,OAAOQ,EAAE1B,MAAMkB,uCAAuCA,OAAOjB,EAAQD,MAAMkB,OAG9G,MAAMmM,EAAU3L,EAAE1B,MAAM+B,GAClBkH,EAAc,GACpB,IAAIqE,EAAY,EACZC,EAAY,EACZtM,EAAY,EAChB,IAAK,IAAIC,EAAI,EAAGA,EAAIkM,IAAalM,EAC7B+H,EAAYxF,KAAK/B,EAAE1B,MAAMkB,IACzBoM,GAAa5L,EAAE1B,MAAMkB,GAEzB,IAAK,IAAIA,EAAIkM,EAAWlM,EAAIa,EAAMb,IAC9B+H,EAAYxF,KAAK/B,EAAE1B,MAAMkB,IACzBqM,GAAa7L,EAAE1B,MAAMkB,GAEzB,IAAK,IAAIA,EAAIkM,EAAWlM,EAAIJ,EAAaI,IACrC+H,EAAYxF,KAAKxD,EAAQD,MAAMkB,IAEnC,IAAK,IAAIA,EAAIa,EAAO,EAAGb,EAAI4F,EAAO5F,IAC9B+H,EAAYxF,KAAK/B,EAAE1B,MAAMkB,IACzBD,GAAaS,EAAE1B,MAAMkB,GAEzB,MAAO,CAAEoM,YAAWrM,YAAWsM,YAAWF,UAASpE,iB,mlCCzEhD,SAASuE,EAAaC,EAAc3K,EAAGC,GAC1C,MAAM2K,EAAO,EAAID,EAAe,EAC1BE,EAAY,IAAIC,aAAaH,GACnC,IAAK,IAAIvM,EAAI,EAAGA,EAAIuM,IAAgBvM,EAAG,CACnC,MAAM2M,EAAU,EAAMjK,KAAKkK,GAAK5M,GAAMuM,EAAeC,EAAO,GAC5DC,EAAUzM,GAAK4B,EAAIC,EAAIa,KAAKmK,IAAIF,GAEpC,OAAO,OAAAG,EAAA,GAASL,EAAW,WCKF,YAAG,CAAEM,eAHlC,SAAwBR,GACpB,OAAOD,EAAaC,EAAc,IAAM,QCErC,MAAMS,EAAa,YAAG,CAAEC,YAH/B,SAAqBV,GACjB,OAAOD,EAAaC,EAAc,GAAK,O,YC6BpC,MAAM,EAAQ,YAAG,CAAEW,OAtB1B,SAAgBC,EAAQC,EAAaC,EAAWC,GAAS,EAAOC,EAAW,GACvE,IAAIrI,EAAQ,EACZ,MAAMsI,EAAS,GACf,KAAOtI,EAAQkI,GAAeD,EAAOzN,MACjC8N,EAAOjL,KAAK,OAAAnC,EAAA,GAAM+M,EAAQjI,EAAOkI,IACjClI,GAASmI,EAEb,GAAIC,EACA,KAAOpI,EAAQiI,EAAOzN,MAAM,CACxB,MAAM+N,EAAUvI,EAAQkI,EAAeD,EAAOzN,KACxCgO,EAAM,OAAA3H,EAAA,GAAO,CACf,OAAA3F,EAAA,GAAM+M,EAAQjI,EAAOkI,EAAcK,GAAS,OAAA3H,EAAA,GAAK,CAAC2H,GAASF,KAE/DC,EAAOjL,KAAKmL,GACZxI,GAASmI,EAGjB,OAAsB,IAAlBG,EAAOlO,OACA,OAAAqO,EAAA,GAAS,GAAI,CAAC,EAAGP,IAErB,OAAAQ,EAAA,GAAQ,OAAA7H,EAAA,GAAOyH,GAAS,CAACA,EAAOlO,OAAQ8N,OCZ/B,YAAG,CAAES,MARzB,SAAeV,EAAQC,EAAaC,EAAWS,EAAWC,EAAWf,GJrB9D,IAA6B/C,EIsBf,MAAb6D,IJtB4B7D,EIuBImD,EAAhCU,EJrBGpL,KAAKiI,MAAMjI,KAAK+F,IAAI,EAAG/F,KAAKC,KAAKD,KAAKyE,IAAI8C,GAASvH,KAAKyE,IAAI,OIuBnE,MAAM6G,EAAe,EAAMb,EAAQC,EAAaC,GAC1CY,EAAiB,OAAAC,EAAA,GAAIF,EAAcD,EAASX,IAClD,OAAO,OAAAe,EAAA,GAAKF,EAAgBH,M,gQCgEzB,MAAMM,GAAsB,YAAG,CAAEC,qBAhCxC,SAA8BtP,EAASsK,EAAQiF,EAAYC,GACvD,MAAMC,EAAW,aAAgBzP,EAAS,UAAW,uBAC/C0P,EAAU,aAAgBpF,EAAQ,SAAU,uBAC5CqF,EAAc,aAAgBJ,EAAY,aAAc,uBACxDK,EAAgB,aAAgBJ,EAAc,eAAgB,sBAAuBE,EAAQhP,OACnG,GAAsB,IAAlB+O,EAAStP,KACT,MAAM,IAAIG,MAAM,0DACdmP,EAAS1P,SAEf,GAAqB,IAAjB2P,EAAQvP,KACR,MAAM,IAAIG,MAAM,gDAAgDoP,EAAQ3P,SAE5E,GAAyB,IAArB4P,EAAYxP,KACZ,MAAM,IAAIG,MAAM,qDAAqDqP,EAAY5P,SAErF,GAA2B,IAAvB6P,EAAczP,KACd,MAAM,IAAIG,MAAM,uDAAuDsP,EAAc7P,SAEzF,MAAM2B,EAAS,CACX1B,QAASyP,EACTnF,OAAQoF,EACRH,WAAYI,EACZH,aAAcI,GAEZC,EAAS,KAAOlO,UAAU,MAAqBD,GACrD,MAAO,CACHoO,cAAeD,EAAO,GACtBE,aAAcF,EAAO,GACrBG,kBAAmBH,EAAO,GAC1BI,gBAAiBJ,EAAO,OC7BzB,MAAMK,GAAgB,YAAG,CAAEC,eAtBlC,SAAwBC,EAAcpM,EAAYyD,GAC9C,MAAM4I,EAAgB,aAAgBD,EAAc,eAAgB,iBAC9DE,EAAc,aAAgBtM,EAAY,aAAc,iBACxDuM,EAAY,aAAgB9I,EAAU,WAAY,iBACxD,GAA2B,IAAvB4I,EAAclQ,KACd,MAAM,IAAIG,MAAM,gEACd+P,EAActQ,SAEpB,GAAyB,IAArBuQ,EAAYnQ,KACZ,MAAM,IAAIG,MAAM,qDAAqDgQ,EAAYvQ,SAErF,GAAuB,IAAnBwQ,EAAUpQ,KACV,MAAM,IAAIG,MAAM,mDAAmDiQ,EAAUxQ,SAEjF,MAAM2B,EAAS,CACX0O,aAAcC,EACdrM,WAAYsM,EACZ7I,SAAU8I,GAERV,EAAS,KAAOlO,UAAU,MAAeD,GAC/C,MAAO,CAAEoO,cAAeD,EAAO,GAAI7G,YAAa6G,EAAO,OCEpD,MAAMW,GAAoB,YAAG,CAAEC,mBAtBtC,SAA4BC,EAAM1Q,EAAS2Q,GACvC,MAAMC,EAAQ,aAAgBF,EAAM,OAAQ,qBACtCjB,EAAW,aAAgBzP,EAAS,UAAW,qBAC/C6Q,EAAc,aAAgBF,EAAY,aAAc,qBAC9D,GAAIC,EAAMzQ,KAAO,EACb,MAAM,IAAIG,MAAM,6DAEpB,GAAsB,IAAlBmP,EAAStP,KACT,MAAM,IAAIG,MAAM,4DACZmP,EAAS1P,SAEjB,GAAyB,IAArB8Q,EAAY1Q,KACZ,MAAM,IAAIG,MAAM,gEACZuQ,EAAY9Q,SAEpB,MAAM2B,EAAS,CACXgP,KAAME,EACN5Q,QAASyP,EACTkB,WAAYE,GAEhB,OAAO,KAAOlP,UAAU,MAAmBD,MCExC,MAAMoP,GAAmB,YAAG,CAAEC,kBAtBrC,SAA2BL,EAAM1Q,EAAS2Q,GACtC,MAAMC,EAAQ,aAAgBF,EAAM,OAAQ,oBACtCjB,EAAW,aAAgBzP,EAAS,UAAW,oBAC/C6Q,EAAc,aAAgBF,EAAY,aAAc,oBAC9D,GAAIC,EAAMzQ,KAAO,EACb,MAAM,IAAIG,MAAM,6DAEpB,GAAsB,IAAlBmP,EAAStP,KACT,MAAM,IAAIG,MAAM,2DACbmP,EAAS1P,SAEhB,GAAyB,IAArB8Q,EAAY1Q,KACZ,MAAM,IAAIG,MAAM,+DACbuQ,EAAY9Q,SAEnB,MAAM2B,EAAS,CACXgP,KAAME,EACN5Q,QAASyP,EACTkB,WAAYE,GAEhB,OAAO,KAAOlP,UAAU,MAAkBD,MCWvC,MAAMsP,GAAe,YAAG,CAAEC,cAxBjC,SAAuBP,EAAMQ,EAAYC,EAAWC,EAAaC,EAASC,EAAUC,EAAUC,GAC1F,MAAMZ,EAAQ,aAAgBF,EAAM,OAAQ,eAAgB,UAC5D,GAAoB,WAAhBE,EAAMlQ,MACN,MAAM,IAAIJ,MAAM,mCAEpB,GAA2B,IAAvBsQ,EAAM7Q,MAAMQ,OACZ,MAAM,IAAID,MAAM,+BAA+BsQ,EAAM7Q,SAEzD,MAAM0R,EAAc,aAAgBP,EAAY,aAAc,gBAC9D,GAA0B,UAAtBO,EAAY/Q,MACZ,MAAM,IAAIJ,MAAM,yCAEpB,MAAMyB,EAAQ,CACVoP,YACAC,cACAC,UACAC,WACAC,WACAC,0BAEE9P,EAAS,CAAEgP,KAAME,EAAOM,WAAYO,GACpC5B,EAAS,KAAOlO,UAAU,MAAcD,EAAQK,GACtD,MAAO,CAAE2P,OAAQ7B,EAAO,GAAI8B,aAAc9B,EAAO,OCjB9C,MAAM+B,GAAc,YAAG,CAAEC,aAdhC,SAAsB3O,EAAO4O,EAAWC,GAAY,GAChD,MAAMC,EAAS,aAAgB9O,EAAO,QAAS,cAAe,UACxD+O,EAAa,aAAgBH,EAAW,YAAa,cAAe,UAC1E,GAAoB,IAAhBE,EAAO7R,KACP,MAAM,IAAIG,MAAM,+CAA+C0R,EAAOjS,SAE1E,GAAwB,IAApBkS,EAAW9R,KACX,MAAM,IAAIG,MAAM,mDAAmD2R,EAAWlS,SAElF,MAAMgC,EAAQ,CAAEgQ,aACVrQ,EAAS,CAAEwB,MAAO8O,EAAQF,UAAWG,GACrCpC,EAAS,KAAOlO,UAAU,MAAaD,EAAQK,GACrD,MAAO,CAAE/B,QAAS6P,EAAO,GAAIvF,OAAQuF,EAAO,GAAI9P,MAAO8P,EAAO,OCd3D,MAAMqC,GAAyB,YAAG,CAAEC,wBAT3C,SAAiCjP,EAAOkP,GACpC,MAAMJ,EAAS,aAAgB9O,EAAO,QAAS,yBAA0B,UACnEnB,EAAQ,CAAEqQ,cAChB,GAAIA,GAAc,EACd,MAAM,IAAI9R,MAAM,wCAEpB,MAAMoB,EAAS,CAAEwB,MAAO8O,GACxB,OAAO,KAAOrQ,UAAU,MAAwBD,EAAQK,MCqMtD,IA9BFsQ,EAAA,EACAC,EAAA,EACAlD,EAAA,EACA1G,EAAA,EA2BU,CACV6J,cAAA,IACAC,sBAAA,IACAC,eAAA,IACAC,iBAAA,IACAC,cAAA,IACAC,kBAAA,IACAC,uBAAA,IACAC,2BAAA,IACAC,gCAAA,IACAC,wBAAA,IACAC,6BAAA,IACAC,YAAA,EACAC,YAAA,IAoCEC,IA7BF,IACA,IACAC,EAAA,EAaA,IACA,IACA,IACA,IACA,IACA,KACA,KACA,KACA,KAMW,CACXhE,uBACAa,iBACAM,qBACAM,sBAMEwC,GAAS,CACXtC,gBACAY,eACAM,4B,iCCnTJ,2DAkBO,MAAMqB,EACT,YAAYC,EAAcC,GACtBC,KAAKF,aAAeA,EACpBE,KAAKD,OAASA,EACA,MAAVA,IACAC,KAAKD,OAAS,IAAIE,GAG1B,cAAcC,EAAYlS,EAAQmS,GAC9B,IAAIC,EACJ,MAAMC,EAAsB,KACxBD,EAAUD,KAEd,IAAIG,EACJ,MAAM7N,EAAQ,QACd,GAAIuN,KAAKF,aAAaS,iBAClBD,EAAQN,KAAKF,aAAaU,KAAKH,OAE9B,CACDA,IACA,IAAK,MAAMtF,KAAUqF,EACjBrF,EAAO0F,WAEXH,EAAQI,QAAQC,QAAQ,CAAEC,SAAU,QAAanO,IAErD,GAAI,cAAMoO,QAAQ,gCACd,IAAK,IAAItT,EAAI,EAAGA,EAAI6S,EAAQvT,OAAQU,IAAK,CACrC,MAAMwN,EAASqF,EAAQ7S,GAGvBwN,EAAOiC,OAAO8D,MAAKC,IACfC,EAA0BD,EAAYhG,EAAO/N,MAAOkT,MAahE,MATsB,CAClBA,aACAE,UACApS,SACAiT,OAAQX,EAAMQ,MAAKI,GAAUA,EAAON,WACpCO,UAAWb,EAAMQ,MAAKI,GAAwC,MAA9BA,EAAOE,oBACnCF,EAAOE,sBACP,MAIZ,iBAAiBC,GACb,MAAM,WAAEnB,EAAU,QAAEE,EAAO,OAAEa,EAAM,OAAEjT,EAAM,UAAEmT,GAAcE,EAC3DjB,EAAQrR,SAAQoN,IACZuE,QAAQY,IAAI,CAACnF,EAAOa,OAAQiE,EAAQE,IAAYL,MAAKS,IACjDvB,KAAKD,OAAOyB,iBAAiBtB,EAAY/D,EAAQoF,EAAe,GAAIA,EAAe,GAAIvT,EAAQuT,EAAe,WAKvH,SAASP,EAA0BS,EAAMzU,EAAOkT,GACnD,GAAc,YAAVlT,EAEA,OAAO,EAEX,IAAK,IAAIO,EAAI,EAAGA,EAAIkU,EAAK5U,OAAQU,IAAK,CAClC,MAAMmU,EAAMD,EAAKlU,GACjB,GAAIoU,MAAMD,KAASE,SAASF,GAGxB,OADAjN,QAAQoN,KAAK,SAASH,uBAAyBxB,OACxC,EAGf,OAAO,EAEJ,MAAMD,EACT,iBAAiB6B,EAAM3F,EAAQsF,EAAMR,EAAQjT,EAAQmT,GACjD,MAAMX,EAAyB,iBAAXS,EAAsB,IAAc,GAAGA,MAAY,GACnEA,EAAc,MACZc,EAAa,IAAcD,EAAM,IACjCrV,EAAO0P,EAAO1P,KACdQ,EAAOkP,EAAOlP,KACdZ,EAAQ,IAAc8P,EAAO9P,MAAMsI,WAAY,IACrD,IAAIqN,EAAyB,GAC7B,IAAK,MAAMF,KAAQ9T,EAAQ,CACvB,MAAMwB,EAAQxB,EAAO8T,GACrB,GAAa,MAATtS,EAAe,CAGf,MAAMc,EAAad,EAAMnD,OAAS8P,EAAO9P,MACnCqD,EAAYY,EAAWzD,OAC7BmV,GACI,GAAGF,MAASpS,MAAcA,EAAY,EAAIY,EAAa,OAGnEmE,QAAQC,IAAI,KAAKqN,QAAiBvB,QAAW/T,MAASJ,QAAYY,QAAW+U,QAA6Bb,IAAa,mBAAoB,YAAa,aAAc,gBAAiB,eAAgB,uB,+BC5G/M,oDAwBO,SAASc,EAAG9B,GACf,MAAM+B,EAAOC,OAAOD,KAAK/B,GACzB,GAAoB,IAAhB+B,EAAKrV,OACL,MAAM,IAAID,MAEN,yGAAGsV,EAAKrV,gBAEhB,IAAIuV,EAASF,EAAK,GAClB,MAAMG,EAAKlC,EAAEiC,GAETA,EAAOE,SAAS,OAChBF,EAASA,EAAOG,UAAU,EAAGH,EAAOvV,OAAS,IAGjDuV,GApB2B,OAsB3B,MAAMI,EAAK,IAAIC,KACX,IAAOC,WAAWN,GAClB,IACI,MAAMjG,EAASkG,KAAMI,GAKrB,OAJI,YAAUtG,IACV1H,QAAQkO,MAAM,2CAElB,IAAOC,SAASzG,GACTA,EAEX,MAAO0G,GAEH,MADA,IAAOD,SAAS,MACVC,IAKd,OAFAV,OAAOW,eAAeN,EAAI,OAAQ,CAAEhL,MAAO4K,EAAQW,cAAc,IAE1DP,I,gCCzDX,4DAmCO,SAASnI,EAASzD,EAAQ5J,GAC7B,YAAc4J,GACd,MAAMkB,EAAgB,YAAWlB,EAAQ5J,GACzC,GAA6B,IAAzB8K,EAAcjL,OACd,MAAM,IAAID,MAAM,sDAGpB,OAAO,YAAWgK,EADJ,KACmBkB,EAAe9K,K,iCC1CpD,4CAqBO,MAAMgW,EACT,MAAMC,EAAMC,GACR,OAAOC,MAAMF,EAAMC,GAEvB,MACI,OAAOE,YAAYC,MAEvB,OAAOC,EAAMC,GACT,GAAiB,UAAbA,GAAqC,SAAbA,EACxB,MAAM,IAAI3W,MAAM,kDAAkD2W,KAKtE,OAHwB,MAApBvD,KAAKwD,cACLxD,KAAKwD,YAAc,IAAIC,aAEpBzD,KAAKwD,YAAYE,OAAOJ,GAEnC,OAAOK,EAAOJ,GACV,OAAO,IAAIK,YAAYL,GAAUM,OAAOF,IAGhD,GAAI,cAAMG,IAAI,cAAe,CACzB,cAAMC,YAAY,UAAW,IAAIf,GAEjC,IACI,IAA0BgB,gBAAgB,IAAoBC,WAAY,IAAI,KAElF,MAAOC,IAGP,IACI,IAA0BF,gBAAgB,IAAiBC,WAAY,IAAI,KAE/E,MAAOC,O,kCCrDX,uBAkBO,MAAMC,EAEI,IAAM,EAAQ,KAE/B,IAAIC,EAYG,MAAMC,EACT,cAEIrE,KAAKsE,KAAO,EAAQ,KAGpBtE,KAAKwD,YAAc,IAAIxD,KAAKsE,KAAKb,YAErC,MAAMR,EAAMsB,GACR,OAA0B,MAAtB,cAAMC,OAAOrB,MACN,cAAMqB,OAAOrB,MAAMF,EAAMsB,IAEjB,MAAfH,IACAA,EAAcD,KAEXC,EAAYnB,EAAMsB,IAE7B,MACI,MAAM/D,EAAOiE,EAAQC,SACrB,OAAiB,IAAVlE,EAAK,GAAYA,EAAK,GAAK,IAEtC,OAAO8C,EAAMC,GACT,GAAiB,UAAbA,GAAqC,SAAbA,EACxB,MAAM,IAAI3W,MAAM,sDAAsD2W,KAE1E,OAAOvD,KAAKwD,YAAYE,OAAOJ,GAEnC,OAAOK,EAAOJ,GACV,OAAqB,IAAjBI,EAAM9W,OACC,GAEJ,IAAImT,KAAKsE,KAAKV,YAAYL,GAAUM,OAAOF,IAGtD,cAAMG,IAAI,YACV,cAAMC,YAAY,OAAQ,IAAIM,K,kDCrElC,6CAiBA,SAASM,EAAsBC,EAAOC,EAAQC,EAAeC,EAAcC,EAAgBC,GACnE,MAAhBF,IACAA,EAAe,IAEG,MAAlBC,IACAA,EAAiB5S,OAAO8S,mBAER,MAAhBD,IACAA,EAAe,GAEnB,MAAME,EAAWP,EAAMvY,MAAM,GAS7B,OARAyY,EAAgB7U,KAAKmV,IAAIN,EAAeK,GACxC,IAAY,GAAKJ,GAAgBA,GAAgB,GAAG,IAAM,4CAA4CA,OACtG,IAA2B,IAAfH,EAAMnY,MAAY,IAAM,+CAA+CmY,EAAMnY,UACzF,IAA+B,IAAnBmY,EAAMvY,MAAM,IAAU,IAAM,oDAAoDuY,EAAMvY,MAAM,OACxG,IAA4B,IAAhBwY,EAAOpY,MAAY,IAAM,+BACrC,IAAYoY,EAAOxY,MAAM,KAAO8Y,GAAU,IAAM,sDAAsDA,cACvFN,EAAOxY,MAAM,OAC5B,IAAY,GAAK4Y,GAAgBA,GAAgB,GAAG,IAAM,4CAA4CA,OAC/F,CAAEH,gBAAeC,eAAcC,iBAAgBC,kB,gCCpC1D,kFA+DO,MAAMI,EAAQ,YAAG,CAAEC,OAlB1B,SAAgBC,EAAWpW,EAAGC,GAC1B,MAAMC,EAAK,YAAgBF,EAAG,IAAK,SAC7BG,EAAK,YAAgBF,EAAG,IAAK,SAC7BoW,EAAa,YAAgBD,EAAW,YAAa,QAAS,QAI9DE,EAAiB,YAA2B,YAA2BD,EAAWnZ,MAAOgD,EAAGhD,OAAQiD,EAAGjD,OAIvG2B,EAAS,CACXuX,UAJ0B,YAAYC,EAAYC,GAKlDC,EAJkB,YAAYrW,EAAIoW,GAKlCE,EAJkB,YAAYrW,EAAImW,IAMtC,OAAO,IAAOxX,UAAU,KAAQD,O,gCC7DpC,2DAmBO,SAAS6I,EAAWD,EAAQvK,EAAOyL,EAAe9K,GAIrD,GAHa,MAATA,IACAA,EAAQ,YAAW4J,IAET,cAAV5J,EACA,MAAM,IAAIJ,MAAM,oFAGpB,IAAK,YAAagK,KAAYvF,MAAMoG,QAAQb,IACtB,iBAAXA,GAAyC,kBAAXA,GACnB,iBAAXA,EACP,MAAM,IAAIhK,MAAM,4HAGpB,GAAa,MAATP,EAAe,CACf,YAAmCA,GACnC,MAAMuZ,EAAe,YAAcvZ,GAC7BwZ,EAAe,YAAc/N,GACnC,YAAO8N,IAAiBC,GAAc,IAAM,iCAAiCxZ,8BACtEuZ,oBAA+BC,MACtC,IAAK,IAAItY,EAAI,EAAGA,EAAIuK,EAAcjL,SAAUU,EAAG,CAC3C,MAAMuY,EAAWhO,EAAcvK,GACzBwY,EAAoBxY,IAAMuK,EAAcjL,OAAS,GACnDiZ,IAAa,YAAczZ,EAAMsB,MAAMJ,IAE3C,YAAOuK,EAAcvK,KAAOlB,EAAMkB,KAAOwY,GAAmB,IACxD,gDAAIjO,yCACMzL,UAUtB,OAPK,YAAauK,IAAYvF,MAAMoG,QAAQb,KACxCA,EAAS,CAACA,IAEdvK,EAAQA,GAASyL,EACjBlB,EAAmB,WAAV5J,EACL,uBAAa4J,EAAQ5J,GACrB,YAAQ4J,EAAQ,IAAI,GACjB,IAAOC,WAAWD,EAAQvK,EAAOW,K,gCCxD5C,yEA8CO,MAAMgZ,EAAQ,YAAG,CAAEC,OAV1B,SAAgBC,EAAS9X,EAAO,GAC5B,MAAM+X,EAAW,YAAqBD,EAAS,UAAW,QAAS,qBACnE,IAAYC,EAAStZ,QAAU,GAAG,IAAM,yCACpCsZ,EAAStZ,OAAS,GAClB,IAAYuB,GAAQ+X,EAAS,GAAG1Z,MAAM,IAAM,uCAEhD,MAAMuB,EAASmY,EACT9X,EAAQ,CAAED,QAChB,OAAO,IAAOH,UAAU,KAAMD,EAAQK,O,gCC5C1C,kEA6DO,MAAM+X,EAAQ,YAAG,CAAEC,OAN1B,SAAgBtY,EAAG4K,EAAiBvK,EAAO,GACvC,MACMJ,EAAS,CAAED,EADN,YAAgBA,EAAG,IAAK,UAE7BuY,EAAO,CAAE3N,kBAAiBvK,QAChC,OAAO,IAAOH,UAAU,KAAQD,EAAQsY,O,gCC3D5C,4DAgCO,SAASC,EAAMla,EAAOW,EAAQ,WACjC,GAAc,cAAVA,EAAuB,CACvB,MAAM0J,EAAO6P,EAAMla,EAAO,WACpBsK,EAAO4P,EAAMla,EAAO,WAC1B,OAAO,YAAQqK,EAAMC,GAEzB,MAAMC,EAAS,YAAoB,YAAcvK,GAAQW,GACzD,OAAO,IAAO6J,WAAWD,EAAQvK,EAAOW,K,gCCvC5C,kEAsCO,MAAMwZ,EAAO,YAAG,CAAEC,MALzB,SAAe1Y,GACX,MACMC,EAAS,CAAED,EADN,YAAgBA,EAAG,IAAK,SAEnC,OAAO,IAAOE,UAAU,KAAMD,O,gCCpClC,qDA8CO,SAAS0Y,EAAO9P,EAAQvK,EAAOW,GAClC,MAAM8K,EAAgB,YAAWlB,EAAQ5J,GACzC,OAAO,YAAW4J,EAAQvK,EAAOyL,EAAe9K,K,gCChDpD,4DA0CO,SAASkO,EAAStE,EAAQvK,EAAOW,GAEpC,GADA,YAAc4J,GACD,MAATvK,GAAkC,IAAjBA,EAAMQ,OACvB,MAAM,IAAID,MAAM,iDAEpB,MAAMkL,EAAgB,YAAWlB,EAAQ5J,GACzC,GAA6B,IAAzB8K,EAAcjL,QAAyC,IAAzBiL,EAAcjL,OAC5C,MAAM,IAAID,MAAM,kEAEpB,GAA6B,IAAzBkL,EAAcjL,QAAyB,MAATR,EAC9B,MAAM,IAAIO,MAAM,gFAGpB,OAAO,YAAWgK,EAAQvK,EAAOyL,EAAe9K,K,gCCvDpD,oDAqCO,SAAS2Z,EAAMlU,EAAOG,EAAMsE,EAAO,EAAGlK,EAAQ,WACjD,GAAa,IAATkK,EACA,MAAM,IAAItK,MAAM,8BAEpB,MAAMyB,EAAQ,CAAEoE,QAAOG,OAAMsE,OAAMlK,SACnC,OAAO,IAAOiB,UAAU,KAAO,GAAiBI,K,gCC1CpD,kEA2CO,MAAMuQ,EAAO,YAAG,CAAEgI,MANzB,SAAepX,GACX,YAAuB,cAAhBA,EAAMxC,OAAuB,IAChC,8DAAWwC,EAAMxC,WACrB,MAAMgB,EAAS,CAAEwB,SACjB,OAAO,IAAOvB,UAAU,KAAMD,O,gCCzClC,kEAwCO,MAAM0I,EAAO,YAAG,CAAEmQ,MALzB,SAAerX,GACX,MACMxB,EAAS,CAAEwB,MADF,YAAgBA,EAAO,QAAS,SAE/C,OAAO,IAAOvB,UAAU,KAAMD,O,+BCtClC,kEAoDO,MAAMmN,EAAU,YAAG,CAAE2L,SAN5B,SAAkB/Y,EAAG1B,GACjB,MACM2B,EAAS,CAAED,EADN,YAAgBA,EAAG,IAAK,UAAW,sBAExCM,EAAQ,CAAEhC,SAChB,OAAO,IAAO4B,UAAU,KAASD,EAAQK,O,gCClD7C,yEA0CO,MAAM0Y,EAAU,YAAG,CAAEC,SAP5B,SAAkBjZ,EAAGK,EAAO,GACxB,MAAMQ,EAAK,YAAgBb,EAAG,IAAK,UAAW,qBAC9C,IAAYK,IAASQ,EAAGvC,MAAMQ,QAAUuB,EAAOQ,EAAGvC,MAAMQ,QAAQ,IAAM,UAAUuB,iBAAoBQ,EAAGvC,MAAMQ,WAAW+B,EAAGvC,MAAMQ,YACjI,MAAMmB,EAAS,CAAEwJ,MAAO5I,GAClBP,EAAQ,CAAED,QAChB,OAAO,IAAOH,UAAU,KAAQD,EAAQK,O,gCCxC5C,kEA2CO,MAAMsQ,EAAM,YAAG,CAAEsI,KANxB,SAAczX,GACV,YAAuB,cAAhBA,EAAMxC,OAAuB,IAChC,6DAAWwC,EAAMxC,WACrB,MAAMgB,EAAS,CAAEwB,SACjB,OAAO,IAAOvB,UAAU,IAAKD,O,gCCzCjC,oIAgFO,MAAM0N,EAAO,YAAG,CAAEwL,MArCzB,SAAe1X,EAAO6L,GAClB,YAAuB,YAAhB7L,EAAMxC,OAAqB,IAAM,mDAAmDwC,EAAMxC,UACjG,IAAIkI,EAAqB1F,EAAMnD,MAAMmD,EAAMnD,MAAMQ,OAAS,GAC1D,MAAMsI,EAAQ3F,EAAMvC,KAAOiI,EAC3B,IAAIiS,EACJ,GAAiB,MAAb9L,GAAqBA,EAAYnG,EAAoB,CAErD,MAAMzF,EAAQD,EAAMnD,MAAMwC,KAAIyF,GAAK,IAC7BrH,EAAOuC,EAAMnD,MAAMwC,KAAIyF,GAAKA,IAClCrH,EAAKuC,EAAMnD,MAAMQ,OAAS,GAAKwO,EAC/B8L,EAAgB,YAAM3X,EAAOC,EAAOxC,GACpCiI,EAAqBmG,OAEpB,GAAiB,MAAbA,GAAqBA,EAAYnG,EAAoB,CAE1D,MAAMkS,EAAa5X,EAAMnD,MAAMwC,KAAIyF,GAAKA,IACxC8S,EAAW5X,EAAMnD,MAAMQ,OAAS,GAAKwO,EAAYnG,EACjDiS,EAAgB,YAAO,CAAC3X,EAAO,YAAM4X,IAAc5X,EAAMnD,MAAMQ,OAAS,GACxEqI,EAAqBmG,OAGrB8L,EAAgB3X,EAGpB,MAAM6X,EAAa,YAAUF,GACvB9R,EAAe,YAAQ,YAAQ8R,EAAeE,GAAa,CAAClS,EAAOD,IACnEE,EAAM,YAAIC,GAEViS,EAAOrX,KAAKiI,MAAMhD,EAAqB,GAAK,EAC5CqS,EAAa,YAAKnS,GAClBoS,EAAa,YAAKpS,GAClBqS,EAAuB,YAAMF,EAAY,CAACD,EAAMpS,EAAqBoS,GAAOC,EAAWlb,MAAMQ,OAAS,GACtG6a,EAAuB,YAAMF,EAAY,CAACF,EAAMpS,EAAqBoS,GAAOE,EAAWnb,MAAMQ,OAAS,GACtGyI,EAAc6R,EAAc9a,MAAMsB,QAExC,OADA2H,EAAY6R,EAAc9a,MAAMQ,OAAS,GAAKya,EACvC,YAAQ,YAAQG,EAAqB,GAAIC,EAAqB,IAAKpS,O,gCC9E9E,6IA6EA,SAASqS,EAAS5Z,EAAG6Z,EAAGxZ,EAAO,MAC3B,GAAe,IAAXL,EAAEtB,KACF,OAAO,YAAIsB,GAGf,GAAe,IAAXA,EAAEtB,MAAuB,OAAT2B,EAChB,OAAOuZ,EAAS,YAAQ5Z,EAAG,EAAE,IAAK6Z,EAAGxZ,GAGzC,GAAe,IAAXL,EAAEtB,MAA8B,iBAAT2B,GACvBiD,MAAMoG,QAAQrJ,IAAyB,IAAhBA,EAAKvB,OAAc,CAC1C,GAAU,IAAN+a,EACA,OAAO,YAAI,YAAI7Z,GAAIK,GAEvB,GAAIwZ,IAAMC,IACN,OAAO,YAAI,YAAI9Z,GAAIK,GAEvB,GAAIwZ,KAAOC,IACP,OAAO,YAAI,YAAI9Z,GAAIK,GAEvB,GAAU,cAANwZ,GAA2B,IAANA,EAErB,OAAO,YAAK,YAAI,YAAI,YAAI7Z,GAAI,YAAO,EAAG,UAAWK,IAErD,MAAM,IAAIxB,MAAM,qCAAqCgb,KAGzD,GAAIvW,MAAMoG,QAAQrJ,IAAyB,IAAhBA,EAAKvB,OAAc,CAC1C,GAAU,IAAN+a,EACA,OAAO,YAAI,YAAI,YAAI7Z,GAAIK,EAAK,IAAKA,EAAK,GAAK,GAE/C,GAAIwZ,IAAMC,IACN,OAAO,YAAI,YAAI,YAAI9Z,GAAIK,EAAK,IAAKA,EAAK,IAE1C,GAAIwZ,KAAOC,IACP,OAAO,YAAI,YAAI,YAAI9Z,GAAIK,EAAK,IAAKA,EAAK,IAE1C,GAAU,QAANwZ,GAAqB,cAANA,EAEf,OAAO,YAAK,YAAI,YAAO7Z,GAAIK,IAE/B,MAAM,IAAIxB,MAAM,qCAAqCgb,KAEzD,MAAM,IAAIhb,MAAM,gCAAgCwB,KAE7C,MAAM0Z,EAAO,YAAG,CAAEC,MAvDzB,SAAeha,EAAGia,EAAM,YAAa5Z,EAAO,KAAMoI,GAAW,GAEzD,MAAMsR,EAAOH,EADb5Z,EAAI,YAAgBA,EAAG,IAAK,QACHia,EAAK5Z,GAC9B,IAAI6Z,EAAgBH,EAAKzb,MACzB,GAAImK,EAAU,CACV,MAAM3G,EAAO,YAAezB,EAAML,EAAE1B,OACpC4b,EAAgB,IAA+BH,EAAKzb,MAAOwD,GAE/D,OAAO,YAAQiY,EAAMG,O,gCC3EzB,2DAoCO,MAAMC,EAAS,YAAG,CAAEC,QAL3B,SAAiBpa,GACb,MAAMa,EAAK,YAAgBb,EAAG,IAAK,UAEnC,OAAO,IAAOE,UAAU,SAAU,CAAEF,EAAGa,GADzB,Q,gCCjClB,yEAsDO,MAAMwZ,EAAO,YAAG,CAAEC,MARzB,SAAeta,EAAGua,GACd,MAAM1Z,EAAK,YAAgBb,EAAG,IAAK,OAAQ,qBAC3C,IAAYa,EAAGnC,OAAS6b,EAAKzb,QAAQ,IAAM,qCAAqC+B,EAAGnC,kCAClD6b,OACjC,MAAMta,EAAS,CAAED,EAAGa,GACdP,EAAQ,CAAEia,QAChB,OAAO,IAAOra,UAAU,KAAMD,EAAQK","file":"js/bundle~bundle~58c2b9c4.4df25162.js","sourcesContent":["import { computeStrides, sizeFromShape } from '../util';\n/**\n * Check whether updates.shape = indices.shape[:batchDim] +\n * shape[sliceDim:]\n *\n * @param x The input tensor.\n */\nexport function validateUpdateShape(shape, indices, updates) {\n    const sliceDim = (indices.rank > 1) ? indices.shape[indices.rank - 1] : 1;\n    const batchDim = (indices.rank > 1) ? indices.rank - 1 : 1;\n    const shapeError = 'Must have updates.shape = indices.shape[:batchDim] + ' +\n        `shape[sliceDim:], got updates.shape: ${updates.shape}` +\n        `, indices.shape: ${indices.shape}, shape: ${shape}` +\n        `, sliceDim: ${sliceDim}, and batchDim: ${batchDim}.`;\n    if (updates.rank < batchDim) {\n        throw new Error(shapeError + ` update.rank < ${batchDim}. `);\n    }\n    if (shape.length < sliceDim + (updates.rank - batchDim)) {\n        throw new Error(shapeError +\n            ` Output shape length < ${sliceDim + (updates.rank - batchDim)}`);\n    }\n    if (updates.rank !== batchDim + shape.length - sliceDim) {\n        throw new Error(shapeError + ` update.rank != ${batchDim + shape.length - sliceDim}`);\n    }\n    for (let d = 0; d < batchDim; ++d) {\n        if (updates.shape[d] !== indices.shape[d]) {\n            throw new Error(shapeError +\n                ` updates.shape[${d}] (${updates.shape[d]}) != indices.shape[${d}] (${indices.shape[d]}).`);\n        }\n    }\n    for (let d = 0; d < updates.rank - batchDim; ++d) {\n        if (updates.shape[d + batchDim] !== shape[d + sliceDim]) {\n            throw new Error(shapeError +\n                ` updates.shape[${d + batchDim}] (${updates.shape[d + batchDim]}) != shape[${d + batchDim}] (${shape[d + batchDim]})`);\n        }\n    }\n}\n/**\n * Validate scatter nd inputs.\n *\n * @param update The tensor contains the update values.\n * @param indices The tensor contains the indices for the update values.\n * @param shape The shape of the output tensor.\n */\nexport function validateInput(updates, indices, shape) {\n    if (indices.rank < 1) {\n        throw new Error('tf.scatterND() expects the indices to be rank 1 or higher,' +\n            ` but the rank was ${indices.rank}.`);\n    }\n    if (updates.rank < 1) {\n        throw new Error('tf.scatterND() expects the updates to be rank 1 or higher,' +\n            ` but the rank was ${updates.rank}.`);\n    }\n    if (indices.dtype !== 'int32') {\n        throw new Error(`The dtype of 'indices' should be int32, but got dtype: ${indices.dtype}`);\n    }\n    if (shape.length < 1) {\n        throw new Error(`Output rank must be greater or equal to 1, but got shape: ${shape}`);\n    }\n    if (shape.length === 0) {\n        if (indices.size === 0) {\n            throw new Error(`Indices specified for empty output. indices shape: ${indices.shape}`);\n        }\n        if (updates.size === 0) {\n            throw new Error(`Updates specified for empty output. updates shape: ${updates.shape}`);\n        }\n    }\n    validateUpdateShape(shape, indices, updates);\n}\n/**\n * Calculate the shape information for the output.\n *\n * @param update The tensor contains the update values.\n * @param indices The tensor contains the indices for the update values.\n * @param shape The shape of the output tensor.\n *\n * @returns ScatterShapeInfo\n */\nexport function calculateShapes(updates, indices, shape) {\n    // Calculate the number of dimensions in indices\n    const indicesRank = indices.shape.length;\n    const sliceRank = (indicesRank > 1) ? indices.shape[indicesRank - 1] : 1;\n    // Calculate the number of elements that make up each slice of our updated\n    // tensor. This allows us to work with flattened tensors and copy over whole\n    // slices at a time.\n    const totalNd = shape.length;\n    let sliceSize = 1;\n    for (let i = sliceRank; i < totalNd; ++i) {\n        sliceSize *= shape[i];\n    }\n    const safeSliceDim = (sliceRank < 1) ? 1 : sliceRank;\n    const numUpdates = sizeFromShape(indices.shape) / safeSliceDim;\n    const strides = [...computeStrides(shape.slice(0, sliceRank)), 1];\n    const outputSize = sizeFromShape(shape);\n    return { sliceRank, numUpdates, sliceSize, strides, outputSize };\n}\n//# sourceMappingURL=scatter_nd_util.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { ZerosLike } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Creates a `tf.Tensor` with all elements set to 0 with the same shape as the\n * given tensor.\n *\n * ```js\n * const x = tf.tensor([1, 2]);\n * tf.zerosLike(x).print();\n * ```\n *\n * @param x The tensor of required shape.\n *\n * @doc {heading: 'Tensors', subheading: 'Creation'}\n */\nfunction zerosLike_(x) {\n    const $x = convertToTensor(x, 'x', 'zerosLike');\n    const inputs = { x: $x };\n    return ENGINE.runKernel(ZerosLike, inputs);\n}\nexport const zerosLike = op({ zerosLike_ });\n//# sourceMappingURL=zeros_like.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Reverse } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Reverses a `tf.Tensor` along a specified axis.\n *\n * Also available are stricter rank-specific methods that assert that `x` is\n * of the given rank:\n *   - `tf.reverse1d`\n *   - `tf.reverse2d`\n *   - `tf.reverse3d`\n *   - `tf.reverse4d`\n *\n * Except `tf.reverse1d` (which does not have axis param), all methods have\n * same signature as this method.\n *\n * ```js\n * const x = tf.tensor1d([1, 2, 3, 4]);\n *\n * x.reverse().print();\n * ```\n *\n * ```js\n * const x = tf.tensor2d([1, 2, 3, 4], [2, 2]);\n *\n * const axis = 1;\n * x.reverse(axis).print();\n * ```\n * @param x The input tensor to be reversed.\n * @param axis The set of dimensions to reverse. Must be in the\n *     range [-rank(x), rank(x)). Defaults to all axes.\n *\n * @doc {heading: 'Tensors', subheading: 'Slicing and Joining'}\n */\nfunction reverse_(x, axis) {\n    const $x = convertToTensor(x, 'x', 'reverse');\n    const inputs = { x: $x };\n    const attrs = { dims: axis };\n    return ENGINE.runKernel(Reverse, inputs, attrs);\n}\nexport const reverse = op({ reverse_ });\n//# sourceMappingURL=reverse.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Sqrt } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes square root of the input `tf.Tensor` element-wise: `y = sqrt(x)`\n *\n * ```js\n * const x = tf.tensor1d([1, 2, 4, -1]);\n *\n * x.sqrt().print();  // or tf.sqrt(x)\n * ```\n * @param x The input tensor.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction sqrt_(x) {\n    const $x = convertToTensor(x, 'x', 'sqrt');\n    const inputs = { x: $x };\n    return ENGINE.runKernel(Sqrt, inputs);\n}\nexport const sqrt = op({ sqrt_ });\n//# sourceMappingURL=sqrt.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Transpose } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport * as util from '../util';\nimport { op } from './operation';\n/**\n * Transposes the `tf.Tensor`. Permutes the dimensions according to `perm`.\n *\n * The returned `tf.Tensor`'s dimension `i` will correspond to the input\n * dimension `perm[i]`. If `perm` is not given, it is set to `[n-1...0]`,\n * where `n` is the rank of the input `tf.Tensor`. Hence by default, this\n * operation performs a regular matrix transpose on 2-D input `tf.Tensor`s.\n *\n * ```js\n * const a = tf.tensor2d([1, 2, 3, 4, 5, 6], [2, 3]);\n *\n * a.transpose().print();  // or tf.transpose(a)\n * ```\n *\n * @param x The tensor to transpose.\n * @param perm The permutation of the dimensions of a.\n *\n * @doc {heading: 'Operations', subheading: 'Matrices'}\n */\nfunction transpose_(x, perm) {\n    const $x = convertToTensor(x, 'x', 'transpose');\n    if (perm == null) {\n        perm = $x.shape.map((s, i) => i).reverse();\n    }\n    util.assert($x.rank === perm.length, () => `Error in transpose: rank of input ${$x.rank} ` +\n        `must match length of perm ${perm}.`);\n    perm.forEach(axis => {\n        util.assert(axis >= 0 && axis < $x.rank, () => `All entries in 'perm' must be between 0 and ${$x.rank - 1}` +\n            ` but got ${perm}`);\n    });\n    if ($x.rank <= 1) {\n        return $x.clone();\n    }\n    const inputs = { x: $x };\n    const attrs = { perm };\n    return ENGINE.runKernel(Transpose, inputs, attrs);\n}\nexport const transpose = op({ transpose_ });\n//# sourceMappingURL=transpose.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Sub } from '../kernel_names';\nimport { makeTypesMatch } from '../tensor_util';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Subtracts two `tf.Tensor`s element-wise, A - B. Supports broadcasting.\n *\n * ```js\n * const a = tf.tensor1d([10, 20, 30, 40]);\n * const b = tf.tensor1d([1, 2, 3, 4]);\n *\n * a.sub(b).print();  // or tf.sub(a, b)\n * ```\n *\n * ```js\n * // Broadcast subtract a with b.\n * const a = tf.tensor1d([10, 20, 30, 40]);\n * const b = tf.scalar(5);\n *\n * a.sub(b).print();  // or tf.sub(a, b)\n * ```\n * @param a The first `tf.Tensor` to subtract from.\n * @param b The second `tf.Tensor` to be subtracted. Must have the same dtype as\n * `a`.\n *\n * @doc {heading: 'Operations', subheading: 'Arithmetic'}\n */\nfunction sub_(a, b) {\n    let $a = convertToTensor(a, 'a', 'sub');\n    let $b = convertToTensor(b, 'b', 'sub');\n    [$a, $b] = makeTypesMatch($a, $b);\n    const inputs = { a: $a, b: $b };\n    return ENGINE.runKernel(Sub, inputs);\n}\nexport const sub = op({ sub_ });\n//# sourceMappingURL=sub.js.map","/**\n * @license\n * Copyright 2017 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport * as util from '../util';\nexport function assertParamsValid(input, begin, size) {\n    const inputRank = input.shape.length;\n    util.assert(inputRank === begin.length, () => `Error in slice${inputRank}D: Length of begin ${begin} must ` +\n        `match the rank of the array (${inputRank}).`);\n    util.assert(inputRank === size.length, () => `Error in slice${inputRank}D: Length of size ${size} must ` +\n        `match the rank of the array (${inputRank}).`);\n    for (let i = 0; i < inputRank; ++i) {\n        util.assert(begin[i] + size[i] <= input.shape[i], () => `Error in slice${inputRank}D: begin[${i}] + size[${i}] ` +\n            `(${begin[i] + size[i]}) would overflow input.shape[${i}] (${input.shape[i]})`);\n    }\n}\n/** Converts a binary mask to an array of axes. Used in stridedSlice(). */\nexport function maskToAxes(mask) {\n    const axes = [];\n    let axis = 0;\n    while (mask > 0) {\n        if (mask & 1) {\n            axes.push(axis);\n        }\n        mask /= 2;\n        axis++;\n    }\n    return axes;\n}\n/** Computes the output shape given the strided slice params. */\nexport function computeOutShape(begin, end, strides) {\n    const size = [];\n    for (let axis = 0; axis < begin.length; axis++) {\n        size[axis] = Math.ceil((end[axis] - begin[axis]) / strides[axis]);\n    }\n    return size;\n}\n// Creates full selection at the elided dimensions. If the dimension matches\n// the ellipsis mask, override the current stride value. Otherwise, insert.\nexport function stridesWithElidedDims(strides, ellipsisInsertionIndex, numElidedAxes, inputShape) {\n    const newStrides = [...strides];\n    for (let i = newStrides.length; i < inputShape.length; i++) {\n        newStrides.push(1);\n    }\n    for (let i = 0; i < numElidedAxes; i++) {\n        if (i === 0) {\n            newStrides[ellipsisInsertionIndex] = 1;\n        }\n        else {\n            newStrides.splice(ellipsisInsertionIndex, 0 /* num elements to delete */, 1 /* element to add */);\n            newStrides.pop();\n        }\n    }\n    return newStrides;\n}\nfunction unnormalizeAxis(ellipsisInsertionIndex, numElidedAxes, normalizedAxis) {\n    if (normalizedAxis <= ellipsisInsertionIndex) {\n        return normalizedAxis;\n    }\n    return normalizedAxis - (numElidedAxes - 1);\n}\nfunction getElidedAxes(numElidedAxes, ellipsisInsertionIndex) {\n    const elidedAxes = [];\n    for (let i = 0; i < numElidedAxes; i++) {\n        elidedAxes.push(ellipsisInsertionIndex + i);\n    }\n    return elidedAxes;\n}\n// Normalize the start, end and strides.\nexport function getNormalizedAxes(inputShape, ellipsisAxes, numInterpolatedAxes, begin, end, strides, beginMask, endMask, ellipsisMask) {\n    const inputRank = inputShape.length;\n    let normalizedBegin = new Array(inputRank), normalizedEnd = new Array(inputRank), normalizedStrides = new Array(inputRank);\n    if (ellipsisAxes.length && numInterpolatedAxes > 0) {\n        const fullIndex = ellipsisAxes[0];\n        // The ellipsis applies to the masked index as well as any dimensions\n        // that are interpolated.\n        const numElidedAxes = numInterpolatedAxes + 1;\n        normalizedBegin = startIndicesWithElidedDims(beginMask, fullIndex, numElidedAxes, begin, inputShape);\n        normalizedEnd = stopIndicesWithElidedDims(endMask, fullIndex, numElidedAxes, end, inputShape);\n        normalizedStrides =\n            stridesWithElidedDims(strides, fullIndex, numElidedAxes, inputShape);\n    }\n    else {\n        for (let axis = 0; axis < inputRank; axis++) {\n            normalizedBegin[axis] = startForAxis(beginMask, begin, strides, inputShape, axis, ellipsisMask);\n            normalizedEnd[axis] =\n                stopForAxis(endMask, end, strides, inputShape, axis, ellipsisMask);\n            normalizedStrides[axis] = stridesForAxis(strides, axis, ellipsisMask);\n        }\n    }\n    return {\n        begin: normalizedBegin,\n        end: normalizedEnd,\n        strides: normalizedStrides\n    };\n}\n// Creates full selection at the elided dimensions. If the dimension matches\n// the ellipsis mask, override the current start value. Otherwise, insert.\nexport function startIndicesWithElidedDims(beginMask, ellipsisInsertionIndex, numElidedAxes, originalBegin, inputShape) {\n    const newIndices = [...inputShape];\n    const elidedAxes = getElidedAxes(numElidedAxes, ellipsisInsertionIndex);\n    for (let axis = 0; axis < newIndices.length; axis++) {\n        if (elidedAxes.indexOf(axis) > -1) {\n            newIndices[axis] = 0;\n        }\n        else {\n            const originalAxis = unnormalizeAxis(ellipsisInsertionIndex, numElidedAxes, axis);\n            let originalValue = originalBegin[originalAxis];\n            if (beginMask & 1 << originalAxis) {\n                originalValue = 0;\n            }\n            newIndices[axis] = originalValue;\n        }\n    }\n    return newIndices;\n}\n// Creates full selection at the elided dimensions. If the dimension matches\n// the ellipsis mask, override the current stop value. Otherwise, insert.\nexport function stopIndicesWithElidedDims(endMask, ellipsisInsertionIndex, numElidedAxes, originalEnd, inputShape) {\n    const newIndices = [...inputShape];\n    const elidedAxes = getElidedAxes(numElidedAxes, ellipsisInsertionIndex);\n    for (let axis = 0; axis < newIndices.length; axis++) {\n        if (elidedAxes.indexOf(axis) > -1) {\n            newIndices[axis] = Number.MAX_SAFE_INTEGER;\n        }\n        else {\n            const originalAxis = unnormalizeAxis(ellipsisInsertionIndex, numElidedAxes, axis);\n            let originalValue = originalEnd[originalAxis];\n            if (endMask & 1 << originalAxis) {\n                originalValue = Number.MAX_SAFE_INTEGER;\n            }\n            newIndices[axis] = originalValue;\n        }\n    }\n    for (let i = 0; i < newIndices.length; i++) {\n        // Handle negative indices\n        const axisSize = inputShape[i];\n        if (newIndices[i] < 0) {\n            newIndices[i] += axisSize;\n        }\n        newIndices[i] = util.clamp(0, newIndices[i], inputShape[i]);\n    }\n    return newIndices;\n}\nexport function stridesForAxis(strides, axis, ellipsisMask) {\n    let stride = strides[axis];\n    if (ellipsisMask & (1 << axis) || stride == null) {\n        stride = 1;\n    }\n    return stride;\n}\nexport function startForAxis(beginMask, startIndices, strides, inputShape, axis, ellipsisMask) {\n    // Begin with the specified index\n    let start = startIndices[axis];\n    const stride = strides[axis] || 1;\n    // Check the axis bit from right of masked axes, or the begin index is not set\n    // for the axis.\n    if (beginMask & 1 << axis || ellipsisMask & 1 << axis || start == null) {\n        if (stride > 0) {\n            // Forward iteration - use the first element. These values will get\n            // clamped below (Note: We could have set them to 0 and axis_size-1, but\n            // use lowest() and max() to maintain symmetry with StopForAxis())\n            start = Number.MIN_SAFE_INTEGER;\n        }\n        else {\n            // Backward iteration - use the last element.\n            start = Number.MAX_SAFE_INTEGER;\n        }\n    }\n    // Handle negative indices\n    const axisSize = inputShape[axis];\n    if (start < 0) {\n        start += axisSize;\n    }\n    // Clamping\n    start = util.clamp(0, start, axisSize - 1);\n    return start;\n}\nexport function stopForAxis(endMask, stopIndices, strides, inputShape, axis, ellipsisMask) {\n    // Begin with the specified index\n    let stop = stopIndices[axis];\n    const stride = strides[axis] || 1;\n    // Check the axis bit from right of masked axes, or if the stop index is not\n    // set for this axis.\n    if (endMask & (1 << axis) || ellipsisMask & (1 << axis) || stop == null) {\n        if (stride > 0) {\n            // Forward iteration - use the last element. These values will get\n            // clamped below\n            stop = Number.MAX_SAFE_INTEGER;\n        }\n        else {\n            // Backward iteration - use the first element.\n            stop = Number.MIN_SAFE_INTEGER;\n        }\n    }\n    // Handle negative indices\n    const axisSize = inputShape[axis];\n    if (stop < 0) {\n        stop += axisSize;\n    }\n    // Clamping\n    // Because the end index points one past the last element, we need slightly\n    // different clamping ranges depending on the direction.\n    if (stride > 0) {\n        // Forward iteration\n        stop = util.clamp(0, stop, axisSize);\n    }\n    else {\n        // Backward iteration\n        stop = util.clamp(-1, stop, axisSize - 1);\n    }\n    return stop;\n}\n/**\n * Returns true if the slice occupies a continous set of elements in the\n * 'flat' space.\n */\nexport function isSliceContinous(shape, begin, size) {\n    // Index of the first axis that has size > 1.\n    let firstNonOneAxis = size.length;\n    for (let i = 0; i < size.length; i++) {\n        if (size[i] > 1) {\n            firstNonOneAxis = i;\n            break;\n        }\n    }\n    for (let i = firstNonOneAxis + 1; i < size.length; i++) {\n        if (begin[i] > 0 || size[i] !== shape[i]) {\n            return false;\n        }\n    }\n    return true;\n}\nexport function computeFlatOffset(begin, strides) {\n    let flatOffset = begin.length > 0 ? begin[begin.length - 1] : 1;\n    for (let i = 0; i < begin.length - 1; i++) {\n        flatOffset += begin[i] * strides[i];\n    }\n    return flatOffset;\n}\nexport function parseSliceParams(x, begin, size) {\n    // The following logic allows for more ergonomic calls.\n    let begin_;\n    const xRank = x.shape.length;\n    if (typeof begin === 'number') {\n        begin_ = [begin, ...new Array(xRank - 1).fill(0)];\n    }\n    else if (begin.length < xRank) {\n        begin_ = begin.concat(new Array(xRank - begin.length).fill(0));\n    }\n    else {\n        begin_ = begin.slice();\n    }\n    begin_.forEach(d => {\n        util.assert(d !== -1, () => 'slice() does not support negative begin indexing.');\n    });\n    let size_;\n    if (size == null) {\n        size_ = new Array(xRank).fill(-1);\n    }\n    else if (typeof size === 'number') {\n        size_ = [size, ...new Array(xRank - 1).fill(-1)];\n    }\n    else if (size.length < xRank) {\n        size_ = size.concat(new Array(xRank - size.length).fill(-1));\n    }\n    else {\n        size_ = size;\n    }\n    size_ = size_.map((d, i) => {\n        if (d >= 0) {\n            return d;\n        }\n        else {\n            util.assert(d === -1, () => `Negative size values should be exactly -1 but got ` +\n                `${d} for the slice() size at index ${i}.`);\n            return x.shape[i] - begin_[i];\n        }\n    });\n    return [begin_, size_];\n}\nexport function sliceInfo(xShape, begin, end, strides, beginMask, endMask, ellipsisMask, newAxisMask, shrinkAxisMask) {\n    // make a copy because it may be modified further down.\n    let $begin = begin.slice();\n    let $end = end.slice();\n    let $strides = strides;\n    if (strides == null) {\n        $strides = new Array($begin.length);\n    }\n    const ellipsisAxes = maskToAxes(ellipsisMask);\n    if (ellipsisAxes.length > 1) {\n        throw new Error('Multiple ellipses in slice is not allowed.');\n    }\n    if (ellipsisMask !== 0 && newAxisMask !== 0) {\n        throw new Error('Using both ellipsisMask and newAxisMask is not yet supported.');\n    }\n    if (ellipsisMask !== 0 && shrinkAxisMask !== 0) {\n        throw new Error('Using both ellipsisMask and shrinkAxisMask is not yet supported.');\n    }\n    const numInterpolatedAxes = xShape.length - $begin.length;\n    // Expand the dims of x based on the newAxisMask.\n    const expandAxes = maskToAxes(newAxisMask);\n    const newShape = xShape.slice();\n    expandAxes.forEach(axis => {\n        $begin[axis] = 0;\n        $end[axis] = 1;\n        newShape.splice(axis, 0, 1);\n    });\n    const { begin: normalizedBegin, end: normalizedEnd, strides: normalizedStrides } = getNormalizedAxes(newShape, ellipsisAxes, numInterpolatedAxes, $begin, $end, $strides, beginMask, endMask, ellipsisMask);\n    $begin = normalizedBegin;\n    $end = normalizedEnd;\n    $strides = normalizedStrides;\n    const shrinkAxes = maskToAxes(shrinkAxisMask);\n    // Adjust the ends based on the shrink mask.\n    shrinkAxes.forEach(axis => {\n        $end[axis] = $begin[axis] + 1;\n        $strides[axis] = 1;\n    });\n    // Figure out the output shape.\n    const size = computeOutShape($begin, $end, $strides);\n    // Remove the axes based on shrinkMask.\n    const outShape = size.filter((_, axis) => shrinkAxes.indexOf(axis) === -1);\n    const nonStrided = $strides.every(v => v === 1);\n    return { nonStrided, $begin, $end, $strides, size, newShape, outShape };\n}\n//# sourceMappingURL=slice_util.js.map","/**\n * @license\n * Copyright 2020 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n/**\n * Prints information about the `tf.Tensor` including its data.\n *\n * ```js\n * const verbose = true;\n * tf.tensor2d([1, 2, 3, 4], [2, 2]).print(verbose);\n * ```\n * @param x The tensor to be printed.\n * @param verbose Whether to print verbose information about the ` Tensor`,\n * including dtype and size.\n *\n * @doc {heading: 'Tensors', subheading: 'Creation'}\n */\nexport function print(x, verbose = false) {\n    console.log(x.toString(verbose));\n}\n//# sourceMappingURL=print.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Sigmoid } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes sigmoid element-wise, `1 / (1 + exp(-x))`\n *\n * ```js\n * const x = tf.tensor1d([0, -1, 2, -3]);\n *\n * x.sigmoid().print();  // or tf.sigmoid(x)\n * ```\n * @param x The input tensor.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction sigmoid_(x) {\n    const $x = convertToTensor(x, 'x', 'sigmoid');\n    const inputs = { x: $x };\n    return ENGINE.runKernel(Sigmoid, inputs);\n}\nexport const sigmoid = op({ sigmoid_ });\n//# sourceMappingURL=sigmoid.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { convertToTensor } from '../tensor_util_env';\nimport { squeezeShape } from '../util';\nimport { op } from './operation';\nimport { reshape } from './reshape';\n/**\n * Removes dimensions of size 1 from the shape of a `tf.Tensor`.\n *\n * ```js\n * const x = tf.tensor([1, 2, 3, 4], [1, 1, 4]);\n * x.squeeze().print();\n * ```\n *\n * @param x The input tensor to be squeezed.\n * @param axis An optional list of numbers. If specified, only\n *     squeezes the dimensions listed. The dimension index starts at 0. It\n * is an error to squeeze a dimension that is not 1.\n *\n * @doc {heading: 'Tensors', subheading: 'Transformations'}\n */\nfunction squeeze_(x, axis) {\n    const $x = convertToTensor(x, 'x', 'squeeze');\n    return reshape($x, squeezeShape($x.shape, axis).newShape);\n}\nexport const squeeze = op({ squeeze_ });\n//# sourceMappingURL=squeeze.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { complex } from '../complex';\nimport { concat } from '../concat';\nimport { imag } from '../imag';\nimport { mul } from '../mul';\nimport { op } from '../operation';\nimport { real } from '../real';\nimport { reshape } from '../reshape';\nimport { reverse } from '../reverse';\nimport { scalar } from '../scalar';\nimport { slice } from '../slice';\nimport { ifft } from './ifft';\n/**\n * Inversed real value input fast Fourier transform.\n *\n * Computes the 1-dimensional inversed discrete Fourier transform over the\n * inner-most dimension of the real input.\n *\n * ```js\n * const real = tf.tensor1d([1, 2, 3]);\n * const imag = tf.tensor1d([0, 0, 0]);\n * const x = tf.complex(real, imag);\n *\n * x.irfft().print();\n * ```\n * @param input The real value input to compute an irfft over.\n *\n * @doc {heading: 'Operations', subheading: 'Spectral', namespace: 'spectral'}\n */\nfunction irfft_(input) {\n    const innerDimensionSize = input.shape[input.shape.length - 1];\n    const batch = input.size / innerDimensionSize;\n    let ret;\n    if (innerDimensionSize <= 2) {\n        const complexInput = reshape(input, [batch, innerDimensionSize]);\n        ret = ifft(complexInput);\n    }\n    else {\n        // The length of unique components of the DFT of a real-valued signal\n        // is 2 * (input_len - 1)\n        const outputShape = [batch, 2 * (innerDimensionSize - 1)];\n        const realInput = reshape(real(input), [batch, innerDimensionSize]);\n        const imagInput = reshape(imag(input), [batch, innerDimensionSize]);\n        const realConjugate = reverse(slice(realInput, [0, 1], [batch, innerDimensionSize - 2]), 1);\n        const imagConjugate = mul(reverse(slice(imagInput, [0, 1], [batch, innerDimensionSize - 2]), 1), scalar(-1));\n        const r = concat([realInput, realConjugate], 1);\n        const i = concat([imagInput, imagConjugate], 1);\n        const complexInput = reshape(complex(r, i), [outputShape[0], outputShape[1]]);\n        ret = ifft(complexInput);\n    }\n    ret = real(ret);\n    // reshape the result if the input is 3D tensor.\n    if (input.rank === 3 && input.shape[0] !== 0) {\n        const temp = ret;\n        const batch = input.shape[0];\n        ret = reshape(ret, [batch, ret.shape[0] / batch, ret.shape[1]]);\n        temp.dispose();\n    }\n    return ret;\n}\nexport const irfft = op({ irfft_ });\n//# sourceMappingURL=irfft.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Round } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes round of input `tf.Tensor` element-wise: `round(x)`.\n * It implements banker's rounding.\n *\n * ```js\n * const x = tf.tensor1d([.6, 1.1, -3.3]);\n *\n * x.round().print();  // or tf.round(x)\n * ```\n * @param x The input tensor.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction round_(x) {\n    const $x = convertToTensor(x, 'x', 'round');\n    const inputs = { x: $x };\n    return ENGINE.runKernel(Round, inputs);\n}\nexport const round = op({ round_ });\n//# sourceMappingURL=round.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Pow } from '../kernel_names';\nimport { makeTypesMatch } from '../tensor_util';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes the power of one `tf.Tensor` to another. Supports broadcasting.\n *\n * Given a `tf.Tensor` x and a `tf.Tensor` y, this operation computes x^y for\n * corresponding elements in x and y. The result's dtype will be the upcasted\n * type of the `base` and `exp` dtypes.\n *\n * ```js\n * const a = tf.tensor([[2, 3], [4, 5]])\n * const b = tf.tensor([[1, 2], [3, 0]]).toInt();\n *\n * a.pow(b).print();  // or tf.pow(a, b)\n * ```\n *\n * ```js\n * const a = tf.tensor([[1, 2], [3, 4]])\n * const b = tf.tensor(2).toInt();\n *\n * a.pow(b).print();  // or tf.pow(a, b)\n * ```\n * We also expose `powStrict` which has the same signature as this op and\n * asserts that `base` and `exp` are the same shape (does not broadcast).\n *\n * @param base The base `tf.Tensor` to pow element-wise.\n * @param exp The exponent `tf.Tensor` to pow element-wise.\n *\n * @doc {heading: 'Operations', subheading: 'Arithmetic'}\n */\nfunction pow_(base, exp) {\n    let $base = convertToTensor(base, 'base', 'pow');\n    let $exp = convertToTensor(exp, 'exp', 'pow');\n    [$base, $exp] = makeTypesMatch($base, $exp);\n    const inputs = { a: $base, b: $exp };\n    return ENGINE.runKernel(Pow, inputs);\n}\nexport const pow = op({ pow_ });\n//# sourceMappingURL=pow.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Sum } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { cast } from './cast';\nimport { op } from './operation';\n/**\n * Computes the sum of elements across dimensions of a `tf.Tensor`.\n *\n * Reduces the input along the dimensions given in `axes`. Unless `keepDims`\n * is true, the rank of the `tf.Tensor` is reduced by 1 for each entry in\n * `axes`. If `keepDims` is true, the reduced dimensions are retained with\n * length 1. If axes has no entries, all dimensions are reduced, and a\n * `tf.Tensor` with a single element is returned.\n *\n * ```js\n * const x = tf.tensor1d([1, 2, 3]);\n *\n * x.sum().print();  // or tf.sum(x)\n * ```\n *\n * ```js\n * const x = tf.tensor2d([1, 2, 3, 4], [2, 2]);\n *\n * const axis = 1;\n * x.sum(axis).print();  // or tf.sum(x, axis)\n * ```\n *\n * @param x The input tensor to compute the sum over. If the dtype is `bool`\n *   it will be converted to `int32` and the output dtype will be `int32`.\n * @param axis The dimension(s) to reduce. By default it reduces\n *     all dimensions.\n * @param keepDims If true, retains reduced dimensions with size 1.\n *\n * @doc {heading: 'Operations', subheading: 'Reduction'}\n */\nfunction sum_(x, axis = null, keepDims = false) {\n    let $x = convertToTensor(x, 'x', 'sum');\n    if ($x.dtype === 'bool') {\n        $x = cast($x, 'int32');\n    }\n    const inputs = { x: $x };\n    const attrs = { axis, keepDims };\n    return ENGINE.runKernel(Sum, inputs, attrs);\n}\nexport const sum = op({ sum_ });\n//# sourceMappingURL=sum.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { makeOnesTypedArray, sizeFromShape } from '../util';\nimport { complex } from './complex';\nimport { zeros } from './zeros';\n/**\n * Creates a `tf.Tensor` with all elements set to 1.\n *\n * ```js\n * tf.ones([2, 2]).print();\n * ```\n *\n * @param shape An array of integers defining the output tensor shape.\n * @param dtype The type of an element in the resulting tensor. Defaults to\n *     'float'.\n *\n * @doc {heading: 'Tensors', subheading: 'Creation'}\n */\nexport function ones(shape, dtype = 'float32') {\n    if (dtype === 'complex64') {\n        const real = ones(shape, 'float32');\n        const imag = zeros(shape, 'float32');\n        return complex(real, imag);\n    }\n    const values = makeOnesTypedArray(sizeFromShape(shape), dtype);\n    return ENGINE.makeTensor(values, shape, dtype);\n}\n//# sourceMappingURL=ones.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { NotEqual } from '../kernel_names';\nimport { makeTypesMatch } from '../tensor_util';\nimport { convertToTensor } from '../tensor_util_env';\nimport { assertAndGetBroadcastShape } from './broadcast_util';\nimport { op } from './operation';\n/**\n * Returns the truth value of (a != b) element-wise. Supports broadcasting.\n *\n * ```js\n * const a = tf.tensor1d([1, 2, 3]);\n * const b = tf.tensor1d([0, 2, 3]);\n *\n * a.notEqual(b).print();\n * ```\n * @param a The first input tensor.\n * @param b The second input tensor. Must have the same dtype as `a`.\n *\n * @doc {heading: 'Operations', subheading: 'Logical'}\n */\nfunction notEqual_(a, b) {\n    let $a = convertToTensor(a, 'a', 'notEqual', 'string_or_numeric');\n    let $b = convertToTensor(b, 'b', 'notEqual', 'string_or_numeric');\n    [$a, $b] = makeTypesMatch($a, $b);\n    assertAndGetBroadcastShape($a.shape, $b.shape);\n    const inputs = { a: $a, b: $b };\n    return ENGINE.runKernel(NotEqual, inputs);\n}\nexport const notEqual = op({ notEqual_ });\n//# sourceMappingURL=not_equal.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { SquaredDifference } from '../kernel_names';\nimport { makeTypesMatch } from '../tensor_util';\nimport { convertToTensor } from '../tensor_util_env';\nimport { assertAndGetBroadcastShape } from './broadcast_util';\nimport { op } from './operation';\n/**\n * Returns (a - b) * (a - b) element-wise.\n * Supports broadcasting.\n *\n * ```js\n * const a = tf.tensor1d([1, 4, 3, 16]);\n * const b = tf.tensor1d([1, 2, 9, 4]);\n *\n * a.squaredDifference(b).print();  // or tf.squaredDifference(a, b)\n * ```\n *\n * ```js\n * // Broadcast squared difference  a with b.\n * const a = tf.tensor1d([2, 4, 6, 8]);\n * const b = tf.scalar(5);\n *\n * a.squaredDifference(b).print();  // or tf.squaredDifference(a, b)\n * ```\n *\n * @param a The first tensor.\n * @param b The second tensor. Must have the same type as `a`.\n *\n * @doc {heading: 'Operations', subheading: 'Arithmetic'}\n */\nfunction squaredDifference_(a, b) {\n    let $a = convertToTensor(a, 'a', 'squaredDifference');\n    let $b = convertToTensor(b, 'b', 'squaredDifference');\n    [$a, $b] = makeTypesMatch($a, $b);\n    assertAndGetBroadcastShape($a.shape, $b.shape);\n    const inputs = { a: $a, b: $b };\n    const attrs = {};\n    return ENGINE.runKernel(SquaredDifference, inputs, attrs);\n}\nexport const squaredDifference = op({ squaredDifference_ });\n//# sourceMappingURL=squared_difference.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Step } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes step of the input `tf.Tensor` element-wise: `x > 0 ? 1 : alpha * x`\n *\n * ```js\n * const x = tf.tensor1d([0, 2, -1, -3]);\n *\n * x.step(.5).print();  // or tf.step(x, .5)\n * ```\n * @param x The input tensor.\n * @param alpha The gradient when input is negative.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction step_(x, alpha = 0.0) {\n    const $x = convertToTensor(x, 'x', 'step');\n    const inputs = { x: $x };\n    const attrs = { alpha };\n    return ENGINE.runKernel(Step, inputs, attrs);\n}\nexport const step = op({ step_ });\n//# sourceMappingURL=step.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Relu6 } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes rectified linear 6 element-wise: `min(max(x, 0), 6)`.\n *\n * ```js\n * const x = tf.tensor1d([-1, 2, -3, 8]);\n *\n * x.relu6().print();  // or tf.relu6(x)\n * ```\n * @param x The input tensor. If the dtype is `bool`, the output dtype will be\n *     `int32'.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction relu6_(x) {\n    const $x = convertToTensor(x, 'x', 'relu6');\n    const inputs = { x: $x };\n    return ENGINE.runKernel(Relu6, inputs);\n}\nexport const relu6 = op({ relu6_ });\n//# sourceMappingURL=relu6.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { isTypedArray } from '../util';\nimport { makeTensor } from './tensor_ops_util';\n/**\n * Creates rank-0 `tf.Tensor` (scalar) with the provided value and dtype.\n *\n * The same functionality can be achieved with `tf.tensor`, but in general\n * we recommend using `tf.scalar` as it makes the code more readable.\n *\n * ```js\n * tf.scalar(3.14).print();\n * ```\n *\n * @param value The value of the scalar.\n * @param dtype The data type.\n *\n * @doc {heading: 'Tensors', subheading: 'Creation'}\n */\nexport function scalar(value, dtype) {\n    if (((isTypedArray(value) && dtype !== 'string') || Array.isArray(value)) &&\n        dtype !== 'complex64') {\n        throw new Error('Error creating a new Scalar: value must be a primitive ' +\n            '(number|boolean|string)');\n    }\n    if (dtype === 'string' && isTypedArray(value) &&\n        !(value instanceof Uint8Array)) {\n        throw new Error('When making a scalar from encoded string, ' +\n            'the value must be `Uint8Array`.');\n    }\n    const shape = [];\n    const inferredShape = [];\n    return makeTensor(value, shape, inferredShape, dtype);\n}\n//# sourceMappingURL=scalar.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Prelu } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes leaky rectified linear element-wise with parametric alphas.\n *\n * `x < 0 ? alpha * x : f(x) = x`\n *\n * ```js\n * const x = tf.tensor1d([-1, 2, -3, 4]);\n * const alpha = tf.scalar(0.1);\n *\n * x.prelu(alpha).print();  // or tf.prelu(x, alpha)\n * ```\n * @param x The input tensor.\n * @param alpha Scaling factor for negative values.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction prelu_(x, alpha) {\n    const $x = convertToTensor(x, 'x', 'prelu');\n    const $alpha = convertToTensor(alpha, 'alpha', 'prelu');\n    const inputs = { x: $x, alpha: $alpha };\n    return ENGINE.runKernel(Prelu, inputs);\n}\nexport const prelu = op({ prelu_ });\n//# sourceMappingURL=prelu.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { inferShape } from '../tensor_util_env';\nimport { assertNonNull } from '../util';\nimport { makeTensor } from './tensor_ops_util';\n/**\n * Creates rank-3 `tf.Tensor` with the provided values, shape and dtype.\n *\n * The same functionality can be achieved with `tf.tensor`, but in general\n * we recommend using `tf.tensor3d` as it makes the code more readable.\n *\n *  ```js\n * // Pass a nested array.\n * tf.tensor3d([[[1], [2]], [[3], [4]]]).print();\n * ```\n * ```js\n * // Pass a flat array and specify a shape.\n * tf.tensor3d([1, 2, 3, 4], [2, 2, 1]).print();\n * ```\n *\n * @param values The values of the tensor. Can be nested array of numbers,\n *     or a flat array, or a `TypedArray`.\n * @param shape The shape of the tensor. If not provided,  it is inferred from\n *     `values`.\n * @param dtype The data type.\n *\n * @doc {heading: 'Tensors', subheading: 'Creation'}\n */\nexport function tensor3d(values, shape, dtype) {\n    assertNonNull(values);\n    if (shape != null && shape.length !== 3) {\n        throw new Error('tensor3d() requires shape to have three numbers');\n    }\n    const inferredShape = inferShape(values, dtype);\n    if (inferredShape.length !== 3 && inferredShape.length !== 1) {\n        throw new Error('tensor3d() requires values to be number[][][] or flat/TypedArray');\n    }\n    if (inferredShape.length === 1 && shape == null) {\n        throw new Error('tensor3d() requires shape to be provided when `values` ' +\n            'are a flat array');\n    }\n    return makeTensor(values, shape, inferredShape, dtype);\n}\n//# sourceMappingURL=tensor3d.js.map","/**\n * @license\n * Copyright 2017 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n/**\n * Inputs of size above this threshold will be parallelized by calling multiple\n * shader programs.\n */\nimport { nearestDivisor } from '../util';\nexport const PARALLELIZE_THRESHOLD = 30;\nexport function computeOptimalWindowSize(inSize) {\n    if (inSize <= PARALLELIZE_THRESHOLD) {\n        return inSize;\n    }\n    return nearestDivisor(inSize, Math.floor(Math.sqrt(inSize)));\n}\n//# sourceMappingURL=reduce_util.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Slice } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Extracts a slice from a `tf.Tensor` starting at coordinates `begin`\n * and is of size `size`.\n *\n * Also available are stricter rank-specific methods with the same signature\n * as this method that assert that `x` is of the given rank:\n *   - `tf.slice1d`\n *   - `tf.slice2d`\n *   - `tf.slice3d`\n *   - `tf.slice4d`\n *\n * ```js\n * const x = tf.tensor1d([1, 2, 3, 4]);\n *\n * x.slice([1], [2]).print();\n * ```\n *\n * ```js\n * const x = tf.tensor2d([1, 2, 3, 4], [2, 2]);\n *\n * x.slice([1, 0], [1, 2]).print();\n * ```\n * @param x The input `tf.Tensor` to slice from.\n * @param begin The coordinates to start the slice from. The length can be\n *     less than the rank of x - the rest of the axes will have implicit 0 as\n *     start. Can also be a single number, in which case it specifies the\n *     first axis.\n * @param size The size of the slice. The length can be less than the rank of\n *     x - the rest of the axes will have implicit -1. A value of -1 requests\n *     the rest of the dimensions in the axis. Can also be a single number,\n *     in which case it specifies the size of the first axis.\n *\n * @doc {heading: 'Tensors', subheading: 'Slicing and Joining'}\n */\nfunction slice_(x, begin, size) {\n    const $x = convertToTensor(x, 'x', 'slice', 'string_or_numeric');\n    if ($x.rank === 0) {\n        throw new Error('Slicing scalar is not possible');\n    }\n    const inputs = { x: $x };\n    const attrs = { begin, size };\n    return ENGINE.runKernel(Slice, inputs, attrs);\n}\nexport const slice = op({ slice_ });\n//# sourceMappingURL=slice.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n// Returns the image center in pixels.\nexport function getImageCenter(center, imageHeight, imageWidth) {\n    const centerX = imageWidth * (typeof center === 'number' ? center : center[0]);\n    const centerY = imageHeight * (typeof center === 'number' ? center : center[1]);\n    return [centerX, centerY];\n}\n//# sourceMappingURL=rotate_util.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nexport const SELU_SCALEALPHA = 1.7580993408473768599402175208123;\nexport const SELU_SCALE = 1.0507009873554804934193349852946;\n//# sourceMappingURL=selu_util.js.map","import { assert } from '../util';\n/**\n * Prepare the split size array. When the input is a number, the axis is evenly\n * divided among the split size. When the input contains the negative value, the\n * rest of the axis is allocated toward that.\n */\nexport function prepareSplitSize(x, numOrSizeSplits, axis = 0) {\n    let splitSizes = [];\n    if (typeof (numOrSizeSplits) === 'number') {\n        assert(x.shape[axis] % numOrSizeSplits === 0, () => 'Number of splits must evenly divide the axis.');\n        splitSizes =\n            new Array(numOrSizeSplits).fill(x.shape[axis] / numOrSizeSplits);\n    }\n    else {\n        const numOfNegs = numOrSizeSplits.reduce((count, value) => {\n            if (value === -1) {\n                count += 1;\n            }\n            return count;\n        }, 0);\n        assert(numOfNegs <= 1, () => 'There should be only one negative value in split array.');\n        const negIndex = numOrSizeSplits.indexOf(-1);\n        // Allow the number of split array to be -1, which indicates the rest\n        // of dimension is allocated to that split.\n        if (negIndex !== -1) {\n            const total = numOrSizeSplits.reduce((a, b) => b > 0 ? a + b : a);\n            numOrSizeSplits[negIndex] = x.shape[axis] - total;\n        }\n        assert(x.shape[axis] === numOrSizeSplits.reduce((a, b) => a + b), () => 'The sum of sizes must match the size of the axis dimension.');\n        splitSizes = numOrSizeSplits;\n    }\n    return splitSizes;\n}\n//# sourceMappingURL=split_util.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { nearestDivisor } from '../util';\nimport { PARALLELIZE_THRESHOLD } from './reduce_util';\nexport function segOpComputeOptimalWindowSize(inSize, numSegments) {\n    let done = false;\n    let res;\n    if (inSize <= PARALLELIZE_THRESHOLD) {\n        res = inSize;\n        done = true;\n    }\n    else {\n        res = nearestDivisor(inSize, Math.floor(Math.sqrt(inSize)));\n    }\n    while (!done) {\n        if (res > numSegments || res === inSize) {\n            done = true;\n        }\n        else {\n            res = nearestDivisor(inSize, res + 1);\n        }\n    }\n    return res;\n}\nexport function computeOutShape(aShape, axis, numSegments) {\n    const outShape = [];\n    const rank = aShape.length;\n    for (let dim = 0; dim < rank; dim++) {\n        if (dim !== axis) {\n            outShape.push(aShape[dim]);\n        }\n        else {\n            outShape.push(numSegments);\n        }\n    }\n    return outShape;\n}\nexport function collectGatherOpShapeInfo(x, indices, axis, batchDims) {\n    const indicesRank = indices.shape.length;\n    const xRank = x.shape.length;\n    if (batchDims !== 0) {\n        if (batchDims < -indicesRank || batchDims > indicesRank) {\n            throw new Error(`Expect batchDims in the range of [-${indicesRank}, ${indicesRank}], but got ${batchDims}`);\n        }\n    }\n    if (batchDims < 0) {\n        batchDims += indicesRank;\n    }\n    if (batchDims > xRank) {\n        throw new Error(`batchDims (${batchDims}) must be less than rank(x) (\n    ${xRank}).`);\n    }\n    if (axis < batchDims) {\n        throw new Error(`batchDims (${batchDims}) must be less than or equal to axis (${axis}).`);\n    }\n    for (let i = 0; i < batchDims; ++i) {\n        if (x.shape[i] !== indices.shape[i]) {\n            throw new Error(`x.shape[${i}]: ${x.shape[i]} should be equal to indices.shape[${i}]: ${indices.shape[i]}.`);\n        }\n    }\n    const dimSize = x.shape[axis];\n    const outputShape = [];\n    let batchSize = 1;\n    let outerSize = 1;\n    let sliceSize = 1;\n    for (let i = 0; i < batchDims; ++i) {\n        outputShape.push(x.shape[i]);\n        batchSize *= x.shape[i];\n    }\n    for (let i = batchDims; i < axis; i++) {\n        outputShape.push(x.shape[i]);\n        outerSize *= x.shape[i];\n    }\n    for (let i = batchDims; i < indicesRank; i++) {\n        outputShape.push(indices.shape[i]);\n    }\n    for (let i = axis + 1; i < xRank; i++) {\n        outputShape.push(x.shape[i]);\n        sliceSize *= x.shape[i];\n    }\n    return { batchSize, sliceSize, outerSize, dimSize, outputShape };\n}\n//# sourceMappingURL=segment_util.js.map","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { tensor1d } from './tensor1d';\nexport function enclosingPowerOfTwo(value) {\n    // Return 2**N for integer N such that 2**N >= value.\n    return Math.floor(Math.pow(2, Math.ceil(Math.log(value) / Math.log(2.0))));\n}\nexport function cosineWindow(windowLength, a, b) {\n    const even = 1 - windowLength % 2;\n    const newValues = new Float32Array(windowLength);\n    for (let i = 0; i < windowLength; ++i) {\n        const cosArg = (2.0 * Math.PI * i) / (windowLength + even - 1);\n        newValues[i] = a - b * Math.cos(cosArg);\n    }\n    return tensor1d(newValues, 'float32');\n}\n//# sourceMappingURL=signal_ops_util.js.map","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { op } from '../operation';\nimport { cosineWindow } from '../signal_ops_util';\n/**\n * Generate a hamming window.\n *\n * See: https://en.wikipedia.org/wiki/Window_function#Hann_and_Hamming_windows\n *\n * ```js\n * tf.signal.hammingWindow(10).print();\n * ```\n * @param The length of window\n *\n * @doc {heading: 'Operations', subheading: 'Signal', namespace: 'signal'}\n */\nfunction hammingWindow_(windowLength) {\n    return cosineWindow(windowLength, 0.54, 0.46);\n}\nexport const hammingWindow = op({ hammingWindow_ });\n//# sourceMappingURL=hamming_window.js.map","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { op } from '../operation';\nimport { cosineWindow } from '../signal_ops_util';\n/**\n * Generate a Hann window.\n *\n * See: https://en.wikipedia.org/wiki/Window_function#Hann_and_Hamming_windows\n *\n * ```js\n * tf.signal.hannWindow(10).print();\n * ```\n * @param The length of window\n *\n * @doc {heading: 'Operations', subheading: 'Signal', namespace: 'signal'}\n */\nfunction hannWindow_(windowLength) {\n    return cosineWindow(windowLength, 0.5, 0.5);\n}\nexport const hannWindow = op({ hannWindow_ });\n//# sourceMappingURL=hann_window.js.map","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { concat } from '../concat';\nimport { fill } from '../fill';\nimport { op } from '../operation';\nimport { reshape } from '../reshape';\nimport { slice } from '../slice';\nimport { tensor2d } from '../tensor2d';\n/**\n * Expands input into frames of frameLength.\n * Slides a window size with frameStep.\n *\n * ```js\n * tf.signal.frame([1, 2, 3], 2, 1).print();\n * ```\n * @param signal The input tensor to be expanded\n * @param frameLength Length of each frame\n * @param frameStep The frame hop size in samples.\n * @param padEnd Whether to pad the end of signal with padValue.\n * @param padValue An number to use where the input signal does\n *     not exist when padEnd is True.\n *\n * @doc {heading: 'Operations', subheading: 'Signal', namespace: 'signal'}\n */\nfunction frame_(signal, frameLength, frameStep, padEnd = false, padValue = 0) {\n    let start = 0;\n    const output = [];\n    while (start + frameLength <= signal.size) {\n        output.push(slice(signal, start, frameLength));\n        start += frameStep;\n    }\n    if (padEnd) {\n        while (start < signal.size) {\n            const padLen = (start + frameLength) - signal.size;\n            const pad = concat([\n                slice(signal, start, frameLength - padLen), fill([padLen], padValue)\n            ]);\n            output.push(pad);\n            start += frameStep;\n        }\n    }\n    if (output.length === 0) {\n        return tensor2d([], [0, frameLength]);\n    }\n    return reshape(concat(output), [output.length, frameLength]);\n}\nexport const frame = op({ frame_ });\n//# sourceMappingURL=frame.js.map","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { mul } from '../mul';\nimport { op } from '../operation';\nimport { enclosingPowerOfTwo } from '../signal_ops_util';\nimport { rfft } from '../spectral/rfft';\nimport { frame } from './frame';\nimport { hannWindow } from './hann_window';\n/**\n * Computes the Short-time Fourier Transform of signals\n * See: https://en.wikipedia.org/wiki/Short-time_Fourier_transform\n *\n * ```js\n * const input = tf.tensor1d([1, 1, 1, 1, 1])\n * tf.signal.stft(input, 3, 1).print();\n * ```\n * @param signal 1-dimensional real value tensor.\n * @param frameLength The window length of samples.\n * @param frameStep The number of samples to step.\n * @param fftLength The size of the FFT to apply.\n * @param windowFn A callable that takes a window length and returns 1-d tensor.\n *\n * @doc {heading: 'Operations', subheading: 'Signal', namespace: 'signal'}\n */\nfunction stft_(signal, frameLength, frameStep, fftLength, windowFn = hannWindow) {\n    if (fftLength == null) {\n        fftLength = enclosingPowerOfTwo(frameLength);\n    }\n    const framedSignal = frame(signal, frameLength, frameStep);\n    const windowedSignal = mul(framedSignal, windowFn(frameLength));\n    return rfft(windowedSignal, fftLength);\n}\nexport const stft = op({ stft_ });\n//# sourceMappingURL=stft.js.map","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../../engine';\nimport { SparseFillEmptyRows } from '../../kernel_names';\nimport { convertToTensor } from '../../tensor_util_env';\nimport { op } from '../operation';\n/**\n * The input SparseTensor is represented via the map of inputs {`indices`,\n * `values`, `denseShape`}. The output SparseTensor has the same `denseShape`\n * but with indices `outputIndices` and values `outputValues`. This op inserts a\n * single entry for every row that doesn't have any values. The index is created\n * as `[row, 0, ..., 0]` and the inserted value is `defaultValue`.\n *\n * For example, suppose `spInput` has shape [5, 6] and non-empty values:\n * [0, 1]: a\n * [0, 3]: b\n * [2, 0]: c\n * [3, 1]: d\n *\n * Rows 1 and 4 are empty, so the output will be of shape [5, 6] with values:\n * [0, 1]: a\n * [0, 3]: b\n * [1, 0]: `defaultValue`\n * [2, 0]: c\n * [3, 1]: d\n * [4, 0]: `defaultValue`\n *\n * The output SparseTensor will be in row-major order and will have the same\n * shape as the input.\n *\n * This op also returns an indicator vector shaped [dense_shape[0]] such that\n * emptyRowIndicator[i] = True iff row i was an empty row.\n *\n * And a reverse index map vector shaped [indices.shape[0]] that is used during\n * backpropagation, reverseIndexMap[i] = outi s.t. indices[i, j] ==\n * outputIndices[outi, j] for all j\n *\n * ```js\n * const result = tf.sparse.sparseFillEmptyRows(\n *   [[0, 0], [1, 0], [1, 3], [1, 4], [3, 2], [3, 3]],\n *   [0, 10, 13, 14, 32, 33], [5, 6], -1);\n * console.log(result);\n * result['outputIndices'].print(); // [[0, 0], [1, 0], [1, 3], [1, 4],\n *                                  //  [2, 0], [3, 2], [3, 3], [4, 0]]\n * result['outputValues'].print(); // [0, 10, 13, 14,-1, 32, 33, -1]\n * result['emptyRowIndicator'].print(); // [false, false, true, false, true]\n * result['reverseIndexMap'].print(); // [0, 1, 2, 3, 5, 6]\n * ```\n * @param indices: 2-D. the indices of the sparse tensor.\n * @param values: 1-D. the values of the sparse tensor.\n * @param denseShape: 1-D. the shape of the sparse tensor.\n * @param defaultValue: 0-D. default value to insert into location [row, 0, ...,\n *     0] for rows missing from the input sparse tensor.\n * @return A map with the following properties:\n *     - outputIndices\n *     - outputValues: 1-D. the values of the filled sparse tensor.\n *     - emptyRowIndicator: 1-D. whether the dense row was missing in the input\n * sparse tensor.\n *     - reverseIndexMap: 1-D. a map from the input indices to the output\n * indices.\n * @doc {heading: 'Operations', subheading: 'Sparse'}\n */\nfunction sparseFillEmptyRows_(indices, values, denseShape, defaultValue) {\n    const $indices = convertToTensor(indices, 'indices', 'sparseFillEmptyRows');\n    const $values = convertToTensor(values, 'values', 'sparseFillEmptyRows');\n    const $denseShape = convertToTensor(denseShape, 'denseShape', 'sparseFillEmptyRows');\n    const $defaultValue = convertToTensor(defaultValue, 'defaultValue', 'sparseFillEmptyRows', $values.dtype);\n    if ($indices.rank !== 2) {\n        throw new Error(`Indices should be Tensor2D but received shape\n        ${$indices.shape}`);\n    }\n    if ($values.rank !== 1) {\n        throw new Error(`Values should be Tensor1D but received shape ${$values.shape}`);\n    }\n    if ($denseShape.rank !== 1) {\n        throw new Error(`Dense shape should be Tensor1D but received shape ${$denseShape.shape}`);\n    }\n    if ($defaultValue.rank !== 0) {\n        throw new Error(`Default value should be a scalar but received shape ${$defaultValue.shape}`);\n    }\n    const inputs = {\n        indices: $indices,\n        values: $values,\n        denseShape: $denseShape,\n        defaultValue: $defaultValue\n    };\n    const result = ENGINE.runKernel(SparseFillEmptyRows, inputs);\n    return {\n        outputIndices: result[0],\n        outputValues: result[1],\n        emptyRowIndicator: result[2],\n        reverseIndexMap: result[3]\n    };\n}\nexport const sparseFillEmptyRows = op({ sparseFillEmptyRows_ });\n//# sourceMappingURL=sparse_fill_empty_rows.js.map","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../../engine';\nimport { SparseReshape } from '../../kernel_names';\nimport { convertToTensor } from '../../tensor_util_env';\nimport { op } from '../operation';\n/**\n * This operation has the same semantics as reshape on the represented dense\n * tensor. The `inputIndices` are recomputed based on the requested `newShape`.\n * If one component of `newShape` is the special value -1, the size of that\n * dimension is computed so that the total dense size remains constant. At most\n * one component of `newShape` can be -1. The number of dense elements implied\n * by `newShape` must be the same as the number of dense elements originally\n * implied by `inputShape`. Reshaping does not affect the order of values in the\n * SparseTensor. If the input tensor has rank R_in and N non-empty values, and\n * `newShape` has length R_out, then `inputIndices` has shape [N, R_in],\n * `inputShape` has length R_in, `outputIndices` has shape [N, R_out], and\n * `outputShape` has length R_out.\n *\n * ```js\n * const result = tf.sparse.sparseReshape(\n *   [[0, 0, 0], [0, 0, 1], [0, 1, 0], [1, 0, 0], [1, 2, 3]],\n *   [2, 3, 6], [9, -1]);\n * console.log(result);\n * result['outputIndices'].print(); //[[0, 0], [0, 1], [1, 2], [4, 2], [8, 1]]\n * result['outputShape'].print(); // [9, 4]\n * ```\n * @param inputIndices: 2-D. N x R_in matrix with the indices of non-empty\n * values in a SparseTensor.\n * @param inputShape: 1-D. R_in Tensor1D with the input SparseTensor's dense\n * shape.\n * @param newShape: 1-D. R_out Tensor1D with the requested new dense shape.\n * @return A map with the following properties:\n *     - outputIndices: 2-D. N x R_out matrix with the updated indices of\n *       non-empty values in the output SparseTensor.\n *     - outputShape: 1-D. R_out vector with the full dense shape of the output\n *       SparseTensor. This is the same as newShape but with any -1 dimensions\n *        filled in.\n * @doc {heading: 'Operations', subheading: 'Sparse'}\n */\nfunction sparseReshape_(inputIndices, inputShape, newShape) {\n    const $inputIndices = convertToTensor(inputIndices, 'inputIndices', 'sparseReshape');\n    const $inputShape = convertToTensor(inputShape, 'inputShape', 'sparseReshape');\n    const $newShape = convertToTensor(newShape, 'newShape', 'sparseReshape');\n    if ($inputIndices.rank !== 2) {\n        throw new Error(`Input indices should be Tensor2D but received shape\n        ${$inputIndices.shape}`);\n    }\n    if ($inputShape.rank !== 1) {\n        throw new Error(`Input shape should be Tensor1D but received shape ${$inputShape.shape}`);\n    }\n    if ($newShape.rank !== 1) {\n        throw new Error(`New shape should be Tensor1D but received shape ${$newShape.shape}`);\n    }\n    const inputs = {\n        inputIndices: $inputIndices,\n        inputShape: $inputShape,\n        newShape: $newShape\n    };\n    const result = ENGINE.runKernel(SparseReshape, inputs);\n    return { outputIndices: result[0], outputShape: result[1] };\n}\nexport const sparseReshape = op({ sparseReshape_ });\n//# sourceMappingURL=sparse_reshape.js.map","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../../engine';\nimport { SparseSegmentMean } from '../../kernel_names';\nimport { convertToTensor } from '../../tensor_util_env';\nimport { op } from '../operation';\n/**\n * Computes the mean along sparse segments of a tensor.\n *\n * ```js\n * const c = tf.tensor2d([[1,2,3,4], [-1,-2,-3,-4], [6,7,8,9]]);\n * // Select two rows, one segment.\n * const result1 = tf.sparse.sparseSegmentMean(c,\n *                                           tf.tensor1d([0, 1], 'int32'),\n *                                           tf.tensor1d([0, 0], 'int32'));\n * result1.print(); // [[0, 0, 0, 0]]\n *\n * // Select two rows, two segments.\n * const result2 = tf.sparse.sparseSegmentMean(c,\n *                                             tf.tensor1d([0, 1], 'int32'),\n *                                             tf.tensor1d([0, 1], 'int32'));\n * result2.print(); // [[1, 2, 3, 4], [-1, -2, -3, -4]]\n *\n * // Select all rows, two segments.\n * const result3 = tf.sparse.sparseSegmentMean(c,\n *                                             tf.tensor1d([0, 1, 2], 'int32'),\n *                                             tf.tensor1d([0, 1, 1], 'int32'));\n * result3.print(); // [[1.0, 2.0, 3.0, 4.0], [2.5, 2.5, 2.5, 2.5]]\n * ```\n * @param data: A Tensor of at least one dimension with data that will be\n *     assembled in the output.\n * @param indices: A 1-D Tensor with indices into data. Has same rank as\n *     segmentIds.\n * @param segmentIds: A 1-D Tensor with indices into the output Tensor. Values\n *     should be sorted and can be repeated.\n * @return Has same shape as data, except for dimension 0 which has equal to\n *         the number of segments.\n *\n * @doc {heading: 'Operations', subheading: 'Sparse'}\n */\nfunction sparseSegmentMean_(data, indices, segmentIds) {\n    const $data = convertToTensor(data, 'data', 'sparseSegmentMean');\n    const $indices = convertToTensor(indices, 'indices', 'sparseSegmentMean');\n    const $segmentIds = convertToTensor(segmentIds, 'segmentIds', 'sparseSegmentMean');\n    if ($data.rank < 1) {\n        throw new Error(`Data should be at least 1 dimensional but received scalar`);\n    }\n    if ($indices.rank !== 1) {\n        throw new Error(`Indices should be Tensor1D but received shape\n          ${$indices.shape}`);\n    }\n    if ($segmentIds.rank !== 1) {\n        throw new Error(`Segment ids should be Tensor1D but received shape\n          ${$segmentIds.shape}`);\n    }\n    const inputs = {\n        data: $data,\n        indices: $indices,\n        segmentIds: $segmentIds\n    };\n    return ENGINE.runKernel(SparseSegmentMean, inputs);\n}\nexport const sparseSegmentMean = op({ sparseSegmentMean_ });\n//# sourceMappingURL=sparse_segment_mean.js.map","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../../engine';\nimport { SparseSegmentSum } from '../../kernel_names';\nimport { convertToTensor } from '../../tensor_util_env';\nimport { op } from '../operation';\n/**\n * Computes the sum along sparse segments of a tensor.\n *\n * ```js\n * const c = tf.tensor2d([[1,2,3,4], [-1,-2,-3,-4], [5,6,7,8]]);\n * // Select two rows, one segment.\n * const result1 = tf.sparse.sparseSegmentSum(c,\n *                                           tf.tensor1d([0, 1], 'int32'),\n *                                           tf.tensor1d([0, 0], 'int32'));\n * result1.print(); // [[0, 0, 0, 0]]\n *\n * // Select two rows, two segment.\n * const result2 = tf.sparse.sparseSegmentSum(c,\n *                                           tf.tensor1d([0, 1], 'int32'),\n *                                           tf.tensor1d([0, 1], 'int32'));\n * result2.print(); // [[1, 2, 3, 4], [-1, -2, -3, -4]]\n *\n * // Select all rows, two segments.\n * const result3 = tf.sparse.sparseSegmentSum(c,\n *                                           tf.tensor1d([0, 1, 2], 'int32'),\n *                                           tf.tensor1d([0, 0, 1], 'int32'));\n * result3.print(); // [[0, 0, 0, 0], [5, 6, 7, 8]]\n * ```\n * @param data: A Tensor of at least one dimension with data that will be\n *     assembled in the output.\n * @param indices: A 1-D Tensor with indices into data. Has same rank as\n *     segmentIds.\n * @param segmentIds: A 1-D Tensor with indices into the output Tensor. Values\n *     should be sorted and can be repeated.\n * @return Has same shape as data, except for dimension 0 which has equal to\n *         the number of segments.\n *\n * @doc {heading: 'Operations', subheading: 'Sparse'}\n */\nfunction sparseSegmentSum_(data, indices, segmentIds) {\n    const $data = convertToTensor(data, 'data', 'sparseSegmentSum');\n    const $indices = convertToTensor(indices, 'indices', 'sparseSegmentSum');\n    const $segmentIds = convertToTensor(segmentIds, 'segmentIds', 'sparseSegmentSum');\n    if ($data.rank < 1) {\n        throw new Error(`Data should be at least 1 dimensional but received scalar`);\n    }\n    if ($indices.rank !== 1) {\n        throw new Error(`Indices should be Tensor1D but received shape\n         ${$indices.shape}`);\n    }\n    if ($segmentIds.rank !== 1) {\n        throw new Error(`Segment ids should be Tensor1D but received shape\n         ${$segmentIds.shape}`);\n    }\n    const inputs = {\n        data: $data,\n        indices: $indices,\n        segmentIds: $segmentIds\n    };\n    return ENGINE.runKernel(SparseSegmentSum, inputs);\n}\nexport const sparseSegmentSum = op({ sparseSegmentSum_ });\n//# sourceMappingURL=sparse_segment_sum.js.map","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../../engine';\nimport { StringNGrams } from '../../kernel_names';\nimport { convertToTensor } from '../../tensor_util_env';\nimport { op } from '../operation';\n/**\n * Creates ngrams from ragged string data.\n *\n * This op accepts a ragged tensor with 1 ragged dimension containing only\n * strings and outputs a ragged tensor with 1 ragged dimension containing ngrams\n * of that string, joined along the innermost axis.\n *\n * ```js\n * const result = tf.string.stringNGrams(\n *   ['a', 'b', 'c', 'd'], tf.tensor1d([0, 2, 4], 'int32'),\n *   '|', [1, 2], 'LP', 'RP', -1, false);\n * result['nGrams'].print(); // ['a', 'b', 'LP|a', 'a|b', 'b|RP',\n *                           //  'c', 'd', 'LP|c', 'c|d', 'd|RP']\n * result['nGramsSplits'].print(); // [0, 5, 10]\n * ```\n * @param data: The values tensor of the ragged string tensor to make ngrams out\n *     of. Must be a 1D string tensor.\n * @param dataSplits: The splits tensor of the ragged string tensor to make\n *     ngrams out of.\n * @param separator: The string to append between elements of the token. Use \"\"\n *     for no separator.\n * @param nGramWidths: The sizes of the ngrams to create.\n * @param leftPad: The string to use to pad the left side of the ngram sequence.\n *     Only used if pad_width !== 0.\n * @param rightPad: The string to use to pad the right side of the ngram\n *     sequence. Only used if pad_width !== 0.\n * @param padWidth: The number of padding elements to add to each side of each\n *     sequence. Note that padding will never be greater than `nGramWidths`-1\n *     regardless of this value. If `padWidth`=-1 , then add max(`nGramWidths)-1\n *     elements.\n * @param preserveShortSequences: If true, then ensure that at least one ngram\n *     is generated for each input sequence. In particular, if an input sequence\n *     is shorter than min(ngramWidth) + 2*padWidth, then generate a single\n *     ngram containing the entire sequence. If false, then no ngrams are\n *     generated for these short input sequences.\n * @return A map with the following properties:\n *     - nGrams: The values tensor of the output ngrams ragged tensor.\n *     - nGramsSplits: The splits tensor of the output ngrams ragged tensor.\n *\n * @doc {heading: 'Operations', subheading: 'String'}\n */\nfunction stringNGrams_(data, dataSplits, separator, nGramWidths, leftPad, rightPad, padWidth, preserveShortSequences) {\n    const $data = convertToTensor(data, 'data', 'stringNGrams', 'string');\n    if ($data.dtype !== 'string') {\n        throw new Error('Data must be of datatype string');\n    }\n    if ($data.shape.length !== 1) {\n        throw new Error(`Data must be a vector, saw: ${$data.shape}`);\n    }\n    const $dataSplits = convertToTensor(dataSplits, 'dataSplits', 'stringNGrams');\n    if ($dataSplits.dtype !== 'int32') {\n        throw new Error('Data splits must be of datatype int32');\n    }\n    const attrs = {\n        separator,\n        nGramWidths,\n        leftPad,\n        rightPad,\n        padWidth,\n        preserveShortSequences\n    };\n    const inputs = { data: $data, dataSplits: $dataSplits };\n    const result = ENGINE.runKernel(StringNGrams, inputs, attrs);\n    return { nGrams: result[0], nGramsSplits: result[1] };\n}\nexport const stringNGrams = op({ stringNGrams_ });\n//# sourceMappingURL=string_n_grams.js.map","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../../engine';\nimport { StringSplit } from '../../kernel_names';\nimport { convertToTensor } from '../../tensor_util_env';\nimport { op } from '../operation';\n/**\n * Split elements of `input` based on `delimiter` into a SparseTensor .\n *\n * Let N be the size of source (typically N will be the batch size). Split each\n * element of `input` based on `delimiter` and return a SparseTensor containing\n * the splitted tokens. Empty tokens are ignored if `skipEmpty` is set to True.\n *\n * `delimiter` can be empty, or a string of split characters. If `delimiter` is\n * an empty string, each element of `input` is split into individual\n * character strings. Otherwise every character of `delimiter` is a potential\n * split point.\n *\n * ```js\n * const result = tf.string.stringSplit(['hello world',  'a b c'], ' ');\n * result['indices'].print(); // [[0, 0], [0, 1], [1, 0], [1, 1], [1, 2]]\n * result['values'].print(); // ['hello', 'world', 'a', 'b', 'c']\n * result['shape'].print(); // [2, 3]\n * ```\n * @param input: 1-D. Strings to split.\n * @param delimiter: 0-D. Delimiter characters, or empty string.\n * @param skipEmpty: Optional. If true, skip the empty strings from the result.\n *     Defaults to true.\n * @return A map with the following properties:\n *     - indices: A dense matrix of int32 representing the indices of the sparse\n *       tensor.\n *     - values: A vector of strings corresponding to the splited values.\n *     - shape: a length-2 vector of int32 representing the shape of the sparse\n * tensor, where the first value is N and the second value is the maximum number\n * of tokens in a single input entry.\n *\n * @doc {heading: 'Operations', subheading: 'String'}\n */\nfunction stringSplit_(input, delimiter, skipEmpty = true) {\n    const $input = convertToTensor(input, 'input', 'stringSplit', 'string');\n    const $delimiter = convertToTensor(delimiter, 'delimiter', 'stringSplit', 'string');\n    if ($input.rank !== 1) {\n        throw new Error(`Input should be Tensor1D but received shape ${$input.shape}`);\n    }\n    if ($delimiter.rank !== 0) {\n        throw new Error(`Delimiter should be a scalar but received shape ${$delimiter.shape}`);\n    }\n    const attrs = { skipEmpty };\n    const inputs = { input: $input, delimiter: $delimiter };\n    const result = ENGINE.runKernel(StringSplit, inputs, attrs);\n    return { indices: result[0], values: result[1], shape: result[2] };\n}\nexport const stringSplit = op({ stringSplit_ });\n//# sourceMappingURL=string_split.js.map","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../../engine';\nimport { StringToHashBucketFast } from '../../kernel_names';\nimport { convertToTensor } from '../../tensor_util_env';\nimport { op } from '../operation';\n/**\n * Converts each string in the input Tensor to its hash mod by a number of\n * buckets.\n *\n * The hash function is deterministic on the content of the string within the\n * process and will never change. However, it is not suitable for cryptography.\n * This function may be used when CPU time is scarce and inputs are trusted or\n * unimportant. There is a risk of adversaries constructing inputs that all hash\n * to the same bucket.\n *\n * ```js\n * const result = tf.string.stringToHashBucketFast(\n *   ['Hello', 'TensorFlow', '2.x'], 3);\n * result.print(); // [0, 2, 2]\n * ```\n * @param input: The strings to assign a hash bucket.\n * @param numBuckets: The number of buckets.\n * @return A Tensor of the same shape as the input tensor.\n *\n * @doc {heading: 'Operations', subheading: 'String'}\n */\nfunction stringToHashBucketFast_(input, numBuckets) {\n    const $input = convertToTensor(input, 'input', 'stringToHashBucketFast', 'string');\n    const attrs = { numBuckets };\n    if (numBuckets <= 0) {\n        throw new Error(`Number of buckets must be at least 1`);\n    }\n    const inputs = { input: $input };\n    return ENGINE.runKernel(StringToHashBucketFast, inputs, attrs);\n}\nexport const stringToHashBucketFast = op({ stringToHashBucketFast_ });\n//# sourceMappingURL=string_to_hash_bucket_fast.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n// Modularized ops.\nexport { abs } from './abs';\nexport { acos } from './acos';\nexport { acosh } from './acosh';\nexport { add } from './add';\nexport { addN } from './add_n';\nexport { all } from './all';\nexport { any } from './any';\nexport { argMax } from './arg_max';\nexport { argMin } from './arg_min';\nexport { asin } from './asin';\nexport { asinh } from './asinh';\nexport { atan } from './atan';\nexport { atan2 } from './atan2';\nexport { atanh } from './atanh';\nexport { avgPool } from './avg_pool';\nexport { avgPool3d } from './avg_pool_3d';\nexport { basicLSTMCell } from './basic_lstm_cell';\nexport { batchToSpaceND } from './batch_to_space_nd';\nexport { batchNorm } from './batchnorm';\nexport { batchNorm2d } from './batchnorm2d';\nexport { batchNorm3d } from './batchnorm3d';\nexport { batchNorm4d } from './batchnorm4d';\nexport { bincount } from './bincount';\nexport { broadcastTo } from './broadcast_to';\nexport { buffer } from './buffer';\nexport { cast } from './cast';\nexport { ceil } from './ceil';\nexport { clipByValue } from './clip_by_value';\nexport { clone } from './clone';\nexport { complex } from './complex';\nexport { concat } from './concat';\nexport { concat1d } from './concat_1d';\nexport { concat2d } from './concat_2d';\nexport { concat3d } from './concat_3d';\nexport { concat4d } from './concat_4d';\nexport { conv1d } from './conv1d';\nexport { conv2d } from './conv2d';\nexport { conv2dTranspose } from './conv2d_transpose';\nexport { conv3d } from './conv3d';\nexport { conv3dTranspose } from './conv3d_transpose';\nexport { cos } from './cos';\nexport { cosh } from './cosh';\nexport { cumsum } from './cumsum';\nexport { denseBincount } from './dense_bincount';\nexport { depthToSpace } from './depth_to_space';\nexport { depthwiseConv2d } from './depthwise_conv2d';\nexport { diag } from './diag';\nexport { dilation2d } from './dilation2d';\nexport { div } from './div';\nexport { divNoNan } from './div_no_nan';\nexport { dot } from './dot';\nexport { einsum } from './einsum';\nexport { elu } from './elu';\nexport { equal } from './equal';\nexport { erf } from './erf';\nexport { exp } from './exp';\nexport { expandDims } from './expand_dims';\nexport { expm1 } from './expm1';\nexport { eye } from './eye';\nexport { fill } from './fill';\nexport { floor } from './floor';\nexport { floorDiv } from './floorDiv';\nexport { gather } from './gather';\nexport { greater } from './greater';\nexport { greaterEqual } from './greater_equal';\nexport { imag } from './imag';\nexport { isFinite } from './is_finite';\nexport { isInf } from './is_inf';\nexport { isNaN } from './is_nan';\nexport { leakyRelu } from './leaky_relu';\nexport { less } from './less';\nexport { lessEqual } from './less_equal';\nexport { linspace } from './linspace';\nexport { localResponseNormalization } from './local_response_normalization';\nexport { log } from './log';\nexport { log1p } from './log1p';\nexport { logSigmoid } from './log_sigmoid';\nexport { logSoftmax } from './log_softmax';\nexport { logSumExp } from './log_sum_exp';\nexport { logicalAnd } from './logical_and';\nexport { logicalNot } from './logical_not';\nexport { logicalOr } from './logical_or';\nexport { logicalXor } from './logical_xor';\nexport { matMul } from './mat_mul';\nexport { max } from './max';\nexport { maxPool } from './max_pool';\nexport { maxPool3d } from './max_pool_3d';\nexport { maxPoolWithArgmax } from './max_pool_with_argmax';\nexport { maximum } from './maximum';\nexport { mean } from './mean';\nexport { meshgrid } from './meshgrid';\nexport { min } from './min';\nexport { minimum } from './minimum';\nexport { mirrorPad } from './mirror_pad';\nexport { mod } from './mod';\nexport { moments } from './moments';\nexport { mul } from './mul';\nexport { multiRNNCell } from './multi_rnn_cell';\nexport { multinomial } from './multinomial';\nexport { neg } from './neg';\nexport { notEqual } from './not_equal';\nexport { oneHot } from './one_hot';\nexport { ones } from './ones';\nexport { onesLike } from './ones_like';\nexport { outerProduct } from './outer_product';\nexport { pad } from './pad';\nexport { pad1d } from './pad1d';\nexport { pad2d } from './pad2d';\nexport { pad3d } from './pad3d';\nexport { pad4d } from './pad4d';\nexport { pool } from './pool';\nexport { pow } from './pow';\nexport { prelu } from './prelu';\nexport { print } from './print';\nexport { prod } from './prod';\nexport { rand } from './rand';\nexport { randomGamma } from './random_gamma';\nexport { randomNormal } from './random_normal';\nexport { randomUniform } from './random_uniform';\nexport { range } from './range';\nexport { real } from './real';\nexport { reciprocal } from './reciprocal';\nexport { relu } from './relu';\nexport { relu6 } from './relu6';\nexport { reshape } from './reshape';\nexport { reverse } from './reverse';\nexport { reverse1d } from './reverse_1d';\nexport { reverse2d } from './reverse_2d';\nexport { reverse3d } from './reverse_3d';\nexport { reverse4d } from './reverse_4d';\nexport { round } from './round';\nexport { rsqrt } from './rsqrt';\nexport { scalar } from './scalar';\nexport { selu } from './selu';\nexport { separableConv2d } from './separable_conv2d';\nexport { setdiff1dAsync } from './setdiff1d_async';\nexport { sigmoid } from './sigmoid';\nexport { sign } from './sign';\nexport { sin } from './sin';\nexport { sinh } from './sinh';\nexport { slice } from './slice';\nexport { slice1d } from './slice1d';\nexport { slice2d } from './slice2d';\nexport { slice3d } from './slice3d';\nexport { slice4d } from './slice4d';\nexport { softmax } from './softmax';\nexport { softplus } from './softplus';\nexport { spaceToBatchND } from './space_to_batch_nd';\nexport { fft } from './spectral/fft';\nexport { ifft } from './spectral/ifft';\nexport { irfft } from './spectral/irfft';\nexport { rfft } from './spectral/rfft';\nexport { split } from './split';\nexport { sqrt } from './sqrt';\nexport { square } from './square';\nexport { squaredDifference } from './squared_difference';\nexport { squeeze } from './squeeze';\nexport { stack } from './stack';\nexport { step } from './step';\nexport { stridedSlice } from './strided_slice';\nexport { sub } from './sub';\nexport { sum } from './sum';\nexport { tan } from './tan';\nexport { tanh } from './tanh';\nexport { tensor } from './tensor';\nexport { tensor1d } from './tensor1d';\nexport { tensor2d } from './tensor2d';\nexport { tensor3d } from './tensor3d';\nexport { tensor4d } from './tensor4d';\nexport { tensor5d } from './tensor5d';\nexport { tensor6d } from './tensor6d';\nexport { tile } from './tile';\nexport { topk } from './topk';\nexport { truncatedNormal } from './truncated_normal';\nexport { unique } from './unique';\nexport { unsortedSegmentSum } from './unsorted_segment_sum';\nexport { unstack } from './unstack';\nexport { variable } from './variable';\nexport { where } from './where';\nexport { whereAsync } from './where_async';\nexport { zeros } from './zeros';\nexport { zerosLike } from './zeros_like';\nexport * from './boolean_mask';\nexport * from './transpose';\nexport * from './norm';\nexport * from './moving_average';\nexport * from './scatter_nd';\nexport * from './sparse_to_dense';\nexport * from './gather_nd';\nexport * from './dropout';\nexport * from './signal_ops_util';\nexport * from './in_top_k';\nexport { op, OP_SCOPE_SUFFIX } from './operation';\nimport { rfft } from './spectral/rfft';\nimport { fft } from './spectral/fft';\nimport { ifft } from './spectral/ifft';\nimport { irfft } from './spectral/irfft';\nconst spectral = {\n    fft,\n    ifft,\n    rfft,\n    irfft\n};\nimport * as fused from './fused_ops';\nimport { hammingWindow } from './signal/hamming_window';\nimport { hannWindow } from './signal/hann_window';\nimport { frame } from './signal/frame';\nimport { stft } from './signal/stft';\nconst signal = {\n    hammingWindow,\n    hannWindow,\n    frame,\n    stft,\n};\n// Image Ops namespace\nimport { cropAndResize } from './image/crop_and_resize';\nimport { flipLeftRight } from './image/flip_left_right';\nimport { rotateWithOffset } from './image/rotate_with_offset';\nimport { nonMaxSuppression } from './image/non_max_suppression';\nimport { nonMaxSuppressionAsync } from './image/non_max_suppression_async';\nimport { nonMaxSuppressionWithScore } from './image/non_max_suppression_with_score';\nimport { nonMaxSuppressionWithScoreAsync } from './image/non_max_suppression_with_score_async';\nimport { nonMaxSuppressionPadded } from './image/non_max_suppression_padded';\nimport { nonMaxSuppressionPaddedAsync } from './image/non_max_suppression_padded_async';\nimport { resizeBilinear } from './image/resize_bilinear';\nimport { resizeNearestNeighbor } from './image/resize_nearest_neighbor';\nimport { threshold } from './image/threshold';\nimport { transform } from './image/transform';\nconst image = {\n    flipLeftRight,\n    resizeNearestNeighbor,\n    resizeBilinear,\n    rotateWithOffset,\n    cropAndResize,\n    nonMaxSuppression,\n    nonMaxSuppressionAsync,\n    nonMaxSuppressionWithScore,\n    nonMaxSuppressionWithScoreAsync,\n    nonMaxSuppressionPadded,\n    nonMaxSuppressionPaddedAsync,\n    threshold,\n    transform\n};\n// linalg namespace\nimport { bandPart } from './linalg/band_part';\nimport { gramSchmidt } from './linalg/gram_schmidt';\nimport { qr } from './linalg/qr';\nconst linalg = {\n    bandPart,\n    gramSchmidt,\n    qr\n};\n// losses namespace;\nimport { absoluteDifference } from './losses/absolute_difference';\nimport { computeWeightedLoss } from './losses/compute_weighted_loss';\nimport { cosineDistance } from './losses/cosine_distance';\nimport { hingeLoss } from './losses/hinge_loss';\nimport { huberLoss } from './losses/huber_loss';\nimport { logLoss } from './losses/log_loss';\nimport { meanSquaredError } from './losses/mean_squared_error';\nimport { sigmoidCrossEntropy } from './losses/sigmoid_cross_entropy';\nimport { softmaxCrossEntropy } from './losses/softmax_cross_entropy';\nconst losses = {\n    absoluteDifference,\n    computeWeightedLoss,\n    cosineDistance,\n    hingeLoss,\n    huberLoss,\n    logLoss,\n    meanSquaredError,\n    sigmoidCrossEntropy,\n    softmaxCrossEntropy\n};\nimport { sparseFillEmptyRows } from './sparse/sparse_fill_empty_rows';\nimport { sparseReshape } from './sparse/sparse_reshape';\nimport { sparseSegmentMean } from './sparse/sparse_segment_mean';\nimport { sparseSegmentSum } from './sparse/sparse_segment_sum';\nconst sparse = {\n    sparseFillEmptyRows,\n    sparseReshape,\n    sparseSegmentMean,\n    sparseSegmentSum\n};\nimport { stringNGrams } from './string/string_n_grams';\nimport { stringSplit } from './string/string_split';\nimport { stringToHashBucketFast } from './string/string_to_hash_bucket_fast';\n// tslint:disable-next-line:variable-name\nconst string = {\n    stringNGrams,\n    stringSplit,\n    stringToHashBucketFast\n};\n// Second level exports.\nexport { image, linalg, losses, spectral, fused, signal, sparse, string };\n//# sourceMappingURL=ops.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { env } from './environment';\nimport * as util from './util';\nexport class Profiler {\n    constructor(backendTimer, logger) {\n        this.backendTimer = backendTimer;\n        this.logger = logger;\n        if (logger == null) {\n            this.logger = new Logger();\n        }\n    }\n    profileKernel(kernelName, inputs, f) {\n        let outputs;\n        const holdResultWrapperFn = () => {\n            outputs = f();\n        };\n        let timer;\n        const start = util.now();\n        if (this.backendTimer.timerAvailable()) {\n            timer = this.backendTimer.time(holdResultWrapperFn);\n        }\n        else {\n            holdResultWrapperFn();\n            for (const output of outputs) {\n                output.dataSync();\n            }\n            timer = Promise.resolve({ kernelMs: util.now() - start });\n        }\n        if (env().getBool('CHECK_COMPUTATION_FOR_ERRORS')) {\n            for (let i = 0; i < outputs.length; i++) {\n                const output = outputs[i];\n                // Dangling promise here because we don't want to propagate up\n                // asynchronicity.\n                output.data().then(tensorVals => {\n                    checkComputationForErrors(tensorVals, output.dtype, kernelName);\n                });\n            }\n        }\n        const kernelProfile = {\n            kernelName,\n            outputs,\n            inputs,\n            timeMs: timer.then(timing => timing.kernelMs),\n            extraInfo: timer.then(timing => timing.getExtraProfileInfo != null ?\n                timing.getExtraProfileInfo() :\n                '')\n        };\n        return kernelProfile;\n    }\n    logKernelProfile(kernelProfile) {\n        const { kernelName, outputs, timeMs, inputs, extraInfo } = kernelProfile;\n        outputs.forEach(result => {\n            Promise.all([result.data(), timeMs, extraInfo]).then(valueContainer => {\n                this.logger.logKernelProfile(kernelName, result, valueContainer[0], valueContainer[1], inputs, valueContainer[2]);\n            });\n        });\n    }\n}\nexport function checkComputationForErrors(vals, dtype, kernelName) {\n    if (dtype !== 'float32') {\n        // Only floating point computations will generate NaN values\n        return false;\n    }\n    for (let i = 0; i < vals.length; i++) {\n        const num = vals[i];\n        if (isNaN(num) || !isFinite(num)) {\n            // Throwing custom exception so behavior is testable.\n            console.warn(`Found ${num} in the result of '${kernelName}'`);\n            return true;\n        }\n    }\n    return false;\n}\nexport class Logger {\n    logKernelProfile(name, result, vals, timeMs, inputs, extraInfo) {\n        const time = typeof timeMs === 'number' ? util.rightPad(`${timeMs}ms`, 9) :\n            timeMs['error'];\n        const paddedName = util.rightPad(name, 25);\n        const rank = result.rank;\n        const size = result.size;\n        const shape = util.rightPad(result.shape.toString(), 14);\n        let inputShapesDescription = '';\n        for (const name in inputs) {\n            const input = inputs[name];\n            if (input != null) {\n                // The input might be a non-tensor (e.g HTMLImageElement), in which case\n                // we claim the output shape as input shape.\n                const inputShape = input.shape || result.shape;\n                const inputRank = inputShape.length;\n                inputShapesDescription +=\n                    `${name}: ${inputRank}D ${inputRank > 0 ? inputShape : ''} `;\n            }\n        }\n        console.log(`%c${paddedName}\\t%c${time}\\t%c${rank}D ${shape}\\t%c${size}\\t%c${inputShapesDescription}\\t%c${extraInfo}`, 'font-weight:bold', 'color:red', 'color:blue', 'color: orange', 'color: green', 'color: steelblue');\n    }\n}\n//# sourceMappingURL=profiler.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { isPromise } from '../util';\nexport const OP_SCOPE_SUFFIX = '__op';\n/**\n * Used for wrapping functions that perform math operations on\n * Tensors. The function will be wrapped in a named scope that cleans all\n * memory usage after the function is done.\n */\nexport function op(f) {\n    const keys = Object.keys(f);\n    if (keys.length !== 1) {\n        throw new Error(`Please provide an object with a single key ` +\n            `(operation name) mapping to a function. Got an object with ` +\n            `${keys.length} keys.`);\n    }\n    let opName = keys[0];\n    const fn = f[opName];\n    // Strip the underscore from the end of the function name.\n    if (opName.endsWith('_')) {\n        opName = opName.substring(0, opName.length - 1);\n    }\n    // add an __op suffix to distinguish ops from kernels in tf.profile\n    opName = opName + OP_SCOPE_SUFFIX;\n    // tslint:disable-next-line:no-any\n    const f2 = (...args) => {\n        ENGINE.startScope(opName);\n        try {\n            const result = fn(...args);\n            if (isPromise(result)) {\n                console.error('Cannot return a Promise inside of tidy.');\n            }\n            ENGINE.endScope(result);\n            return result;\n        }\n        catch (ex) {\n            ENGINE.endScope(null);\n            throw ex;\n        }\n    };\n    Object.defineProperty(f2, 'name', { value: opName, configurable: true });\n    // tslint:disable-next-line:no-any\n    return f2;\n}\n//# sourceMappingURL=operation.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { inferShape } from '../tensor_util_env';\nimport { assertNonNull } from '../util';\nimport { makeTensor } from './tensor_ops_util';\n/**\n * Creates rank-1 `tf.Tensor` with the provided values, shape and dtype.\n *\n * The same functionality can be achieved with `tf.tensor`, but in general\n * we recommend using `tf.tensor1d` as it makes the code more readable.\n *\n * ```js\n * tf.tensor1d([1, 2, 3]).print();\n * ```\n *\n * @param values The values of the tensor. Can be array of numbers,\n *     or a `TypedArray`.\n * @param dtype The data type.\n *\n * @doc {heading: 'Tensors', subheading: 'Creation'}\n */\nexport function tensor1d(values, dtype) {\n    assertNonNull(values);\n    const inferredShape = inferShape(values, dtype);\n    if (inferredShape.length !== 1) {\n        throw new Error('tensor1d() requires values to be a flat/TypedArray');\n    }\n    const shape = null;\n    return makeTensor(values, shape, inferredShape, dtype);\n}\n//# sourceMappingURL=tensor1d.js.map","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport '../flags';\nimport { env } from '../environment';\nimport { BrowserIndexedDB, BrowserIndexedDBManager } from '../io/indexed_db';\nimport { BrowserLocalStorage, BrowserLocalStorageManager } from '../io/local_storage';\nimport { ModelStoreManagerRegistry } from '../io/model_management';\nexport class PlatformBrowser {\n    fetch(path, init) {\n        return fetch(path, init);\n    }\n    now() {\n        return performance.now();\n    }\n    encode(text, encoding) {\n        if (encoding !== 'utf-8' && encoding !== 'utf8') {\n            throw new Error(`Browser's encoder only supports utf-8, but got ${encoding}`);\n        }\n        if (this.textEncoder == null) {\n            this.textEncoder = new TextEncoder();\n        }\n        return this.textEncoder.encode(text);\n    }\n    decode(bytes, encoding) {\n        return new TextDecoder(encoding).decode(bytes);\n    }\n}\nif (env().get('IS_BROWSER')) {\n    env().setPlatform('browser', new PlatformBrowser());\n    // Register LocalStorage IOHandler\n    try {\n        ModelStoreManagerRegistry.registerManager(BrowserLocalStorage.URL_SCHEME, new BrowserLocalStorageManager());\n    }\n    catch (err) {\n    }\n    // Register IndexedDB IOHandler\n    try {\n        ModelStoreManagerRegistry.registerManager(BrowserIndexedDB.URL_SCHEME, new BrowserIndexedDBManager());\n    }\n    catch (err) {\n    }\n}\n//# sourceMappingURL=platform_browser.js.map","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { env } from '../environment';\n// We are wrapping this within an object so it can be stubbed by Jasmine.\nexport const getNodeFetch = {\n    // tslint:disable-next-line:no-require-imports\n    importFetch: () => require('node-fetch')\n};\nlet systemFetch;\n// These getters and setters are for testing so we don't export a mutable\n// variable.\nexport function resetSystemFetch() {\n    systemFetch = null;\n}\nexport function setSystemFetch(fetchFn) {\n    systemFetch = fetchFn;\n}\nexport function getSystemFetch() {\n    return systemFetch;\n}\nexport class PlatformNode {\n    constructor() {\n        // tslint:disable-next-line:no-require-imports\n        this.util = require('util');\n        // According to the spec, the built-in encoder can do only UTF-8 encoding.\n        // https://developer.mozilla.org/en-US/docs/Web/API/TextEncoder/TextEncoder\n        this.textEncoder = new this.util.TextEncoder();\n    }\n    fetch(path, requestInits) {\n        if (env().global.fetch != null) {\n            return env().global.fetch(path, requestInits);\n        }\n        if (systemFetch == null) {\n            systemFetch = getNodeFetch.importFetch();\n        }\n        return systemFetch(path, requestInits);\n    }\n    now() {\n        const time = process.hrtime();\n        return time[0] * 1000 + time[1] / 1000000;\n    }\n    encode(text, encoding) {\n        if (encoding !== 'utf-8' && encoding !== 'utf8') {\n            throw new Error(`Node built-in encoder only supports utf-8, but got ${encoding}`);\n        }\n        return this.textEncoder.encode(text);\n    }\n    decode(bytes, encoding) {\n        if (bytes.length === 0) {\n            return '';\n        }\n        return new this.util.TextDecoder(encoding).decode(bytes);\n    }\n}\nif (env().get('IS_NODE')) {\n    env().setPlatform('node', new PlatformNode());\n}\n//# sourceMappingURL=platform_node.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport * as util from '../util';\nfunction nonMaxSuppSanityCheck(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma) {\n    if (iouThreshold == null) {\n        iouThreshold = 0.5;\n    }\n    if (scoreThreshold == null) {\n        scoreThreshold = Number.NEGATIVE_INFINITY;\n    }\n    if (softNmsSigma == null) {\n        softNmsSigma = 0.0;\n    }\n    const numBoxes = boxes.shape[0];\n    maxOutputSize = Math.min(maxOutputSize, numBoxes);\n    util.assert(0 <= iouThreshold && iouThreshold <= 1, () => `iouThreshold must be in [0, 1], but was '${iouThreshold}'`);\n    util.assert(boxes.rank === 2, () => `boxes must be a 2D tensor, but was of rank '${boxes.rank}'`);\n    util.assert(boxes.shape[1] === 4, () => `boxes must have 4 columns, but 2nd dimension was ${boxes.shape[1]}`);\n    util.assert(scores.rank === 1, () => 'scores must be a 1D tensor');\n    util.assert(scores.shape[0] === numBoxes, () => `scores has incompatible shape with boxes. Expected ${numBoxes}, ` +\n        `but was ${scores.shape[0]}`);\n    util.assert(0 <= softNmsSigma && softNmsSigma <= 1, () => `softNmsSigma must be in [0, 1], but was '${softNmsSigma}'`);\n    return { maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma };\n}\nexport { nonMaxSuppSanityCheck };\n//# sourceMappingURL=nonmax_util.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Select } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { broadcastTo } from './broadcast_to';\nimport { assertAndGetBroadcastShape } from './broadcast_util';\nimport { op } from './operation';\n/**\n * Returns the elements, either `a` or `b` depending on the `condition`.\n *\n * If the condition is true, select from `a`, otherwise select from `b`.\n *\n * ```js\n * const cond = tf.tensor1d([false, false, true], 'bool');\n * const a = tf.tensor1d([1 , 2, 3]);\n * const b = tf.tensor1d([-1, -2, -3]);\n *\n * a.where(cond, b).print();\n * ```\n *\n * @param condition The input condition. Must be of dtype bool.\n * @param a If `condition` is rank 1, `a` may have a higher rank but\n *     its first dimension must match the size of `condition`.\n * @param b A tensor with the same dtype as `a` and with shape that is\n *     compatible with `a`.\n * @return A tensor with same dtype as `a` and `b`, and shape that is\n *     broadcastable from `a` and `b`.\n *\n * @doc {heading: 'Operations', subheading: 'Logical'}\n */\nfunction where_(condition, a, b) {\n    const $a = convertToTensor(a, 'a', 'where');\n    const $b = convertToTensor(b, 'b', 'where');\n    const $condition = convertToTensor(condition, 'condition', 'where', 'bool');\n    // TODO: move this logic to forward function when the broadcastTo op is\n    // implemented in WASM.\n    // Find the broadcastable shape for $condition, $a, and $b.\n    const broadcastShape = assertAndGetBroadcastShape(assertAndGetBroadcastShape($condition.shape, $a.shape), $b.shape);\n    const $broadcastedCondition = broadcastTo($condition, broadcastShape);\n    const $broadcastedA = broadcastTo($a, broadcastShape);\n    const $broadcastedB = broadcastTo($b, broadcastShape);\n    const inputs = {\n        condition: $broadcastedCondition,\n        t: $broadcastedA,\n        e: $broadcastedB\n    };\n    return ENGINE.runKernel(Select, inputs);\n}\nexport const where = op({ where_ });\n//# sourceMappingURL=where.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { assert, assertNonNegativeIntegerDimensions, flatten, inferDtype, isTypedArray, sizeFromShape, toTypedArray } from '../util';\n/** This is shared code across all tensor creation methods. */\nexport function makeTensor(values, shape, inferredShape, dtype) {\n    if (dtype == null) {\n        dtype = inferDtype(values);\n    }\n    if (dtype === 'complex64') {\n        throw new Error(`Cannot construct a complex64 tensor directly. ` +\n            `Please use tf.complex(real, imag).`);\n    }\n    if (!isTypedArray(values) && !Array.isArray(values) &&\n        typeof values !== 'number' && typeof values !== 'boolean' &&\n        typeof values !== 'string') {\n        throw new Error('values passed to tensor(values) must be a number/boolean/string or ' +\n            'an array of numbers/booleans/strings, or a TypedArray');\n    }\n    if (shape != null) {\n        assertNonNegativeIntegerDimensions(shape);\n        const providedSize = sizeFromShape(shape);\n        const inferredSize = sizeFromShape(inferredShape);\n        assert(providedSize === inferredSize, () => `Based on the provided shape, [${shape}], the tensor should have ` +\n            `${providedSize} values but has ${inferredSize}`);\n        for (let i = 0; i < inferredShape.length; ++i) {\n            const inferred = inferredShape[i];\n            const flatDimsDontMatch = i === inferredShape.length - 1 ?\n                inferred !== sizeFromShape(shape.slice(i)) :\n                true;\n            assert(inferredShape[i] === shape[i] || !flatDimsDontMatch, () => `Error creating a new Tensor. Inferred shape ` +\n                `(${inferredShape}) does not match the provided ` +\n                `shape (${shape}). `);\n        }\n    }\n    if (!isTypedArray(values) && !Array.isArray(values)) {\n        values = [values];\n    }\n    shape = shape || inferredShape;\n    values = dtype !== 'string' ?\n        toTypedArray(values, dtype) :\n        flatten(values, [], true);\n    return ENGINE.makeTensor(values, shape, dtype);\n}\n//# sourceMappingURL=tensor_ops_util.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Pack } from '../kernel_names';\nimport { convertToTensorArray } from '../tensor_util_env';\nimport * as util from '../util';\nimport { op } from './operation';\n/**\n * Stacks a list of rank-`R` `tf.Tensor`s into one rank-`(R+1)` `tf.Tensor`.\n *\n * ```js\n * const a = tf.tensor1d([1, 2]);\n * const b = tf.tensor1d([3, 4]);\n * const c = tf.tensor1d([5, 6]);\n * tf.stack([a, b, c]).print();\n * ```\n *\n * @param tensors A list of tensor objects with the same shape and dtype.\n * @param axis The axis to stack along. Defaults to 0 (the first dim).\n *\n * @doc {heading: 'Tensors', subheading: 'Slicing and Joining'}\n */\nfunction stack_(tensors, axis = 0) {\n    const $tensors = convertToTensorArray(tensors, 'tensors', 'stack', 'string_or_numeric');\n    util.assert($tensors.length >= 1, () => 'Pass at least one tensor to tf.stack');\n    if ($tensors.length > 0) {\n        util.assert(axis <= $tensors[0].rank, () => 'Axis must be <= rank of the tensor');\n    }\n    const inputs = $tensors;\n    const attrs = { axis };\n    return ENGINE.runKernel(Pack, inputs, attrs);\n}\nexport const stack = op({ stack_ });\n//# sourceMappingURL=stack.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { SplitV } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Splits a `tf.Tensor` into sub tensors.\n *\n * If `numOrSizeSplits` is a number, splits `x` along dimension `axis`\n * into `numOrSizeSplits` smaller tensors.\n * Requires that `numOrSizeSplits` evenly divides `x.shape[axis]`.\n *\n * If `numOrSizeSplits` is a number array, splits `x` into\n * `numOrSizeSplits.length` pieces. The shape of the `i`-th piece has the\n * same size as `x` except along dimension `axis` where the size is\n * `numOrSizeSplits[i]`.\n *\n * ```js\n * const x = tf.tensor2d([1, 2, 3, 4, 5, 6, 7, 8], [2, 4]);\n * const [a, b] = tf.split(x, 2, 1);\n * a.print();\n * b.print();\n *\n * const [c, d, e] = tf.split(x, [1, 2, 1], 1);\n * c.print();\n * d.print();\n * e.print();\n * ```\n *\n * @param x The input tensor to split.\n * @param numOrSizeSplits Either an integer indicating the number of\n * splits along the axis or an array of integers containing the sizes of\n * each output tensor along the axis. If a number then it must evenly divide\n * `x.shape[axis]`; otherwise the sum of sizes must match `x.shape[axis]`.\n * Can contain one -1 indicating that dimension is to be inferred.\n * @param axis The dimension along which to split. Defaults to 0 (the first\n * dim).\n *\n * @doc {heading: 'Tensors', subheading: 'Slicing and Joining'}\n */\nfunction split_(x, numOrSizeSplits, axis = 0) {\n    const $x = convertToTensor(x, 'x', 'split');\n    const inputs = { x: $x };\n    const attr = { numOrSizeSplits, axis };\n    return ENGINE.runKernel(SplitV, inputs, attr);\n}\nexport const split = op({ split_ });\n//# sourceMappingURL=split.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { makeZerosTypedArray, sizeFromShape } from '../util';\nimport { complex } from './complex';\n/**\n * Creates a `tf.Tensor` with all elements set to 0.\n *\n * ```js\n * tf.zeros([2, 2]).print();\n * ```\n *\n * @param shape An array of integers defining the output tensor shape.\n * @param dtype The type of an element in the resulting tensor. Can\n *     be 'float32', 'int32' or 'bool'. Defaults to 'float'.\n *\n * @doc {heading: 'Tensors', subheading: 'Creation'}\n */\nexport function zeros(shape, dtype = 'float32') {\n    if (dtype === 'complex64') {\n        const real = zeros(shape, 'float32');\n        const imag = zeros(shape, 'float32');\n        return complex(real, imag);\n    }\n    const values = makeZerosTypedArray(sizeFromShape(shape), dtype);\n    return ENGINE.makeTensor(values, shape, dtype);\n}\n//# sourceMappingURL=zeros.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Relu } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes rectified linear element-wise: `max(x, 0)`.\n *\n * ```js\n * const x = tf.tensor1d([-1, 2, -3, 4]);\n *\n * x.relu().print();  // or tf.relu(x)\n * ```\n * @param x The input tensor. If the dtype is `bool`, the output dtype will be\n *     `int32'.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction relu_(x) {\n    const $x = convertToTensor(x, 'x', 'relu');\n    const inputs = { x: $x };\n    return ENGINE.runKernel(Relu, inputs);\n}\nexport const relu = op({ relu_ });\n//# sourceMappingURL=relu.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { inferShape } from '../tensor_util_env';\nimport { makeTensor } from './tensor_ops_util';\n/**\n * Creates a `tf.Tensor` with the provided values, shape and dtype.\n *\n * ```js\n * // Pass an array of values to create a vector.\n * tf.tensor([1, 2, 3, 4]).print();\n * ```\n *\n * ```js\n * // Pass a nested array of values to make a matrix or a higher\n * // dimensional tensor.\n * tf.tensor([[1, 2], [3, 4]]).print();\n * ```\n *\n * ```js\n * // Pass a flat array and specify a shape yourself.\n * tf.tensor([1, 2, 3, 4], [2, 2]).print();\n * ```\n *\n * @param values The values of the tensor. Can be nested array of numbers,\n *     or a flat array, or a `TypedArray`. If the values are strings,\n *     they will be encoded as utf-8 and kept as `Uint8Array[]`.\n * @param shape The shape of the tensor. Optional. If not provided,\n *   it is inferred from `values`.\n * @param dtype The data type.\n *\n * @doc {heading: 'Tensors', subheading: 'Creation'}\n */\nexport function tensor(values, shape, dtype) {\n    const inferredShape = inferShape(values, dtype);\n    return makeTensor(values, shape, inferredShape, dtype);\n}\n//# sourceMappingURL=tensor.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { inferShape } from '../tensor_util_env';\nimport { assertNonNull } from '../util';\nimport { makeTensor } from './tensor_ops_util';\n/**\n * Creates rank-2 `tf.Tensor` with the provided values, shape and dtype.\n *\n * The same functionality can be achieved with `tf.tensor`, but in general\n * we recommend using `tf.tensor2d` as it makes the code more readable.\n *\n *  ```js\n * // Pass a nested array.\n * tf.tensor2d([[1, 2], [3, 4]]).print();\n * ```\n * ```js\n * // Pass a flat array and specify a shape.\n * tf.tensor2d([1, 2, 3, 4], [2, 2]).print();\n * ```\n *\n * @param values The values of the tensor. Can be nested array of numbers,\n *     or a flat array, or a `TypedArray`.\n * @param shape The shape of the tensor. If not provided, it is inferred from\n *     `values`.\n * @param dtype The data type.\n *\n * @doc {heading: 'Tensors', subheading: 'Creation'}\n */\nexport function tensor2d(values, shape, dtype) {\n    assertNonNull(values);\n    if (shape != null && shape.length !== 2) {\n        throw new Error('tensor2d() requires shape to have two numbers');\n    }\n    const inferredShape = inferShape(values, dtype);\n    if (inferredShape.length !== 2 && inferredShape.length !== 1) {\n        throw new Error('tensor2d() requires values to be number[][] or flat/TypedArray');\n    }\n    if (inferredShape.length === 1 && shape == null) {\n        throw new Error('tensor2d() requires shape to be provided when `values` ' +\n            'are a flat/TypedArray');\n    }\n    return makeTensor(values, shape, inferredShape, dtype);\n}\n//# sourceMappingURL=tensor2d.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Range } from '../kernel_names';\n/**\n * Creates a new `tf.Tensor1D` filled with the numbers in the range provided.\n *\n * The tensor is a is half-open interval meaning it includes start, but\n * excludes stop. Decrementing ranges and negative step values are also\n * supported.sv\n *\n *\n * ```js\n * tf.range(0, 9, 2).print();\n * ```\n *\n * @param start An integer start value\n * @param stop An integer stop value\n * @param step An integer increment (will default to 1 or -1)\n * @param dtype The data type of the output tensor. Defaults to 'float32'.\n *\n * @doc {heading: 'Tensors', subheading: 'Creation'}\n */\nexport function range(start, stop, step = 1, dtype = 'float32') {\n    if (step === 0) {\n        throw new Error('Cannot have a step of zero');\n    }\n    const attrs = { start, stop, step, dtype };\n    return ENGINE.runKernel(Range, {} /* inputs */, attrs);\n}\n//# sourceMappingURL=range.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../../engine';\nimport { IFFT } from '../../kernel_names';\nimport { assert } from '../../util';\nimport { op } from '../operation';\n/**\n * Inverse fast Fourier transform.\n *\n * Computes the inverse 1-dimensional discrete Fourier transform over the\n * inner-most dimension of input.\n *\n * ```js\n * const real = tf.tensor1d([1, 2, 3]);\n * const imag = tf.tensor1d([1, 2, 3]);\n * const x = tf.complex(real, imag);\n *\n * x.ifft().print();  // tf.spectral.ifft(x).print();\n * ```\n * @param input The complex input to compute an ifft over.\n *\n * @doc {heading: 'Operations', subheading: 'Spectral', namespace: 'spectral'}\n */\nfunction ifft_(input) {\n    assert(input.dtype === 'complex64', () => `The dtype for tf.spectral.ifft() must be complex64 ` +\n        `but got ${input.dtype}.`);\n    const inputs = { input };\n    return ENGINE.runKernel(IFFT, inputs);\n}\nexport const ifft = op({ ifft_ });\n//# sourceMappingURL=ifft.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Real } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Returns the real part of a complex (or real) tensor.\n *\n * Given a tensor input, this operation returns a tensor of type float that is\n * the real part of each element in input considered as a complex number.\n *\n * If the input is real, it simply makes a clone.\n *\n * ```js\n * const x = tf.complex([-2.25, 3.25], [4.75, 5.75]);\n * tf.real(x).print();\n * ```\n *\n * @doc {heading: 'Tensors', subheading: 'Creation'}\n */\nfunction real_(input) {\n    const $input = convertToTensor(input, 'input', 'real');\n    const inputs = { input: $input };\n    return ENGINE.runKernel(Real, inputs);\n}\nexport const real = op({ real_ });\n//# sourceMappingURL=real.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Reshape } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Reshapes a `tf.Tensor` to a given shape.\n *\n * Given an input tensor, returns a new tensor with the same values as the\n * input tensor with shape `shape`.\n *\n * If one component of shape is the special value -1, the size of that\n * dimension is computed so that the total size remains constant. In\n * particular, a shape of [-1] flattens into 1-D. At most one component of\n * shape can be -1.\n *\n * If shape is 1-D or higher, then the operation returns a tensor with shape\n * shape filled with the values of tensor. In this case, the number of\n * elements implied by shape must be the same as the number of elements in\n * tensor.\n *\n * ```js\n * const x = tf.tensor1d([1, 2, 3, 4]);\n * x.reshape([2, 2]).print();\n * ```\n *\n * @param x The input tensor to be reshaped.\n * @param shape An array of integers defining the output tensor shape.\n *\n * @doc {heading: 'Tensors', subheading: 'Transformations'}\n */\nfunction reshape_(x, shape) {\n    const $x = convertToTensor(x, 'x', 'reshape', 'string_or_numeric');\n    const inputs = { x: $x };\n    const attrs = { shape };\n    return ENGINE.runKernel(Reshape, inputs, attrs);\n}\nexport const reshape = op({ reshape_ });\n//# sourceMappingURL=reshape.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Unpack } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport * as util from '../util';\nimport { op } from './operation';\n/**\n * Unstacks a `tf.Tensor` of rank-`R` into a list of rank-`(R-1)` `tf.Tensor`s.\n *\n * ```js\n * const a = tf.tensor2d([1, 2, 3, 4], [2, 2]);\n *\n * tf.unstack(a).forEach(tensor => tensor.print());\n * ```\n *\n * @param x A tensor object.\n * @param axis The axis to unstack along. Defaults to 0 (the first dim).\n *\n * @doc {heading: 'Tensors', subheading: 'Slicing and Joining'}\n */\nfunction unstack_(x, axis = 0) {\n    const $x = convertToTensor(x, 'x', 'unstack', 'string_or_numeric');\n    util.assert(axis >= -$x.shape.length && axis < $x.shape.length, () => `Axis = ${axis} is not in [-${$x.shape.length}, ${$x.shape.length})`);\n    const inputs = { value: $x };\n    const attrs = { axis };\n    return ENGINE.runKernel(Unpack, inputs, attrs);\n}\nexport const unstack = op({ unstack_ });\n//# sourceMappingURL=unstack.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../../engine';\nimport { FFT } from '../../kernel_names';\nimport { assert } from '../../util';\nimport { op } from '../operation';\n/**\n * Fast Fourier transform.\n *\n * Computes the 1-dimensional discrete Fourier transform over the inner-most\n * dimension of input.\n *\n * ```js\n * const real = tf.tensor1d([1, 2, 3]);\n * const imag = tf.tensor1d([1, 2, 3]);\n * const x = tf.complex(real, imag);\n *\n * x.fft().print();  // tf.spectral.fft(x).print();\n * ```\n * @param input The complex input to compute an fft over.\n *\n * @doc {heading: 'Operations', subheading: 'Spectral', namespace: 'spectral'}\n */\nfunction fft_(input) {\n    assert(input.dtype === 'complex64', () => `The dtype for tf.spectral.fft() must be complex64 ` +\n        `but got ${input.dtype}.`);\n    const inputs = { input };\n    return ENGINE.runKernel(FFT, inputs);\n}\nexport const fft = op({ fft_ });\n//# sourceMappingURL=fft.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { assert } from '../../util';\nimport { complex } from '../complex';\nimport { concat } from '../concat';\nimport { imag } from '../imag';\nimport { op } from '../operation';\nimport { real } from '../real';\nimport { reshape } from '../reshape';\nimport { slice } from '../slice';\nimport { split } from '../split';\nimport { zeros } from '../zeros';\nimport { zerosLike } from '../zeros_like';\nimport { fft } from './fft';\n/**\n * Real value input fast Fourier transform.\n *\n * Computes the 1-dimensional discrete Fourier transform over the\n * inner-most dimension of the real input.\n *\n * ```js\n * const real = tf.tensor1d([1, 2, 3]);\n *\n * real.rfft().print();\n * ```\n * @param input The real value input to compute an rfft over.\n *\n * @doc {heading: 'Operations', subheading: 'Spectral', namespace: 'spectral'}\n */\nfunction rfft_(input, fftLength) {\n    assert(input.dtype === 'float32', () => `The dtype for rfft() must be real value but got ${input.dtype}`);\n    let innerDimensionSize = input.shape[input.shape.length - 1];\n    const batch = input.size / innerDimensionSize;\n    let adjustedInput;\n    if (fftLength != null && fftLength < innerDimensionSize) {\n        // Need to crop\n        const begin = input.shape.map(v => 0);\n        const size = input.shape.map(v => v);\n        size[input.shape.length - 1] = fftLength;\n        adjustedInput = slice(input, begin, size);\n        innerDimensionSize = fftLength;\n    }\n    else if (fftLength != null && fftLength > innerDimensionSize) {\n        // Need to pad with zeros\n        const zerosShape = input.shape.map(v => v);\n        zerosShape[input.shape.length - 1] = fftLength - innerDimensionSize;\n        adjustedInput = concat([input, zeros(zerosShape)], input.shape.length - 1);\n        innerDimensionSize = fftLength;\n    }\n    else {\n        adjustedInput = input;\n    }\n    // Complement the input with zero imaginary numbers.\n    const zerosInput = zerosLike(adjustedInput);\n    const complexInput = reshape(complex(adjustedInput, zerosInput), [batch, innerDimensionSize]);\n    const ret = fft(complexInput);\n    // Exclude complex conjugations. These conjugations are put symmetrically.\n    const half = Math.floor(innerDimensionSize / 2) + 1;\n    const realValues = real(ret);\n    const imagValues = imag(ret);\n    const realComplexConjugate = split(realValues, [half, innerDimensionSize - half], realValues.shape.length - 1);\n    const imagComplexConjugate = split(imagValues, [half, innerDimensionSize - half], imagValues.shape.length - 1);\n    const outputShape = adjustedInput.shape.slice();\n    outputShape[adjustedInput.shape.length - 1] = half;\n    return reshape(complex(realComplexConjugate[0], imagComplexConjugate[0]), outputShape);\n}\nexport const rfft = op({ rfft_ });\n//# sourceMappingURL=rfft.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { convertToTensor } from '../tensor_util_env';\nimport { parseAxisParam } from '../util';\nimport { abs } from './abs';\nimport * as axis_util from './axis_util';\nimport { max } from './max';\nimport { min } from './min';\nimport { op } from './operation';\nimport { pow } from './pow';\nimport { reshape } from './reshape';\nimport { scalar } from './scalar';\nimport { sqrt } from './sqrt';\nimport { square } from './square';\nimport { sum } from './sum';\n/**\n * Computes the norm of scalar, vectors, and matrices.\n * This function can compute several different vector norms (the 1-norm, the\n * Euclidean or 2-norm, the inf-norm, and in general the p-norm for p > 0)\n * and matrix norms (Frobenius, 1-norm, and inf-norm).\n *\n * ```js\n * const x = tf.tensor1d([1, 2, 3, 4]);\n *\n * x.norm().print();  // or tf.norm(x)\n * ```\n *\n * @param x The input array.\n * @param ord Optional. Order of the norm. Supported norm types are\n * following:\n *\n *  | ord        | norm for matrices         | norm for vectors\n *  |------------|---------------------------|---------------------\n *  |'euclidean' |Frobenius norm             |2-norm\n *  |'fro'       |Frobenius norm\t           |\n *  |Infinity    |max(sum(abs(x), axis=1))   |max(abs(x))\n *  |-Infinity   |min(sum(abs(x), axis=1))   |min(abs(x))\n *  |1           |max(sum(abs(x), axis=0))   |sum(abs(x))\n *  |2           |                           |sum(abs(x)^2)^1/2*\n *\n * @param axis Optional. If axis is null (the default), the input is\n * considered a vector and a single vector norm is computed over the entire\n * set of values in the Tensor, i.e. norm(x, ord) is equivalent\n * to norm(x.reshape([-1]), ord). If axis is a integer, the input\n * is considered a batch of vectors, and axis determines the axis in x\n * over which to compute vector norms. If axis is a 2-tuple of integer it is\n * considered a batch of matrices and axis determines the axes in NDArray\n * over which to compute a matrix norm.\n * @param keepDims Optional. If true, the norm have the same dimensionality\n * as the input.\n *\n * @doc {heading: 'Operations', subheading: 'Matrices'}\n */\nfunction norm_(x, ord = 'euclidean', axis = null, keepDims = false) {\n    x = convertToTensor(x, 'x', 'norm');\n    const norm = normImpl(x, ord, axis);\n    let keepDimsShape = norm.shape;\n    if (keepDims) {\n        const axes = parseAxisParam(axis, x.shape);\n        keepDimsShape = axis_util.expandShapeToKeepDim(norm.shape, axes);\n    }\n    return reshape(norm, keepDimsShape);\n}\nfunction normImpl(x, p, axis = null) {\n    if (x.rank === 0) {\n        return abs(x);\n    }\n    // consider vector when no axis is specified\n    if (x.rank !== 1 && axis === null) {\n        return normImpl(reshape(x, [-1]), p, axis);\n    }\n    // vector\n    if (x.rank === 1 || typeof axis === 'number' ||\n        Array.isArray(axis) && axis.length === 1) {\n        if (p === 1) {\n            return sum(abs(x), axis);\n        }\n        if (p === Infinity) {\n            return max(abs(x), axis);\n        }\n        if (p === -Infinity) {\n            return min(abs(x), axis);\n        }\n        if (p === 'euclidean' || p === 2) {\n            // norm(x, 2) = sum(abs(xi) ^ 2) ^ 1/2\n            return sqrt(sum(pow(abs(x), scalar(2, 'int32')), axis));\n        }\n        throw new Error(`Error in norm: invalid ord value: ${p}`);\n    }\n    // matrix (assumption axis[0] < axis[1])\n    if (Array.isArray(axis) && axis.length === 2) {\n        if (p === 1) {\n            return max(sum(abs(x), axis[0]), axis[1] - 1);\n        }\n        if (p === Infinity) {\n            return max(sum(abs(x), axis[1]), axis[0]);\n        }\n        if (p === -Infinity) {\n            return min(sum(abs(x), axis[1]), axis[0]);\n        }\n        if (p === 'fro' || p === 'euclidean') {\n            // norm(x) = sqrt(sum(pow(x, 2)))\n            return sqrt(sum(square(x), axis));\n        }\n        throw new Error(`Error in norm: invalid ord value: ${p}`);\n    }\n    throw new Error(`Error in norm: invalid axis: ${axis}`);\n}\nexport const norm = op({ norm_ });\n//# sourceMappingURL=norm.js.map","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes square of `x` element-wise: `x ^ 2`\n *\n * ```js\n * const x = tf.tensor1d([1, 2, Math.sqrt(2), -1]);\n *\n * x.square().print();  // or tf.square(x)\n * ```\n * @param x The input Tensor.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction square_(x) {\n    const $x = convertToTensor(x, 'x', 'square');\n    const attrs = {};\n    return ENGINE.runKernel('Square', { x: $x }, attrs);\n}\nexport const square = op({ square_ });\n//# sourceMappingURL=square.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Tile } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport * as util from '../util';\nimport { op } from './operation';\n/**\n * Construct a tensor by repeating it the number of times given by reps.\n *\n * This operation creates a new tensor by replicating `input` `reps`\n * times. The output tensor's i'th dimension has `input.shape[i] *\n * reps[i]` elements, and the values of `input` are replicated\n * `reps[i]` times along the i'th dimension. For example, tiling\n * `[a, b, c, d]` by `[2]` produces `[a, b, c, d, a, b, c, d]`.\n *\n * ```js\n * const a = tf.tensor1d([1, 2]);\n *\n * a.tile([2]).print();    // or a.tile([2])\n * ```\n *\n * ```js\n * const a = tf.tensor2d([1, 2, 3, 4], [2, 2]);\n *\n * a.tile([1, 2]).print();  // or a.tile([1, 2])\n * ```\n * @param x The tensor to tile.\n * @param reps Determines the number of replications per dimension.\n *\n * @doc {heading: 'Tensors', subheading: 'Slicing and Joining'}\n */\nfunction tile_(x, reps) {\n    const $x = convertToTensor(x, 'x', 'tile', 'string_or_numeric');\n    util.assert($x.rank === reps.length, () => `Error in transpose: rank of input ${$x.rank} ` +\n        `must match length of reps ${reps}.`);\n    const inputs = { x: $x };\n    const attrs = { reps };\n    return ENGINE.runKernel(Tile, inputs, attrs);\n}\nexport const tile = op({ tile_ });\n//# sourceMappingURL=tile.js.map"],"sourceRoot":""}