{"version":3,"sources":["webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/conv2d.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/bincount.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/eye.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/elu.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/depthwise_conv2d.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/broadcast_util.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/conv2d_backprop_input.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/cast.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/add.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/concat_2d.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/browser.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/concat_util.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/array_ops_util.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/erf_util.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/log.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/conv2d_backprop_filter.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/depthwise_conv2d_native_backprop_input.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/div.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/depthwise_conv2d_native_backprop_filter.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/abs.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/concat.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/conv_util.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/complex.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/clone.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/exp.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/buffer.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/expand_dims.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/axis_util.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/broadcast_to.js"],"names":["conv2d","conv2d_","x","filter","strides","pad","dataFormat","dilations","dimRoundingMode","$x","$filter","x4D","reshapedTo4D","rank","shape","inDepth","inputs","attrs","res","runKernel","bincount","bincount_","weights","size","$weights","dtype","eye","eye_","numRows","numColumns","batchShape","buff","n","i","set","out","toTensor","length","Error","elu","elu_","depthwiseConv2d","depthwiseConv2d_","getBroadcastDims","inShape","outShape","inRank","dims","dim","a","unshift","getReductionAxes","result","inDim","outAxis","outDim","assertAndGetBroadcastShape","shapeA","shapeB","l","Math","max","b","conv2DBackpropInput","conv2DBackpropInput_","xShape","dy","xShape4D","dy4D","outDepth","inputShape","cast","cast_","add","add_","$a","$b","concat2d","concat2d_","tensors","axis","fromPixels2DContext","fromPixels_","pixels","numChannels","isPixelData","isImageData","isVideo","isImage","isCanvasLike","isImageBitmap","data","Uint8Array","ImageData","HTMLVideoElement","HTMLImageElement","getContext","ImageBitmap","constructor","name","HAVE_CURRENT_DATA_READY_STATE","readyState","backendName","width","height","videoWidth","videoHeight","vals","values","getImageData","document","createElement","canvas","drawImage","Int32Array","numPixels","channel","canWrapPixelsToImageBitmap","window","hasOwnProperty","isNonEmptyPixels","async","fromPixelsAsync","getBool","imageBitmap","createImageBitmap","premultiplyAlpha","e","toPixels","img","$img","originalImgTensor","dispose","slice","depth","multiplier","bytes","Uint8ClampedArray","rgba","d","value","j","round","ctx","imageData","putImageData","fromPixels","assertParamsConsistent","shapes","forEach","firstShape","r","computeOutShape","outputShape","getReshaped","blockShape","prod","batchToSpace","reshaped","concat","push","spatialLength","getPermuted","reshapedRank","blockShapeRank","permuted","permutedBeforeBatch","permutedAfterBatch","getReshapedPermuted","reshapedPermuted","getSliceBeginCoords","crops","sliceBeginCoords","getSliceSize","uncroppedShape","sliceSize","ERF_P","ERF_A1","ERF_A2","ERF_A3","ERF_A4","ERF_A5","warn","msg","console","log","conv2DBackpropFilter","conv2DBackpropFilter_","filterShape","depthwiseConv2dNativeBackpropInput","depthwiseConv2dNativeBackpropInput_","div","div_","depthwiseConv2dNativeBackpropFilter","depthwiseConv2dNativeBackpropFilter_","abs","abs_","concat_","$tensors","tensor","attr","computeDilation2DInfo","computeConv2DInfo","convertConv2DDataFormat","computePool2DInfo","filterSize","roundingMode","filterHeight","filterWidth","parseTupleParam","computePool3DInfo","filterDepth","parse3TupleParam","$dataFormat","computeConv3DInfo","depthwise","batchSize","inHeight","inWidth","inChannels","filterChannels","strideHeight","strideWidth","dilationHeight","dilationWidth","effectiveFilterHeight","getEffectiveFilterSize","effectiveFilterWidth","padInfo","outHeight","outWidth","top","bottom","left","right","type","fieldSize","stride","zeroPad","computeDefaultPad","inputRows","inputCols","outputRows","outputCols","computeOutputShape2D","ceil","padAlongHeight","padAlongWidth","floor","getPadAndOutInfo","outChannels","strideDepth","dilationDepth","effectiveFilterDepth","front","back","inputDepth","outputDepths","computeOutputShape4D","padAlongDepth","get3DPadAndOutInfo","dilation","effectiveFieldSize","param","trunc","tupleValuesAreOne","dimA","dimB","dimC","eitherStridesOrDilationsAreOne","complex","complex_","real","imag","$real","$imag","clone","clone_","exp","exp_","buffer","expandDims","expandDims_","input","axesAreInnerMostDims","axes","combineLocations","outputLoc","reduceLoc","loc","outIdx","reduceIdx","indexOf","computeOutAndReduceShapes","aShape","map","expandShapeToKeepDim","assertAxesAreInnerMostDims","getAxesPermutation","getUndoAxesPermutation","sort","getInnerMostAxes","numAxes","broadcastTo","broadcastTo_","some","newShape","reps","Array","from"],"mappings":";sJAAA,wFAqFO,MAAMA,EAAS,YAAG,CAAEC,QA9B3B,SAAiBC,EAAGC,EAAQC,EAASC,EAAKC,EAAa,OAAQC,EAAY,CAAC,EAAG,GAAIC,GAC/E,MAAMC,EAAK,YAAgBP,EAAG,IAAK,UAC7BQ,EAAU,YAAgBP,EAAQ,SAAU,UAClD,IAAIQ,EAAMF,EACNG,GAAe,EACH,IAAZH,EAAGI,OACHD,GAAe,EACfD,EAAM,YAAQF,EAAI,CAAC,EAAGA,EAAGK,MAAM,GAAIL,EAAGK,MAAM,GAAIL,EAAGK,MAAM,MAE7D,IAAyB,IAAbH,EAAIE,MAAY,IAAM,uDAAuDF,EAAIE,UAC7F,IAA6B,IAAjBH,EAAQG,MAAY,IAC5B,wDAAGH,EAAQG,UACQ,MAAnBL,GACA,IAAY,IAAWH,IAAM,IACzB,uEAAmBG,iBAA+BH,OAE1D,MAAMU,EAAyB,SAAfT,EAAwBK,EAAIG,MAAM,GAAKH,EAAIG,MAAM,GACjE,IAAYC,IAAYL,EAAQI,MAAM,IAAI,IAAM,oCAAoCC,wCACtDL,EAAQI,MAAM,QAC5C,IAAY,IAAyCV,EAASG,IAAY,IACtE,uEAAeH,oBAA0BG,OAC7C,MAAMS,EAAS,CAAEd,EAAGS,EAAKR,OAAQO,GAC3BO,EAAQ,CAAEb,UAASC,MAAKC,aAAYC,YAAWC,mBAE/CU,EAAM,IAAOC,UAAU,IAAQH,EAAQC,GAC7C,OAAIL,EACO,YAAQM,EAAK,CAACA,EAAIJ,MAAM,GAAII,EAAIJ,MAAM,GAAII,EAAIJ,MAAM,KAExDI,M,iCCnFX,yEAmDO,MAAME,EAAW,YAAG,CAAEC,UAb7B,SAAmBnB,EAAGoB,EAASC,GAC3B,MAAMd,EAAK,YAAgBP,EAAG,IAAK,YAC7BsB,EAAW,YAAgBF,EAAS,UAAW,YACrD,IAAyB,UAAbb,EAAGgB,OAAmB,IAC9B,yDAAgChB,EAAGgB,UACvC,IAAYF,GAAQ,GAAG,IAAM,sCAAsCA,OACnE,IAAYC,EAASD,OAASd,EAAGc,MAA0B,IAAlBC,EAASD,MAAY,IAC1D,gGAAkCd,EAAGK,yBAClCU,EAASV,WAChB,MAAME,EAAS,CAAEd,EAAGO,EAAIa,QAASE,GAC3BP,EAAQ,CAAEM,QAChB,OAAO,IAAOJ,UAAU,IAAUH,EAAQC,O,iCCjD9C,4EAqEO,MAAMS,EAAM,YAAG,CAAEC,KAlCxB,SAAcC,EAASC,EAAYC,EAAYL,EAAQ,WACjC,MAAdI,IACAA,EAAaD,GAEjB,MAAMG,EAAO,YAAO,CAACH,EAASC,GAAaJ,GACrCO,EAAIJ,GAAWC,EAAaD,EAAUC,EAC5C,IAAK,IAAII,EAAI,EAAGA,EAAID,IAAKC,EACrBF,EAAKG,IAAI,EAAGD,EAAGA,GAEnB,MAAME,EAAM,YAAQJ,EAAKK,WAAY,CAACR,EAASC,IAC/C,GAAkB,MAAdC,EACA,OAAOK,EAGP,GAA0B,IAAtBL,EAAWO,OACX,OAAO,YAAK,YAAWF,EAAK,GAAI,CAACL,EAAW,GAAI,EAAG,IAElD,GAA0B,IAAtBA,EAAWO,OAEhB,OAAO,YAAK,YAAW,YAAWF,EAAK,GAAI,GAAI,CAACL,EAAW,GAAIA,EAAW,GAAI,EAAG,IAEhF,GAA0B,IAAtBA,EAAWO,OAEhB,OAAO,YAAK,YAAW,YAAW,YAAWF,EAAK,GAAI,GAAI,GAAI,CAC1DL,EAAW,GAAIA,EAAW,GAAIA,EAAW,GAAI,EAAG,IAIpD,MAAM,IAAIQ,MAEN,qEAA6BR,EAAWO,gB,iCCjExD,kEAqCO,MAAME,EAAM,YAAG,CAAEC,KALxB,SAActC,GACV,MACMc,EAAS,CAAEd,EADN,YAAgBA,EAAG,IAAK,QAEnC,OAAO,IAAOiB,UAAU,IAAKH,O,iCCnCjC,gFAgGO,MAAMyB,EAAkB,YAAG,CAAEC,iBA7BpC,SAA0BxC,EAAGC,EAAQC,EAASC,EAAKC,EAAa,OAAQC,EAAY,CAAC,EAAG,GAAIC,GACxF,MAAMC,EAAK,YAAgBP,EAAG,IAAK,mBAC7BQ,EAAU,YAAgBP,EAAQ,SAAU,mBAClD,IAAIQ,EAAMF,EACNG,GAAe,EACH,IAAZH,EAAGI,OACHD,GAAe,EACfD,EAAM,YAAQF,EAAI,CAAC,EAAGA,EAAGK,MAAM,GAAIL,EAAGK,MAAM,GAAIL,EAAGK,MAAM,MAE7D,IAAyB,IAAbH,EAAIE,MAAY,IACxB,gEAAQF,EAAIE,UAChB,IAA6B,IAAjBH,EAAQG,MAAY,IAC5B,iEAAGH,EAAQG,UACf,IAAYF,EAAIG,MAAM,KAAOJ,EAAQI,MAAM,IAAI,IAC3C,uDAAIH,EAAIG,MAAM,qDACJJ,EAAQI,MAAM,QACL,MAAnBN,GACA,IAAY,IAAWH,IAAM,IACzB,gFAAmBG,iBAA+BH,OAE1D,MAAMW,EAAS,CAAEd,EAAGS,EAAKR,OAAQO,GAC3BO,EAAQ,CAAEb,UAASC,MAAKC,aAAYC,YAAWC,mBAE/CU,EAAM,IAAOC,UAAU,IAAuBH,EAAQC,GAC5D,OAAIL,EACO,YAAQM,EAAK,CAACA,EAAIJ,MAAM,GAAII,EAAIJ,MAAM,GAAII,EAAIJ,MAAM,KAExDI,M,gCCrEJ,SAASyB,EAAiBC,EAASC,GACtC,MAAMC,EAASF,EAAQP,OACjBU,EAAO,GACb,IAAK,IAAId,EAAI,EAAGA,EAAIa,EAAQb,IAAK,CAC7B,MAAMe,EAAMF,EAAS,EAAIb,EACnBgB,EAAIL,EAAQI,IAAQ,GAChBH,EAASA,EAASR,OAAS,EAAIJ,IAAM,GACvC,GAAW,IAANgB,GACTF,EAAKG,QAAQF,GAGrB,OAAOD,EAMJ,SAASI,EAAiBP,EAASC,GACtC,MAAMO,EAAS,GACf,IAAK,IAAInB,EAAI,EAAGA,EAAIY,EAASR,OAAQJ,IAAK,CACtC,MAAMoB,EAAQT,EAAQA,EAAQP,OAASJ,EAAI,GACrCqB,EAAUT,EAASR,OAASJ,EAAI,EAChCsB,EAASV,EAASS,IACX,MAATD,GAA4B,IAAVA,GAAeE,EAAS,IAC1CH,EAAOF,QAAQI,GAGvB,OAAOF,EAEJ,SAASI,EAA2BC,EAAQC,GAC/C,MAAMN,EAAS,GACTO,EAAIC,KAAKC,IAAIJ,EAAOpB,OAAQqB,EAAOrB,QACzC,IAAK,IAAIJ,EAAI,EAAGA,EAAI0B,EAAG1B,IAAK,CACxB,IAAIgB,EAAIQ,EAAOA,EAAOpB,OAASJ,EAAI,GAC1B,MAALgB,IACAA,EAAI,GAER,IAAIa,EAAIJ,EAAOA,EAAOrB,OAASJ,EAAI,GAInC,GAHS,MAAL6B,IACAA,EAAI,GAEE,IAANb,EACAG,EAAOF,QAAQY,QAEd,GAAU,IAANA,EACLV,EAAOF,QAAQD,OAEd,IAAIA,IAAMa,EAAG,CAGd,MAAMxB,MADF,wDAAGmB,SAAcC,MAIrBN,EAAOF,QAAQD,IAGvB,OAAOG,EAjFX,uG,iCCAA,yEAiFO,MAAMW,EAAsB,YAAG,CAAEC,qBApCxC,SAA8BC,EAAQC,EAAI/D,EAAQC,EAASC,EAAKC,EAAa,OAAQE,GACjF,IAAYyD,EAAO5B,SAAW6B,EAAGrD,MAAM,IACnC,sBAAIoD,EAAO5B,2BAA2B6B,EAAGrD,qBAC7C,IAAIsD,EAAWF,EACXG,EAAOF,EACPtD,GAAe,EACH,IAAZsD,EAAGrD,OACHD,GAAe,EACfwD,EAAO,YAAQF,EAAI,CAAC,EAAGA,EAAGpD,MAAM,GAAIoD,EAAGpD,MAAM,GAAIoD,EAAGpD,MAAM,KAC1DqD,EAAW,CAAC,EAAGF,EAAO,GAAIA,EAAO,GAAIA,EAAO,KAEhD,IAAgC,IAApBE,EAAS9B,QAAc,IAC/B,qEAAG8B,EAAS9B,YAChB,IAA0B,IAAd+B,EAAKvD,MAAY,IACzB,4DAAQuD,EAAKvD,SACjB,IAA4B,IAAhBV,EAAOU,MAAY,IAC3B,gEAAQV,EAAOU,SACnB,MAAME,EAAyB,SAAfT,EAAwB6D,EAAS,GAAKA,EAAS,GACzDE,EAA0B,SAAf/D,EAAwB8D,EAAKtD,MAAM,GAAKsD,EAAKtD,MAAM,GACpE,IAAYC,IAAYZ,EAAOW,MAAM,IAAI,IAAM,4CAA4CC,wCACvDZ,EAAOW,MAAM,QACjD,IAAYuD,IAAalE,EAAOW,MAAM,IAAI,IAAM,6CAA6CuD,yCACxDlE,EAAOW,MAAM,QAC3B,MAAnBN,GACA,IAAY,IAAWH,IAAM,IACzB,+EAAmBG,iBAA+BH,OAE1D,MAAMW,EAAS,CAAEkD,GAAIE,EAAMjE,UACrBc,EAAQ,CAAEb,UAASC,MAAKC,aAAYE,kBAAiB8D,WAAYH,GAEjEjD,EAAM,IAAOC,UAAU,IAAqBH,EAAQC,GAC1D,OAAIL,EACO,YAAQM,EAAK,CAACA,EAAIJ,MAAM,GAAII,EAAIJ,MAAM,GAAII,EAAIJ,MAAM,KAExDI,M,gCC/EX,yEA+CO,MAAMqD,EAAO,YAAG,CAAEC,MAdzB,SAAetE,EAAGuB,GACd,MAAMhB,EAAK,YAAgBP,EAAG,IAAK,QAEnC,IAAK,IAAkBuB,GACnB,MAAM,IAAIa,MAAM,mCAAmCb,KAEvD,GAAc,WAAVA,GAAmC,WAAbhB,EAAGgB,OACf,WAAVA,GAAmC,WAAbhB,EAAGgB,MACzB,MAAM,IAAIa,MAAM,yCAEpB,MAAMtB,EAAS,CAAEd,EAAGO,GACdQ,EAAQ,CAAEQ,SAChB,OAAO,IAAON,UAAU,IAAMH,EAAQC,O,gCC7C1C,0EAmDO,MAAMwD,EAAM,YAAG,CAAEC,KAPxB,SAAczB,EAAGa,GACb,IAAIa,EAAK,YAAgB1B,EAAG,IAAK,OAC7B2B,EAAK,YAAgBd,EAAG,IAAK,QAChCa,EAAIC,GAAM,YAAeD,EAAIC,GAC9B,MAAM5D,EAAS,CAAEiC,EAAG0B,EAAIb,EAAGc,GAC3B,OAAO,IAAOzD,UAAU,IAAKH,O,iCCjDjC,qDAgCO,MAAM6D,EAAW,YAAG,CAAEC,UAH7B,SAAmBC,EAASC,GACxB,OAAO,YAAOD,EAASC,O,iCC9B3B,mNAyBA,IAAIC,EA0BJ,SAASC,EAAYC,EAAQC,EAAc,GAEvC,GAAIA,EAAc,EACd,MAAM,IAAI9C,MAAM,kEAEpB,GAAc,MAAV6C,EACA,MAAM,IAAI7C,MAAM,4DAEpB,IAAI+C,GAAc,EACdC,GAAc,EACdC,GAAU,EACVC,GAAU,EACVC,GAAe,EACfC,GAAgB,EACpB,GAAIP,EAAOQ,gBAAgBC,WACvBP,GAAc,OAEb,GAA2B,oBAAhB,WAA+BF,aAAkBU,UAC7DP,GAAc,OAEb,GAAkC,oBAAvB,kBACZH,aAAkBW,iBAClBP,GAAU,OAET,GAAkC,oBAAvB,kBACZJ,aAAkBY,iBAClBP,GAAU,OAGT,GAAyB,MAArBL,EAAOa,WACZP,GAAe,MAEd,MAA6B,oBAAlB,aAAiCN,aAAkBc,aAI/D,MAAM,IAAI3D,MAIN,qPAAW6C,EAAOe,YAAYC,QAPlCT,GAAgB,EASpB,GAAIH,EAAS,CACT,MAAMa,EAAgC,EACtC,GAAIb,GACAJ,EAAOkB,WACHD,EACJ,MAAM,IAAI9D,MAAM,yGAOxB,GAAc,MADC,YAAU,IAAY,IAAOgE,aACxB,CAChB,MAAMtF,EAAS,CAAEmE,UACXlE,EAAQ,CAAEmE,eAChB,OAAO,IAAOjE,UAAU,IAAYH,EAAQC,GAEhD,MAAOsF,EAAOC,GAAUjB,EACpB,CACIJ,EAAOsB,WACPtB,EAAOuB,aAEX,CAACvB,EAAOoB,MAAOpB,EAAOqB,QAC1B,IAAIG,EAkBAC,EACJ,GAlBInB,EACAkB,EAEIxB,EAAOa,WAAW,MAAMa,aAAa,EAAG,EAAGN,EAAOC,GAAQb,KAEzDL,GAAeD,EACpBsB,EAAOxB,EAAOQ,MAETH,GAAWD,GAAWG,KACA,MAAvBT,IACAA,EAAsB6B,SAASC,cAAc,UAAUf,WAAW,OAEtEf,EAAoB+B,OAAOT,MAAQA,EACnCtB,EAAoB+B,OAAOR,OAASA,EACpCvB,EAAoBgC,UAAU9B,EAAQ,EAAG,EAAGoB,EAAOC,GACnDG,EAAO1B,EAAoB4B,aAAa,EAAG,EAAGN,EAAOC,GAAQb,MAG7C,IAAhBP,EACAwB,EAAS,IAAIM,WAAWP,OAEvB,CACD,MAAMQ,EAAYZ,EAAQC,EAC1BI,EAAS,IAAIM,WAAWC,EAAY/B,GACpC,IAAK,IAAInD,EAAI,EAAGA,EAAIkF,EAAWlF,IAC3B,IAAK,IAAImF,EAAU,EAAGA,EAAUhC,IAAegC,EAC3CR,EAAO3E,EAAImD,EAAcgC,GAAWT,EAAS,EAAJ1E,EAAQmF,GAI7D,MAAMvE,EAAW,CAAC2D,EAAQD,EAAOnB,GACjC,OAAO,YAASwB,EAAQ/D,EAAU,SAetC,SAASwE,EAA2BlC,GAChC,MARyB,oBAAXmC,QACe,oBAAlB,aACPA,OAAOC,eAAe,wBAMgBpC,aAAkBc,cAJhE,SAA0Bd,GACtB,OAAiB,MAAVA,GAAmC,IAAjBA,EAAOoB,OAAiC,IAAlBpB,EAAOqB,OAIlDgB,CAAiBrC,KAbzB,SAAqBA,GACjB,OAAkB,MAAVA,GAAoBA,EAAOQ,gBAAgBC,WAYlBP,CAAYF,GA4B1CsC,eAAeC,EAAgBvC,EAAQC,EAAc,GACxD,IAAIpE,EAAS,KAGb,GAAI,cAAM2G,QAAQ,wBACdN,EAA2BlC,GAAS,CAGpC,IAAIyC,EACJ,IAKIA,QAAoBC,kBAAkB1C,EAAQ,CAAE2C,iBAAkB,SAEtE,MAAOC,GACHH,EAAc,KAUd5G,EAFe,MAAf4G,GAAuBA,EAAYrB,QAAUpB,EAAOoB,OACpDqB,EAAYpB,SAAWrB,EAAOqB,OACrBoB,EAGAzC,OAIbnE,EAASmE,EAEb,OAAOD,EAAYlE,EAAQoE,GAsBxBqC,eAAeO,EAASC,EAAKjB,GAChC,IAAIkB,EAAO,YAAgBD,EAAK,MAAO,YACvC,KAAMA,aAAe,KAAS,CAE1B,MAAME,EAAoBD,EAC1BA,EAAO,YAAKC,EAAmB,SAC/BA,EAAkBC,UAEtB,GAAkB,IAAdF,EAAKrH,MAA4B,IAAdqH,EAAKrH,KACxB,MAAM,IAAIyB,MAAM,wDAAwD4F,EAAKrH,SAEjF,MAAO2F,EAAQD,GAAS2B,EAAKpH,MAAMuH,MAAM,EAAG,GACtCC,EAAsB,IAAdJ,EAAKrH,KAAa,EAAIqH,EAAKpH,MAAM,GAC/C,GAAIwH,EAAQ,GAAe,IAAVA,EACb,MAAM,IAAIhG,MACN,0DAAqBgG,KAE7B,GAAmB,YAAfJ,EAAKzG,OAAsC,UAAfyG,EAAKzG,MACjC,MAAM,IAAIa,MAAM,kCAAkC4F,EAAKzG,+CAG3D,MAAMkE,QAAauC,EAAKvC,OAClB4C,EAA4B,YAAfL,EAAKzG,MAAsB,IAAM,EAC9C+G,EAAQ,IAAIC,kBAAkBlC,EAAQC,EAAS,GACrD,IAAK,IAAIvE,EAAI,EAAGA,EAAIuE,EAASD,IAAStE,EAAG,CACrC,MAAMyG,EAAO,CAAC,EAAG,EAAG,EAAG,KACvB,IAAK,IAAIC,EAAI,EAAGA,EAAIL,EAAOK,IAAK,CAC5B,MAAMC,EAAQjD,EAAK1D,EAAIqG,EAAQK,GAC/B,GAAmB,YAAfT,EAAKzG,OACL,GAAImH,EAAQ,GAAKA,EAAQ,EACrB,MAAM,IAAItG,MACN,mFAAiCsG,WAGxC,GAAmB,UAAfV,EAAKzG,QACNmH,EAAQ,GAAKA,EAAQ,KACrB,MAAM,IAAItG,MACN,mFAAmCsG,MAGjC,IAAVN,GACAI,EAAK,GAAKE,EAAQL,EAClBG,EAAK,GAAKE,EAAQL,EAClBG,EAAK,GAAKE,EAAQL,GAGlBG,EAAKC,GAAKC,EAAQL,EAG1B,MAAMM,EAAQ,EAAJ5G,EACVuG,EAAMK,EAAI,GAAKjF,KAAKkF,MAAMJ,EAAK,IAC/BF,EAAMK,EAAI,GAAKjF,KAAKkF,MAAMJ,EAAK,IAC/BF,EAAMK,EAAI,GAAKjF,KAAKkF,MAAMJ,EAAK,IAC/BF,EAAMK,EAAI,GAAKjF,KAAKkF,MAAMJ,EAAK,IAEnC,GAAc,MAAV1B,EAAgB,CAChBA,EAAOT,MAAQA,EACfS,EAAOR,OAASA,EAChB,MAAMuC,EAAM/B,EAAOhB,WAAW,MACxBgD,EAAY,IAAInD,UAAU2C,EAAOjC,EAAOC,GAC9CuC,EAAIE,aAAaD,EAAW,EAAG,GAKnC,OAHId,IAASD,GACTC,EAAKE,UAEFI,EAEJ,MAAMU,EAAa,YAAG,CAAEhE,iB,iCC9T/B,+EAiBO,SAASiE,EAAuBC,EAAQpE,GAC3C,MAAMnE,EAAOuI,EAAO,GAAG/G,OACvB+G,EAAOC,SAAQ,CAACvI,EAAOmB,KACnB,IAAYnB,EAAMuB,SAAWxB,GAAM,IAAM,kBAAkBA,uBAA0BoB,gDACrDpB,UAEpC,IAAYmE,GAAQ,GAAKA,EAAOnE,GAAM,IAAM,kBAAkBA,kCAAqCA,EAAO,OAC1G,MAAMyI,EAAaF,EAAO,GAC1BA,EAAOC,SAAQ,CAACvI,EAAOmB,KACnB,IAAK,IAAIsH,EAAI,EAAGA,EAAI1I,EAAM0I,IACtB,IAAaA,IAAMvE,GAAUlE,EAAMyI,KAAOD,EAAWC,IAAK,IAAM,kBAAkB1I,wBAA2BoB,OAAOnB,4CACvEwI,sCACNrH,UAI5C,SAASuH,EAAgBJ,EAAQpE,GACpC,MAAMyE,EAAcL,EAAO,GAAGf,QAC9B,IAAK,IAAIpG,EAAI,EAAGA,EAAImH,EAAO/G,OAAQJ,IAC/BwH,EAAYzE,IAASoE,EAAOnH,GAAG+C,GAEnC,OAAOyE,I,iCCdJ,SAASC,EAAYpF,EAAYqF,EAAYC,EAAMC,GAAe,GACrE,IAAIC,EAAW,GACf,GAAID,EACAC,EAAWA,EAASC,OAAOJ,EAAWtB,MAAM,IAC5CyB,EAASE,KAAK1F,EAAW,GAAKsF,GAC9BE,EAAWA,EAASC,OAAOzF,EAAW+D,MAAM,QAE3C,CACDyB,EAAWA,EAASC,OAAOzF,EAAW,IACtC,MAAM2F,EAAgBN,EAAWtH,OACjC,IAAK,IAAIJ,EAAI,EAAGA,EAAIgI,IAAiBhI,EACjC6H,EACIA,EAASC,OAAO,CAACzF,EAAWrC,EAAI,GAAK0H,EAAW1H,GAAI0H,EAAW1H,KAEvE6H,EAAWA,EAASC,OAAOzF,EAAW+D,MAAM4B,EAAgB,IAEhE,OAAOH,EAWJ,SAASI,EAAYC,EAAcC,EAAgBP,GAAe,GACrE,MAAMQ,EAAW,GACjB,GAAIR,EAAc,CACdQ,EAASL,KAAKI,GACd,IAAK,IAAInI,EAAImI,EAAiB,EAAGnI,EAAIkI,IAAgBlI,EAC7CA,GAAK,EAAImI,GACTC,EAASL,KAAK/H,GACdoI,EAASL,KAAK/H,GAAKmI,EAAiB,KAGpCC,EAASL,KAAK/H,OAIrB,CACD,MAAMqI,EAAsB,GACtBC,EAAqB,GAC3B,IAAK,IAAItI,EAAI,EAAGA,EAAIkI,IAAgBlI,EAC5BA,GAAsB,EAAjBmI,EAAqB,GAAKnI,EAAI,GAAM,EACzCsI,EAAmBP,KAAK/H,GAGxBqI,EAAoBN,KAAK/H,GAGjCoI,EAASL,QAAQM,GACjBD,EAASL,KAAK,GACdK,EAASL,QAAQO,GAErB,OAAOF,EAWJ,SAASG,EAAoBlG,EAAYqF,EAAYC,EAAMC,GAAe,GAC7E,MAAMY,EAAmB,GACrBZ,EACAY,EAAiBT,KAAK1F,EAAW,GAAKsF,GAGtCa,EAAiBT,KAAK1F,EAAW,GAAKsF,GAE1C,IAAK,IAAI3H,EAAI,EAAGA,EAAIqC,EAAWjC,SAAUJ,EACjCA,GAAK0H,EAAWtH,OACZwH,EACAY,EAAiBT,KAAKL,EAAW1H,EAAI,GAAKqC,EAAWrC,IAGrDwI,EAAiBT,KAAK1F,EAAWrC,GAAK0H,EAAW1H,EAAI,IAIzDwI,EAAiBT,KAAK1F,EAAWrC,IAGzC,OAAOwI,EAMJ,SAASC,EAAoBC,EAAOhB,GACvC,MAAMiB,EAAmB,CAAC,GAC1B,IAAK,IAAI3I,EAAI,EAAGA,EAAI0H,IAAc1H,EAC9B2I,EAAiBZ,KAAKW,EAAM1I,GAAG,IAEnC,OAAO2I,EAaJ,SAASC,EAAaC,EAAgBH,EAAOhB,GAChD,MAAMoB,EAAYD,EAAezC,MAAM,EAAG,GAC1C,IAAK,IAAIpG,EAAI,EAAGA,EAAI0H,IAAc1H,EAC9B8I,EAAUf,KAAKc,EAAe7I,EAAI,GAAK0I,EAAM1I,GAAG,GAAK0I,EAAM1I,GAAG,IAElE,OAAO8I,EA7IX,2K,iCCAA,4MAgBO,MAAMC,EAAQ,SACRC,EAAS,WACTC,GAAU,WACVC,EAAS,YACTC,GAAU,YACVC,EAAS,a,iCCrBtB,+EAiBO,SAASC,KAAQC,GACf,cAAM5D,QAAQ,YACf6D,QAAQF,QAAQC,GAGjB,SAASE,KAAOF,GACd,cAAM5D,QAAQ,YACf6D,QAAQC,OAAOF,K,iCCxBvB,yEAuEO,MAAMG,EAAuB,YAAG,CAAEC,sBA9BzC,SAA+BzL,EAAGgE,EAAI0H,EAAaxL,EAASC,EAAKC,EAAa,OAAQE,GAClF,IAAIG,EAAMT,EACK,IAAXA,EAAEW,OACFF,EAAM,YAAQT,EAAG,CAAC,EAAGA,EAAEY,MAAM,GAAIZ,EAAEY,MAAM,GAAIZ,EAAEY,MAAM,MAEzD,IAAIsD,EAAOF,EACO,IAAdE,EAAKvD,OACLuD,EAAO,YAAQF,EAAI,CAAC,EAAGA,EAAGpD,MAAM,GAAIoD,EAAGpD,MAAM,GAAIoD,EAAGpD,MAAM,MAE9D,IAAyB,IAAbH,EAAIE,MAAY,IACxB,iEAAGF,EAAIG,WACX,IAA0B,IAAdsD,EAAKvD,MAAY,IACzB,8DAAGuD,EAAKtD,WACZ,IAAmC,IAAvB8K,EAAYvJ,QAAc,IAClC,mEAAGuJ,OACP,MAAM7K,EAAyB,SAAfT,EAAwBK,EAAIG,MAAM,GAAKH,EAAIG,MAAM,GAC3DuD,EAA0B,SAAf/D,EAAwB8D,EAAKtD,MAAM,GAAKsD,EAAKtD,MAAM,GACpE,IAAYC,IAAY6K,EAAY,IAAI,IAAM,4CAA4C7K,wCACtD6K,EAAY,QAChD,IAAYvH,IAAauH,EAAY,IAAI,IAAM,0CAA0CvH,0CACnDuH,EAAY,SAC3B,MAAnBpL,GACA,IAAY,IAAWH,IAAM,IACzB,gFAAmBG,iBAA+BH,OAE1D,MAAMW,EAAS,CAAEd,EAAGS,EAAKuD,GAAIE,GACvBnD,EAAQ,CAAEb,UAASC,MAAKC,aAAYE,kBAAiBoL,eAE3D,OAAO,IAAOzK,UAAU,IAAsBH,EAAQC,O,iCCrE1D,kEAqCO,MAAM4K,EAAqC,YAAG,CAAEC,oCAjBvD,SAA6C7H,EAAQC,EAAI/D,EAAQC,EAASC,EAAKE,EAAY,CAAC,EAAG,GAAIC,GAC/F,IAAI4D,EAAOF,EACPtD,GAAe,EACH,IAAZsD,EAAGrD,OACHD,GAAe,EACfwD,EAAO,YAAQF,EAAI,CAAC,EAAGA,EAAGpD,MAAM,GAAIoD,EAAGpD,MAAM,GAAIoD,EAAGpD,MAAM,MAE9D,MAAME,EAAS,CAAEkD,GAAIE,EAAMjE,UACrBc,EAAQ,CAAEb,UAASC,MAAKG,kBAAiBD,YAAW+D,WAAYL,GAChE/C,EAEN,IAAOC,UAAU,IAAoCH,EAAQC,GAC7D,OAAIL,EACO,YAAQM,EAAK,CAACA,EAAIJ,MAAM,GAAII,EAAIJ,MAAM,GAAII,EAAIJ,MAAM,KAExDI,M,gCCnCX,mFA0DO,MAAM6K,EAAM,YAAG,CAAEC,KAZxB,SAAc/I,EAAGa,GACb,IAAIa,EAAK,YAAgB1B,EAAG,IAAK,OAC7B2B,EAAK,YAAgBd,EAAG,IAAK,OAEjC,IADCa,EAAIC,GAAM,YAAeD,EAAIC,GACb,UAAbD,EAAGlD,OAAkC,UAAbmD,EAAGnD,MAC3B,OAAO,YAASkD,EAAIC,GAExB,MAAM5D,EAAS,CAAEiC,EAAG0B,EAAIb,EAAGc,GAG3B,OAAO,IAAOzD,UAAU,KAASH,EAFnB,Q,iCCtDlB,kEAkCO,MAAMiL,EAAsC,YAAG,CAAEC,qCAdxD,SAA8ChM,EAAGgE,EAAI0H,EAAaxL,EAASC,EAAKE,EAAY,CAAC,EAAG,GAAIC,GAChG,IAAIG,EAAMT,EACK,IAAXA,EAAEW,OACFF,EAAM,YAAQT,EAAG,CAAC,EAAGA,EAAEY,MAAM,GAAIZ,EAAEY,MAAM,GAAIZ,EAAEY,MAAM,MAEzD,IAAIsD,EAAOF,EACO,IAAdE,EAAKvD,OACLuD,EAAO,YAAQF,EAAI,CAAC,EAAGA,EAAGpD,MAAM,GAAIoD,EAAGpD,MAAM,GAAIoD,EAAGpD,MAAM,MAE9D,MAAME,EAAS,CAAEd,EAAGS,EAAKuD,GAAIE,GACvBnD,EAAQ,CAAEb,UAASC,MAAKG,kBAAiBD,YAAWqL,eAE1D,OAAO,IAAOzK,UAAU,IAAqCH,EAAQC,O,gCChCzE,kEA2CO,MAAMkL,EAAM,YAAG,CAAEC,KAXxB,SAAclM,GACV,MAAMO,EAAK,YAAgBP,EAAG,IAAK,OACnC,GAAiB,cAAbO,EAAGgB,MAAuB,CAC1B,MAAMT,EAAS,CAAEd,EAAGO,GACpB,OAAO,IAAOU,UAAU,IAAYH,GAEnC,CACD,MAAMA,EAAS,CAAEd,EAAGO,GACpB,OAAO,IAAOU,UAAU,IAAKH,Q,gCCxCrC,iFAgFO,MAAM+I,EAAS,YAAG,CAAEsC,QAlB3B,SAAiBtH,EAASC,EAAO,GAC7B,YAAOD,EAAQ1C,QAAU,GAAG,IAAM,uCAClC,MAAMiK,EAAW,YAAqBvH,EAAS,UAAW,SAAU,qBASpE,GAR0B,cAAtBuH,EAAS,GAAG7K,OACZ6K,EAASjD,SAAQkD,IACb,GAAqB,cAAjBA,EAAO9K,MACP,MAAM,IAAIa,MAAM,4EACTiK,EAAO9K,cAIF,IAApB6K,EAASjK,OACT,OAAO,YAAMiK,EAAS,IAE1B,MAAMtL,EAASsL,EACTE,EAAO,CAAExH,QACf,OAAO,IAAO7D,UAAU,IAAQH,EAAQwL,O,gCCtCrC,SAASC,EAAsBnI,EAAYsH,EAAaxL,EAASC,EAAKC,EAAa,OAAQC,GAQ9F,OAAOmM,EAAkBpI,EAFJ,IAAIsH,EADHtH,EAAW,IAGkBlE,EAASG,EAAWF,EAAK,KAAyB,KADjFsM,EAAwBrM,IAGzC,SAASsM,EAAkBhK,EAASiK,EAAYzM,EAASG,EAAWF,EAAKyM,EAAcxM,EAAa,gBACvG,MAAOyM,EAAcC,GAAeC,EAAgBJ,GACpD,IAAIjB,EACJ,GAAmB,iBAAftL,EACAsL,EAAc,CAACmB,EAAcC,EAAapK,EAAQ,GAAIA,EAAQ,QAE7D,IAAmB,kBAAftC,EAIL,MAAM,IAAIgC,MAAM,sBAAsBhC,KAHtCsL,EAAc,CAACmB,EAAcC,EAAapK,EAAQ,GAAIA,EAAQ,IAKlE,OAAO8J,EAAkB9J,EAASgJ,EAAaxL,EAASG,EAAWF,EAAKyM,GAAc,EAAOxM,GAK1F,SAAS4M,EAAkBtK,EAASiK,EAAYzM,EAASG,EAAWF,EAAKyM,EAAcxM,EAAa,SACvG,MAAO6M,EAAaJ,EAAcC,GAAeI,EAAiBP,GAClE,IAAIjB,EACAyB,EACJ,GAAmB,UAAf/M,EACA+M,EAAc,eACdzB,EACI,CAACuB,EAAaJ,EAAcC,EAAapK,EAAQ,GAAIA,EAAQ,QAEhE,IAAmB,UAAftC,EAML,MAAM,IAAIgC,MAAM,sBAAsBhC,KALtC+M,EAAc,gBACdzB,EACI,CAACuB,EAAaJ,EAAcC,EAAapK,EAAQ,GAAIA,EAAQ,IAKrE,OAAO0K,EAAkB1K,EAASgJ,EAAaxL,EAASG,EAAWF,GAAK,EAAOgN,EAAaP,GAMzF,SAASJ,EAAkB9J,EAASgJ,EAAaxL,EAASG,EAAWF,EAAKyM,EAAcS,GAAY,EAAOjN,EAAa,gBAC3H,IAAKkN,EAAWC,EAAUC,EAASC,GAAc,EAAE,GAAI,GAAI,GAAI,GAC/D,GAAmB,iBAAfrN,GACCkN,EAAWC,EAAUC,EAASC,GAAc/K,MAE5C,IAAmB,kBAAftC,EAIL,MAAM,IAAIgC,MAAM,sBAAsBhC,MAHrCkN,EAAWG,EAAYF,EAAUC,GAAW9K,EAKjD,MAAOmK,EAAcC,EAAa,CAAEY,GAAkBhC,GAC/CiC,EAAcC,GAAeb,EAAgB7M,IAC7C2N,EAAgBC,GAAiBf,EAAgB1M,GAClD0N,EAAwBC,EAAuBnB,EAAcgB,GAC7DI,EAAuBD,EAAuBlB,EAAagB,IAC3D,QAAEI,EAAO,UAAEC,EAAS,SAAEC,GAkJhC,SAA0BjO,EAAKoN,EAAUC,EAASG,EAAcC,EAAaf,EAAcC,EAAaF,EAAcxM,GAClH,IAAI8N,EACAC,EACAC,EACJ,GAAmB,iBAARjO,EAAkB,CAEzB+N,EAAU,CAAEG,IAAKlO,EAAKmO,OAAQnO,EAAKoO,KAAMpO,EAAKqO,MAAOrO,EAAKsO,KADjC,IAARtO,EAAa,QAAU,UAExC,MAAMwC,EA9Dd,SAA8BD,EAASgM,EAAWC,EAAQC,EAAShC,GAChD,MAAXgC,IACAA,EAAUC,EAAkBnM,EAASgM,EAAWC,IAEpD,MAAMG,EAAYpM,EAAQ,GACpBqM,EAAYrM,EAAQ,GACpBsM,EAAapG,GAAOkG,EAAYJ,EAAY,EAAIE,GAAWD,EAAS,EAAG/B,GACvEqC,EAAarG,GAAOmG,EAAYL,EAAY,EAAIE,GAAWD,EAAS,EAAG/B,GAC7E,MAAO,CAACoC,EAAYC,GAsDCC,CAAqB,CAAC3B,EAAUC,GAAUX,EAAcc,EAAcxN,EAAKyM,GAC5FuB,EAAYxL,EAAS,GACrByL,EAAWzL,EAAS,QAEnB,GAAY,SAARxC,EAAgB,CACrBgO,EAAYzK,KAAKyL,KAAK5B,EAAWI,GACjCS,EAAW1K,KAAKyL,KAAK3B,EAAUI,GAC/B,MAAMwB,EAAiB1L,KAAKC,IAAI,GAAIwK,EAAY,GAAKR,EAAed,EAAeU,GAC7E8B,EAAgB3L,KAAKC,IAAI,GAAIyK,EAAW,GAAKR,EAAcd,EAAcU,GACzEa,EAAM3K,KAAK4L,MAAMF,EAAiB,GAClCd,EAASc,EAAiBf,EAC1BE,EAAO7K,KAAK4L,MAAMD,EAAgB,GAExCnB,EAAU,CAAEG,MAAKC,SAAQC,OAAMC,MADjBa,EAAgBd,EACQE,KAAM,aAE3C,GAAY,UAARtO,EACL+N,EAAU,CAAEG,IAAK,EAAGC,OAAQ,EAAGC,KAAM,EAAGC,MAAO,EAAGC,KAAM,SACxDN,EAAYzK,KAAKyL,MAAM5B,EAAWV,EAAe,GAAKc,GACtDS,EAAW1K,KAAKyL,MAAM3B,EAAUV,EAAc,GAAKc,OAElD,IAAmB,iBAARzN,EAaZ,MAAMiC,MAAM,8BAA8BjC,KAbZ,CAC9B,MAAMkO,EAAqB,iBAAfjO,EAAgCD,EAAI,GAAG,GAAKA,EAAI,GAAG,GACzDmO,EAAwB,iBAAflO,EAAgCD,EAAI,GAAG,GAAKA,EAAI,GAAG,GAC5DoO,EAAsB,iBAAfnO,EAAgCD,EAAI,GAAG,GAAKA,EAAI,GAAG,GAC1DqO,EAAuB,iBAAfpO,EAAgCD,EAAI,GAAG,GAAKA,EAAI,GAAG,GAIjE+N,EAAU,CAAEG,MAAKC,SAAQC,OAAMC,QAAOC,KAHb,IAARJ,GAAwB,IAAXC,GAAyB,IAATC,GAAwB,IAAVC,EACxD,QACA,YAEJL,EAAYvF,GAAO2E,EAAWV,EAAewB,EAAMC,GAAUX,EAAe,EAAGf,GAC/EwB,EAAWxF,GAAO4E,EAAUV,EAAcyB,EAAOC,GAASZ,EAAc,EAAGhB,IAK/E,MAAO,CAAEsB,UAASC,YAAWC,YA5LYmB,CAAiBpP,EAAKoN,EAAUC,EAASG,EAAcC,EAAaG,EAAuBE,EAAsBrB,EAAcxM,GAClKoP,EAAcnC,EAAYK,EAAiBD,EAAaC,EAC9D,IAAI/K,EAOJ,MANmB,kBAAfvC,EACAuC,EAAW,CAAC2K,EAAWkC,EAAarB,EAAWC,GAE3B,iBAAfhO,IACLuC,EAAW,CAAC2K,EAAWa,EAAWC,EAAUoB,IAEzC,CACHlC,YACAlN,aACAmN,WACAC,UACAC,aACAU,YACAC,WACAoB,cACAtB,UACAP,eACAC,cACAf,eACAC,cACAiB,wBACAE,uBACAJ,iBACAC,gBACApL,UACAC,WACA+I,eAOD,SAAS0B,EAAkB1K,EAASgJ,EAAaxL,EAASG,EAAWF,EAAKkN,GAAY,EAAOjN,EAAa,eAAgBwM,GAC7H,IAAKU,EAAWzM,EAAS0M,EAAUC,EAASC,GAAc,EAAE,GAAI,GAAI,GAAI,GAAI,GAC5E,GAAmB,iBAAfrN,GACCkN,EAAWzM,EAAS0M,EAAUC,EAASC,GAAc/K,MAErD,IAAmB,kBAAftC,EAIL,MAAM,IAAIgC,MAAM,sBAAsBhC,MAHrCkN,EAAWG,EAAY5M,EAAS0M,EAAUC,GAAW9K,EAK1D,MAAOuK,EAAaJ,EAAcC,EAAa,CAAEY,GAAkBhC,GAC5D+D,EAAa9B,EAAcC,GAAeV,EAAiBhN,IAC3DwP,EAAe7B,EAAgBC,GAAiBZ,EAAiB7M,GAClEsP,EAAuB3B,EAAuBf,EAAayC,GAC3D3B,EAAwBC,EAAuBnB,EAAcgB,GAC7DI,EAAuBD,EAAuBlB,EAAagB,IAC3D,QAAEI,EAAO,SAAE/J,EAAQ,UAAEgK,EAAS,SAAEC,GAyI1C,SAA4BjO,EAAKU,EAAS0M,EAAUC,EAASiC,EAAa9B,EAAcC,EAAaX,EAAaJ,EAAcC,EAAaF,GACzI,IAAIsB,EACA/J,EACAgK,EACAC,EACJ,GAAmB,iBAARjO,EAAkB,CAEzB+N,EAAU,CACNG,IAAKlO,EACLmO,OAAQnO,EACRoO,KAAMpO,EACNqO,MAAOrO,EACPyP,MAAOzP,EACP0P,KAAM1P,EACNsO,KARqB,IAARtO,EAAa,QAAU,UAUxC,MAAMwC,EAzGd,SAA8BD,EAASgM,EAAWc,EAAab,EAAQC,EAAShC,GAC7D,MAAXgC,IACAA,EAAUC,EAAkBnM,EAASgM,EAAWC,IAEpD,MAAMmB,EAAapN,EAAQ,GACrBoM,EAAYpM,EAAQ,GACpBqM,EAAYrM,EAAQ,GACpBqN,EAAenH,GAAOkH,EAAapB,EAAY,EAAIE,GAAWD,EAAS,EAAG/B,GAC1EoC,EAAapG,GAAOkG,EAAYJ,EAAY,EAAIE,GAAWD,EAAS,EAAG/B,GACvEqC,EAAarG,GAAOmG,EAAYL,EAAY,EAAIE,GAAWD,EAAS,EAAG/B,GAC7E,MAAO,CAACmD,EAAcf,EAAYC,EAAYO,GA+FzBQ,CAAqB,CAACnP,EAAS0M,EAAUC,EAAS,GAAIP,EAAa,EAAGwC,EAAatP,EAAKyM,GACzGzI,EAAWxB,EAAS,GACpBwL,EAAYxL,EAAS,GACrByL,EAAWzL,EAAS,QAEnB,GAAY,SAARxC,EAAgB,CACrBgE,EAAWT,KAAKyL,KAAKtO,EAAU4O,GAC/BtB,EAAYzK,KAAKyL,KAAK5B,EAAWI,GACjCS,EAAW1K,KAAKyL,KAAK3B,EAAUI,GAC/B,MAAMqC,GAAiB9L,EAAW,GAAKsL,EAAcxC,EAAcpM,EAC7DuO,GAAkBjB,EAAY,GAAKR,EAAed,EAAeU,EACjE8B,GAAiBjB,EAAW,GAAKR,EAAcd,EAAcU,EAC7DoC,EAAQlM,KAAK4L,MAAMW,EAAgB,GACnCJ,EAAOI,EAAgBL,EACvBvB,EAAM3K,KAAK4L,MAAMF,EAAiB,GAClCd,EAASc,EAAiBf,EAC1BE,EAAO7K,KAAK4L,MAAMD,EAAgB,GAExCnB,EAAU,CAAEG,MAAKC,SAAQC,OAAMC,MADjBa,EAAgBd,EACQqB,QAAOC,OAAMpB,KAAM,YAExD,IAAY,UAARtO,EAeL,MAAMiC,MAAM,8BAA8BjC,KAd1C+N,EAAU,CACNG,IAAK,EACLC,OAAQ,EACRC,KAAM,EACNC,MAAO,EACPoB,MAAO,EACPC,KAAM,EACNpB,KAAM,SAEVtK,EAAWT,KAAKyL,MAAMtO,EAAUoM,EAAc,GAAKwC,GACnDtB,EAAYzK,KAAKyL,MAAM5B,EAAWV,EAAe,GAAKc,GACtDS,EAAW1K,KAAKyL,MAAM3B,EAAUV,EAAc,GAAKc,GAKvD,MAAO,CAAEM,UAAS/J,WAAUgK,YAAWC,YA9LY8B,CAAmB/P,EAAKU,EAAS0M,EAAUC,EAASiC,EAAa9B,EAAcC,EAAa+B,EAAsB5B,EAAuBE,EAAsBrB,GAC5M4C,EAAcnC,EAAYK,EAAiBD,EAAaC,EAC9D,IAAI/K,EAOJ,MANmB,kBAAfvC,EACAuC,EAAW,CAAC2K,EAAWkC,EAAarL,EAAUgK,EAAWC,GAErC,iBAAfhO,IACLuC,EAAW,CAAC2K,EAAWnJ,EAAUgK,EAAWC,EAAUoB,IAEnD,CACHlC,YACAlN,aACAS,UACA0M,WACAC,UACAC,aACAtJ,WACAgK,YACAC,WACAoB,cACAtB,UACAuB,cACA9B,eACAC,cACAX,cACAJ,eACAC,cACA6C,uBACA5B,wBACAE,uBACAyB,gBACA7B,iBACAC,gBACApL,UACAC,WACA+I,eAyBD,SAASmD,EAAkBzK,EAAYsK,EAAWC,EAAQwB,EAAW,GACxE,MAAMC,EAAqBpC,EAAuBU,EAAWyB,GAC7D,OAAOzM,KAAK4L,OAAOlL,EAAW,IAAMuK,EAAS,GAAKA,EAASyB,GAAsB,GAErF,SAASrD,EAAgBsD,GACrB,MAAqB,iBAAVA,EACA,CAACA,EAAOA,EAAOA,GAEL,IAAjBA,EAAMlO,OACC,CAACkO,EAAM,GAAIA,EAAM,GAAI,GAEzBA,EAEX,SAASnD,EAAiBmD,GACtB,MAAwB,iBAAVA,EAAqB,CAACA,EAAOA,EAAOA,GAASA,EAa/D,SAASrC,EAAuBrB,EAAYwD,GACxC,OAAIA,GAAY,EACLxD,EAEJA,GAAcA,EAAa,IAAMwD,EAAW,GA2GvD,SAASvH,EAAMF,EAAOkE,GAClB,IAAKA,EACD,OAAOlJ,KAAK4M,MAAM5H,GAEtB,OAAQkE,GACJ,IAAK,QAED,OAAOlJ,KAAKkF,MAAMF,GACtB,IAAK,OAED,OAAOhF,KAAKyL,KAAKzG,GACrB,IAAK,QACD,OAAOhF,KAAK4L,MAAM5G,GACtB,QACI,MAAM,IAAItG,MAAM,wBAAwBwK,MAG7C,SAAS2D,EAAkBF,GAC9B,MAAOG,EAAMC,EAAMC,GAAQ3D,EAAgBsD,GAC3C,OAAgB,IAATG,GAAuB,IAATC,GAAuB,IAATC,EAEhC,SAASC,EAA+BzQ,EAASG,GACpD,OAAOkQ,EAAkBrQ,IAAYqQ,EAAkBlQ,GASpD,SAASoM,EAAwBrM,GACpC,GAAmB,SAAfA,EACA,MAAO,eAEN,GAAmB,SAAfA,EACL,MAAO,gBAGP,MAAM,IAAIgC,MAAM,sBAAsBhC,KA5Y9C,mT,gCCAA,yEAiDO,MAAMwQ,EAAU,YAAG,CAAEC,SAR5B,SAAkBC,EAAMC,GACpB,MAAMC,EAAQ,YAAgBF,EAAM,OAAQ,WACtCG,EAAQ,YAAgBF,EAAM,OAAQ,WAC5C,IAAuBC,EAAMpQ,MAAOqQ,EAAMrQ,MAAO,yBAAyBoQ,EAAMpQ,aAAaqQ,EAAMrQ,8CAEnG,MAAME,EAAS,CAAEgQ,KAAME,EAAOD,KAAME,GACpC,OAAO,IAAOhQ,UAAU,IAASH,O,gCC/CrC,kEAyCO,MAAMoQ,EAAQ,YAAG,CAAEC,OAP1B,SAAgBnR,GACZ,MACMc,EAAS,CAAEd,EADN,YAAgBA,EAAG,IAAK,QAAS,sBAI5C,OAAO,IAAOiB,UAAU,KAAUH,O,gCCvCtC,kEAqCO,MAAMsQ,EAAM,YAAG,CAAEC,KALxB,SAAcrR,GACV,MACMc,EAAS,CAAEd,EADN,YAAgBA,EAAG,IAAK,QAEnC,OAAO,IAAOiB,UAAU,IAAKH,O,gCCnCjC,qDA4CO,SAASwQ,EAAO1Q,EAAOW,EAAQ,UAAWmF,GAG7C,OAFAnF,EAAQA,GAAS,UACjB,IAAwCX,GACjC,IAAI,IAAaA,EAAOW,EAAOmF,K,gCC/C1C,yEA4CO,MAAM6K,EAAa,YAAG,CAAEC,YAP/B,SAAqBxR,EAAG8E,EAAO,GAC3B,MAAMvE,EAAK,YAAgBP,EAAG,IAAK,aAAc,qBACjD,IAAY8E,GAAQvE,EAAGI,MAAM,IAAM,uCACnC,MAAMG,EAAS,CAAE2Q,MAAOlR,GAClBQ,EAAQ,CAAE+B,IAAKgC,GACrB,OAAO,IAAO7D,UAAU,IAAYH,EAAQC,O,gCC1ChD,2RAqBO,SAAS2Q,EAAqBC,EAAMhR,GACvC,IAAK,IAAIoB,EAAI,EAAGA,EAAI4P,EAAKxP,SAAUJ,EAC/B,GAAI4P,EAAKA,EAAKxP,OAASJ,EAAI,KAAOpB,EAAO,EAAIoB,EACzC,OAAO,EAGf,OAAO,EAEJ,SAAS6P,EAAiBC,EAAWC,EAAWH,GACnD,MAAMhR,EAAOkR,EAAU1P,OAAS2P,EAAU3P,OACpC4P,EAAM,GACZ,IAAIC,EAAS,EACTC,EAAY,EAChB,IAAK,IAAInP,EAAM,EAAGA,EAAMnC,EAAMmC,KACC,IAAvB6O,EAAKO,QAAQpP,GACbiP,EAAIjI,KAAK+H,EAAUG,MAGnBD,EAAIjI,KAAKgI,EAAUG,MAG3B,OAAOF,EAEJ,SAASI,EAA0BC,EAAQT,GAC9C,MAAMhP,EAAW,GACXhC,EAAOyR,EAAOjQ,OACpB,IAAK,IAAIW,EAAM,EAAGA,EAAMnC,EAAMmC,KACC,IAAvB6O,EAAKO,QAAQpP,IACbH,EAASmH,KAAKsI,EAAOtP,IAI7B,MAAO,CAACH,EADYgP,EAAKU,KAAIvP,GAAOsP,EAAOtP,MAGxC,SAASwP,EAAqB1R,EAAO+Q,GAExC,OAAOC,EAAiBhR,EADD+Q,EAAKU,KAAIrS,GAAK,IACU2R,GAE5C,SAASY,EAA2BlH,EAAKsG,EAAMhR,GAClD,IAAY+Q,EAAqBC,EAAMhR,IAAO,IAAM,GAAG0K,qDACvCsG,cAAiBhR,aAO9B,SAAS6R,EAAmBb,EAAMhR,GACrC,GAAI+Q,EAAqBC,EAAMhR,GAC3B,OAAO,KAEX,MAAMuC,EAAS,GACf,IAAK,IAAInB,EAAI,EAAGA,EAAIpB,IAAQoB,GACC,IAArB4P,EAAKO,QAAQnQ,IACbmB,EAAO4G,KAAK/H,GAIpB,OADA4P,EAAKxI,SAAQrE,GAAQ5B,EAAO4G,KAAKhF,KAC1B5B,EAGJ,SAASuP,EAAuBd,GACnC,OAAOA,EAAKU,KAAI,CAACvN,EAAM/C,IAAM,CAACA,EAAG+C,KAC5B4N,MAAK,CAAC3P,EAAGa,IAAMb,EAAE,GAAKa,EAAE,KACxByO,KAAIrS,GAAKA,EAAE,KAEb,SAAS2S,EAAiBC,EAASjS,GACtC,MAAMK,EAAM,GACZ,IAAK,IAAIe,EAAIpB,EAAOiS,EAAS7Q,EAAIpB,IAAQoB,EACrCf,EAAI8I,KAAK/H,GAEb,OAAOf,I,gCC5FX,iFAuEO,MAAM6R,EAAc,YAAG,CAAEC,aAnChC,SAAsB9S,EAAGY,GACrB,IAAI6Q,EAAQ,YAAgBzR,EAAG,cAAe,KAC9C,MAAM+D,EAAS0N,EAAM7Q,MACrB,GAAIA,EAAMmS,MAAKtK,KAAOA,EAAI,IAAMA,EAAI,GAAM,IACtC,MAAM,IAAIrG,MAAM,2CAA2CxB,OAE/D,GAAIA,EAAMuB,OAASsP,EAAM9Q,KACrB,MAAM,IAAIyB,MAAM,+BAA+BxB,EAAMuB,uBAAuBsP,EAAM9Q,SAEtF,GAAIC,EAAMuB,OAASsP,EAAM9Q,KAAM,CAC3B,MAAMqS,EAAWvB,EAAM7Q,MAAMuH,QAC7B,KAAO6K,EAAS7Q,OAASvB,EAAMuB,QAC3B6Q,EAAShQ,QAAQ,GAErByO,EAAQ,YAAQA,EAAOuB,GAE3B,MAAM5O,EAAaqN,EAAM7Q,MACnBqS,EAAOC,MAAMC,KAAKvS,GACxB,IAAK,IAAImB,EAAInB,EAAMuB,OAAS,EAAGJ,GAAK,EAAGA,IACnC,GAAIqC,EAAWrC,KAAOnB,EAAMmB,GACxBkR,EAAKlR,GAAK,OAET,GAAuB,IAAnB0P,EAAM7Q,MAAMmB,GACjB,MAAM,IAAIK,MAAM,mBAAmB2B,8BAAmCnD,OAI9E,GAAoB,IADPqS,EAAKZ,KAAI,CAACvQ,EAAGC,IAAMD,EAAI,EAAIC,GAAK,IAAG9B,QAAO8B,GAAKA,GAAK,IACxDI,OACL,OAAO,YAAMsP,GAGjB,MAAM3Q,EAAS,CAAEd,EAAGyR,GACd1Q,EAAQ,CAAEkS,QAChB,OAAO,IAAOhS,UAAU,KAAMH,EAAQC","file":"js/bundle~bundle~a1212309.f3faa6c6.js","sourcesContent":["/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Conv2D } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport * as util from '../util';\nimport * as conv_util from './conv_util';\nimport { op } from './operation';\nimport { reshape } from './reshape';\n/**\n * Computes a 2D convolution over the input x.\n *\n * @param x The input tensor, of rank 4 or rank 3, of shape\n *     `[batch, height, width, inChannels]`. If rank 3, batch of 1 is\n * assumed.\n * @param filter The filter, rank 4, of shape\n *     `[filterHeight, filterWidth, inDepth, outDepth]`.\n * @param strides The strides of the convolution: `[strideHeight,\n * strideWidth]`.\n * @param pad The type of padding algorithm.\n *    - `same` and stride 1: output will be of same size as input,\n *       regardless of filter size.\n *    - `valid`: output will be smaller than input if filter is larger\n *       than 1x1.\n *   - For more info, see this guide:\n *     [https://www.tensorflow.org/api_guides/python/nn#Convolution](\n *          https://www.tensorflow.org/api_guides/python/nn#Convolution)\n * @param dataFormat: An optional string from: \"NHWC\", \"NCHW\". Defaults to\n *     \"NHWC\". Specify the data format of the input and output data. With the\n *     default format \"NHWC\", the data is stored in the order of: [batch,\n *     height, width, channels].\n * @param dilations The dilation rates: `[dilationHeight, dilationWidth]`\n *     in which we sample input values across the height and width dimensions\n *     in atrous convolution. Defaults to `[1, 1]`. If `dilations` is a single\n *     number, then `dilationHeight == dilationWidth`. If it is greater than\n *     1, then all values of `strides` must be 1.\n * @param dimRoundingMode A string from: 'ceil', 'round', 'floor'. If none is\n *     provided, it will default to truncate.\n *\n * @doc {heading: 'Operations', subheading: 'Convolution'}\n */\nfunction conv2d_(x, filter, strides, pad, dataFormat = 'NHWC', dilations = [1, 1], dimRoundingMode) {\n    const $x = convertToTensor(x, 'x', 'conv2d');\n    const $filter = convertToTensor(filter, 'filter', 'conv2d');\n    let x4D = $x;\n    let reshapedTo4D = false;\n    if ($x.rank === 3) {\n        reshapedTo4D = true;\n        x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);\n    }\n    util.assert(x4D.rank === 4, () => `Error in conv2d: input must be rank 4, but got rank ${x4D.rank}.`);\n    util.assert($filter.rank === 4, () => `Error in conv2d: filter must be rank 4, but got rank ` +\n        `${$filter.rank}.`);\n    if (dimRoundingMode != null) {\n        util.assert(util.isInt(pad), () => `Error in conv2d: pad must be an integer when using, ` +\n            `dimRoundingMode ${dimRoundingMode} but got pad ${pad}.`);\n    }\n    const inDepth = dataFormat === 'NHWC' ? x4D.shape[3] : x4D.shape[1];\n    util.assert(inDepth === $filter.shape[2], () => `Error in conv2d: depth of input (${inDepth}) must match ` +\n        `input depth for filter ${$filter.shape[2]}.`);\n    util.assert(conv_util.eitherStridesOrDilationsAreOne(strides, dilations), () => 'Error in conv2D: Either strides or dilations must be 1. ' +\n        `Got strides ${strides} and dilations '${dilations}'`);\n    const inputs = { x: x4D, filter: $filter };\n    const attrs = { strides, pad, dataFormat, dilations, dimRoundingMode };\n    // tslint:disable-next-line: no-unnecessary-type-assertion\n    const res = ENGINE.runKernel(Conv2D, inputs, attrs);\n    if (reshapedTo4D) {\n        return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);\n    }\n    return res;\n}\nexport const conv2d = op({ conv2d_ });\n//# sourceMappingURL=conv2d.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Bincount } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport * as util from '../util';\nimport { op } from './operation';\n/**\n * Outputs a vector with length `size` and the same dtype as `weights`.\n *\n * If `weights` are empty, then index `i` stores the number of times the value\n * `i` is counted in `x`. If `weights` are non-empty, then index `i` stores the\n * sum of the value in `weights` at each index where the corresponding value in\n * `x` is `i`.\n *\n * Values in `x` outside of the range [0, size) are ignored.\n *\n * @param x The input int tensor, rank 1.\n * @param weights The weights tensor, must have the same shape as x, or a\n *     length-0 Tensor, in which case it acts as all weights equal to 1.\n * @param size Non-negative integer.\n *\n * @doc {heading: 'Operations', subheading: 'Reduction'}\n */\nfunction bincount_(x, weights, size) {\n    const $x = convertToTensor(x, 'x', 'bincount');\n    const $weights = convertToTensor(weights, 'weights', 'bincount');\n    util.assert($x.dtype === 'int32', () => `Error in bincount: input ` +\n        `dtype must be int32, but got ${$x.dtype}`);\n    util.assert(size >= 0, () => `size must be non-negative, but got ${size}.`);\n    util.assert($weights.size === $x.size || $weights.size === 0, () => `Error in bincount: weights must have the same size as input or` +\n        `0-length, but got input shape: ${$x.shape}, weights shape: ` +\n        `${$weights.shape}.`);\n    const inputs = { x: $x, weights: $weights };\n    const attrs = { size };\n    return ENGINE.runKernel(Bincount, inputs, attrs);\n}\nexport const bincount = op({ bincount_ });\n//# sourceMappingURL=bincount.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { buffer } from './buffer';\nimport { expandDims } from './expand_dims';\nimport { op } from './operation';\nimport { reshape } from './reshape';\nimport { tile } from './tile';\n/**\n * Create an identity matrix.\n *\n * @param numRows Number of rows.\n * @param numColumns Number of columns. Defaults to `numRows`.\n * @param batchShape If provided, will add the batch shape to the beginning\n *   of the shape of the returned `tf.Tensor` by repeating the identity\n *   matrix.\n * @param dtype Data type.\n * @returns Identity matrix of the specified size and data type, possibly\n *   with batch repetition if `batchShape` is specified.\n *\n * @doc {heading: 'Tensors', subheading: 'Creation'}\n */\nfunction eye_(numRows, numColumns, batchShape, dtype = 'float32') {\n    if (numColumns == null) {\n        numColumns = numRows;\n    }\n    const buff = buffer([numRows, numColumns], dtype);\n    const n = numRows <= numColumns ? numRows : numColumns;\n    for (let i = 0; i < n; ++i) {\n        buff.set(1, i, i);\n    }\n    const out = reshape(buff.toTensor(), [numRows, numColumns]);\n    if (batchShape == null) {\n        return out;\n    }\n    else {\n        if (batchShape.length === 1) {\n            return tile(expandDims(out, 0), [batchShape[0], 1, 1]);\n        }\n        else if (batchShape.length === 2) {\n            // tslint:disable-next-line:no-unnecessary-type-assertion\n            return tile(expandDims(expandDims(out, 0), 0), [batchShape[0], batchShape[1], 1, 1]);\n        }\n        else if (batchShape.length === 3) {\n            // tslint:disable-next-line:no-unnecessary-type-assertion\n            return tile(expandDims(expandDims(expandDims(out, 0), 0), 0), [\n                batchShape[0], batchShape[1], batchShape[2], 1, 1\n            ]);\n        }\n        else {\n            throw new Error(`eye() currently supports only 1D and 2D ` +\n                // tslint:disable-next-line:no-any\n                `batchShapes, but received ${batchShape.length}D.`);\n        }\n    }\n}\nexport const eye = op({ eye_ });\n//# sourceMappingURL=eye.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Elu } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes exponential linear element-wise: `x > 0 ? e ^ x - 1 : 0`.\n *\n * ```js\n * const x = tf.tensor1d([-1, 1, -3, 2]);\n *\n * x.elu().print();  // or tf.elu(x)\n * ```\n * @param x The input tensor.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction elu_(x) {\n    const $x = convertToTensor(x, 'x', 'elu');\n    const inputs = { x: $x };\n    return ENGINE.runKernel(Elu, inputs);\n}\nexport const elu = op({ elu_ });\n//# sourceMappingURL=elu.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { DepthwiseConv2dNative } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport * as util from '../util';\nimport { op } from './operation';\nimport { reshape } from './reshape';\n/**\n * Depthwise 2D convolution.\n *\n * Given a 4D `input` array and a `filter` array of shape\n * `[filterHeight, filterWidth, inChannels, channelMultiplier]` containing\n * `inChannels` convolutional filters of depth 1, this op applies a\n * different filter to each input channel (expanding from 1 channel to\n * `channelMultiplier` channels for each), then concatenates the results\n * together. The output has `inChannels * channelMultiplier` channels.\n *\n * See\n * [https://www.tensorflow.org/api_docs/python/tf/nn/depthwise_conv2d](\n *     https://www.tensorflow.org/api_docs/python/tf/nn/depthwise_conv2d)\n * for more details.\n *\n * @param x The input tensor, of rank 4 or rank 3, of shape\n *     `[batch, height, width, inChannels]`. If rank 3, batch of 1 is\n * assumed.\n * @param filter The filter tensor, rank 4, of shape\n *     `[filterHeight, filterWidth, inChannels, channelMultiplier]`.\n * @param strides The strides of the convolution: `[strideHeight,\n * strideWidth]`. If strides is a single number, then `strideHeight ==\n * strideWidth`.\n * @param pad The type of padding algorithm.\n *   - `same` and stride 1: output will be of same size as input,\n *       regardless of filter size.\n *   - `valid`: output will be smaller than input if filter is larger\n *       than 1x1.\n *   - For more info, see this guide:\n *     [https://www.tensorflow.org/api_guides/python/nn#Convolution](\n *          https://www.tensorflow.org/api_guides/python/nn#Convolution)\n * @param dilations The dilation rates: `[dilationHeight, dilationWidth]`\n *     in which we sample input values across the height and width dimensions\n *     in atrous convolution. Defaults to `[1, 1]`. If `rate` is a single\n *     number, then `dilationHeight == dilationWidth`. If it is greater than\n *     1, then all values of `strides` must be 1.\n * @param dataFormat: An optional string from: \"NHWC\", \"NCHW\". Defaults to\n *     \"NHWC\". Specify the data format of the input and output data. With the\n *     default format \"NHWC\", the data is stored in the order of: [batch,\n *     height, width, channels]. Only \"NHWC\" is currently supported.\n * @param dimRoundingMode A string from: 'ceil', 'round', 'floor'. If none is\n *     provided, it will default to truncate.\n *\n * @doc {heading: 'Operations', subheading: 'Convolution'}\n */\nfunction depthwiseConv2d_(x, filter, strides, pad, dataFormat = 'NHWC', dilations = [1, 1], dimRoundingMode) {\n    const $x = convertToTensor(x, 'x', 'depthwiseConv2d');\n    const $filter = convertToTensor(filter, 'filter', 'depthwiseConv2d');\n    let x4D = $x;\n    let reshapedTo4D = false;\n    if ($x.rank === 3) {\n        reshapedTo4D = true;\n        x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);\n    }\n    util.assert(x4D.rank === 4, () => `Error in depthwiseConv2d: input must be rank 4, but got ` +\n        `rank ${x4D.rank}.`);\n    util.assert($filter.rank === 4, () => `Error in depthwiseConv2d: filter must be rank 4, but got rank ` +\n        `${$filter.rank}.`);\n    util.assert(x4D.shape[3] === $filter.shape[2], () => `Error in depthwiseConv2d: number of input channels ` +\n        `(${x4D.shape[3]}) must match the inChannels dimension in ` +\n        `filter ${$filter.shape[2]}.`);\n    if (dimRoundingMode != null) {\n        util.assert(util.isInt(pad), () => `Error in depthwiseConv2d: pad must be an integer when using, ` +\n            `dimRoundingMode ${dimRoundingMode} but got pad ${pad}.`);\n    }\n    const inputs = { x: x4D, filter: $filter };\n    const attrs = { strides, pad, dataFormat, dilations, dimRoundingMode };\n    // tslint:disable-next-line: no-unnecessary-type-assertion\n    const res = ENGINE.runKernel(DepthwiseConv2dNative, inputs, attrs);\n    if (reshapedTo4D) {\n        return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);\n    }\n    return res;\n}\nexport const depthwiseConv2d = op({ depthwiseConv2d_ });\n//# sourceMappingURL=depthwise_conv2d.js.map","/**\n * @license\n * Copyright 2017 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n/**\n * Returns the dimensions in the input shape that are broadcasted to\n * produce the provided output shape.\n *\n * The returned dimensions are 0-indexed and sorted. An example:\n * inShape = [4, 1, 3]\n * outShape = [5, 4, 3, 3]\n * result = [1]. Dimension 1 (2nd dimension of input) gets broadcasted 1 => 3.\n */\nexport function getBroadcastDims(inShape, outShape) {\n    const inRank = inShape.length;\n    const dims = [];\n    for (let i = 0; i < inRank; i++) {\n        const dim = inRank - 1 - i;\n        const a = inShape[dim] || 1;\n        const b = outShape[outShape.length - 1 - i] || 1;\n        if (b > 1 && a === 1) {\n            dims.unshift(dim);\n        }\n    }\n    return dims;\n}\n/**\n * Returns the axes in the output space that should be reduced to produce\n * the input space.\n */\nexport function getReductionAxes(inShape, outShape) {\n    const result = [];\n    for (let i = 0; i < outShape.length; i++) {\n        const inDim = inShape[inShape.length - i - 1];\n        const outAxis = outShape.length - i - 1;\n        const outDim = outShape[outAxis];\n        if (inDim == null || (inDim === 1 && outDim > 1)) {\n            result.unshift(outAxis);\n        }\n    }\n    return result;\n}\nexport function assertAndGetBroadcastShape(shapeA, shapeB) {\n    const result = [];\n    const l = Math.max(shapeA.length, shapeB.length);\n    for (let i = 0; i < l; i++) {\n        let a = shapeA[shapeA.length - i - 1];\n        if (a == null) {\n            a = 1;\n        }\n        let b = shapeB[shapeB.length - i - 1];\n        if (b == null) {\n            b = 1;\n        }\n        if (a === 1) {\n            result.unshift(b);\n        }\n        else if (b === 1) {\n            result.unshift(a);\n        }\n        else if (a !== b) {\n            const errMsg = `Operands could not be broadcast together with shapes ` +\n                `${shapeA} and ${shapeB}.`;\n            throw Error(errMsg);\n        }\n        else {\n            result.unshift(a);\n        }\n    }\n    return result;\n}\n//# sourceMappingURL=broadcast_util.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Conv2DBackpropInput } from '../kernel_names';\nimport * as util from '../util';\nimport { op } from './operation';\nimport { reshape } from './reshape';\n/**\n * Computes the derivative of the input of a 2D convolution.\n *\n * @param xShape The shape of the input: [batch, height, width, inDepth].\n * If length of 3, batch of 1 is assumed.\n * @param dy The derivative of the output, of rank 4 or rank 3 of shape\n *   `[batch, outHeight, outWidth, outDepth]`. If rank 3, batch of 1 is\n * assumed.\n * @param filter The filter, rank 4, of shape\n *     `[filterHeight, filterWidth, inDepth, outDepth]`.\n * @param strides The strides of the convolution: `[strideHeight,\n * strideWidth]`.\n * @param pad The type of padding algorithm used:\n *    - `same` and stride 1: output will be of same size as input,\n *       regardless of filter size.\n *    - `valid`: output will be smaller than input if filter is larger\n *       than 1x1.\n * @param dataFormat: An optional string from: \"NHWC\", \"NCHW\". Defaults to\n *     \"NHWC\". Specify the data format of the input and output data. With the\n *     default format \"NHWC\", the data is stored in the order of: [batch,\n *     height, width, channels].\n * @param dimRoundingMode A string from: 'ceil', 'round', 'floor'. If none is\n *     provided, it will default to truncate.\n */\nfunction conv2DBackpropInput_(xShape, dy, filter, strides, pad, dataFormat = 'NHWC', dimRoundingMode) {\n    util.assert(xShape.length === dy.rank, () => `Length of inShape ` +\n        `(${xShape.length}) and rank of dy (${dy.rank}) must match`);\n    let xShape4D = xShape;\n    let dy4D = dy;\n    let reshapedTo4D = false;\n    if (dy.rank === 3) {\n        reshapedTo4D = true;\n        dy4D = reshape(dy, [1, dy.shape[0], dy.shape[1], dy.shape[2]]);\n        xShape4D = [1, xShape[0], xShape[1], xShape[2]];\n    }\n    util.assert(xShape4D.length === 4, () => `Error in conv2dDerInput: inShape must be length 4, but got length ` +\n        `${xShape4D.length}.`);\n    util.assert(dy4D.rank === 4, () => `Error in conv2dDerInput: dy must be rank 4, but got ` +\n        `rank ${dy4D.rank}`);\n    util.assert(filter.rank === 4, () => `Error in conv2dDerInput: filter must be rank 4, but got ` +\n        `rank ${filter.rank}`);\n    const inDepth = dataFormat === 'NHWC' ? xShape4D[3] : xShape4D[1];\n    const outDepth = dataFormat === 'NHWC' ? dy4D.shape[3] : dy4D.shape[1];\n    util.assert(inDepth === filter.shape[2], () => `Error in conv2dDerInput: depth of input (${inDepth}) must ` +\n        `match input depth for filter ${filter.shape[2]}.`);\n    util.assert(outDepth === filter.shape[3], () => `Error in conv2dDerInput: depth of output (${outDepth}) must ` +\n        `match output depth for filter ${filter.shape[3]}.`);\n    if (dimRoundingMode != null) {\n        util.assert(util.isInt(pad), () => `Error in conv2dDerInput: pad must be an integer when using, ` +\n            `dimRoundingMode ${dimRoundingMode} but got pad ${pad}.`);\n    }\n    const inputs = { dy: dy4D, filter };\n    const attrs = { strides, pad, dataFormat, dimRoundingMode, inputShape: xShape4D };\n    // tslint:disable-next-line: no-unnecessary-type-assertion\n    const res = ENGINE.runKernel(Conv2DBackpropInput, inputs, attrs);\n    if (reshapedTo4D) {\n        return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);\n    }\n    return res;\n}\nexport const conv2DBackpropInput = op({ conv2DBackpropInput_ });\n//# sourceMappingURL=conv2d_backprop_input.js.map","/**\n * @license\n * Copyright 2020 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Cast } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport * as util from '../util';\nimport { op } from './operation';\n/**\n * Casts a `tf.Tensor` to a new dtype.\n *\n * ```js\n * const x = tf.tensor1d([1.5, 2.5, 3]);\n * tf.cast(x, 'int32').print();\n * ```\n * @param x The input tensor to be casted.\n * @param dtype The dtype to cast the input tensor to.\n *\n * @doc {heading: 'Tensors', subheading: 'Transformations'}\n */\nfunction cast_(x, dtype) {\n    const $x = convertToTensor(x, 'x', 'cast');\n    // Sanity checks.\n    if (!util.isValidDtype(dtype)) {\n        throw new Error(`Failed to cast to unknown dtype ${dtype}`);\n    }\n    if (dtype === 'string' && $x.dtype !== 'string' ||\n        dtype !== 'string' && $x.dtype === 'string') {\n        throw new Error('Only strings can be casted to strings');\n    }\n    const inputs = { x: $x };\n    const attrs = { dtype };\n    return ENGINE.runKernel(Cast, inputs, attrs);\n}\nexport const cast = op({ cast_ });\n//# sourceMappingURL=cast.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Add } from '../kernel_names';\nimport { makeTypesMatch } from '../tensor_util';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Adds two `tf.Tensor`s element-wise, A + B. Supports broadcasting.\n *\n *\n * ```js\n * const a = tf.tensor1d([1, 2, 3, 4]);\n * const b = tf.tensor1d([10, 20, 30, 40]);\n *\n * a.add(b).print();  // or tf.add(a, b)\n * ```\n *\n * ```js\n * // Broadcast add a with b.\n * const a = tf.scalar(5);\n * const b = tf.tensor1d([10, 20, 30, 40]);\n *\n * a.add(b).print();  // or tf.add(a, b)\n * ```\n * @param a The first `tf.Tensor` to add.\n * @param b The second `tf.Tensor` to add. Must have the same type as `a`.\n *\n * @doc {heading: 'Operations', subheading: 'Arithmetic'}\n */\nfunction add_(a, b) {\n    let $a = convertToTensor(a, 'a', 'add');\n    let $b = convertToTensor(b, 'b', 'add');\n    [$a, $b] = makeTypesMatch($a, $b);\n    const inputs = { a: $a, b: $b };\n    return ENGINE.runKernel(Add, inputs);\n}\nexport const add = op({ add_ });\n//# sourceMappingURL=add.js.map","import { concat } from './concat';\nimport { op } from './operation';\n/**\n * Concatenates a list of`tf.Tensor2D`s along an axis. See `concat` for details.\n *\n * For example, if:\n * A: shape(2, 3) = | r1, g1, b1 |\n *                  | r2, g2, b2 |\n *\n * B: shape(2, 3) = | r3, g3, b3 |\n *                  | r4, g4, b4 |\n *\n * C = tf.concat2d([A, B], axis)\n *\n * if axis = 0:\n * C: shape(4, 3) = | r1, g1, b1 |\n *                  | r2, g2, b2 |\n *                  | r3, g3, b3 |\n *                  | r4, g4, b4 |\n *\n * if axis = 1:\n * C = shape(2, 6) = | r1, g1, b1, r3, g3, b3 |\n *                   | r2, g2, b2, r4, g4, b4 |\n *\n *\n * @param tensors A list of `tf.Tensor`s to concatenate.\n * @param axis The axis to concatenate along.\n * @return The concatenated array.\n */\nfunction concat2d_(tensors, axis) {\n    return concat(tensors, axis);\n}\nexport const concat2d = op({ concat2d_ });\n//# sourceMappingURL=concat_2d.js.map","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { env } from '../environment';\nimport { FromPixels } from '../kernel_names';\nimport { getKernel } from '../kernel_registry';\nimport { Tensor } from '../tensor';\nimport { convertToTensor } from '../tensor_util_env';\nimport { cast } from './cast';\nimport { op } from './operation';\nimport { tensor3d } from './tensor3d';\nlet fromPixels2DContext;\n/**\n * Creates a `tf.Tensor` from an image.\n *\n * ```js\n * const image = new ImageData(1, 1);\n * image.data[0] = 100;\n * image.data[1] = 150;\n * image.data[2] = 200;\n * image.data[3] = 255;\n *\n * tf.browser.fromPixels(image).print();\n * ```\n *\n * @param pixels The input image to construct the tensor from. The\n * supported image types are all 4-channel. You can also pass in an image\n * object with following attributes:\n * `{data: Uint8Array; width: number; height: number}`\n * @param numChannels The number of channels of the output tensor. A\n * numChannels value less than 4 allows you to ignore channels. Defaults to\n * 3 (ignores alpha channel of input image).\n *\n * @returns A Tensor3D with the shape `[height, width, numChannels]`.\n *\n * @doc {heading: 'Browser', namespace: 'browser', ignoreCI: true}\n */\nfunction fromPixels_(pixels, numChannels = 3) {\n    // Sanity checks.\n    if (numChannels > 4) {\n        throw new Error('Cannot construct Tensor with more than 4 channels from pixels.');\n    }\n    if (pixels == null) {\n        throw new Error('pixels passed to tf.browser.fromPixels() can not be null');\n    }\n    let isPixelData = false;\n    let isImageData = false;\n    let isVideo = false;\n    let isImage = false;\n    let isCanvasLike = false;\n    let isImageBitmap = false;\n    if (pixels.data instanceof Uint8Array) {\n        isPixelData = true;\n    }\n    else if (typeof (ImageData) !== 'undefined' && pixels instanceof ImageData) {\n        isImageData = true;\n    }\n    else if (typeof (HTMLVideoElement) !== 'undefined' &&\n        pixels instanceof HTMLVideoElement) {\n        isVideo = true;\n    }\n    else if (typeof (HTMLImageElement) !== 'undefined' &&\n        pixels instanceof HTMLImageElement) {\n        isImage = true;\n        // tslint:disable-next-line: no-any\n    }\n    else if (pixels.getContext != null) {\n        isCanvasLike = true;\n    }\n    else if (typeof (ImageBitmap) !== 'undefined' && pixels instanceof ImageBitmap) {\n        isImageBitmap = true;\n    }\n    else {\n        throw new Error('pixels passed to tf.browser.fromPixels() must be either an ' +\n            `HTMLVideoElement, HTMLImageElement, HTMLCanvasElement, ImageData ` +\n            `in browser, or OffscreenCanvas, ImageData in webworker` +\n            ` or {data: Uint32Array, width: number, height: number}, ` +\n            `but was ${pixels.constructor.name}`);\n    }\n    if (isVideo) {\n        const HAVE_CURRENT_DATA_READY_STATE = 2;\n        if (isVideo &&\n            pixels.readyState <\n                HAVE_CURRENT_DATA_READY_STATE) {\n            throw new Error('The video element has not loaded data yet. Please wait for ' +\n                '`loadeddata` event on the <video> element.');\n        }\n    }\n    // If the current backend has 'FromPixels' registered, it has a more\n    // efficient way of handling pixel uploads, so we call that.\n    const kernel = getKernel(FromPixels, ENGINE.backendName);\n    if (kernel != null) {\n        const inputs = { pixels };\n        const attrs = { numChannels };\n        return ENGINE.runKernel(FromPixels, inputs, attrs);\n    }\n    const [width, height] = isVideo ?\n        [\n            pixels.videoWidth,\n            pixels.videoHeight\n        ] :\n        [pixels.width, pixels.height];\n    let vals;\n    if (isCanvasLike) {\n        vals =\n            // tslint:disable-next-line:no-any\n            pixels.getContext('2d').getImageData(0, 0, width, height).data;\n    }\n    else if (isImageData || isPixelData) {\n        vals = pixels.data;\n    }\n    else if (isImage || isVideo || isImageBitmap) {\n        if (fromPixels2DContext == null) {\n            fromPixels2DContext = document.createElement('canvas').getContext('2d');\n        }\n        fromPixels2DContext.canvas.width = width;\n        fromPixels2DContext.canvas.height = height;\n        fromPixels2DContext.drawImage(pixels, 0, 0, width, height);\n        vals = fromPixels2DContext.getImageData(0, 0, width, height).data;\n    }\n    let values;\n    if (numChannels === 4) {\n        values = new Int32Array(vals);\n    }\n    else {\n        const numPixels = width * height;\n        values = new Int32Array(numPixels * numChannels);\n        for (let i = 0; i < numPixels; i++) {\n            for (let channel = 0; channel < numChannels; ++channel) {\n                values[i * numChannels + channel] = vals[i * 4 + channel];\n            }\n        }\n    }\n    const outShape = [height, width, numChannels];\n    return tensor3d(values, outShape, 'int32');\n}\n// Helper functions for |fromPixelsAsync| to check whether the input can\n// be wrapped into imageBitmap.\nfunction isPixelData(pixels) {\n    return (pixels != null) && (pixels.data instanceof Uint8Array);\n}\nfunction isImageBitmapFullySupported() {\n    return typeof window !== 'undefined' &&\n        typeof (ImageBitmap) !== 'undefined' &&\n        window.hasOwnProperty('createImageBitmap');\n}\nfunction isNonEmptyPixels(pixels) {\n    return pixels != null && pixels.width !== 0 && pixels.height !== 0;\n}\nfunction canWrapPixelsToImageBitmap(pixels) {\n    return isImageBitmapFullySupported() && !(pixels instanceof ImageBitmap) &&\n        isNonEmptyPixels(pixels) && !isPixelData(pixels);\n}\n/**\n * Creates a `tf.Tensor` from an image in async way.\n *\n * ```js\n * const image = new ImageData(1, 1);\n * image.data[0] = 100;\n * image.data[1] = 150;\n * image.data[2] = 200;\n * image.data[3] = 255;\n *\n * (await tf.browser.fromPixelsAsync(image)).print();\n * ```\n * This API is the async version of fromPixels. The API will first\n * check |WRAP_TO_IMAGEBITMAP| flag, and try to wrap the input to\n * imageBitmap if the flag is set to true.\n *\n * @param pixels The input image to construct the tensor from. The\n * supported image types are all 4-channel. You can also pass in an image\n * object with following attributes:\n * `{data: Uint8Array; width: number; height: number}`\n * @param numChannels The number of channels of the output tensor. A\n * numChannels value less than 4 allows you to ignore channels. Defaults to\n * 3 (ignores alpha channel of input image).\n *\n * @doc {heading: 'Browser', namespace: 'browser', ignoreCI: true}\n */\nexport async function fromPixelsAsync(pixels, numChannels = 3) {\n    let inputs = null;\n    // Check whether the backend needs to wrap |pixels| to imageBitmap and\n    // whether |pixels| can be wrapped to imageBitmap.\n    if (env().getBool('WRAP_TO_IMAGEBITMAP') &&\n        canWrapPixelsToImageBitmap(pixels)) {\n        // Force the imageBitmap creation to not do any premultiply alpha\n        // ops.\n        let imageBitmap;\n        try {\n            // wrap in try-catch block, because createImageBitmap may not work\n            // properly in some browsers, e.g.\n            // https://bugzilla.mozilla.org/show_bug.cgi?id=1335594\n            // tslint:disable-next-line: no-any\n            imageBitmap = await createImageBitmap(pixels, { premultiplyAlpha: 'none' });\n        }\n        catch (e) {\n            imageBitmap = null;\n        }\n        // createImageBitmap will clip the source size.\n        // In some cases, the input will have larger size than its content.\n        // E.g. new Image(10, 10) but with 1 x 1 content. Using\n        // createImageBitmap will clip the size from 10 x 10 to 1 x 1, which\n        // is not correct. We should avoid wrapping such resouce to\n        // imageBitmap.\n        if (imageBitmap != null && imageBitmap.width === pixels.width &&\n            imageBitmap.height === pixels.height) {\n            inputs = imageBitmap;\n        }\n        else {\n            inputs = pixels;\n        }\n    }\n    else {\n        inputs = pixels;\n    }\n    return fromPixels_(inputs, numChannels);\n}\n/**\n * Draws a `tf.Tensor` of pixel values to a byte array or optionally a\n * canvas.\n *\n * When the dtype of the input is 'float32', we assume values in the range\n * [0-1]. Otherwise, when input is 'int32', we assume values in the range\n * [0-255].\n *\n * Returns a promise that resolves when the canvas has been drawn to.\n *\n * @param img A rank-2 tensor with shape `[height, width]`, or a rank-3 tensor\n * of shape `[height, width, numChannels]`. If rank-2, draws grayscale. If\n * rank-3, must have depth of 1, 3 or 4. When depth of 1, draws\n * grayscale. When depth of 3, we draw with the first three components of\n * the depth dimension corresponding to r, g, b and alpha = 1. When depth of\n * 4, all four components of the depth dimension correspond to r, g, b, a.\n * @param canvas The canvas to draw to.\n *\n * @doc {heading: 'Browser', namespace: 'browser'}\n */\nexport async function toPixels(img, canvas) {\n    let $img = convertToTensor(img, 'img', 'toPixels');\n    if (!(img instanceof Tensor)) {\n        // Assume int32 if user passed a native array.\n        const originalImgTensor = $img;\n        $img = cast(originalImgTensor, 'int32');\n        originalImgTensor.dispose();\n    }\n    if ($img.rank !== 2 && $img.rank !== 3) {\n        throw new Error(`toPixels only supports rank 2 or 3 tensors, got rank ${$img.rank}.`);\n    }\n    const [height, width] = $img.shape.slice(0, 2);\n    const depth = $img.rank === 2 ? 1 : $img.shape[2];\n    if (depth > 4 || depth === 2) {\n        throw new Error(`toPixels only supports depth of size ` +\n            `1, 3 or 4 but got ${depth}`);\n    }\n    if ($img.dtype !== 'float32' && $img.dtype !== 'int32') {\n        throw new Error(`Unsupported type for toPixels: ${$img.dtype}.` +\n            ` Please use float32 or int32 tensors.`);\n    }\n    const data = await $img.data();\n    const multiplier = $img.dtype === 'float32' ? 255 : 1;\n    const bytes = new Uint8ClampedArray(width * height * 4);\n    for (let i = 0; i < height * width; ++i) {\n        const rgba = [0, 0, 0, 255];\n        for (let d = 0; d < depth; d++) {\n            const value = data[i * depth + d];\n            if ($img.dtype === 'float32') {\n                if (value < 0 || value > 1) {\n                    throw new Error(`Tensor values for a float32 Tensor must be in the ` +\n                        `range [0 - 1] but encountered ${value}.`);\n                }\n            }\n            else if ($img.dtype === 'int32') {\n                if (value < 0 || value > 255) {\n                    throw new Error(`Tensor values for a int32 Tensor must be in the ` +\n                        `range [0 - 255] but encountered ${value}.`);\n                }\n            }\n            if (depth === 1) {\n                rgba[0] = value * multiplier;\n                rgba[1] = value * multiplier;\n                rgba[2] = value * multiplier;\n            }\n            else {\n                rgba[d] = value * multiplier;\n            }\n        }\n        const j = i * 4;\n        bytes[j + 0] = Math.round(rgba[0]);\n        bytes[j + 1] = Math.round(rgba[1]);\n        bytes[j + 2] = Math.round(rgba[2]);\n        bytes[j + 3] = Math.round(rgba[3]);\n    }\n    if (canvas != null) {\n        canvas.width = width;\n        canvas.height = height;\n        const ctx = canvas.getContext('2d');\n        const imageData = new ImageData(bytes, width, height);\n        ctx.putImageData(imageData, 0, 0);\n    }\n    if ($img !== img) {\n        $img.dispose();\n    }\n    return bytes;\n}\nexport const fromPixels = op({ fromPixels_ });\n//# sourceMappingURL=browser.js.map","/**\n * @license\n * Copyright 2017 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport * as util from '../util';\nexport function assertParamsConsistent(shapes, axis) {\n    const rank = shapes[0].length;\n    shapes.forEach((shape, i) => {\n        util.assert(shape.length === rank, () => `Error in concat${rank}D: rank of tensors[${i}] must be the same ` +\n            `as the rank of the rest (${rank})`);\n    });\n    util.assert(axis >= 0 && axis < rank, () => `Error in concat${rank}D: axis must be between 0 and ${rank - 1}.`);\n    const firstShape = shapes[0];\n    shapes.forEach((shape, i) => {\n        for (let r = 0; r < rank; r++) {\n            util.assert((r === axis) || (shape[r] === firstShape[r]), () => `Error in concat${rank}D: Shape of tensors[${i}] (${shape}) ` +\n                `does not match the shape of the rest (${firstShape}) ` +\n                `along the non-concatenated axis ${i}.`);\n        }\n    });\n}\nexport function computeOutShape(shapes, axis) {\n    const outputShape = shapes[0].slice();\n    for (let i = 1; i < shapes.length; i++) {\n        outputShape[axis] += shapes[i][axis];\n    }\n    return outputShape;\n}\n//# sourceMappingURL=concat_util.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n/**\n * Gets the new shape of the input Tensor after it's been reshaped\n * to:\n * [blockShape[0], ..., blockShape[M-1], batch / prod(blockShape),\n * inputShape[1], ..., inputShape[N-1]]\n *\n * See step 1: https://www.tensorflow.org/api_docs/python/tf/batch_to_space_nd\n */\nexport function getReshaped(inputShape, blockShape, prod, batchToSpace = true) {\n    let reshaped = [];\n    if (batchToSpace) {\n        reshaped = reshaped.concat(blockShape.slice(0));\n        reshaped.push(inputShape[0] / prod);\n        reshaped = reshaped.concat(inputShape.slice(1));\n    }\n    else {\n        reshaped = reshaped.concat(inputShape[0]);\n        const spatialLength = blockShape.length;\n        for (let i = 0; i < spatialLength; ++i) {\n            reshaped =\n                reshaped.concat([inputShape[i + 1] / blockShape[i], blockShape[i]]);\n        }\n        reshaped = reshaped.concat(inputShape.slice(spatialLength + 1));\n    }\n    return reshaped;\n}\n/**\n * Gets the permutation that will transpose the dimensions of the\n * reshaped tensor to shape:\n *\n * [batch / prod(block_shape),inputShape[1], blockShape[0], ...,\n * inputShape[M], blockShape[M-1],inputShape[M+1], ..., inputShape[N-1]]\n *\n * see step 2: https://www.tensorflow.org/api_docs/python/tf/batch_to_space_nd\n */\nexport function getPermuted(reshapedRank, blockShapeRank, batchToSpace = true) {\n    const permuted = [];\n    if (batchToSpace) {\n        permuted.push(blockShapeRank);\n        for (let i = blockShapeRank + 1; i < reshapedRank; ++i) {\n            if (i <= 2 * blockShapeRank) {\n                permuted.push(i);\n                permuted.push(i - (blockShapeRank + 1));\n            }\n            else {\n                permuted.push(i);\n            }\n        }\n    }\n    else {\n        const permutedBeforeBatch = [];\n        const permutedAfterBatch = [];\n        for (let i = 1; i < reshapedRank; ++i) {\n            if (i >= blockShapeRank * 2 + 1 || i % 2 === 1) {\n                permutedAfterBatch.push(i);\n            }\n            else {\n                permutedBeforeBatch.push(i);\n            }\n        }\n        permuted.push(...permutedBeforeBatch);\n        permuted.push(0);\n        permuted.push(...permutedAfterBatch);\n    }\n    return permuted;\n}\n/**\n * Gets the shape of the reshaped and permuted input Tensor before any cropping\n * is applied.  The new shape will be:\n *\n * [batch / prod(blockShape),inputShape[1] * blockShape[0], ...,\n * inputShape[M] * blockShape[M-1],inputShape[M+1], ..., inputShape[N-1]]\n *\n * See step 3: https://www.tensorflow.org/api_docs/python/tf/batch_to_space_nd\n */\nexport function getReshapedPermuted(inputShape, blockShape, prod, batchToSpace = true) {\n    const reshapedPermuted = [];\n    if (batchToSpace) {\n        reshapedPermuted.push(inputShape[0] / prod);\n    }\n    else {\n        reshapedPermuted.push(inputShape[0] * prod);\n    }\n    for (let i = 1; i < inputShape.length; ++i) {\n        if (i <= blockShape.length) {\n            if (batchToSpace) {\n                reshapedPermuted.push(blockShape[i - 1] * inputShape[i]);\n            }\n            else {\n                reshapedPermuted.push(inputShape[i] / blockShape[i - 1]);\n            }\n        }\n        else {\n            reshapedPermuted.push(inputShape[i]);\n        }\n    }\n    return reshapedPermuted;\n}\n/**\n * Converts the crops argument into the beginning coordinates of a slice\n * operation.\n */\nexport function getSliceBeginCoords(crops, blockShape) {\n    const sliceBeginCoords = [0];\n    for (let i = 0; i < blockShape; ++i) {\n        sliceBeginCoords.push(crops[i][0]);\n    }\n    return sliceBeginCoords;\n}\n/**\n * Converts the crops argument into the size of a slice operation.  When\n * combined with getSliceBeginCoords this function allows the reshaped and\n * permuted Tensor to be cropped to its final output shape of:\n *\n * inputShape[1] * blockShape[0] - crops[0,0] - crops[0,1], ...,\n * inputShape[M] * blockShape[M-1] -crops[M-1,0] -\n * crops[M-1,1],inputShape[M+1], ..., inputShape[N-1]]\n *\n * See step 4: https://www.tensorflow.org/api_docs/python/tf/batch_to_space_nd\n */\nexport function getSliceSize(uncroppedShape, crops, blockShape) {\n    const sliceSize = uncroppedShape.slice(0, 1);\n    for (let i = 0; i < blockShape; ++i) {\n        sliceSize.push(uncroppedShape[i + 1] - crops[i][0] - crops[i][1]);\n    }\n    return sliceSize;\n}\n//# sourceMappingURL=array_ops_util.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nexport const ERF_P = 0.3275911;\nexport const ERF_A1 = 0.254829592;\nexport const ERF_A2 = -0.284496736;\nexport const ERF_A3 = 1.421413741;\nexport const ERF_A4 = -1.453152027;\nexport const ERF_A5 = 1.061405429;\n//# sourceMappingURL=erf_util.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { env } from './environment';\nexport function warn(...msg) {\n    if (!env().getBool('IS_TEST')) {\n        console.warn(...msg);\n    }\n}\nexport function log(...msg) {\n    if (!env().getBool('IS_TEST')) {\n        console.log(...msg);\n    }\n}\n//# sourceMappingURL=log.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Conv2DBackpropFilter } from '../kernel_names';\nimport * as util from '../util';\nimport { op } from './operation';\nimport { reshape } from './reshape';\n/**\n * Computes the derivative of the filter of a 2D convolution.\n *\n * @param x The input tensor, of rank 4 or rank 3 of shape\n *     [batch, height, width, inChannels]. If rank 3, batch of 1 is assumed.\n * @param dy The dy image, of rank 4 or rank 3, of shape\n *     [batch, height, width, outDepth]. If rank 3, batch of 1 is assumed.\n * @param filterShape The shape of the filter, length 4,\n *     [filterHeight, filterWidth, inDepth, outDepth].\n * @param strides The strides of the convolution: [strideHeight,\n * strideWidth].\n * @param pad A string from: 'same', 'valid'. The type of padding algorithm\n *     used in the forward prop of the op.\n * @param dataFormat: An optional string from: \"NHWC\", \"NCHW\". Defaults to\n *     \"NHWC\". Specify the data format of the input and output data. With the\n *     default format \"NHWC\", the data is stored in the order of: [batch,\n *     height, width, channels].\n * @param dimRoundingMode A string from: 'ceil', 'round', 'floor'. If none is\n *     provided, it will default to truncate.\n */\nfunction conv2DBackpropFilter_(x, dy, filterShape, strides, pad, dataFormat = 'NHWC', dimRoundingMode) {\n    let x4D = x;\n    if (x.rank === 3) {\n        x4D = reshape(x, [1, x.shape[0], x.shape[1], x.shape[2]]);\n    }\n    let dy4D = dy;\n    if (dy4D.rank === 3) {\n        dy4D = reshape(dy, [1, dy.shape[0], dy.shape[1], dy.shape[2]]);\n    }\n    util.assert(x4D.rank === 4, () => `Error in conv2dDerFilter: input must be rank 4, but got shape ` +\n        `${x4D.shape}.`);\n    util.assert(dy4D.rank === 4, () => `Error in conv2dDerFilter: dy must be rank 4, but got shape ` +\n        `${dy4D.shape}.`);\n    util.assert(filterShape.length === 4, () => `Error in conv2dDerFilter: filterShape must be length 4, but got ` +\n        `${filterShape}.`);\n    const inDepth = dataFormat === 'NHWC' ? x4D.shape[3] : x4D.shape[1];\n    const outDepth = dataFormat === 'NHWC' ? dy4D.shape[3] : dy4D.shape[1];\n    util.assert(inDepth === filterShape[2], () => `Error in conv2dDerFilter: depth of input ${inDepth}) must ` +\n        `match input depth in filter (${filterShape[2]}.`);\n    util.assert(outDepth === filterShape[3], () => `Error in conv2dDerFilter: depth of dy (${outDepth}) must ` +\n        `match output depth for filter (${filterShape[3]}).`);\n    if (dimRoundingMode != null) {\n        util.assert(util.isInt(pad), () => `Error in conv2dDerFilter: pad must be an integer when using, ` +\n            `dimRoundingMode ${dimRoundingMode} but got pad ${pad}.`);\n    }\n    const inputs = { x: x4D, dy: dy4D };\n    const attrs = { strides, pad, dataFormat, dimRoundingMode, filterShape };\n    // tslint:disable-next-line: no-unnecessary-type-assertion\n    return ENGINE.runKernel(Conv2DBackpropFilter, inputs, attrs);\n}\nexport const conv2DBackpropFilter = op({ conv2DBackpropFilter_ });\n//# sourceMappingURL=conv2d_backprop_filter.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { DepthwiseConv2dNativeBackpropInput } from '../kernel_names';\nimport { op } from './operation';\nimport { reshape } from './reshape';\nfunction depthwiseConv2dNativeBackpropInput_(xShape, dy, filter, strides, pad, dilations = [1, 1], dimRoundingMode) {\n    let dy4D = dy;\n    let reshapedTo4D = false;\n    if (dy.rank === 3) {\n        reshapedTo4D = true;\n        dy4D = reshape(dy, [1, dy.shape[0], dy.shape[1], dy.shape[2]]);\n    }\n    const inputs = { dy: dy4D, filter };\n    const attrs = { strides, pad, dimRoundingMode, dilations, inputShape: xShape };\n    const res = \n    // tslint:disable-next-line: no-unnecessary-type-assertion\n    ENGINE.runKernel(DepthwiseConv2dNativeBackpropInput, inputs, attrs);\n    if (reshapedTo4D) {\n        return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);\n    }\n    return res;\n}\nexport const depthwiseConv2dNativeBackpropInput = op({ depthwiseConv2dNativeBackpropInput_ });\n//# sourceMappingURL=depthwise_conv2d_native_backprop_input.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { RealDiv } from '../kernel_names';\nimport { makeTypesMatch } from '../tensor_util';\nimport { convertToTensor } from '../tensor_util_env';\nimport { floorDiv } from './floorDiv';\nimport { op } from './operation';\n/**\n * Divides two `tf.Tensor`s element-wise, A / B. Supports broadcasting.\n *\n * ```js\n * const a = tf.tensor1d([1, 4, 9, 16]);\n * const b = tf.tensor1d([1, 2, 3, 4]);\n *\n * a.div(b).print();  // or tf.div(a, b)\n * ```\n *\n * ```js\n * // Broadcast div a with b.\n * const a = tf.tensor1d([2, 4, 6, 8]);\n * const b = tf.scalar(2);\n *\n * a.div(b).print();  // or tf.div(a, b)\n * ```\n *\n * @param a The first tensor as the numerator.\n * @param b The second tensor as the denominator. Must have the same dtype as\n * `a`.\n *\n * @doc {heading: 'Operations', subheading: 'Arithmetic'}\n */\nfunction div_(a, b) {\n    let $a = convertToTensor(a, 'a', 'div');\n    let $b = convertToTensor(b, 'b', 'div');\n    [$a, $b] = makeTypesMatch($a, $b);\n    if ($a.dtype === 'int32' && $b.dtype === 'int32') {\n        return floorDiv($a, $b);\n    }\n    const inputs = { a: $a, b: $b };\n    const attrs = {};\n    // tslint:disable-next-line: no-unnecessary-type-assertion\n    return ENGINE.runKernel(RealDiv, inputs, attrs);\n}\nexport const div = op({ div_ });\n//# sourceMappingURL=div.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { DepthwiseConv2dNativeBackpropFilter } from '../kernel_names';\nimport { op } from './operation';\nimport { reshape } from './reshape';\nfunction depthwiseConv2dNativeBackpropFilter_(x, dy, filterShape, strides, pad, dilations = [1, 1], dimRoundingMode) {\n    let x4D = x;\n    if (x.rank === 3) {\n        x4D = reshape(x, [1, x.shape[0], x.shape[1], x.shape[2]]);\n    }\n    let dy4D = dy;\n    if (dy4D.rank === 3) {\n        dy4D = reshape(dy, [1, dy.shape[0], dy.shape[1], dy.shape[2]]);\n    }\n    const inputs = { x: x4D, dy: dy4D };\n    const attrs = { strides, pad, dimRoundingMode, dilations, filterShape };\n    // tslint:disable-next-line: no-unnecessary-type-assertion\n    return ENGINE.runKernel(DepthwiseConv2dNativeBackpropFilter, inputs, attrs);\n}\nexport const depthwiseConv2dNativeBackpropFilter = op({ depthwiseConv2dNativeBackpropFilter_ });\n//# sourceMappingURL=depthwise_conv2d_native_backprop_filter.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Abs, ComplexAbs } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes absolute value element-wise: `abs(x)`\n *\n * ```js\n * const x = tf.tensor1d([-1, 2, -3, 4]);\n *\n * x.abs().print();  // or tf.abs(x)\n * ```\n * @param x The input `tf.Tensor`.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction abs_(x) {\n    const $x = convertToTensor(x, 'x', 'abs');\n    if ($x.dtype === 'complex64') {\n        const inputs = { x: $x };\n        return ENGINE.runKernel(ComplexAbs, inputs);\n    }\n    else {\n        const inputs = { x: $x };\n        return ENGINE.runKernel(Abs, inputs);\n    }\n}\nexport const abs = op({ abs_ });\n//# sourceMappingURL=abs.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Concat } from '../kernel_names';\nimport { convertToTensorArray } from '../tensor_util_env';\nimport { assert } from '../util';\nimport { clone } from './clone';\nimport { op } from './operation';\n/**\n * Concatenates a list of `tf.Tensor`s along a given axis.\n *\n * The tensors ranks and types must match, and their sizes must match in all\n * dimensions except `axis`.\n *\n * Also available are stricter rank-specific methods that assert that\n * `tensors` are of the given rank:\n *   - `tf.concat1d`\n *   - `tf.concat2d`\n *   - `tf.concat3d`\n *   - `tf.concat4d`\n *\n * Except `tf.concat1d` (which does not have axis param), all methods have\n * same signature as this method.\n *\n * ```js\n * const a = tf.tensor1d([1, 2]);\n * const b = tf.tensor1d([3, 4]);\n * a.concat(b).print();  // or a.concat(b)\n * ```\n *\n * ```js\n * const a = tf.tensor1d([1, 2]);\n * const b = tf.tensor1d([3, 4]);\n * const c = tf.tensor1d([5, 6]);\n * tf.concat([a, b, c]).print();\n * ```\n *\n * ```js\n * const a = tf.tensor2d([[1, 2], [10, 20]]);\n * const b = tf.tensor2d([[3, 4], [30, 40]]);\n * const axis = 1;\n * tf.concat([a, b], axis).print();\n * ```\n * @param tensors A list of tensors to concatenate.\n * @param axis The axis to concate along. Defaults to 0 (the first dim).\n *\n * @doc {heading: 'Tensors', subheading: 'Slicing and Joining'}\n */\nfunction concat_(tensors, axis = 0) {\n    assert(tensors.length >= 1, () => 'Pass at least one tensor to concat');\n    const $tensors = convertToTensorArray(tensors, 'tensors', 'concat', 'string_or_numeric');\n    if ($tensors[0].dtype === 'complex64') {\n        $tensors.forEach(tensor => {\n            if (tensor.dtype !== 'complex64') {\n                throw new Error(`Cannot concatenate complex64 tensors with a tensor\n          with dtype ${tensor.dtype}. `);\n            }\n        });\n    }\n    if ($tensors.length === 1) {\n        return clone($tensors[0]);\n    }\n    const inputs = $tensors;\n    const attr = { axis };\n    return ENGINE.runKernel(Concat, inputs, attr);\n}\nexport const concat = op({ concat_ });\n//# sourceMappingURL=concat.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n/**\n *\n * @param inputShape Input tensor shape is of the following dimensions:\n *     `[batch, height, width, inChannels]`.\n * @param filterShape The filter shape is of the following dimensions:\n *     `[filterHeight, filterWidth, depth]`.\n * @param strides The strides of the sliding window for each dimension of the\n *     input tensor: `[strideHeight, strideWidth]`.\n *     If `strides` is a single number,\n *     then `strideHeight == strideWidth`.\n * @param pad The type of padding algorithm.\n *    - `same` and stride 1: output will be of same size as input,\n *       regardless of filter size.\n *    - `valid`: output will be smaller than input if filter is larger\n *       than 1*1x1.\n *    - For more info, see this guide:\n *     [https://www.tensorflow.org/api_guides/python/nn#Convolution](\n *          https://www.tensorflow.org/api_guides/python/nn#Convolution)\n * @param dataFormat The data format of the input and output data.\n *     Defaults to 'NHWC'.\n * @param dilations The dilation rates: `[dilationHeight, dilationWidth]`.\n *     Defaults to `[1, 1]`. If `dilations` is a single number, then\n *     `dilationHeight == dilationWidth`.\n */\nexport function computeDilation2DInfo(inputShape, filterShape, strides, pad, dataFormat = 'NHWC', dilations) {\n    // `computerConv2DInfo` require filterShape to be in the dimension of:\n    // `[filterHeight, filterWidth, depth, outDepth]`, dilation2d doesn't have\n    // outDepth, it should have the same depth as the input.\n    // Input shape: [batch, height, width, inChannels]\n    const inputChannels = inputShape[3];\n    const $filterShape = [...filterShape, inputChannels];\n    const $dataFormat = convertConv2DDataFormat(dataFormat);\n    return computeConv2DInfo(inputShape, $filterShape, strides, dilations, pad, null /* roundingMode */, null /* depthWise */, $dataFormat);\n}\nexport function computePool2DInfo(inShape, filterSize, strides, dilations, pad, roundingMode, dataFormat = 'channelsLast') {\n    const [filterHeight, filterWidth] = parseTupleParam(filterSize);\n    let filterShape;\n    if (dataFormat === 'channelsLast') {\n        filterShape = [filterHeight, filterWidth, inShape[3], inShape[3]];\n    }\n    else if (dataFormat === 'channelsFirst') {\n        filterShape = [filterHeight, filterWidth, inShape[1], inShape[1]];\n    }\n    else {\n        throw new Error(`Unknown dataFormat ${dataFormat}`);\n    }\n    return computeConv2DInfo(inShape, filterShape, strides, dilations, pad, roundingMode, false, dataFormat);\n}\n/**\n * Computes the information for a forward pass of a pooling3D operation.\n */\nexport function computePool3DInfo(inShape, filterSize, strides, dilations, pad, roundingMode, dataFormat = 'NDHWC') {\n    const [filterDepth, filterHeight, filterWidth] = parse3TupleParam(filterSize);\n    let filterShape;\n    let $dataFormat;\n    if (dataFormat === 'NDHWC') {\n        $dataFormat = 'channelsLast';\n        filterShape =\n            [filterDepth, filterHeight, filterWidth, inShape[4], inShape[4]];\n    }\n    else if (dataFormat === 'NCDHW') {\n        $dataFormat = 'channelsFirst';\n        filterShape =\n            [filterDepth, filterHeight, filterWidth, inShape[1], inShape[1]];\n    }\n    else {\n        throw new Error(`Unknown dataFormat ${dataFormat}`);\n    }\n    return computeConv3DInfo(inShape, filterShape, strides, dilations, pad, false, $dataFormat, roundingMode);\n}\n/**\n * Computes the information for a forward pass of a convolution/pooling\n * operation.\n */\nexport function computeConv2DInfo(inShape, filterShape, strides, dilations, pad, roundingMode, depthwise = false, dataFormat = 'channelsLast') {\n    let [batchSize, inHeight, inWidth, inChannels] = [-1, -1, -1, -1];\n    if (dataFormat === 'channelsLast') {\n        [batchSize, inHeight, inWidth, inChannels] = inShape;\n    }\n    else if (dataFormat === 'channelsFirst') {\n        [batchSize, inChannels, inHeight, inWidth] = inShape;\n    }\n    else {\n        throw new Error(`Unknown dataFormat ${dataFormat}`);\n    }\n    const [filterHeight, filterWidth, , filterChannels] = filterShape;\n    const [strideHeight, strideWidth] = parseTupleParam(strides);\n    const [dilationHeight, dilationWidth] = parseTupleParam(dilations);\n    const effectiveFilterHeight = getEffectiveFilterSize(filterHeight, dilationHeight);\n    const effectiveFilterWidth = getEffectiveFilterSize(filterWidth, dilationWidth);\n    const { padInfo, outHeight, outWidth } = getPadAndOutInfo(pad, inHeight, inWidth, strideHeight, strideWidth, effectiveFilterHeight, effectiveFilterWidth, roundingMode, dataFormat);\n    const outChannels = depthwise ? filterChannels * inChannels : filterChannels;\n    let outShape;\n    if (dataFormat === 'channelsFirst') {\n        outShape = [batchSize, outChannels, outHeight, outWidth];\n    }\n    else if (dataFormat === 'channelsLast') {\n        outShape = [batchSize, outHeight, outWidth, outChannels];\n    }\n    return {\n        batchSize,\n        dataFormat,\n        inHeight,\n        inWidth,\n        inChannels,\n        outHeight,\n        outWidth,\n        outChannels,\n        padInfo,\n        strideHeight,\n        strideWidth,\n        filterHeight,\n        filterWidth,\n        effectiveFilterHeight,\n        effectiveFilterWidth,\n        dilationHeight,\n        dilationWidth,\n        inShape,\n        outShape,\n        filterShape\n    };\n}\n/**\n * Computes the information for a forward pass of a 3D convolution/pooling\n * operation.\n */\nexport function computeConv3DInfo(inShape, filterShape, strides, dilations, pad, depthwise = false, dataFormat = 'channelsLast', roundingMode) {\n    let [batchSize, inDepth, inHeight, inWidth, inChannels] = [-1, -1, -1, -1, -1];\n    if (dataFormat === 'channelsLast') {\n        [batchSize, inDepth, inHeight, inWidth, inChannels] = inShape;\n    }\n    else if (dataFormat === 'channelsFirst') {\n        [batchSize, inChannels, inDepth, inHeight, inWidth] = inShape;\n    }\n    else {\n        throw new Error(`Unknown dataFormat ${dataFormat}`);\n    }\n    const [filterDepth, filterHeight, filterWidth, , filterChannels] = filterShape;\n    const [strideDepth, strideHeight, strideWidth] = parse3TupleParam(strides);\n    const [dilationDepth, dilationHeight, dilationWidth] = parse3TupleParam(dilations);\n    const effectiveFilterDepth = getEffectiveFilterSize(filterDepth, dilationDepth);\n    const effectiveFilterHeight = getEffectiveFilterSize(filterHeight, dilationHeight);\n    const effectiveFilterWidth = getEffectiveFilterSize(filterWidth, dilationWidth);\n    const { padInfo, outDepth, outHeight, outWidth } = get3DPadAndOutInfo(pad, inDepth, inHeight, inWidth, strideDepth, strideHeight, strideWidth, effectiveFilterDepth, effectiveFilterHeight, effectiveFilterWidth, roundingMode);\n    const outChannels = depthwise ? filterChannels * inChannels : filterChannels;\n    let outShape;\n    if (dataFormat === 'channelsFirst') {\n        outShape = [batchSize, outChannels, outDepth, outHeight, outWidth];\n    }\n    else if (dataFormat === 'channelsLast') {\n        outShape = [batchSize, outDepth, outHeight, outWidth, outChannels];\n    }\n    return {\n        batchSize,\n        dataFormat,\n        inDepth,\n        inHeight,\n        inWidth,\n        inChannels,\n        outDepth,\n        outHeight,\n        outWidth,\n        outChannels,\n        padInfo,\n        strideDepth,\n        strideHeight,\n        strideWidth,\n        filterDepth,\n        filterHeight,\n        filterWidth,\n        effectiveFilterDepth,\n        effectiveFilterHeight,\n        effectiveFilterWidth,\n        dilationDepth,\n        dilationHeight,\n        dilationWidth,\n        inShape,\n        outShape,\n        filterShape\n    };\n}\nfunction computeOutputShape2D(inShape, fieldSize, stride, zeroPad, roundingMode) {\n    if (zeroPad == null) {\n        zeroPad = computeDefaultPad(inShape, fieldSize, stride);\n    }\n    const inputRows = inShape[0];\n    const inputCols = inShape[1];\n    const outputRows = round((inputRows - fieldSize + 2 * zeroPad) / stride + 1, roundingMode);\n    const outputCols = round((inputCols - fieldSize + 2 * zeroPad) / stride + 1, roundingMode);\n    return [outputRows, outputCols];\n}\nfunction computeOutputShape4D(inShape, fieldSize, outChannels, stride, zeroPad, roundingMode) {\n    if (zeroPad == null) {\n        zeroPad = computeDefaultPad(inShape, fieldSize, stride);\n    }\n    const inputDepth = inShape[0];\n    const inputRows = inShape[1];\n    const inputCols = inShape[2];\n    const outputDepths = round((inputDepth - fieldSize + 2 * zeroPad) / stride + 1, roundingMode);\n    const outputRows = round((inputRows - fieldSize + 2 * zeroPad) / stride + 1, roundingMode);\n    const outputCols = round((inputCols - fieldSize + 2 * zeroPad) / stride + 1, roundingMode);\n    return [outputDepths, outputRows, outputCols, outChannels];\n}\nexport function computeDefaultPad(inputShape, fieldSize, stride, dilation = 1) {\n    const effectiveFieldSize = getEffectiveFilterSize(fieldSize, dilation);\n    return Math.floor((inputShape[0] * (stride - 1) - stride + effectiveFieldSize) / 2);\n}\nfunction parseTupleParam(param) {\n    if (typeof param === 'number') {\n        return [param, param, param];\n    }\n    if (param.length === 2) {\n        return [param[0], param[1], 1];\n    }\n    return param;\n}\nfunction parse3TupleParam(param) {\n    return typeof param === 'number' ? [param, param, param] : param;\n}\n/* See https://www.tensorflow.org/api_docs/python/tf/nn/atrous_conv2d\n * Atrous convolution is equivalent to standard convolution with upsampled\n * filters with effective_filter_height =\n * filter_height + (filter_height - 1) * (dilation - 1)\n * and effective_filter_width =\n * filter_width + (filter_width - 1) * (dilation - 1),\n * produced by inserting dilation - 1 zeros along consecutive elements across\n * the filters' spatial dimensions.\n * When there is a dilation, this converts a filter dimension to the\n * effective filter dimension, so it can be used in a standard convolution.\n */\nfunction getEffectiveFilterSize(filterSize, dilation) {\n    if (dilation <= 1) {\n        return filterSize;\n    }\n    return filterSize + (filterSize - 1) * (dilation - 1);\n}\nfunction getPadAndOutInfo(pad, inHeight, inWidth, strideHeight, strideWidth, filterHeight, filterWidth, roundingMode, dataFormat) {\n    let padInfo;\n    let outHeight;\n    let outWidth;\n    if (typeof pad === 'number') {\n        const padType = (pad === 0) ? 'VALID' : 'NUMBER';\n        padInfo = { top: pad, bottom: pad, left: pad, right: pad, type: padType };\n        const outShape = computeOutputShape2D([inHeight, inWidth], filterHeight, strideHeight, pad, roundingMode);\n        outHeight = outShape[0];\n        outWidth = outShape[1];\n    }\n    else if (pad === 'same') {\n        outHeight = Math.ceil(inHeight / strideHeight);\n        outWidth = Math.ceil(inWidth / strideWidth);\n        const padAlongHeight = Math.max(0, (outHeight - 1) * strideHeight + filterHeight - inHeight);\n        const padAlongWidth = Math.max(0, (outWidth - 1) * strideWidth + filterWidth - inWidth);\n        const top = Math.floor(padAlongHeight / 2);\n        const bottom = padAlongHeight - top;\n        const left = Math.floor(padAlongWidth / 2);\n        const right = padAlongWidth - left;\n        padInfo = { top, bottom, left, right, type: 'SAME' };\n    }\n    else if (pad === 'valid') {\n        padInfo = { top: 0, bottom: 0, left: 0, right: 0, type: 'VALID' };\n        outHeight = Math.ceil((inHeight - filterHeight + 1) / strideHeight);\n        outWidth = Math.ceil((inWidth - filterWidth + 1) / strideWidth);\n    }\n    else if (typeof pad === 'object') {\n        const top = dataFormat === 'channelsLast' ? pad[1][0] : pad[2][0];\n        const bottom = dataFormat === 'channelsLast' ? pad[1][1] : pad[2][1];\n        const left = dataFormat === 'channelsLast' ? pad[2][0] : pad[3][0];\n        const right = dataFormat === 'channelsLast' ? pad[2][1] : pad[3][1];\n        const padType = (top === 0 && bottom === 0 && left === 0 && right === 0) ?\n            'VALID' :\n            'EXPLICIT';\n        padInfo = { top, bottom, left, right, type: padType };\n        outHeight = round((inHeight - filterHeight + top + bottom) / strideHeight + 1, roundingMode);\n        outWidth = round((inWidth - filterWidth + left + right) / strideWidth + 1, roundingMode);\n    }\n    else {\n        throw Error(`Unknown padding parameter: ${pad}`);\n    }\n    return { padInfo, outHeight, outWidth };\n}\nfunction get3DPadAndOutInfo(pad, inDepth, inHeight, inWidth, strideDepth, strideHeight, strideWidth, filterDepth, filterHeight, filterWidth, roundingMode) {\n    let padInfo;\n    let outDepth;\n    let outHeight;\n    let outWidth;\n    if (typeof pad === 'number') {\n        const padType = (pad === 0) ? 'VALID' : 'NUMBER';\n        padInfo = {\n            top: pad,\n            bottom: pad,\n            left: pad,\n            right: pad,\n            front: pad,\n            back: pad,\n            type: padType\n        };\n        const outShape = computeOutputShape4D([inDepth, inHeight, inWidth, 1], filterDepth, 1, strideDepth, pad, roundingMode);\n        outDepth = outShape[0];\n        outHeight = outShape[1];\n        outWidth = outShape[2];\n    }\n    else if (pad === 'same') {\n        outDepth = Math.ceil(inDepth / strideDepth);\n        outHeight = Math.ceil(inHeight / strideHeight);\n        outWidth = Math.ceil(inWidth / strideWidth);\n        const padAlongDepth = (outDepth - 1) * strideDepth + filterDepth - inDepth;\n        const padAlongHeight = (outHeight - 1) * strideHeight + filterHeight - inHeight;\n        const padAlongWidth = (outWidth - 1) * strideWidth + filterWidth - inWidth;\n        const front = Math.floor(padAlongDepth / 2);\n        const back = padAlongDepth - front;\n        const top = Math.floor(padAlongHeight / 2);\n        const bottom = padAlongHeight - top;\n        const left = Math.floor(padAlongWidth / 2);\n        const right = padAlongWidth - left;\n        padInfo = { top, bottom, left, right, front, back, type: 'SAME' };\n    }\n    else if (pad === 'valid') {\n        padInfo = {\n            top: 0,\n            bottom: 0,\n            left: 0,\n            right: 0,\n            front: 0,\n            back: 0,\n            type: 'VALID'\n        };\n        outDepth = Math.ceil((inDepth - filterDepth + 1) / strideDepth);\n        outHeight = Math.ceil((inHeight - filterHeight + 1) / strideHeight);\n        outWidth = Math.ceil((inWidth - filterWidth + 1) / strideWidth);\n    }\n    else {\n        throw Error(`Unknown padding parameter: ${pad}`);\n    }\n    return { padInfo, outDepth, outHeight, outWidth };\n}\n/**\n * Rounds a value depending on the rounding mode\n * @param value\n * @param roundingMode A string from: 'ceil', 'round', 'floor'. If none is\n *     provided, it will default to truncate.\n */\nfunction round(value, roundingMode) {\n    if (!roundingMode) {\n        return Math.trunc(value);\n    }\n    switch (roundingMode) {\n        case 'round':\n            // used for Caffe Conv\n            return Math.round(value);\n        case 'ceil':\n            // used for Caffe Pool\n            return Math.ceil(value);\n        case 'floor':\n            return Math.floor(value);\n        default:\n            throw new Error(`Unknown roundingMode ${roundingMode}`);\n    }\n}\nexport function tupleValuesAreOne(param) {\n    const [dimA, dimB, dimC] = parseTupleParam(param);\n    return dimA === 1 && dimB === 1 && dimC === 1;\n}\nexport function eitherStridesOrDilationsAreOne(strides, dilations) {\n    return tupleValuesAreOne(strides) || tupleValuesAreOne(dilations);\n}\n/**\n * Convert Conv2D dataFormat from 'NHWC'|'NCHW' to\n *    'channelsLast'|'channelsFirst'\n * @param dataFormat in 'NHWC'|'NCHW' mode\n * @return dataFormat in 'channelsLast'|'channelsFirst' mode\n * @throws unknown dataFormat\n */\nexport function convertConv2DDataFormat(dataFormat) {\n    if (dataFormat === 'NHWC') {\n        return 'channelsLast';\n    }\n    else if (dataFormat === 'NCHW') {\n        return 'channelsFirst';\n    }\n    else {\n        throw new Error(`Unknown dataFormat ${dataFormat}`);\n    }\n}\n//# sourceMappingURL=conv_util.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Complex } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport * as util from '../util';\nimport { op } from './operation';\n/**\n * Converts two real numbers to a complex number.\n *\n * Given a tensor `real` representing the real part of a complex number, and a\n * tensor `imag` representing the imaginary part of a complex number, this\n * operation returns complex numbers elementwise of the form [r0, i0, r1, i1],\n * where r represents the real part and i represents the imag part.\n *\n * The input tensors real and imag must have the same shape.\n *\n * ```js\n * const real = tf.tensor1d([2.25, 3.25]);\n * const imag = tf.tensor1d([4.75, 5.75]);\n * const complex = tf.complex(real, imag);\n *\n * complex.print();\n * ```\n *\n * @doc {heading: 'Tensors', subheading: 'Creation'}\n */\nfunction complex_(real, imag) {\n    const $real = convertToTensor(real, 'real', 'complex');\n    const $imag = convertToTensor(imag, 'imag', 'complex');\n    util.assertShapesMatch($real.shape, $imag.shape, `real and imag shapes, ${$real.shape} and ${$imag.shape}, ` +\n        `must match in call to tf.complex().`);\n    const inputs = { real: $real, imag: $imag };\n    return ENGINE.runKernel(Complex, inputs);\n}\nexport const complex = op({ complex_ });\n//# sourceMappingURL=complex.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Identity } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Creates a new tensor with the same values and shape as the specified\n * tensor.\n *\n * ```js\n * const x = tf.tensor([1, 2]);\n *\n * x.clone().print();\n * ```\n *\n * @param x The tensor to clone.\n *\n * @doc {heading: 'Tensors', subheading: 'Creation'}\n */\nfunction clone_(x) {\n    const $x = convertToTensor(x, 'x', 'clone', 'string_or_numeric');\n    const inputs = { x: $x };\n    // Note this op is called tf.identity in python. Hence the kernel name used\n    // here.\n    return ENGINE.runKernel(Identity, inputs);\n}\nexport const clone = op({ clone_ });\n//# sourceMappingURL=clone.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Exp } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes exponential of the input `tf.Tensor` element-wise. `e ^ x`\n *\n * ```js\n * const x = tf.tensor1d([1, 2, -3]);\n *\n * x.exp().print();  // or tf.exp(x)\n * ```\n * @param x The input tensor.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction exp_(x) {\n    const $x = convertToTensor(x, 'x', 'exp');\n    const inputs = { x: $x };\n    return ENGINE.runKernel(Exp, inputs);\n}\nexport const exp = op({ exp_ });\n//# sourceMappingURL=exp.js.map","/**\n * @license\n * Copyright 2020 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { TensorBuffer } from '../tensor';\nimport * as util from '../util';\n/**\n * Creates an empty `tf.TensorBuffer` with the specified `shape` and `dtype`.\n *\n * The values are stored in CPU as `TypedArray`. Fill the buffer using\n * `buffer.set()`, or by modifying directly `buffer.values`.\n *\n * When done, call `buffer.toTensor()` to get an immutable `tf.Tensor` with\n * those values.\n *\n * ```js\n * // Create a buffer and set values at particular indices.\n * const buffer = tf.buffer([2, 2]);\n * buffer.set(3, 0, 0);\n * buffer.set(5, 1, 0);\n *\n * // Convert the buffer back to a tensor.\n * buffer.toTensor().print();\n * ```\n *\n * @param shape An array of integers defining the output tensor shape.\n * @param dtype The dtype of the buffer. Defaults to 'float32'.\n * @param values The values of the buffer as `TypedArray`. Defaults to\n * zeros.\n *\n * @doc {heading: 'Tensors', subheading: 'Creation'}\n */\nexport function buffer(shape, dtype = 'float32', values) {\n    dtype = dtype || 'float32';\n    util.assertNonNegativeIntegerDimensions(shape);\n    return new TensorBuffer(shape, dtype, values);\n}\n//# sourceMappingURL=buffer.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { ExpandDims } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport * as util from '../util';\nimport { op } from './operation';\n/**\n * Returns a `tf.Tensor` that has expanded rank, by inserting a dimension\n * into the tensor's shape.\n *\n * ```js\n * const x = tf.tensor1d([1, 2, 3, 4]);\n * const axis = 1;\n * x.expandDims(axis).print();\n * ```\n *\n * @param x The input tensor whose dimensions to be expanded.\n * @param axis The dimension index at which to insert shape of `1`. Defaults\n *     to 0 (the first dimension).\n *\n * @doc {heading: 'Tensors', subheading: 'Transformations'}\n */\nfunction expandDims_(x, axis = 0) {\n    const $x = convertToTensor(x, 'x', 'expandDims', 'string_or_numeric');\n    util.assert(axis <= $x.rank, () => 'Axis must be <= rank of the tensor');\n    const inputs = { input: $x };\n    const attrs = { dim: axis };\n    return ENGINE.runKernel(ExpandDims, inputs, attrs);\n}\nexport const expandDims = op({ expandDims_ });\n//# sourceMappingURL=expand_dims.js.map","/**\n * @license\n * Copyright 2017 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport * as util from '../util';\n/**\n * Returns true if the axis specifies the inner most dimensions of the\n * array.\n */\nexport function axesAreInnerMostDims(axes, rank) {\n    for (let i = 0; i < axes.length; ++i) {\n        if (axes[axes.length - i - 1] !== rank - 1 - i) {\n            return false;\n        }\n    }\n    return true;\n}\nexport function combineLocations(outputLoc, reduceLoc, axes) {\n    const rank = outputLoc.length + reduceLoc.length;\n    const loc = [];\n    let outIdx = 0;\n    let reduceIdx = 0;\n    for (let dim = 0; dim < rank; dim++) {\n        if (axes.indexOf(dim) === -1) {\n            loc.push(outputLoc[outIdx++]);\n        }\n        else {\n            loc.push(reduceLoc[reduceIdx++]);\n        }\n    }\n    return loc;\n}\nexport function computeOutAndReduceShapes(aShape, axes) {\n    const outShape = [];\n    const rank = aShape.length;\n    for (let dim = 0; dim < rank; dim++) {\n        if (axes.indexOf(dim) === -1) {\n            outShape.push(aShape[dim]);\n        }\n    }\n    const reduceShape = axes.map(dim => aShape[dim]);\n    return [outShape, reduceShape];\n}\nexport function expandShapeToKeepDim(shape, axes) {\n    const reduceSubShape = axes.map(x => 1);\n    return combineLocations(shape, reduceSubShape, axes);\n}\nexport function assertAxesAreInnerMostDims(msg, axes, rank) {\n    util.assert(axesAreInnerMostDims(axes, rank), () => `${msg} supports only inner-most axes for now. ` +\n        `Got axes ${axes} and rank-${rank} input.`);\n}\n/**\n * Returns the axes permutation to be used with `tf.transpose`, if such\n * permutation is necessary. Otherwise it returns null. This method is used by\n * operations that operate only on inner-most axes.\n */\nexport function getAxesPermutation(axes, rank) {\n    if (axesAreInnerMostDims(axes, rank)) {\n        return null;\n    }\n    const result = [];\n    for (let i = 0; i < rank; ++i) {\n        if (axes.indexOf(i) === -1) {\n            result.push(i);\n        }\n    }\n    axes.forEach(axis => result.push(axis));\n    return result;\n}\n/** Returns the axes permutation that undoes the original permutation. */\nexport function getUndoAxesPermutation(axes) {\n    return axes.map((axis, i) => [i, axis])\n        .sort((a, b) => a[1] - b[1])\n        .map(x => x[0]);\n}\nexport function getInnerMostAxes(numAxes, rank) {\n    const res = [];\n    for (let i = rank - numAxes; i < rank; ++i) {\n        res.push(i);\n    }\n    return res;\n}\n//# sourceMappingURL=axis_util.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Tile } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { clone } from './clone';\nimport { op } from './operation';\nimport { reshape } from './reshape';\n/**\n * Broadcast an array to a compatible shape NumPy-style.\n *\n * The tensor's shape is compared to the broadcast shape from end to beginning.\n * Ones are prepended to the tensor's shape until is has the same length as\n * the broadcast shape. If input.shape[i]==shape[i], the (i+1)-th axis is\n * already broadcast-compatible. If input.shape[i]==1 and shape[i]==N, then\n * the input tensor is tiled N times along that axis (using tf.tile).\n *\n * @param input The tensor that is to be broadcasted.\n * @param shape The input is to be broadcast to this shape.\n *\n * @doc {heading: 'Tensors', subheading: 'Transformations'}\n */\nfunction broadcastTo_(x, shape) {\n    let input = convertToTensor(x, 'broadcastTo', 'x');\n    const xShape = input.shape;\n    if (shape.some(d => !(d > 0) || d % 1 !== 0)) {\n        throw new Error(`broadcastTo(): Invalid broadcast shape [${shape}].`);\n    }\n    if (shape.length < input.rank) {\n        throw new Error(`broadcastTo(): shape.length=${shape.length} < input.rank=${input.rank}.`);\n    }\n    if (shape.length > input.rank) {\n        const newShape = input.shape.slice();\n        while (newShape.length < shape.length) {\n            newShape.unshift(1);\n        }\n        input = reshape(input, newShape);\n    }\n    const inputShape = input.shape;\n    const reps = Array.from(shape);\n    for (let i = shape.length - 1; i >= 0; i--) {\n        if (inputShape[i] === shape[i]) {\n            reps[i] = 1;\n        }\n        else if (input.shape[i] !== 1) {\n            throw new Error(`broadcastTo(): [${xShape}] cannot be broadcast to [${shape}].`);\n        }\n    }\n    const axes = reps.map((n, i) => n > 1 ? i : -1).filter(i => i >= 0);\n    if (axes.length === 0) {\n        return clone(input);\n    }\n    // TODO call broadcastTo kernel directly once backends implement broadcstTo\n    const inputs = { x: input };\n    const attrs = { reps };\n    return ENGINE.runKernel(Tile, inputs, attrs);\n}\nexport const broadcastTo = op({ broadcastTo_ });\n//# sourceMappingURL=broadcast_to.js.map"],"sourceRoot":""}