{"version":3,"sources":["webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/array_util.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/non_max_suppression_impl.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/flags.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/device_util.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/environment.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/complex_util.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/backend_util.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/backend.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/engine.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/base_side_effects.js"],"names":["binaryInsert","arr","element","comparator","index","target","left","right","length","middle","found","compareResult","binarySearch_","defaultComparator","binarySearch","insertionPoint","splice","a","b","nonMaxSuppressionV3Impl","boxes","scores","maxOutputSize","iouThreshold","scoreThreshold","nonMaxSuppressionImpl_","selectedIndices","nonMaxSuppressionV4Impl","padToMaxOutputSize","nonMaxSuppressionV5Impl","softNmsSigma","returnScoresTensor","returnValidOutputs","candidates","i","push","score","boxIndex","suppressBeginIndex","sort","ascendingComparator","scale","selectedScores","candidate","pop","originalScore","ignoreCandidate","j","iou","intersectionOverUnion","suppressWeight","validOutputs","elemsToPad","Array","fill","result","tensor1d","scalar","iCoord","subarray","jCoord","yminI","Math","min","xminI","ymaxI","max","xmaxI","yminJ","xminJ","ymaxJ","xmaxJ","areaI","areaJ","intersectionYmin","intersectionXmin","intersectionYmax","intersectionXmax","intersectionArea","weight","exp","c1","c2","ENV","registerFlag","debugValue","console","warn","process","versions","node","navigator","userAgent","test","vendor","getBool","isBrowser","window","document","WorkerGlobalScope","TENSORFLOWJS_FLAGS_PREFIX","Environment","global","this","flags","flagRegistry","urlFlags","populateURLFlags","platformName","platform","flagName","evaluationFn","setHook","flagValue","set","evaluateFlag","Promise","Error","get","value","Object","assign","location","search","urlParams","queryString","params","replace","s","t","name","decodeURIComponent","decodeParam","join","getQueryParams","split","forEach","keyValue","key","toLowerCase","parseValue","env","setEnvironmentGlobal","environment","mergeRealAndImagArrays","real","imag","Float32Array","splitRealAndImagArrays","complex","complexWithEvenIndex","len","ceil","floor","complexWithOddIndex","getComplexWithIndex","assignToTypedArray","data","exponents","n","inverse","x","PI","cos","sin","exponent","k","castTensor","dtype","backend","clone","zerosTensor","zeros","shape","floatX","cast","dispose","makeTensorFromDataId","dataId","int","zero","notEqual","reshapeTensor","linspaceImpl","start","stop","num","step","values","DataStorage","dataMover","WeakMap","dataIdsCount","has","moveData","delete","KernelBackend","f","notYetImplemented","floatPrecision","transposeA","transposeB","bias","activation","preluActivationWeights","begin","size","end","strides","axis","tensors","axes","segmentIds","numSegments","condition","sorted","dim","dy","y","alpha","input","filter","convInfo","dY","reps","paddings","constantValue","perm","indices","updates","blockShape","crops","newHeight","newWidth","alignCorners","newHEight","mean","variance","offset","varianceEpsilon","radius","beta","inputImage","outputImage","logits","normalized","numSamples","seed","depth","onValue","offValue","exclusive","reverse","image","cropSize","method","extrapolationValue","blockSize","dataFormat","sizeSplits","sparseIndices","sparseValues","outputShape","defaultValue","kernelName","EngineState","registeredVariables","nextTapeNodeId","numBytes","numTensors","numStringTensors","numDataBuffers","gradientDepth","kernelDepth","scopeStack","numDataMovesStack","nextScopeId","tensorInfo","profiling","activeProfile","newBytes","newTensors","peakBytes","kernels","variableName","Engine","registry","registryFactory","pendingBackendInitId","state","pendingBackendInit","then","backendInstance","sortedBackends","getSortedBackends","backendName","initializeBackend","success","setBackend","asyncInit","initializeBackendsAndReturnBest","keys","factory","priority","setupRegisteredKernels","profiler","kernel","setupFunc","disposeFunc","registryFactoryEntry","resolve","promiseId","catch","err","stack","message","disposeRegisteredKernels","info","srcBackend","readSync","disposeData","move","shouldCheckForMemLeaks","nameOrFn","fn","String","scopedRun","startScope","endScope","error","res","ex","nextTensorId","nextVariableId","inputs","addTapeNode","activeScope","gradInputs","attrs","ENGINE","runKernelFunc","inputsToSave","outputsToSave","numDataIdsBefore","outInfos","numDataIdsAfter","numDataIds","numOutputDataIds","numMoves","dataIdsLeaked","forwardFunc","backwardsFunc","outputs","saved","isTapeOn","startingBytecount","startingNumTensors","kernelFunc","out","kernelProfile","isArray","checkKernelForMemLeak","outTensors","map","tensorsToSave","getTensorsForGradient","outsToSave","_","slice","concat","saveTensorsForBackwardMode","saveFunc","tensor","keep","tidy","outs","profileKernel","logKernelProfile","bytesAdded","totalBytesSnapshot","tensorsAdded","totalTensorsSnapshot","inputShapes","outputShapes","item","kernelTimeMs","timeMs","extraInfo","gradConfig","inputTensorsToSave","saveAllInputs","inputName","outputTensorsToSave","backendVals","d","write","incRef","bytes","initialValue","trainable","toString","v","refCount","track","varName","disposeVariable","disposeTensor","memory","unreliable","reasons","query","startBytes","startNumTensors","gradientsFunc","tapeNode","id","gradFunc","gradient","dys","output","vals","makeTensor","activeTape","kept","scopeInfo","tensorsToTrackInParent","tensorsToTrackInParentSet","Set","oldScope","scopeId","xs","allowNoGradients","startTape","endTape","filteredTape","accumulatedGradientMap","ones","add","grads","every","inputMap","save","gradRes","gradMap","grad","read","timingInfo","time","wallMs","reset","getOrMakeEngine","ns","_tfengine","opHandler","buffer","print"],"mappings":";iRA6BO,SAASA,EAAaC,EAAKC,EAASC,GACvC,MAAMC,EAmBH,SAAsBH,EAAKI,EAAQF,GACtC,OAYJ,SAAuBF,EAAKI,EAAQF,GAChC,IAAIG,EAAO,EACPC,EAAQN,EAAIO,OACZC,EAAS,EACTC,GAAQ,EACZ,KAAOJ,EAAOC,GAAO,CACjBE,EAASH,GAASC,EAAQD,IAAU,GACpC,MAAMK,EAAgBR,EAAWE,EAAQJ,EAAIQ,IACzCE,EAAgB,EAChBL,EAAOG,EAAS,GAGhBF,EAAQE,EAGRC,GAASC,GAGjB,OAAOD,EAAQJ,GAAQA,EAAO,EA9BvBM,CAAcX,EAAKI,EAAQF,GAAcU,GApBlCC,CAAab,EAAKC,EAASC,GACnCY,EAAiBX,EAAQ,IAAMA,EAAQ,GAAKA,EAClDH,EAAIe,OAAOD,EAAgB,EAAGb,GA2BlC,SAASW,EAAkBI,EAAGC,GAC1B,OAAOD,EAAIC,EAAI,EAAID,EAAIC,GAAK,EAAI,ECtC7B,SAASC,EAAwBC,EAAOC,EAAQC,EAAeC,EAAcC,GAChF,OAAOC,EAAuBL,EAAOC,EAAQC,EAAeC,EAAcC,EAAgB,GACrFE,gBAEF,SAASC,EAAwBP,EAAOC,EAAQC,EAAeC,EAAcC,EAAgBI,GAChG,OAAOH,EAAuBL,EAAOC,EAAQC,EAAeC,EAAcC,EAAgB,GAAsB,EAAgCI,GAA6C,GAG1L,SAASC,EAAwBT,EAAOC,EAAQC,EAAeC,EAAcC,EAAgBM,GAChG,OAAOL,EAAuBL,EAAOC,EAAQC,EAAeC,EAAcC,EAAgBM,GAAc,GAE5G,SAASL,EAAuBL,EAAOC,EAAQC,EAAeC,EAAcC,EAAgBM,EAAcC,GAAqB,EAAOH,GAAqB,EAAOI,GAAqB,GAGnL,MAAMC,EAAa,GACnB,IAAK,IAAIC,EAAI,EAAGA,EAAIb,EAAOb,OAAQ0B,IAC3Bb,EAAOa,GAAKV,GACZS,EAAWE,KAAK,CAAEC,MAAOf,EAAOa,GAAIG,SAAUH,EAAGI,mBAAoB,IAG7EL,EAAWM,KAAKC,GAGhB,MAAMC,EAAQX,EAAe,GAAM,GAAMA,EAAgB,EACnDJ,EAAkB,GAClBgB,EAAiB,GACvB,KAAOhB,EAAgBlB,OAASc,GAAiBW,EAAWzB,OAAS,GAAG,CACpE,MAAMmC,EAAYV,EAAWW,OACrBR,MAAOS,EAAa,SAAER,EAAQ,mBAAEC,GAAuBK,EAC/D,GAAIE,EAAgBrB,EAChB,MAQJ,IAAIsB,GAAkB,EACtB,IAAK,IAAIC,EAAIrB,EAAgBlB,OAAS,EAAGuC,GAAKT,IAAsBS,EAAG,CACnE,MAAMC,EAAMC,EAAsB7B,EAAOiB,EAAUX,EAAgBqB,IACnE,GAAIC,GAAOzB,EAAc,CACrBuB,GAAkB,EAClB,MAIJ,GAFAH,EAAUP,MACNO,EAAUP,MAAQc,EAAe3B,EAAckB,EAAOO,GACtDL,EAAUP,OAASZ,EACnB,MAURmB,EAAUL,mBAAqBZ,EAAgBlB,OAC1CsC,IAGGH,EAAUP,QAAUS,GACpBnB,EAAgBS,KAAKE,GACrBK,EAAeP,KAAKQ,EAAUP,QAEzBO,EAAUP,MAAQZ,GAGvBxB,EAAaiC,EAAYU,EAAWH,IAKhD,MAAMW,EAAezB,EAAgBlB,OAC/B4C,EAAa9B,EAAgB6B,EAC/BvB,GAAsBwB,EAAa,IACnC1B,EAAgBS,QAAQ,IAAIkB,MAAMD,GAAYE,KAAK,IACnDZ,EAAeP,QAAQ,IAAIkB,MAAMD,GAAYE,KAAK,KAEtD,MAAMC,EAAS,CAAE7B,gBAAiB,OAAA8B,EAAA,GAAS9B,EAAiB,UAO5D,OANIK,IACAwB,EAAuB,eAAI,OAAAC,EAAA,GAASd,EAAgB,YAEpDV,IACAuB,EAAqB,aAAI,OAAAE,EAAA,GAAON,EAAc,UAE3CI,EAEX,SAASN,EAAsB7B,EAAOc,EAAGa,GACrC,MAAMW,EAAStC,EAAMuC,SAAa,EAAJzB,EAAW,EAAJA,EAAQ,GACvC0B,EAASxC,EAAMuC,SAAa,EAAJZ,EAAW,EAAJA,EAAQ,GACvCc,EAAQC,KAAKC,IAAIL,EAAO,GAAIA,EAAO,IACnCM,EAAQF,KAAKC,IAAIL,EAAO,GAAIA,EAAO,IACnCO,EAAQH,KAAKI,IAAIR,EAAO,GAAIA,EAAO,IACnCS,EAAQL,KAAKI,IAAIR,EAAO,GAAIA,EAAO,IACnCU,EAAQN,KAAKC,IAAIH,EAAO,GAAIA,EAAO,IACnCS,EAAQP,KAAKC,IAAIH,EAAO,GAAIA,EAAO,IACnCU,EAAQR,KAAKI,IAAIN,EAAO,GAAIA,EAAO,IACnCW,EAAQT,KAAKI,IAAIN,EAAO,GAAIA,EAAO,IACnCY,GAASP,EAAQJ,IAAUM,EAAQH,GACnCS,GAASH,EAAQF,IAAUG,EAAQF,GACzC,GAAIG,GAAS,GAAKC,GAAS,EACvB,OAAO,EAEX,MAAMC,EAAmBZ,KAAKI,IAAIL,EAAOO,GACnCO,EAAmBb,KAAKI,IAAIF,EAAOK,GACnCO,EAAmBd,KAAKC,IAAIE,EAAOK,GACnCO,EAAmBf,KAAKC,IAAII,EAAOI,GACnCO,EAAmBhB,KAAKI,IAAIU,EAAmBF,EAAkB,GACnEZ,KAAKI,IAAIW,EAAmBF,EAAkB,GAClD,OAAOG,GAAoBN,EAAQC,EAAQK,GAM/C,SAAS5B,EAAe3B,EAAckB,EAAOO,GACzC,MAAM+B,EAASjB,KAAKkB,IAAIvC,EAAQO,EAAMA,GACtC,OAAOA,GAAOzB,EAAewD,EAAS,EAE1C,SAASvC,EAAoByC,EAAIC,GAK7B,OAAQD,EAAG7C,MAAQ8C,EAAG9C,OAChB6C,EAAG7C,QAAU8C,EAAG9C,OAAW8C,EAAG7C,SAAW4C,EAAG5C,W,kCCrJtD,iCAmBA,MAAM8C,EAAM,cAKZA,EAAIC,aAAa,SAAS,KAAM,IAAOC,IAC/BA,GACAC,QAAQC,KAAK,kJAMrBJ,EAAIC,aAAa,cAAc,IAAM,QAErCD,EAAIC,aAAa,WAAW,SAA0B,IAAZI,QACT,IAArBA,EAAQC,eACkB,IAA1BD,EAAQC,SAASC,OAE7BP,EAAIC,aAAa,aAAa,IAA2B,oBAAdO,WAA0C,MAAbA,WAC7C,MAAvBA,UAAUC,WAAqB,SAASC,KAAKF,UAAUC,YACvD,aAAaC,KAAKF,UAAUG,UAKhCX,EAAIC,aAAa,QAAQ,KAAM,IAK/BD,EAAIC,aAAa,sCAAsC,IAAMD,EAAIY,QAAQ,WAEzEZ,EAAIC,aAAa,gCAAgC,KAAM,IAEvDD,EAAIC,aAAa,WAAW,KAAM,M,oDCrB3B,SAASY,IACZ,MAA0B,oBAAXC,QAA6C,MAAnBA,OAAOC,UAEd,oBAAtBC,kBApChB,mC,gCCAA,sGAiBA,MAAMC,EAA4B,YAQ3B,MAAMC,EAET,YAAYC,GACRC,KAAKD,OAASA,EACdC,KAAKC,MAAQ,GACbD,KAAKE,aAAe,GACpBF,KAAKG,SAAW,GAChBH,KAAKI,mBAET,YAAYC,EAAcC,GACD,MAAjBN,KAAKM,UACLvB,QAAQC,KAAK,YAAYgB,KAAKK,oEACOC,MAEzCN,KAAKK,aAAeA,EACpBL,KAAKM,SAAWA,EAEpB,aAAaC,EAAUC,EAAcC,GAIjC,GAHAT,KAAKE,aAAaK,GAAY,CAAEC,eAAcC,WAGf,MAA3BT,KAAKG,SAASI,GAAmB,CACjC,MAAMG,EAAYV,KAAKG,SAASI,GAChCxB,QAAQC,KAAK,qCAAqCuB,MAAaG,MAC/DV,KAAKW,IAAIJ,EAAUG,IAG3B,eAAeH,GACX,OAAIA,KAAYP,KAAKC,QAGrBD,KAAKC,MAAMM,SAAkBP,KAAKY,aAAaL,IAFpCP,KAAKC,MAAMM,GAK1B,IAAIA,GACA,GAAIA,KAAYP,KAAKC,MACjB,OAAOD,KAAKC,MAAMM,GAEtB,MAAMG,EAAYV,KAAKY,aAAaL,GACpC,GAAIG,aAAqBG,QACrB,MAAM,IAAIC,MAAM,QAAQP,uEAI5B,OADAP,KAAKC,MAAMM,GAAYG,EAChBV,KAAKC,MAAMM,GAEtB,UAAUA,GACN,OAAOP,KAAKe,IAAIR,GAEpB,QAAQA,GACJ,OAAOP,KAAKe,IAAIR,GAEpB,WACI,OAAOP,KAAKC,MAGhB,eACI,OAAOD,KAAKC,MAEhB,IAAIM,EAAUS,GACV,GAAmC,MAA/BhB,KAAKE,aAAaK,GAClB,MAAM,IAAIO,MAAM,mBAAmBP,oCAEvCP,KAAKC,MAAMM,GAAYS,EACoB,MAAvChB,KAAKE,aAAaK,GAAUE,SAC5BT,KAAKE,aAAaK,GAAUE,QAAQO,GAG5C,aAAaT,GACT,GAAmC,MAA/BP,KAAKE,aAAaK,GAClB,MAAM,IAAIO,MAAM,yBAAyBP,qCAE7C,OAAOP,KAAKE,aAAaK,GAAUC,eAEvC,SAASP,GACLD,KAAKC,MAAQgB,OAAOC,OAAO,GAAIjB,GAEnC,QACID,KAAKC,MAAQ,GACbD,KAAKG,SAAW,GAChBH,KAAKI,mBAET,mBACI,QAA2B,IAAhBJ,KAAKD,aACoB,IAAzBC,KAAKD,OAAOoB,eACoB,IAAhCnB,KAAKD,OAAOoB,SAASC,OAC5B,OAEJ,MAAMC,EAUP,SAAwBC,GAC3B,MAAMC,EAAS,GAKf,OAJAD,EAAYE,QAAQ,+BAA+B,CAACC,KAAMC,KAM9D,SAAqBH,EAAQI,EAAMX,GAC/BO,EAAOK,mBAAmBD,IAASC,mBAAmBZ,GAAS,IAN3Da,CAAYN,EAAQG,EAAE,GAAIA,EAAE,IACrBA,EAAEI,KAAK,QAEXP,EAhBeQ,CAAe/B,KAAKD,OAAOoB,SAASC,QACtD,GAAIvB,KAA6BwB,EAAW,CACtBA,EAAmC,UAAEW,MAAM,KACnDC,SAAQC,IACd,MAAOC,EAAKnB,GAASkB,EAASF,MAAM,KACpChC,KAAKG,SAASgC,GAgB9B,SAAoB5B,EAAUS,GAE1B,GAAc,UADdA,EAAQA,EAAMoB,gBACoB,UAAVpB,EACpB,MAAiB,SAAVA,EAEN,GAAI,KAAIA,IAAYA,EACrB,OAAQA,EAEZ,MAAM,IAAIF,MAAM,oCAAoCE,cAAkBT,MAxBrC8B,CAAWF,EAAKnB,QAkC9C,SAASsB,IACZ,OAAO1D,EAEJ,IAAIA,EAAM,KACV,SAAS2D,EAAqBC,GACjC5D,EAAM4D,I,wyPC/HH,SAASC,EAAuBC,EAAMC,GACzC,GAAID,EAAKzI,SAAW0I,EAAK1I,OACrB,MAAM,IAAI6G,MACN,gEAAG4B,EAAKzI,iBAAiB0I,EAAK1I,WAEtC,MAAM+C,EAAS,IAAI4F,aAA2B,EAAdF,EAAKzI,QACrC,IAAK,IAAI0B,EAAI,EAAGA,EAAIqB,EAAO/C,OAAQ0B,GAAK,EACpCqB,EAAOrB,GAAK+G,EAAK/G,EAAI,GACrBqB,EAAOrB,EAAI,GAAKgH,EAAKhH,EAAI,GAE7B,OAAOqB,EAgBJ,SAAS6F,EAAuBC,GACnC,MAAMJ,EAAO,IAAIE,aAAaE,EAAQ7I,OAAS,GACzC0I,EAAO,IAAIC,aAAaE,EAAQ7I,OAAS,GAC/C,IAAK,IAAI0B,EAAI,EAAGA,EAAImH,EAAQ7I,OAAQ0B,GAAK,EACrC+G,EAAK/G,EAAI,GAAKmH,EAAQnH,GACtBgH,EAAKhH,EAAI,GAAKmH,EAAQnH,EAAI,GAE9B,MAAO,CAAE+G,OAAMC,QAMZ,SAASI,EAAqBD,GACjC,MAAME,EAAMzF,KAAK0F,KAAKH,EAAQ7I,OAAS,GACjCyI,EAAO,IAAIE,aAAaI,GACxBL,EAAO,IAAIC,aAAaI,GAC9B,IAAK,IAAIrH,EAAI,EAAGA,EAAImH,EAAQ7I,OAAQ0B,GAAK,EACrC+G,EAAKnF,KAAK2F,MAAMvH,EAAI,IAAMmH,EAAQnH,GAClCgH,EAAKpF,KAAK2F,MAAMvH,EAAI,IAAMmH,EAAQnH,EAAI,GAE1C,MAAO,CAAE+G,OAAMC,QAMZ,SAASQ,EAAoBL,GAChC,MAAME,EAAMzF,KAAK2F,MAAMJ,EAAQ7I,OAAS,GAClCyI,EAAO,IAAIE,aAAaI,GACxBL,EAAO,IAAIC,aAAaI,GAC9B,IAAK,IAAIrH,EAAI,EAAGA,EAAImH,EAAQ7I,OAAQ0B,GAAK,EACrC+G,EAAKnF,KAAK2F,MAAMvH,EAAI,IAAMmH,EAAQnH,GAClCgH,EAAKpF,KAAK2F,MAAMvH,EAAI,IAAMmH,EAAQnH,EAAI,GAE1C,MAAO,CAAE+G,OAAMC,QAOZ,SAASS,EAAoBN,EAASjJ,GAGzC,MAAO,CAAE6I,KAFII,EAAgB,EAARjJ,GAEN8I,KADFG,EAAgB,EAARjJ,EAAY,IAS9B,SAASwJ,EAAmBC,EAAMZ,EAAMC,EAAM9I,GACjDyJ,EAAa,EAARzJ,GAAa6I,EAClBY,EAAa,EAARzJ,EAAY,GAAK8I,EAKnB,SAASY,EAAUC,EAAGC,GACzB,MAAMf,EAAO,IAAIE,aAAaY,EAAI,GAC5Bb,EAAO,IAAIC,aAAaY,EAAI,GAClC,IAAK,IAAI7H,EAAI,EAAGA,EAAI4B,KAAK0F,KAAKO,EAAI,GAAI7H,IAAK,CACvC,MAAM+H,GAAKD,EAAU,GAAK,GAAKlG,KAAKoG,IAAMhI,EAAI6H,GAC9Cd,EAAK/G,GAAK4B,KAAKqG,IAAIF,GACnBf,EAAKhH,GAAK4B,KAAKsG,IAAIH,GAEvB,MAAO,CAAEhB,OAAMC,QAKZ,SAASmB,EAASC,EAAGP,EAAGC,GAC3B,MAAMC,GAAKD,EAAU,GAAK,GAAKlG,KAAKoG,IAAMI,EAAIP,GAG9C,MAAO,CAAEd,KAFInF,KAAKqG,IAAIF,GAEPf,KADFpF,KAAKsG,IAAIH,I,sBCxFnB,SAASM,EAAWN,EAAGO,EAAOC,GACjC,GAAc,cAAVD,EAAuB,CACvB,GAAgB,cAAZP,EAAEO,MACF,OAAOP,EAAES,QAEb,MAAMC,EAAc,OAAAC,EAAA,GAAMX,EAAEY,OACtBC,EAAS,OAAAC,EAAA,GAAKd,EAAG,WACjB1G,EAASkH,EAAQpB,QAAQyB,EAAQH,GAGvC,OAFAA,EAAYK,UACZF,EAAOE,UACAzH,EAEX,IAAK,0BAAgB0G,EAAEO,MAAOA,GAG1B,OAAO,IAAOS,qBAAqBhB,EAAEiB,OAAQjB,EAAEY,MAAOL,GAE1D,GAAgB,cAAZP,EAAEO,MAAuB,CACzB,MAAMvB,EAAOwB,EAAQxB,KAAKgB,GACpB1G,EAAS,OAAAwH,EAAA,GAAK9B,EAAMuB,GAE1B,OADAvB,EAAK+B,UACEzH,EAEX,GAAc,UAAViH,EACA,OAAOC,EAAQU,IAAIlB,GAElB,GAAc,SAAVO,EAAkB,CACvB,MAAMY,EAAO,OAAA3H,EAAA,GAAO,EAAGwG,EAAEO,OACnBjH,EAASkH,EAAQY,SAASpB,EAAGmB,GAEnC,OADAA,EAAKJ,UACEzH,EAGP,MAAM,IAAI8D,MAAM,iCAAiC4C,EAAEO,YAAYA,KAGhE,SAASc,EAAcrB,EAAGY,GAC7B,OAAO,IAAOI,qBAAqBhB,EAAEiB,OAAQL,EAAOZ,EAAEO,OAEnD,SAASe,EAAaC,EAAOC,EAAMC,GACtC,MAAMC,GAAQF,EAAOD,IAAUE,EAAM,GAC/BE,EAAS,8BAAoBF,EAAK,WACxCE,EAAO,GAAKJ,EACZ,IAAK,IAAItJ,EAAI,EAAGA,EAAI0J,EAAOpL,OAAQ0B,IAC/B0J,EAAO1J,GAAK0J,EAAO1J,EAAI,GAAKyJ,EAEhC,OAAO,OAAAnI,EAAA,GAASoI,EAAQ,WCvErB,MAAMC,EACT,YAAYpB,EAASqB,GACjBvF,KAAKkE,QAAUA,EACflE,KAAKuF,UAAYA,EACjBvF,KAAKsD,KAAO,IAAIkC,QAChBxF,KAAKyF,aAAe,EAExB,IAAId,GAIA,OAHK3E,KAAKsD,KAAKoC,IAAIf,IACf3E,KAAKuF,UAAUI,SAAS3F,KAAKkE,QAASS,GAEnC3E,KAAKsD,KAAKvC,IAAI4D,GAEzB,IAAIA,EAAQ3D,GACRhB,KAAKyF,eACLzF,KAAKsD,KAAK3C,IAAIgE,EAAQ3D,GAE1B,IAAI2D,GACA,OAAO3E,KAAKsD,KAAKoC,IAAIf,GAEzB,OAAOA,GAEH,OADA3E,KAAKyF,eACEzF,KAAKsD,KAAKsC,OAAOjB,GAE5B,aACI,OAAO3E,KAAKyF,cASb,MAAMI,EACT,KAAKC,GACD,OAAOC,EAAkB,QAE7B,KAAKpB,GACD,OAAOoB,EAAkB,QAE7B,SAASpB,GACL,OAAOoB,EAAkB,YAE7B,aACI,OAAOA,EAAkB,cAE7B,YAAYpB,GACR,OAAOoB,EAAkB,eAE7B,MAAMV,EAAQf,EAAOL,GACjB,OAAO8B,EAAkB,SAE7B,KAAKpB,EAAQU,EAAQf,EAAOL,GACxB,OAAO8B,EAAkB,QAE7B,SACI,OAAOA,EAAkB,UAG7B,iBACI,OAAOA,EAAkB,kBAG7B,UACI,OAAiC,KAA1B/F,KAAKgG,iBApEW,KACA,KAqE3B,YAAYtL,EAAGC,EAAGsL,EAAYC,GAC1B,OAAOH,EAAkB,eAE7B,kBAAiB,EAAErL,EAAC,EAAEC,EAAC,WAAEsL,EAAU,WAAEC,EAAU,KAAEC,EAAI,WAAEC,EAAU,uBAAEC,IAC/D,OAAON,EAAkB,oBAE7B,MAAMrC,EAAG4C,EAAOC,GACZ,OAAOR,EAAkB,SAE7B,aAAarC,EAAG4C,EAAOE,EAAKC,GACxB,OAAOV,EAAkB,gBAE7B,QAAQrC,EAAGgD,GACP,OAAOX,EAAkB,WAE7B,QAAQrL,EAAGgM,GACP,OAAOX,EAAkB,WAE7B,OAAOY,EAASD,GACZ,OAAOX,EAAkB,UAE7B,IAAIrL,GACA,OAAOqL,EAAkB,OAE7B,IAAIrL,EAAGC,GACH,OAAOoL,EAAkB,OAE7B,KAAKY,GACD,OAAOZ,EAAkB,QAE7B,SAASrL,EAAGC,GACR,OAAOoL,EAAkB,YAE7B,SAASrL,EAAGC,GACR,OAAOoL,EAAkB,YAE7B,WAAWrL,EAAGC,GACV,OAAOoL,EAAkB,cAE7B,SAASrL,EAAGC,GACR,OAAOoL,EAAkB,YAE7B,IAAIrC,EAAGkD,GACH,OAAOb,EAAkB,OAE7B,KAAKrC,EAAGkD,GACJ,OAAOb,EAAkB,QAE7B,mBAAmBrC,EAAGmD,EAAYC,GAC9B,OAAOf,EAAkB,sBAE7B,OAAOrC,EAAGgD,GACN,OAAOX,EAAkB,UAE7B,OAAOrC,EAAGgD,GACN,OAAOX,EAAkB,UAE7B,MAAMrL,EAAGC,GACL,OAAOoL,EAAkB,SAE7B,SAASrL,EAAGC,GACR,OAAOoL,EAAkB,YAE7B,KAAKrL,EAAGC,GACJ,OAAOoL,EAAkB,QAE7B,UAAUrL,EAAGC,GACT,OAAOoL,EAAkB,aAE7B,QAAQrL,EAAGC,GACP,OAAOoL,EAAkB,WAE7B,aAAarL,EAAGC,GACZ,OAAOoL,EAAkB,gBAE7B,WAAWrL,GACP,OAAOqL,EAAkB,cAE7B,WAAWrL,EAAGC,GACV,OAAOoL,EAAkB,cAE7B,UAAUrL,EAAGC,GACT,OAAOoL,EAAkB,aAE7B,MAAMgB,GACF,OAAOhB,EAAkB,SAE7B,OAAOgB,EAAWrM,EAAGC,GACjB,OAAOoL,EAAkB,UAE7B,KAAKrC,EAAGK,EAAGiD,GACP,OAAOjB,EAAkB,QAE7B,IAAIrC,EAAGkD,GACH,OAAOb,EAAkB,OAE7B,QAAQrL,EAAGC,GACP,OAAOoL,EAAkB,WAE7B,IAAIrL,EAAGC,GACH,OAAOoL,EAAkB,OAE7B,IAAIrC,EAAGkD,GACH,OAAOb,EAAkB,OAE7B,QAAQrL,EAAGC,GACP,OAAOoL,EAAkB,WAE7B,IAAIrC,EAAGkD,GACH,OAAOb,EAAkB,OAE7B,IAAIrC,EAAGkD,GACH,OAAOb,EAAkB,OAE7B,kBAAkBrL,EAAGC,GACjB,OAAOoL,EAAkB,qBAE7B,KAAKrC,GACD,OAAOqC,EAAkB,QAE7B,MAAMrC,GACF,OAAOqC,EAAkB,SAE7B,MAAMrC,GACF,OAAOqC,EAAkB,SAE7B,KAAKrC,GACD,OAAOqC,EAAkB,QAE7B,MAAMrC,GACF,OAAOqC,EAAkB,SAE7B,MAAMrC,GACF,OAAOqC,EAAkB,SAE7B,SAASrC,GACL,OAAOqC,EAAkB,YAE7B,IAAIrL,EAAGC,GACH,OAAOoL,EAAkB,OAE7B,IAAIrC,GACA,OAAOqC,EAAkB,OAE7B,MAAMrC,GACF,OAAOqC,EAAkB,SAE7B,QAAQrC,EAAGuD,GACP,OAAOlB,EAAkB,WAE7B,IAAIrC,GACA,OAAOqC,EAAkB,OAE7B,MAAMrC,GACF,OAAOqC,EAAkB,SAE7B,KAAKrC,GACD,OAAOqC,EAAkB,QAE7B,MAAMrC,GACF,OAAOqC,EAAkB,SAE7B,OAAOrC,GACH,OAAOqC,EAAkB,UAE7B,WAAWrC,GACP,OAAOqC,EAAkB,cAE7B,KAAKrC,GACD,OAAOqC,EAAkB,QAE7B,MAAMrC,GACF,OAAOqC,EAAkB,SAE7B,MAAMrC,EAAGhJ,GACL,OAAOqL,EAAkB,SAE7B,IAAIrC,GACA,OAAOqC,EAAkB,OAE7B,OAAOmB,EAAIC,GACP,OAAOpB,EAAkB,UAE7B,KAAKrC,GACD,OAAOqC,EAAkB,QAE7B,IAAIrC,GACA,OAAOqC,EAAkB,OAE7B,KAAKrC,EAAGlG,EAAKG,GACT,OAAOoI,EAAkB,QAE7B,IAAIrC,GACA,OAAOqC,EAAkB,OAE7B,WAAWrC,GACP,OAAOqC,EAAkB,cAE7B,QAAQrC,GACJ,OAAOqC,EAAkB,WAE7B,SAASrC,GACL,OAAOqC,EAAkB,YAE7B,IAAIrC,GACA,OAAOqC,EAAkB,OAE7B,IAAIrC,GACA,OAAOqC,EAAkB,OAE7B,IAAIrC,GACA,OAAOqC,EAAkB,OAE7B,KAAKrC,GACD,OAAOqC,EAAkB,QAE7B,KAAKrC,GACD,OAAOqC,EAAkB,QAE7B,KAAKrC,GACD,OAAOqC,EAAkB,QAE7B,MAAMrL,EAAGC,GACL,OAAOoL,EAAkB,SAE7B,KAAKrC,GACD,OAAOqC,EAAkB,QAE7B,KAAKrC,GACD,OAAOqC,EAAkB,QAE7B,KAAKrC,GACD,OAAOqC,EAAkB,QAE7B,MAAMrC,GACF,OAAOqC,EAAkB,SAE7B,MAAMrC,GACF,OAAOqC,EAAkB,SAE7B,MAAMrC,GACF,OAAOqC,EAAkB,SAE7B,IAAIrC,GACA,OAAOqC,EAAkB,OAE7B,KAAKrC,EAAG0D,GACJ,OAAOrB,EAAkB,QAE7B,aAAY,MAAEsB,EAAK,OAAEC,EAAM,SAAEC,EAAQ,KAAEpB,EAAI,WAAEC,EAAU,uBAAEC,IACrD,OAAON,EAAkB,eAE7B,OAAOrC,EAAG4D,EAAQC,GACd,OAAOxB,EAAkB,UAE7B,eAAemB,EAAII,EAAQC,GACvB,OAAOxB,EAAkB,kBAE7B,gBAAgBrC,EAAG8D,EAAID,GACnB,OAAOxB,EAAkB,mBAE7B,sBAAqB,MAAEsB,EAAK,OAAEC,EAAM,SAAEC,EAAQ,KAAEpB,EAAI,WAAEC,EAAU,uBAAEC,IAC9D,OAAON,EAAkB,wBAE7B,gBAAgBsB,EAAOC,EAAQC,GAC3B,OAAOxB,EAAkB,mBAE7B,wBAAwBmB,EAAII,EAAQC,GAChC,OAAOxB,EAAkB,2BAE7B,yBAAyBrC,EAAG8D,EAAID,GAC5B,OAAOxB,EAAkB,4BAE7B,OAAOrC,EAAG4D,EAAQC,GACd,OAAOxB,EAAkB,UAE7B,eAAemB,EAAII,EAAQC,GACvB,OAAOxB,EAAkB,kBAE7B,gBAAgBrC,EAAG8D,EAAID,GACnB,OAAOxB,EAAkB,mBAE7B,QAAQrC,EAAG6D,GACP,OAAOxB,EAAkB,WAE7B,gBAAgBmB,EAAIxD,EAAGyD,EAAGI,GACtB,OAAOxB,EAAkB,mBAE7B,QAAQrC,EAAG6D,GACP,OAAOxB,EAAkB,WAE7B,gBAAgBmB,EAAIxD,EAAG6D,GACnB,OAAOxB,EAAkB,mBAE7B,UAAUrC,EAAG6D,GACT,OAAOxB,EAAkB,aAE7B,kBAAkBmB,EAAIxD,EAAG6D,GACrB,OAAOxB,EAAkB,qBAE7B,UAAUrC,EAAG6D,GACT,OAAOxB,EAAkB,aAE7B,kBAAkBmB,EAAIxD,EAAGyD,EAAGI,GACxB,OAAOxB,EAAkB,qBAE7B,QAAQrC,EAAGY,GACP,OAAOyB,EAAkB,WAE7B,KAAKrC,EAAGO,GACJ,OAAO8B,EAAkB,QAE7B,KAAKrC,EAAG+D,GACJ,OAAO1B,EAAkB,QAE7B,IAAIrC,EAAGgE,EAAUC,GACb,OAAO5B,EAAkB,OAE7B,UAAUrC,EAAGkE,GACT,OAAO7B,EAAkB,aAE7B,OAAOrC,EAAGmE,EAASnB,GACf,OAAOX,EAAkB,UAE7B,SAASrC,EAAGmE,GACR,OAAO9B,EAAkB,YAE7B,UAAU8B,EAASC,EAASxD,GACxB,OAAOyB,EAAkB,aAE7B,eAAerC,EAAGqE,EAAYC,GAC1B,OAAOjC,EAAkB,kBAE7B,eAAerC,EAAGqE,EAAYL,GAC1B,OAAO3B,EAAkB,kBAE7B,eAAerC,EAAGuE,EAAWC,EAAUC,GACnC,OAAOpC,EAAkB,kBAE7B,uBAAuBmB,EAAIxD,EAAGyE,GAC1B,OAAOpC,EAAkB,0BAE7B,sBAAsBrC,EAAG0E,EAAWF,EAAUC,GAC1C,OAAOpC,EAAkB,yBAE7B,8BAA8BmB,EAAIxD,EAAGyE,GACjC,OAAOpC,EAAkB,iCAE7B,UAAUrC,EAAG2E,EAAMC,EAAUC,EAAQrM,EAAOsM,GACxC,OAAOzC,EAAkB,aAE7B,6BAA6BrC,EAAG+E,EAAQtC,EAAMiB,EAAOsB,GACjD,OAAO3C,EAAkB,gCAE7B,QAAQmB,EAAIyB,EAAYC,EAAaH,EAAQtC,EAAMiB,EAAOsB,GACtD,OAAO3C,EAAkB,WAE7B,YAAY8C,EAAQC,EAAYC,EAAYC,GACxC,OAAOjD,EAAkB,eAE7B,OAAO8B,EAASoB,EAAOC,EAASC,GAC5B,OAAOpD,EAAkB,UAE7B,OAAOrC,EAAGgD,EAAM0C,EAAWC,GACvB,OAAOtD,EAAkB,UAE7B,kBAAkBlL,EAAOC,EAAQC,EAAeC,EAAcC,GAC1D,OAAO8K,EAAkB,qBAE7B,IAAIrC,GACA,OAAOqC,EAAkB,OAE7B,KAAKrC,GACD,OAAOqC,EAAkB,QAE7B,QAAQrD,EAAMC,GACV,OAAOoD,EAAkB,WAE7B,KAAKsB,GACD,OAAOtB,EAAkB,QAE7B,KAAKsB,GACD,OAAOtB,EAAkB,QAE7B,cAAcuD,EAAOzO,EAAOiB,EAAUyN,EAAUC,EAAQC,GACpD,OAAO1D,EAAkB,iBAE7B,aAAarC,EAAGgG,EAAWC,GACvB,OAAO5D,EAAkB,gBAG7B,MAAM/E,EAAO4I,EAAYlD,GACrB,OAAOX,EAAkB,SAE7B,cAAc8D,EAAeC,EAAcC,EAAaC,GACpD,OAAOjE,EAAkB,iBAE7B,KAAKrC,GACD,OAAOqC,EAAkB,QAE7B,KAAKzB,EAAOtD,EAAOiD,GACf,OAAO8B,EAAkB,QAE7B,SAASrC,GACL,OAAOqC,EAAkB,YAE7B,UAAUrC,GACN,OAAOqC,EAAkB,aAE7B,SAASd,EAAOC,EAAMC,GAClB,OAAOY,EAAkB,YAE7B,UACI,OAAOA,EAAkB,YAGjC,SAASA,EAAkBkE,GACvB,MAAM,IAAInJ,MAAM,IAAImJ,6F,2CCvfxB,gJA0BA,MAAMC,EACF,cAEIlK,KAAKmK,oBAAsB,GAC3BnK,KAAKoK,eAAiB,EACtBpK,KAAKqK,SAAW,EAChBrK,KAAKsK,WAAa,EAClBtK,KAAKuK,iBAAmB,EACxBvK,KAAKwK,eAAiB,EAItBxK,KAAKyK,cAAgB,EAGrBzK,KAAK0K,YAAc,EACnB1K,KAAK2K,WAAa,GAKlB3K,KAAK4K,kBAAoB,GACzB5K,KAAK6K,YAAc,EACnB7K,KAAK8K,WAAa,IAAItF,QACtBxF,KAAK+K,WAAY,EACjB/K,KAAKgL,cAAgB,CAAEC,SAAU,EAAGC,WAAY,EAAGC,UAAW,EAAGC,QAAS,GAAIpO,OAAQ,MAE1F,UACI,IAAK,MAAMqO,KAAgBrL,KAAKmK,oBAC5BnK,KAAKmK,oBAAoBkB,GAAc5G,WAI5C,MAAM6G,EACT,YAAY1M,GACRoB,KAAKpB,IAAMA,EACXoB,KAAKuL,SAAW,GAChBvL,KAAKwL,gBAAkB,GACvBxL,KAAKyL,qBAAuB,EAC5BzL,KAAK0L,MAAQ,IAAIxB,EAErB,cACI,GAA+B,MAA3BlK,KAAK2L,mBACL,OAAO3L,KAAK2L,mBAAmBC,MAAK,SAExC,GAA4B,MAAxB5L,KAAK6L,gBACL,OAEJ,MAAMC,EAAiB9L,KAAK+L,oBAC5B,IAAK,IAAIpQ,EAAI,EAAGA,EAAImQ,EAAe7R,OAAQ0B,IAAK,CAC5C,MAAMqQ,EAAcF,EAAenQ,GAEnC,SADsBqE,KAAKiM,kBAAkBD,GAAaE,QAGtD,kBADMlM,KAAKmM,WAAWH,GAI9B,MAAM,IAAIlL,MAAM,0EAGpB,cACI,GAA+B,MAA3Bd,KAAK2L,mBACL,MAAM,IAAI7K,MAAM,YAAYd,KAAKgM,kIAIrC,GAA4B,MAAxBhM,KAAK6L,gBAAyB,CAC9B,MAAM,KAAElK,EAAI,UAAEyK,GAAcpM,KAAKqM,kCACjC,GAAID,EACA,MAAM,IAAItL,MAAM,iCAAiCa,wHAIrD3B,KAAKmM,WAAWxK,GAEpB,OAAO3B,KAAK6L,gBAEhB,eACI,OAAO5K,OAAOqL,KAAKtM,KAAKwL,iBAE5B,YAAYQ,GACR,KAAMA,KAAehM,KAAKuL,UAAW,CAGjC,KAAIS,KAAehM,KAAKwL,iBAQpB,OAAO,KAR8B,CACrC,MAAM,UAAEY,GAAcpM,KAAKiM,kBAAkBD,GAC7C,GAAII,EAEA,OAAO,MAOnB,OAAOpM,KAAKuL,SAASS,GAEzB,mBAAmBA,GACf,OAAMA,KAAehM,KAAKwL,gBAGnBxL,KAAKwL,gBAAgBQ,GAAaO,QAF9B,KAIf,gBAAgBP,EAAaO,EAASC,EAAW,GAC7C,OAAIR,KAAehM,KAAKwL,iBACpBzM,QAAQC,KAAK,GAAGgN,wEAET,IAEXhM,KAAKwL,gBAAgBQ,GAAe,CAAEO,UAASC,aACxC,GAEX,iBAAiBR,GACb,GAAyC,MAArChM,KAAKwL,gBAAgBQ,GACrB,MAAM,IAAIlL,MAAM,iBAAiBkL,4BAGrC,GADAhM,KAAKgM,YAAcA,EACe,MAA9BhM,KAAKuL,SAASS,GAAsB,CACpChM,KAAK6L,gBAAkB,KACvB,MAAM,QAAEK,EAAO,UAAEE,GAAcpM,KAAKiM,kBAAkBD,GAEtD,KADeI,QAAkBF,EAAUA,GAEvC,OAAO,EAOf,OAJAlM,KAAK6L,gBAAkB7L,KAAKuL,SAASS,GACrChM,KAAKyM,yBAELzM,KAAK0M,SAAW,IAAI,IAAS1M,KAAK6L,kBAC3B,EAEX,yBACoB,YAAqB7L,KAAKgM,aAClC/J,SAAQ0K,IACY,MAApBA,EAAOC,WACPD,EAAOC,UAAU5M,KAAK6L,oBAIlC,yBAAyBG,GACL,YAAqBA,GAC7B/J,SAAQ0K,IACc,MAAtBA,EAAOE,aACPF,EAAOE,YAAY7M,KAAKuL,SAASS,OAU7C,kBAAkBA,GACd,MAAMc,EAAuB9M,KAAKwL,gBAAgBQ,GAClD,GAA4B,MAAxBc,EACA,MAAM,IAAIhM,MAAM,6BAA6BkL,6BAEjD,IACI,MAAM9H,EAAU4I,EAAqBP,UAErC,GAAI1L,QAAQkM,QAAQ7I,KAAaA,EAAS,CACtC,MAAM8I,IAAchN,KAAKyL,qBACnBS,EAAUhI,EACX0H,MAAKC,KAEFmB,EAAYhN,KAAKyL,wBAGrBzL,KAAKuL,SAASS,GAAeH,EAC7B7L,KAAK2L,mBAAqB,MACnB,KAENsB,OAAMC,IAEHF,EAAYhN,KAAKyL,uBAGrBzL,KAAK2L,mBAAqB,KAC1B5M,QAAQC,KAAK,6BAA6BgN,YAC1CjN,QAAQC,KAAKkO,EAAIC,OAASD,EAAIE,WAJnB,KAQf,OADApN,KAAK2L,mBAAqBO,EACnB,CAAEA,UAASE,WAAW,GAI7B,OADApM,KAAKuL,SAASS,GAAe9H,EACtB,CAAEgI,SAAS,EAAME,WAAW,GAG3C,MAAOc,GAGH,OAFAnO,QAAQC,KAAK,6BAA6BgN,YAC1CjN,QAAQC,KAAKkO,EAAIC,OAASD,EAAIE,SACvB,CAAElB,SAAS,EAAOE,WAAW,IAG5C,cAAcJ,GACV,KAAMA,KAAehM,KAAKwL,iBACtB,MAAM,IAAI1K,MAAM,GAAGkL,mCAEnBhM,KAAKgM,cAAgBA,GAA0C,MAA3BhM,KAAK2L,oBAGzC3L,KAAKyL,uBAELO,KAAehM,KAAKuL,WACpBvL,KAAKqN,yBAAyBrB,GAC9BhM,KAAKuL,SAASS,GAAavH,iBACpBzE,KAAKuL,SAASS,WAElBhM,KAAKwL,gBAAgBQ,GAExBhM,KAAKgM,cAAgBA,IACrBhM,KAAK2L,mBAAqB,KAC1B3L,KAAKgM,YAAc,KACnBhM,KAAK6L,gBAAkB,MAG/B,oBACI,GAAiD,IAA7C5K,OAAOqL,KAAKtM,KAAKwL,iBAAiBvR,OAClC,MAAM,IAAI6G,MAAM,iCAEpB,OAAOG,OAAOqL,KAAKtM,KAAKwL,iBAAiBxP,MAAK,CAACtB,EAAGC,IAEvCqF,KAAKwL,gBAAgB7Q,GAAG6R,SAC3BxM,KAAKwL,gBAAgB9Q,GAAG8R,WAGpC,kCACI,MAAMV,EAAiB9L,KAAK+L,oBAC5B,IAAK,IAAIpQ,EAAI,EAAGA,EAAImQ,EAAe7R,OAAQ0B,IAAK,CAC5C,MAAMqQ,EAAcF,EAAenQ,IAC7B,QAAEuQ,EAAO,UAAEE,GAAcpM,KAAKiM,kBAAkBD,GACtD,GAAII,GAAaF,EACb,MAAO,CAAEvK,KAAMqK,EAAaI,aAGpC,MAAM,IAAItL,MAAM,0EAGpB,SAASoD,EAASS,GACd,MAAM2I,EAAOtN,KAAK0L,MAAMZ,WAAW/J,IAAI4D,GACjC4I,EAAaD,EAAKpJ,QAClBmB,EAASrF,KAAKwN,SAAS7I,GAG7B4I,EAAWE,YAAY9I,GACvB2I,EAAKpJ,QAAUA,EACfA,EAAQwJ,KAAK/I,EAAQU,EAAQiI,EAAKhJ,MAAOgJ,EAAKrJ,OAC1CjE,KAAK2N,0BAGL3N,KAAK0L,MAAMd,kBAAkB5K,KAAK0L,MAAMd,kBAAkB3Q,OAAS,KAG3E,KAAK2T,EAAUC,GACX,IAsBI7Q,EAtBA2E,EAAO,KACX,GAAU,MAANkM,EAAY,CAEZ,GAAwB,mBAAbD,EACP,MAAM,IAAI9M,MAAM,uCAEpB+M,EAAKD,MAEJ,CAED,GAAwB,iBAAbA,KAA2BA,aAAoBE,QACtD,MAAM,IAAIhN,MAAM,kFAGpB,GAAkB,mBAAP+M,EACP,MAAM,IAAI/M,MAAM,kFAGpBa,EAAOiM,EAKX,OAAO5N,KAAK+N,WAAU,IAAM/N,KAAKgO,WAAWrM,KAAO,IAAM3B,KAAKiO,SAASjR,KAAS,KAC5EA,EAAS6Q,IACL7Q,aAAkB6D,SAClB9B,QAAQmP,MAAM,2CAEXlR,KAGf,UAAUiI,EAAOuB,EAAKV,GAClBb,IACA,IACI,MAAMkJ,EAAMrI,IAEZ,OADAU,IACO2H,EAEX,MAAOC,GAEH,MADA5H,IACM4H,GAGd,eACI,OAAO9C,EAAO+C,eAElB,iBACI,OAAO/C,EAAOgD,iBAWlB,MAAM5K,GACF,MAAMyD,EAAInH,KAAK0E,qBAAqBhB,EAAEiB,OAAQjB,EAAEY,MAAOZ,EAAEO,OACnDsK,EAAS,CAAE7K,KAWjB,OADA1D,KAAKwO,YAAYxO,KAAK0L,MAAM+C,YAAY9M,KAAM4M,EAAQ,CAACpH,IATzCD,IAAO,CACjBxD,EAAG,KACC,MAAMO,EAAQ,UACRyK,EAAa,CAAEhL,EAAGwD,GAClByH,EAAQ,CAAE1K,SAChB,OAAO2K,EAAOC,eAAc3K,GAAWA,EAAQM,KAAK0C,EAAIjD,IAAQyK,EAAY,KAAiB,IAAMC,OAG7F,GAC0D,IACjExH,EAeX,UAAU8C,EAAYsE,EAAQI,EAAOG,EAAcC,GAM/C,OAAO/O,KAAK6O,cALQ,KAKmBN,EAJjB,KAIwCtE,EAAY0E,EAAOG,EAAcC,GAEnG,yBACI,OAAO/O,KAAKpB,IAAIY,QAAQ,WAE5B,sBAAsByK,EAAY+E,EAAkBC,GAChD,MAAMC,EAAkBlP,KAAKkE,QAAQiL,aAErC,IAAIC,EAAmB,EACvBH,EAAShN,SAAQqL,IAGb8B,GAAoC,cAAf9B,EAAKrJ,MAAwB,EAAI,KAO1D,MAAMoL,EAAWrP,KAAK0L,MAAMd,kBAAkB5K,KAAK0L,MAAMd,kBAAkB3Q,OAAS,GAC9EqV,EAAgBJ,EAAkBF,EAAmBI,EAAmBC,EAC9E,GAAIC,EAAgB,EAChB,MAAM,IAAIxO,MAAM,YAAYd,KAAKgM,6CACzBsD,8BAA0CrF,MAO1D,cAAcsF,EAAahB,EAAQiB,EAAevF,EAAY0E,EAAOG,EAAcC,GAC/E,IAAIU,EACAC,EAAQ,GACZ,MAAMC,EAAW3P,KAAK2P,WACJ,MAAd1F,IACAA,EAC8B,MAA1BjK,KAAK0L,MAAM+C,YAAsBzO,KAAK0L,MAAM+C,YAAY9M,KAAO,IAEvE,MAAMiO,EAAoB5P,KAAK0L,MAAMrB,SAC/BwF,EAAqB7P,KAAK0L,MAAMpB,WAItC,IAAIwF,EAHA9P,KAAK2N,0BACL3N,KAAK0L,MAAMd,kBAAkBhP,KAAK,GAGtC,MAAM+Q,EAAS,YAAU1C,EAAYjK,KAAKgM,aAC1C,IAAI+D,EAqDAC,EApDJ,GAAc,MAAVrD,EACAmD,EAAa,KACT,MAAMd,EAAmBhP,KAAKkE,QAAQiL,aACtCY,EAAMpD,EAAOmD,WAAW,CAAEvB,SAAQI,QAAOzK,QAASlE,KAAKkE,UACvD,MAAM+K,EAAWnS,MAAMmT,QAAQF,GAAOA,EAAM,CAACA,GACzC/P,KAAK2N,0BACL3N,KAAKkQ,sBAAsBjG,EAAY+E,EAAkBC,GAE7D,MAAMkB,EAAalB,EAASmB,KAAI,EAAGzL,SAAQL,QAAOL,WAAYjE,KAAK0E,qBAAqBC,EAAQL,EAAOL,KAKvG,GAAI0L,EAAU,CACV,IAAIU,EAAgBrQ,KAAKsQ,sBAAsBrG,EAAYsE,EAAQ4B,GACnE,GAAqB,MAAjBE,EAAuB,CAKF,MAAjBtB,IACAA,EAAgB,IAEpB,MAAMwB,EAAaJ,EAAW7I,QAAO,CAACkJ,EAAG7U,IAAMoT,EAAcpT,KAC7D0U,GAAiBvB,GAAgB,IAAI2B,QAAQC,OAAOH,GAExDb,EAAQ1P,KAAK2Q,2BAA2BN,GAE5C,OAAOF,OAGV,CACD,MAAMS,EAAYjK,IAITgJ,IAGLD,EAAQ/I,EAAQyJ,KAAIS,GAAU7Q,KAAK8Q,KAAK9Q,KAAKmE,MAAM0M,QAEvDf,EAAa,KACT,MAAMd,EAAmBhP,KAAKkE,QAAQiL,aACtCY,EAAM/P,KAAK+Q,MAAK,IAAMxB,EAAYvP,KAAKkE,QAAS0M,KAChD,MAAMI,EAAQlU,MAAMmT,QAAQF,GAAOA,EAAM,CAACA,GAI1C,OAHI/P,KAAK2N,0BACL3N,KAAKkQ,sBAAsBjG,EAAY+E,EAAkBgC,GAEtDA,GAiCf,OA5BAhR,KAAK+N,WAAU,IAAM/N,KAAK0L,MAAMhB,gBAAe,IAAM1K,KAAK0L,MAAMhB,gBAAe,KACtE1K,KAAKpB,IAAIY,QAAQ,UAAaQ,KAAK0L,MAAMX,WAI1CiF,EAAgBhQ,KAAK0M,SAASuE,cAAchH,EAAYsE,GAAQ,IAAMuB,MAClE9P,KAAKpB,IAAIY,QAAQ,UACjBQ,KAAK0M,SAASwE,iBAAiBlB,GAEnCP,EAAUO,EAAcP,SAPxBA,EAAUK,OAUdH,GACA3P,KAAKwO,YAAYvE,EAAYsE,EAAQkB,EAASD,EAAeE,EAAOf,GAEpE3O,KAAK0L,MAAMX,WACX/K,KAAK0L,MAAMV,cAAcI,QAAQxP,KAAK,CAClC+F,KAAMsI,EACNkH,WAAYnR,KAAK0L,MAAMrB,SAAWuF,EAClCwB,mBAAoBpR,KAAK0L,MAAMrB,SAC/BgH,aAAcrR,KAAK0L,MAAMpB,WAAauF,EACtCyB,qBAAsBtR,KAAK0L,MAAMpB,WACjCiH,YAAatQ,OAAOqL,KAAKiC,GAAQ6B,KAAIjO,GAAsB,MAAfoM,EAAOpM,GAAeoM,EAAOpM,GAAKmC,MAAQ,OACtFkN,aAAc/B,EAAQW,KAAIqB,GAAQA,EAAKnN,QACvCoN,aAAc1B,EAAc2B,OAC5BC,UAAW5B,EAAc4B,YAGzB9U,MAAMmT,QAAQF,GAAON,EAAUA,EAAQ,GAOnD,2BAA2B9I,GAEvB,OADcA,EAAQyJ,KAAIS,GAAU7Q,KAAK8Q,KAAK9Q,KAAKmE,MAAM0M,MAa7D,sBAAsB5G,EAAYsE,EAAQkB,GACtC,MAAMoC,EAAa,YAAY5H,GAC/B,GAAkB,MAAd4H,EAAoB,CACpB,MAAM/C,EAAe+C,EAAW/C,cAAgB,GAC1CC,EAAgB8C,EAAW9C,eAAiB,GAGlD,IAAI+C,EACAD,EAAWE,eACX,SAAYjV,MAAMmT,QAAQ1B,IAAS,IAAM,2DACzCuD,EAAqB7Q,OAAOqL,KAAKiC,GAAQ6B,KAAKjO,GAAQoM,EAAOpM,MAG7D2P,EAAqBhD,EAAasB,KAAK4B,GAAczD,EAAOyD,KAEhE,MAAMC,EAAsBxC,EAAQnI,QAAO,CAACkJ,EAAG7U,IAAMoT,EAAcpT,KACnE,OAAOmW,EAAmBpB,OAAOuB,GAIrC,OAAO,KAOX,WAAW5M,EAAQf,EAAOL,EAAOC,GAC7B,GAAc,MAAVmB,EACA,MAAM,IAAIvE,MAAM,iDAEpBmD,EAAQA,GAAS,UACjBC,EAAUA,GAAWlE,KAAKkE,QAC1B,IAAIgO,EAAc7M,EACJ,WAAVpB,GAAsB,WAAcoB,EAAO,MAC3C6M,EAAc7M,EAAO+K,KAAI+B,GAAK,eAAkBA,MAEpD,MAAMxN,EAAST,EAAQkO,MAAMF,EAAa5N,EAAOL,GAC3CvC,EAAI,IAAI,IAAO4C,EAAOL,EAAOU,EAAQ3E,KAAKqO,gBAGhD,GAFArO,KAAKqS,OAAO3Q,EAAGwC,GAED,WAAVD,EAAoB,CACpB,MAAMqJ,EAAOtN,KAAK0L,MAAMZ,WAAW/J,IAAI4D,GACjCsG,EAAW,+BAAqBiH,GACtClS,KAAK0L,MAAMrB,UAAYY,EAAWqC,EAAKgF,MACvChF,EAAKgF,MAAQrH,EAEjB,OAAOvJ,EAOX,qBAAqBiD,EAAQL,EAAOL,EAAOC,GACvCD,EAAQA,GAAS,UACjB,MAAMvC,EAAI,IAAI,IAAO4C,EAAOL,EAAOU,EAAQ3E,KAAKqO,gBAEhD,OADArO,KAAKqS,OAAO3Q,EAAGwC,GACRxC,EAEX,aAAa6Q,EAAcC,GAAY,EAAM7Q,EAAMsC,GAC/CtC,EAAOA,GAAQ3B,KAAKsO,iBAAiBmE,WACxB,MAATxO,GAAiBA,IAAUsO,EAAatO,QACxCsO,EAAeA,EAAa/N,KAAKP,IAErC,MAAMyO,EAAI,IAAI,IAASH,EAAcC,EAAW7Q,EAAM3B,KAAKqO,gBAC3D,GAA8C,MAA1CrO,KAAK0L,MAAMvB,oBAAoBuI,EAAE/Q,MACjC,MAAM,IAAIb,MAAM,sBAAsB4R,EAAE/Q,+BAI5C,OAFA3B,KAAK0L,MAAMvB,oBAAoBuI,EAAE/Q,MAAQ+Q,EACzC1S,KAAKqS,OAAOK,EAAG1S,KAAKkE,SACbwO,EAEX,OAAOhY,EAAGwJ,GACN,MAAMyO,EAAW3S,KAAK0L,MAAMZ,WAAWpF,IAAIhL,EAAEiK,QACzC3E,KAAK0L,MAAMZ,WAAW/J,IAAIrG,EAAEiK,QAAQgO,SACpC,EAKJ,GAJA3S,KAAK0L,MAAMpB,aACK,WAAZ5P,EAAEuJ,OACFjE,KAAK0L,MAAMnB,mBAEE,IAAboI,EAAgB,CAChB3S,KAAK0L,MAAMlB,iBAGX,IAAI8H,EAAQ,EACI,cAAZ5X,EAAEuJ,OAAqC,WAAZvJ,EAAEuJ,QAC7BqO,EAAQ5X,EAAE6L,KAAO,kBAAqB7L,EAAEuJ,QAE5CjE,KAAK0L,MAAMZ,WAAWnK,IAAIjG,EAAEiK,OAAQ,CAChCT,QAASA,GAAWlE,KAAKkE,QACzBD,MAAOvJ,EAAEuJ,MACTK,MAAO5J,EAAE4J,MACTgO,QACAK,SAAU,IAEd3S,KAAK0L,MAAMrB,UAAYiI,EAE3BtS,KAAK0L,MAAMZ,WAAW/J,IAAIrG,EAAEiK,QAAQgO,WAC9BjY,aAAa,KACfsF,KAAK4S,MAAMlY,GAGnB,cAAcA,GACV,IAAKsF,KAAK0L,MAAMZ,WAAWpF,IAAIhL,EAAEiK,QAC7B,OAEJ3E,KAAK0L,MAAMpB,aACK,WAAZ5P,EAAEuJ,OACFjE,KAAK0L,MAAMnB,mBAEf,MAAM+C,EAAOtN,KAAK0L,MAAMZ,WAAW/J,IAAIrG,EAAEiK,QACxB2I,EAAKqF,UACN,GAGI,cAAZjY,EAAEuJ,QACFjE,KAAK0L,MAAMrB,UAAYiD,EAAKgF,OAEhCtS,KAAK0L,MAAMlB,iBACX8C,EAAKpJ,QAAQuJ,YAAY/S,EAAEiK,QAC3B3E,KAAK0L,MAAMZ,WAAWlF,OAAOlL,EAAEiK,SAG/B3E,KAAK0L,MAAMZ,WAAW/J,IAAIrG,EAAEiK,QAAQgO,WAM5C,mBACI,IAAK,MAAME,KAAW7S,KAAK0L,MAAMvB,oBAAqB,CAClD,MAAMuI,EAAI1S,KAAK0L,MAAMvB,oBAAoB0I,GACzC7S,KAAK8S,gBAAgBJ,IAG7B,gBAAgBA,GACZ1S,KAAK+S,cAAcL,GAC2B,MAA1C1S,KAAK0L,MAAMvB,oBAAoBuI,EAAE/Q,cAC1B3B,KAAK0L,MAAMvB,oBAAoBuI,EAAE/Q,MAGhD,SACI,MAAM2L,EAAOtN,KAAKkE,QAAQ8O,SAY1B,OAXA1F,EAAKhD,WAAatK,KAAK0L,MAAMpB,WAC7BgD,EAAK9C,eAAiBxK,KAAK0L,MAAMlB,eACjC8C,EAAKjD,SAAWrK,KAAK0L,MAAMrB,SACvBrK,KAAK0L,MAAMnB,iBAAmB,IAC9B+C,EAAK2F,YAAa,EACE,MAAhB3F,EAAK4F,UACL5F,EAAK4F,QAAU,IAEnB5F,EAAK4F,QAAQtX,KAAK,0EAGf0R,EAEX,cAAc6F,GACVnT,KAAK0L,MAAMX,WAAY,EACvB,MAAMqI,EAAapT,KAAK0L,MAAMrB,SACxBgJ,EAAkBrT,KAAK0L,MAAMpB,WACnCtK,KAAK0L,MAAMV,cAAcI,QAAU,GACnCpL,KAAK0L,MAAMV,cAAchO,aAAemW,IACxCnT,KAAK0L,MAAMX,WAAY,EACvB/K,KAAK0L,MAAMV,cAAcG,UAAY5N,KAAKI,OAAOqC,KAAK0L,MAAMV,cAAcI,QAAQgF,KAAI+B,GAAKA,EAAEf,sBAC7FpR,KAAK0L,MAAMV,cAAcC,SAAWjL,KAAK0L,MAAMrB,SAAW+I,EAC1DpT,KAAK0L,MAAMV,cAAcE,WACrBlL,KAAK0L,MAAMpB,WAAa+I,EAC5B,IAAK,MAAM1G,KAAU3M,KAAK0L,MAAMV,cAAcI,QAC1CuB,EAAO+E,mBAAqB/E,EAAO+E,aACnC/E,EAAOiF,gBAAkBjF,EAAOiF,UAEpC,OAAO5R,KAAK0L,MAAMV,cAEtB,WACI,OAAOhL,KAAK0L,MAAMjB,cAAgB,GAAgC,IAA3BzK,KAAK0L,MAAMhB,YAEtD,YAAYT,EAAYsE,EAAQkB,EAAS6D,EAAe5D,EAAOf,GAC3D,MAAM4E,EAAW,CAAEC,GAAIxT,KAAK0L,MAAMtB,iBAAkBH,aAAYsE,SAAQkB,UAASC,SAC3EmC,EAAa,YAAY5H,GACb,MAAd4H,IACAyB,EAAgBzB,EAAW4B,UAEV,MAAjBH,IACAC,EAASG,SAAYC,IAGjBA,EAAMA,EAAIvD,KAAI,CAAClJ,EAAIvL,KACf,GAAU,MAANuL,EAAY,CACZ,MAAM0M,EAASnE,EAAQ9T,GACjBkY,EAAO,sBAAyBD,EAAOrN,KAAMqN,EAAO3P,OAC1D,OAAOjE,KAAK8T,WAAWD,EAAMD,EAAOtP,MAAOsP,EAAO3P,OAEtD,OAAOiD,KAIJoM,EAAcK,EAAI1Z,OAAS,EAAI0Z,EAAMA,EAAI,GAAIjE,EAAOf,KAGnE3O,KAAK0L,MAAMqI,WAAWnY,KAAK2X,GAE/B,KAAKvW,GAED,OADAA,EAAOgX,MAAO,EACPhX,EAEX,YACqC,IAA7BgD,KAAK0L,MAAMjB,gBACXzK,KAAK0L,MAAMqI,WAAa,IAE5B/T,KAAK0L,MAAMjB,gBAEf,UACIzK,KAAK0L,MAAMjB,gBAMf,WAAW9I,GACP,MAAMsS,EAAY,CACdrB,MAAO,GACPjR,KAAM,gBACN6R,GAAIxT,KAAK0L,MAAMb,eAEflJ,IACAsS,EAAUtS,KAAOA,GAErB3B,KAAK0L,MAAMf,WAAW/O,KAAKqY,GAC3BjU,KAAK0L,MAAM+C,YAAcwF,EAM7B,SAASjX,GACL,MAAMkX,EAAyB,YAAsBlX,GAC/CmX,EAA4B,IAAIC,IAAIF,EAAuB9D,KAAI1O,GAAKA,EAAE8R,MAE5E,IAAK,IAAI7X,EAAI,EAAGA,EAAIqE,KAAK0L,MAAM+C,YAAYmE,MAAM3Y,OAAQ0B,IAAK,CAC1D,MAAMkV,EAAS7Q,KAAK0L,MAAM+C,YAAYmE,MAAMjX,GACvCkV,EAAOmD,MAASG,EAA0BzO,IAAImL,EAAO2C,KACtD3C,EAAOpM,UAGf,MAAM4P,EAAWrU,KAAK0L,MAAMf,WAAWtO,MACvC2D,KAAK0L,MAAM+C,YAA+C,IAAjCzO,KAAK0L,MAAMf,WAAW1Q,OAC3C,KACA+F,KAAK0L,MAAMf,WAAW3K,KAAK0L,MAAMf,WAAW1Q,OAAS,GAEzDia,EAAuBjS,SAAQ4O,IAGtBA,EAAOmD,MAAQnD,EAAOyD,UAAYD,EAASb,IAC5CxT,KAAK4S,MAAM/B,MAUvB,UAAU/K,EAAGyO,EAAIrN,EAAIsN,GAAmB,GAEpC,GADA,SAAYD,EAAGta,OAAS,GAAG,IAAM,8CACvB,MAANiN,GAA2B,YAAbA,EAAGjD,MACjB,MAAM,IAAInD,MAAM,0CAA0CoG,EAAGjD,UAEjE,MAAMkD,EAAInH,KAAK+N,WAAU,IAAM/N,KAAKyU,cAAa,IAAMzU,KAAK0U,YAAW,IAAM1U,KAAK+Q,KAAK,UAAWjL,KAClG,SAAYqB,aAAa,KAAQ,IAAM,mDAEvC,MAAMwN,EAAe,YAAqB3U,KAAK0L,MAAMqI,WAAYQ,EAAIpN,GACrE,IAAKqN,GAA4C,IAAxBG,EAAa1a,QAAgBsa,EAAGta,OAAS,EAC9D,MAAM,IAAI6G,MAAM,uIAIpB,OAAOd,KAAK+Q,KAAK,YAAY,KACzB,MAAM6D,EAAyB,GAC/BA,EAAuBzN,EAAEqM,IAAa,MAANtM,EA6G5C,SAAc5C,GACV,MAAMe,EAAS,6BAAmB,wBAAcf,GAAQ,WACxD,OAAOsK,EAAOkF,WAAWzO,EAAQf,EAAO,WA/GcuQ,CAAK1N,EAAE7C,OAAS4C,EAE9D,YAAuB0N,EAAwBD,GAE/C7O,GAAK9F,KAAK+Q,KAAKjL,IAEfgP,GACA,MAAMC,EAAQR,EAAGnE,KAAI1M,GAAKkR,EAAuBlR,EAAE8P,MAWnD,OAViC,IAA7BxT,KAAK0L,MAAMjB,gBAGXzK,KAAK0L,MAAMqI,WAAW9R,SAAQ9C,IAC1B,IAAK,MAAM0R,KAAU1R,EAAKuQ,MACtBmB,EAAOpM,aAGfzE,KAAK0L,MAAMqI,WAAa,MAErB,CAAE/S,MAAOmG,EAAG4N,YAG3B,WAAWjP,GAEP,OADA,SAAY,aAAgBA,IAAI,IAAM,sDAC/B,IAAIyI,KAGP,IAAIJ,EAFJ,SAAYI,EAAOyG,OAAMtT,GAAKA,aAAa,OAAS,IAAM,qEAG1D,MAAMuT,EAAW,GAIjB,OAHA1G,EAAOtM,SAAQ,CAACoF,EAAO1L,KACnBsZ,EAAStZ,GAAK0L,KAEXrH,KAAK6O,eAAc,CAAC2B,EAAG0E,KAC1B/G,EAAMrI,KAASyI,EAAQ2G,GACvB,SAAY/G,EAAInN,iBAAiB,KAAQ,IAAM,+FAE/C,SAAY,aAAgBmN,EAAIsF,WAAW,IAAM,qGAE1CtF,EAAInN,QACZiU,GAAU,CAAC/N,EAAIwI,KACd,MAAMyF,EAAUhH,EAAIsF,SAASvM,EAAIwI,GAC3BqF,EAAQjY,MAAMmT,QAAQkF,GAAWA,EAAU,CAACA,GAClD,SAAYJ,EAAM9a,SAAWsU,EAAOtU,QAAQ,IAAM,wKAGlD,SAAY8a,EAAMC,OAAMtT,GAAKA,aAAa,OAAS,IAAM,yIAGzD,MAAM0T,EAAU,GAIhB,OAHAL,EAAM9S,SAAQ,CAACoT,EAAM1Z,KACjByZ,EAAQzZ,GAAK,IAAM0Z,KAEhBD,MAInB,SAASzQ,GAGL,OADa3E,KAAK0L,MAAMZ,WAAW/J,IAAI4D,GAC3BT,QAAQsJ,SAAS7I,GAEjC,KAAKA,GAGD,OADa3E,KAAK0L,MAAMZ,WAAW/J,IAAI4D,GAC3BT,QAAQoR,KAAK3Q,GAE7B,WAAWwO,GACP,MAAMlO,EAAQ,gBACRsQ,QAAmBvV,KAAKkE,QAAQsR,KAAKrC,GAE3C,OADAoC,EAAWE,OAAS,gBAAQxQ,EACrBsQ,EAQX,MAAMvY,GAKF,OAJ8B,MAA1BgD,KAAK0L,MAAM+C,cACXzR,EAAOsX,QAAUtU,KAAK0L,MAAM+C,YAAY+E,GACxCxT,KAAK0L,MAAM+C,YAAYmE,MAAMhX,KAAKoB,IAE/BA,EAEX,0BACI,OAAOgD,KAAK0L,MAAMvB,oBAMtB,QAEInK,KAAKyL,uBACLzL,KAAK0L,MAAMjH,UACXzE,KAAKpB,IAAI8W,QACT1V,KAAK0L,MAAQ,IAAIxB,EACjB,IAAK,MAAM8B,KAAehM,KAAKuL,SAC3BvL,KAAKqN,yBAAyBrB,GAC9BhM,KAAKuL,SAASS,GAAavH,iBACpBzE,KAAKuL,SAASS,GAEzBhM,KAAKgM,YAAc,KACnBhM,KAAK6L,gBAAkB,KACvB7L,KAAK2L,mBAAqB,MAS3B,SAASgK,IACZ,MAAMC,EAAK,cACX,GAAoB,MAAhBA,EAAGC,UAAmB,CACtB,MAAMrT,EAAc,IAAI,IAAYoT,GACpCA,EAAGC,UAAY,IAAIvK,EAAO9I,GAM9B,OAJA,YAAqBoT,EAAGC,UAAUjX,KAGlC,aAAiB,IAAMgX,EAAGC,YACnBD,EAAGC,UAhBdvK,EAAO+C,aAAe,EACtB/C,EAAOgD,eAAiB,EAiBjB,MAAMM,EAAS+G,IAOf,SAASb,EAAIpa,EAAGC,GAEnB,MAAM4T,EAAS,CAAE7T,IAAGC,KACpB,OAAOiU,EAAOC,eAAc,CAAC3K,EAASgR,KAClC,MAAM/G,EAAMjK,EAAQ4Q,IAAIpa,EAAGC,GAE3B,OADAua,EAAK,CAACxa,EAAGC,IACFwT,IACRI,EAAQ,KAAqB,O,iCC96BpC,0EAmBA,cAYA,MAAMuH,EAAY,CACdC,OAAA,IACAvR,KAAA,IACAL,MAAA,IACA6R,MAAA,KAEJ,YAAaF","file":"js/bundle~bundle~fb9c722d.0fb024a4.js","sourcesContent":["/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n/**\n * Inserts a value into a sorted array. This method allows duplicate, meaning it\n * allows inserting duplicate value, in which case, the element will be inserted\n * at the lowest index of the value.\n * @param arr The array to modify.\n * @param element The element to insert.\n * @param comparator Optional. If no comparator is specified, elements are\n * compared using array_util.defaultComparator, which is suitable for Strings\n * and Numbers in ascending arrays. If the array contains multiple instances of\n * the target value, the left-most instance will be returned. To provide a\n * comparator, it should take 2 arguments to compare and return a negative,\n * zero, or a positive number.\n */\nexport function binaryInsert(arr, element, comparator) {\n    const index = binarySearch(arr, element, comparator);\n    const insertionPoint = index < 0 ? -(index + 1) : index;\n    arr.splice(insertionPoint, 0, element);\n}\n/**\n * Searches the array for the target using binary search, returns the index\n * of the found element, or position to insert if element not found. If no\n * comparator is specified, elements are compared using array_\n * util.defaultComparator, which is suitable for Strings and Numbers in\n * ascending arrays. If the array contains multiple instances of the target\n * value, the left-most instance will be returned.\n * @param arr The array to be searched in.\n * @param target The target to be searched for.\n * @param comparator Should take 2 arguments to compare and return a negative,\n *    zero, or a positive number.\n * @return Lowest index of the target value if found, otherwise the insertion\n *    point where the target should be inserted, in the form of\n *    (-insertionPoint - 1).\n */\nexport function binarySearch(arr, target, comparator) {\n    return binarySearch_(arr, target, comparator || defaultComparator);\n}\n/**\n * Compares its two arguments for order.\n * @param a The first element to be compared.\n * @param b The second element to be compared.\n * @return A negative number, zero, or a positive number as the first\n *     argument is less than, equal to, or greater than the second.\n */\nfunction defaultComparator(a, b) {\n    return a > b ? 1 : a < b ? -1 : 0;\n}\nfunction binarySearch_(arr, target, comparator) {\n    let left = 0;\n    let right = arr.length;\n    let middle = 0;\n    let found = false;\n    while (left < right) {\n        middle = left + ((right - left) >>> 1);\n        const compareResult = comparator(target, arr[middle]);\n        if (compareResult > 0) {\n            left = middle + 1;\n        }\n        else {\n            right = middle;\n            // If compareResult is 0, the value is found. We record it is found,\n            // and then keep looking because there may be duplicate.\n            found = !compareResult;\n        }\n    }\n    return found ? left : -left - 1;\n}\n//# sourceMappingURL=array_util.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n/**\n * Implementation of the NonMaxSuppression kernel shared between webgl and cpu.\n */\nimport { scalar } from '../ops/scalar';\nimport { tensor1d } from '../ops/tensor1d';\nimport { binaryInsert } from './array_util';\nexport function nonMaxSuppressionV3Impl(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold) {\n    return nonMaxSuppressionImpl_(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, 0 /* softNmsSigma */)\n        .selectedIndices;\n}\nexport function nonMaxSuppressionV4Impl(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, padToMaxOutputSize) {\n    return nonMaxSuppressionImpl_(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, 0 /* softNmsSigma */, false /* returnScoresTensor */, padToMaxOutputSize /* padToMaxOutputSize */, true\n    /* returnValidOutputs */ );\n}\nexport function nonMaxSuppressionV5Impl(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma) {\n    return nonMaxSuppressionImpl_(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma, true /* returnScoresTensor */);\n}\nfunction nonMaxSuppressionImpl_(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma, returnScoresTensor = false, padToMaxOutputSize = false, returnValidOutputs = false) {\n    // The list is sorted in ascending order, so that we can always pop the\n    // candidate with the largest score in O(1) time.\n    const candidates = [];\n    for (let i = 0; i < scores.length; i++) {\n        if (scores[i] > scoreThreshold) {\n            candidates.push({ score: scores[i], boxIndex: i, suppressBeginIndex: 0 });\n        }\n    }\n    candidates.sort(ascendingComparator);\n    // If softNmsSigma is 0, the outcome of this algorithm is exactly same as\n    // before.\n    const scale = softNmsSigma > 0 ? (-0.5 / softNmsSigma) : 0.0;\n    const selectedIndices = [];\n    const selectedScores = [];\n    while (selectedIndices.length < maxOutputSize && candidates.length > 0) {\n        const candidate = candidates.pop();\n        const { score: originalScore, boxIndex, suppressBeginIndex } = candidate;\n        if (originalScore < scoreThreshold) {\n            break;\n        }\n        // Overlapping boxes are likely to have similar scores, therefore we\n        // iterate through the previously selected boxes backwards in order to\n        // see if candidate's score should be suppressed. We use\n        // suppressBeginIndex to track and ensure a candidate can be suppressed\n        // by a selected box no more than once. Also, if the overlap exceeds\n        // iouThreshold, we simply ignore the candidate.\n        let ignoreCandidate = false;\n        for (let j = selectedIndices.length - 1; j >= suppressBeginIndex; --j) {\n            const iou = intersectionOverUnion(boxes, boxIndex, selectedIndices[j]);\n            if (iou >= iouThreshold) {\n                ignoreCandidate = true;\n                break;\n            }\n            candidate.score =\n                candidate.score * suppressWeight(iouThreshold, scale, iou);\n            if (candidate.score <= scoreThreshold) {\n                break;\n            }\n        }\n        // At this point, if `candidate.score` has not dropped below\n        // `scoreThreshold`, then we know that we went through all of the\n        // previous selections and can safely update `suppressBeginIndex` to the\n        // end of the selected array. Then we can re-insert the candidate with\n        // the updated score and suppressBeginIndex back in the candidate list.\n        // If on the other hand, `candidate.score` has dropped below the score\n        // threshold, we will not add it back to the candidates list.\n        candidate.suppressBeginIndex = selectedIndices.length;\n        if (!ignoreCandidate) {\n            // Candidate has passed all the tests, and is not suppressed, so\n            // select the candidate.\n            if (candidate.score === originalScore) {\n                selectedIndices.push(boxIndex);\n                selectedScores.push(candidate.score);\n            }\n            else if (candidate.score > scoreThreshold) {\n                // Candidate's score is suppressed but is still high enough to be\n                // considered, so add back to the candidates list.\n                binaryInsert(candidates, candidate, ascendingComparator);\n            }\n        }\n    }\n    // NonMaxSuppressionV4 feature: padding output to maxOutputSize.\n    const validOutputs = selectedIndices.length;\n    const elemsToPad = maxOutputSize - validOutputs;\n    if (padToMaxOutputSize && elemsToPad > 0) {\n        selectedIndices.push(...new Array(elemsToPad).fill(0));\n        selectedScores.push(...new Array(elemsToPad).fill(0.0));\n    }\n    const result = { selectedIndices: tensor1d(selectedIndices, 'int32') };\n    if (returnScoresTensor) {\n        result['selectedScores'] = tensor1d(selectedScores, 'float32');\n    }\n    if (returnValidOutputs) {\n        result['validOutputs'] = scalar(validOutputs, 'int32');\n    }\n    return result;\n}\nfunction intersectionOverUnion(boxes, i, j) {\n    const iCoord = boxes.subarray(i * 4, i * 4 + 4);\n    const jCoord = boxes.subarray(j * 4, j * 4 + 4);\n    const yminI = Math.min(iCoord[0], iCoord[2]);\n    const xminI = Math.min(iCoord[1], iCoord[3]);\n    const ymaxI = Math.max(iCoord[0], iCoord[2]);\n    const xmaxI = Math.max(iCoord[1], iCoord[3]);\n    const yminJ = Math.min(jCoord[0], jCoord[2]);\n    const xminJ = Math.min(jCoord[1], jCoord[3]);\n    const ymaxJ = Math.max(jCoord[0], jCoord[2]);\n    const xmaxJ = Math.max(jCoord[1], jCoord[3]);\n    const areaI = (ymaxI - yminI) * (xmaxI - xminI);\n    const areaJ = (ymaxJ - yminJ) * (xmaxJ - xminJ);\n    if (areaI <= 0 || areaJ <= 0) {\n        return 0.0;\n    }\n    const intersectionYmin = Math.max(yminI, yminJ);\n    const intersectionXmin = Math.max(xminI, xminJ);\n    const intersectionYmax = Math.min(ymaxI, ymaxJ);\n    const intersectionXmax = Math.min(xmaxI, xmaxJ);\n    const intersectionArea = Math.max(intersectionYmax - intersectionYmin, 0.0) *\n        Math.max(intersectionXmax - intersectionXmin, 0.0);\n    return intersectionArea / (areaI + areaJ - intersectionArea);\n}\n// A Gaussian penalty function, this method always returns values in [0, 1].\n// The weight is a function of similarity, the more overlap two boxes are, the\n// smaller the weight is, meaning highly overlapping boxe will be significantly\n// penalized. On the other hand, a non-overlapping box will not be penalized.\nfunction suppressWeight(iouThreshold, scale, iou) {\n    const weight = Math.exp(scale * iou * iou);\n    return iou <= iouThreshold ? weight : 0.0;\n}\nfunction ascendingComparator(c1, c2) {\n    // For objects with same scores, we make the object with the larger index go\n    // first. In an array that pops from the end, this means that the object with\n    // the smaller index will be popped first. This ensures the same output as\n    // the TensorFlow python version.\n    return (c1.score - c2.score) ||\n        ((c1.score === c2.score) && (c2.boxIndex - c1.boxIndex));\n}\n//# sourceMappingURL=non_max_suppression_impl.js.map","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport './engine';\nimport * as device_util from './device_util';\nimport { env } from './environment';\nconst ENV = env();\n/**\n * This file contains environment-related flag registrations.\n */\n/** Whether to enable debug mode. */\nENV.registerFlag('DEBUG', () => false, debugValue => {\n    if (debugValue) {\n        console.warn('Debugging mode is ON. The output of every math call will ' +\n            'be downloaded to CPU and checked for NaNs. ' +\n            'This significantly impacts performance.');\n    }\n});\n/** Whether we are in a browser (as versus, say, node.js) environment. */\nENV.registerFlag('IS_BROWSER', () => device_util.isBrowser());\n/** Whether we are in a browser (as versus, say, node.js) environment. */\nENV.registerFlag('IS_NODE', () => (typeof process !== 'undefined') &&\n    (typeof process.versions !== 'undefined') &&\n    (typeof process.versions.node !== 'undefined'));\n/** Whether this browser is Chrome. */\nENV.registerFlag('IS_CHROME', () => typeof navigator !== 'undefined' && navigator != null &&\n    navigator.userAgent != null && /Chrome/.test(navigator.userAgent) &&\n    /Google Inc/.test(navigator.vendor));\n/**\n * True when the environment is \"production\" where we disable safety checks\n * to gain performance.\n */\nENV.registerFlag('PROD', () => false);\n/**\n * Whether to do sanity checks when inferring a shape from user-provided\n * values, used when creating a new tensor.\n */\nENV.registerFlag('TENSORLIKE_CHECK_SHAPE_CONSISTENCY', () => ENV.getBool('DEBUG'));\n/** Whether deprecation warnings are enabled. */\nENV.registerFlag('DEPRECATION_WARNINGS_ENABLED', () => true);\n/** True if running unit tests. */\nENV.registerFlag('IS_TEST', () => false);\n//# sourceMappingURL=flags.js.map","/**\n * @license\n * Copyright 2017 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n// tslint:disable-next-line:no-any\nfunction _isNavigatorDefined() {\n    return typeof navigator !== 'undefined' && navigator != null;\n}\nexport function isMobile() {\n    if (_isNavigatorDefined()) {\n        // tslint:disable-next-line:no-any\n        const a = navigator.userAgent || navigator.vendor || window.opera;\n        // tslint:disable-next-line:max-line-length\n        return /(android|bb\\d+|meego).+mobile|avantgo|bada\\/|blackberry|blazer|compal|elaine|fennec|hiptop|iemobile|ip(hone|od)|iris|kindle|lge |maemo|midp|mmp|mobile.+firefox|netfront|opera m(ob|in)i|palm( os)?|phone|p(ixi|re)\\/|plucker|pocket|psp|series(4|6)0|symbian|treo|up\\.(browser|link)|vodafone|wap|windows ce|xda|xiino/i\n            .test(a) ||\n            // tslint:disable-next-line:max-line-length\n            /1207|6310|6590|3gso|4thp|50[1-6]i|770s|802s|a wa|abac|ac(er|oo|s\\-)|ai(ko|rn)|al(av|ca|co)|amoi|an(ex|ny|yw)|aptu|ar(ch|go)|as(te|us)|attw|au(di|\\-m|r |s )|avan|be(ck|ll|nq)|bi(lb|rd)|bl(ac|az)|br(e|v)w|bumb|bw\\-(n|u)|c55\\/|capi|ccwa|cdm\\-|cell|chtm|cldc|cmd\\-|co(mp|nd)|craw|da(it|ll|ng)|dbte|dc\\-s|devi|dica|dmob|do(c|p)o|ds(12|\\-d)|el(49|ai)|em(l2|ul)|er(ic|k0)|esl8|ez([4-7]0|os|wa|ze)|fetc|fly(\\-|_)|g1 u|g560|gene|gf\\-5|g\\-mo|go(\\.w|od)|gr(ad|un)|haie|hcit|hd\\-(m|p|t)|hei\\-|hi(pt|ta)|hp( i|ip)|hs\\-c|ht(c(\\-| |_|a|g|p|s|t)|tp)|hu(aw|tc)|i\\-(20|go|ma)|i230|iac( |\\-|\\/)|ibro|idea|ig01|ikom|im1k|inno|ipaq|iris|ja(t|v)a|jbro|jemu|jigs|kddi|keji|kgt( |\\/)|klon|kpt |kwc\\-|kyo(c|k)|le(no|xi)|lg( g|\\/(k|l|u)|50|54|\\-[a-w])|libw|lynx|m1\\-w|m3ga|m50\\/|ma(te|ui|xo)|mc(01|21|ca)|m\\-cr|me(rc|ri)|mi(o8|oa|ts)|mmef|mo(01|02|bi|de|do|t(\\-| |o|v)|zz)|mt(50|p1|v )|mwbp|mywa|n10[0-2]|n20[2-3]|n30(0|2)|n50(0|2|5)|n7(0(0|1)|10)|ne((c|m)\\-|on|tf|wf|wg|wt)|nok(6|i)|nzph|o2im|op(ti|wv)|oran|owg1|p800|pan(a|d|t)|pdxg|pg(13|\\-([1-8]|c))|phil|pire|pl(ay|uc)|pn\\-2|po(ck|rt|se)|prox|psio|pt\\-g|qa\\-a|qc(07|12|21|32|60|\\-[2-7]|i\\-)|qtek|r380|r600|raks|rim9|ro(ve|zo)|s55\\/|sa(ge|ma|mm|ms|ny|va)|sc(01|h\\-|oo|p\\-)|sdk\\/|se(c(\\-|0|1)|47|mc|nd|ri)|sgh\\-|shar|sie(\\-|m)|sk\\-0|sl(45|id)|sm(al|ar|b3|it|t5)|so(ft|ny)|sp(01|h\\-|v\\-|v )|sy(01|mb)|t2(18|50)|t6(00|10|18)|ta(gt|lk)|tcl\\-|tdg\\-|tel(i|m)|tim\\-|t\\-mo|to(pl|sh)|ts(70|m\\-|m3|m5)|tx\\-9|up(\\.b|g1|si)|utst|v400|v750|veri|vi(rg|te)|vk(40|5[0-3]|\\-v)|vm40|voda|vulc|vx(52|53|60|61|70|80|81|83|85|98)|w3c(\\-| )|webc|whit|wi(g |nc|nw)|wmlb|wonu|x700|yas\\-|your|zeto|zte\\-/i\n                .test(a.substr(0, 4));\n    }\n    return false;\n}\nexport function isBrowser() {\n    return (typeof window !== 'undefined' && window.document != null) ||\n        //@ts-ignore\n        (typeof WorkerGlobalScope !== 'undefined');\n}\n//# sourceMappingURL=device_util.js.map","/**\n * @license\n * Copyright 2017 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n// Expects flags from URL in the format ?tfjsflags=FLAG1:1,FLAG2:true.\nconst TENSORFLOWJS_FLAGS_PREFIX = 'tfjsflags';\n/**\n * The environment contains evaluated flags as well as the registered platform.\n * This is always used as a global singleton and can be retrieved with\n * `tf.env()`.\n *\n * @doc {heading: 'Environment'}\n */\nexport class Environment {\n    // tslint:disable-next-line: no-any\n    constructor(global) {\n        this.global = global;\n        this.flags = {};\n        this.flagRegistry = {};\n        this.urlFlags = {};\n        this.populateURLFlags();\n    }\n    setPlatform(platformName, platform) {\n        if (this.platform != null) {\n            console.warn(`Platform ${this.platformName} has already been set. ` +\n                `Overwriting the platform with ${platform}.`);\n        }\n        this.platformName = platformName;\n        this.platform = platform;\n    }\n    registerFlag(flagName, evaluationFn, setHook) {\n        this.flagRegistry[flagName] = { evaluationFn, setHook };\n        // Override the flag value from the URL. This has to happen here because the\n        // environment is initialized before flags get registered.\n        if (this.urlFlags[flagName] != null) {\n            const flagValue = this.urlFlags[flagName];\n            console.warn(`Setting feature override from URL ${flagName}: ${flagValue}.`);\n            this.set(flagName, flagValue);\n        }\n    }\n    async getAsync(flagName) {\n        if (flagName in this.flags) {\n            return this.flags[flagName];\n        }\n        this.flags[flagName] = await this.evaluateFlag(flagName);\n        return this.flags[flagName];\n    }\n    get(flagName) {\n        if (flagName in this.flags) {\n            return this.flags[flagName];\n        }\n        const flagValue = this.evaluateFlag(flagName);\n        if (flagValue instanceof Promise) {\n            throw new Error(`Flag ${flagName} cannot be synchronously evaluated. ` +\n                `Please use getAsync() instead.`);\n        }\n        this.flags[flagName] = flagValue;\n        return this.flags[flagName];\n    }\n    getNumber(flagName) {\n        return this.get(flagName);\n    }\n    getBool(flagName) {\n        return this.get(flagName);\n    }\n    getFlags() {\n        return this.flags;\n    }\n    // For backwards compatibility.\n    get features() {\n        return this.flags;\n    }\n    set(flagName, value) {\n        if (this.flagRegistry[flagName] == null) {\n            throw new Error(`Cannot set flag ${flagName} as it has not been registered.`);\n        }\n        this.flags[flagName] = value;\n        if (this.flagRegistry[flagName].setHook != null) {\n            this.flagRegistry[flagName].setHook(value);\n        }\n    }\n    evaluateFlag(flagName) {\n        if (this.flagRegistry[flagName] == null) {\n            throw new Error(`Cannot evaluate flag '${flagName}': no evaluation function found.`);\n        }\n        return this.flagRegistry[flagName].evaluationFn();\n    }\n    setFlags(flags) {\n        this.flags = Object.assign({}, flags);\n    }\n    reset() {\n        this.flags = {};\n        this.urlFlags = {};\n        this.populateURLFlags();\n    }\n    populateURLFlags() {\n        if (typeof this.global === 'undefined' ||\n            typeof this.global.location === 'undefined' ||\n            typeof this.global.location.search === 'undefined') {\n            return;\n        }\n        const urlParams = getQueryParams(this.global.location.search);\n        if (TENSORFLOWJS_FLAGS_PREFIX in urlParams) {\n            const keyValues = urlParams[TENSORFLOWJS_FLAGS_PREFIX].split(',');\n            keyValues.forEach(keyValue => {\n                const [key, value] = keyValue.split(':');\n                this.urlFlags[key] = parseValue(key, value);\n            });\n        }\n    }\n}\nexport function getQueryParams(queryString) {\n    const params = {};\n    queryString.replace(/[?&]([^=?&]+)(?:=([^&]*))?/g, (s, ...t) => {\n        decodeParam(params, t[0], t[1]);\n        return t.join('=');\n    });\n    return params;\n}\nfunction decodeParam(params, name, value) {\n    params[decodeURIComponent(name)] = decodeURIComponent(value || '');\n}\nfunction parseValue(flagName, value) {\n    value = value.toLowerCase();\n    if (value === 'true' || value === 'false') {\n        return value === 'true';\n    }\n    else if (`${+value}` === value) {\n        return +value;\n    }\n    throw new Error(`Could not parse value flag value ${value} for flag ${flagName}.`);\n}\n/**\n * Returns the current environment (a global singleton).\n *\n * The environment object contains the evaluated feature values as well as the\n * active platform.\n *\n * @doc {heading: 'Environment'}\n */\nexport function env() {\n    return ENV;\n}\nexport let ENV = null;\nexport function setEnvironmentGlobal(environment) {\n    ENV = environment;\n}\n//# sourceMappingURL=environment.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n/**\n * Merges real and imaginary Float32Arrays into a single complex Float32Array.\n *\n * The memory layout is interleaved as follows:\n * real: [r0, r1, r2]\n * imag: [i0, i1, i2]\n * complex: [r0, i0, r1, i1, r2, i2]\n *\n * This is the inverse of splitRealAndImagArrays.\n *\n * @param real The real values of the complex tensor values.\n * @param imag The imag values of the complex tensor values.\n * @returns A complex tensor as a Float32Array with merged values.\n */\nexport function mergeRealAndImagArrays(real, imag) {\n    if (real.length !== imag.length) {\n        throw new Error(`Cannot merge real and imag arrays of different lengths. real:` +\n            `${real.length}, imag: ${imag.length}.`);\n    }\n    const result = new Float32Array(real.length * 2);\n    for (let i = 0; i < result.length; i += 2) {\n        result[i] = real[i / 2];\n        result[i + 1] = imag[i / 2];\n    }\n    return result;\n}\n/**\n * Splits a complex Float32Array into real and imag parts.\n *\n * The memory layout is interleaved as follows:\n * complex: [r0, i0, r1, i1, r2, i2]\n * real: [r0, r1, r2]\n * imag: [i0, i1, i2]\n *\n * This is the inverse of mergeRealAndImagArrays.\n *\n * @param complex The complex tensor values.\n * @returns An object with real and imag Float32Array components of the complex\n *     tensor.\n */\nexport function splitRealAndImagArrays(complex) {\n    const real = new Float32Array(complex.length / 2);\n    const imag = new Float32Array(complex.length / 2);\n    for (let i = 0; i < complex.length; i += 2) {\n        real[i / 2] = complex[i];\n        imag[i / 2] = complex[i + 1];\n    }\n    return { real, imag };\n}\n/**\n * Extracts even indexed complex values in the given array.\n * @param complex The complex tensor values\n */\nexport function complexWithEvenIndex(complex) {\n    const len = Math.ceil(complex.length / 4);\n    const real = new Float32Array(len);\n    const imag = new Float32Array(len);\n    for (let i = 0; i < complex.length; i += 4) {\n        real[Math.floor(i / 4)] = complex[i];\n        imag[Math.floor(i / 4)] = complex[i + 1];\n    }\n    return { real, imag };\n}\n/**\n * Extracts odd indexed comple values in the given array.\n * @param complex The complex tensor values\n */\nexport function complexWithOddIndex(complex) {\n    const len = Math.floor(complex.length / 4);\n    const real = new Float32Array(len);\n    const imag = new Float32Array(len);\n    for (let i = 2; i < complex.length; i += 4) {\n        real[Math.floor(i / 4)] = complex[i];\n        imag[Math.floor(i / 4)] = complex[i + 1];\n    }\n    return { real, imag };\n}\n/**\n * Get the map representing a complex value in the given array.\n * @param complex The complex tensor values.\n * @param index An index of the target complex value.\n */\nexport function getComplexWithIndex(complex, index) {\n    const real = complex[index * 2];\n    const imag = complex[index * 2 + 1];\n    return { real, imag };\n}\n/**\n * Insert a given complex value into the TypedArray.\n * @param data The array in which the complex value is inserted.\n * @param c The complex value to be inserted.\n * @param index An index of the target complex value.\n */\nexport function assignToTypedArray(data, real, imag, index) {\n    data[index * 2] = real;\n    data[index * 2 + 1] = imag;\n}\n/**\n * Make the list of exponent terms used by FFT.\n */\nexport function exponents(n, inverse) {\n    const real = new Float32Array(n / 2);\n    const imag = new Float32Array(n / 2);\n    for (let i = 0; i < Math.ceil(n / 2); i++) {\n        const x = (inverse ? 2 : -2) * Math.PI * (i / n);\n        real[i] = Math.cos(x);\n        imag[i] = Math.sin(x);\n    }\n    return { real, imag };\n}\n/**\n * Make the exponent term used by FFT.\n */\nexport function exponent(k, n, inverse) {\n    const x = (inverse ? 2 : -2) * Math.PI * (k / n);\n    const real = Math.cos(x);\n    const imag = Math.sin(x);\n    return { real, imag };\n}\n//# sourceMappingURL=complex_util.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { cast } from '../ops/cast';\nimport { scalar } from '../ops/scalar';\nimport { tensor1d } from '../ops/tensor1d';\nimport { zeros } from '../ops/zeros';\nimport { hasEncodingLoss, makeZerosTypedArray } from '../util';\n// Utilities needed by backend consumers of tf-core.\nexport * from '../ops/axis_util';\nexport * from '../ops/broadcast_util';\nexport * from '../ops/concat_util';\nexport * from '../ops/conv_util';\nexport * from '../ops/fused_util';\nexport * from '../ops/reduce_util';\nimport * as slice_util from '../ops/slice_util';\nexport { slice_util };\nexport { upcastType } from '../types';\nexport * from '../ops/rotate_util';\nexport * from '../ops/array_ops_util';\nexport * from '../ops/gather_nd_util';\nexport * from '../ops/scatter_nd_util';\nexport * from '../ops/selu_util';\nexport * from '../ops/fused_util';\nexport * from '../ops/erf_util';\nexport * from '../log';\nexport * from '../backends/complex_util';\nexport * from '../ops/split_util';\nimport * as segment_util from '../ops/segment_util';\nexport { segment_util };\nexport function castTensor(x, dtype, backend) {\n    if (dtype === 'complex64') {\n        if (x.dtype === 'complex64') {\n            return x.clone();\n        }\n        const zerosTensor = zeros(x.shape);\n        const floatX = cast(x, 'float32');\n        const result = backend.complex(floatX, zerosTensor);\n        zerosTensor.dispose();\n        floatX.dispose();\n        return result;\n    }\n    if (!hasEncodingLoss(x.dtype, dtype)) {\n        // We don't change the underlying data, since we cast to higher\n        // precision.\n        return ENGINE.makeTensorFromDataId(x.dataId, x.shape, dtype);\n    }\n    if (x.dtype === 'complex64') {\n        const real = backend.real(x);\n        const result = cast(real, dtype);\n        real.dispose();\n        return result;\n    }\n    if (dtype === 'int32') {\n        return backend.int(x);\n    }\n    else if (dtype === 'bool') {\n        const zero = scalar(0, x.dtype);\n        const result = backend.notEqual(x, zero);\n        zero.dispose();\n        return result;\n    }\n    else {\n        throw new Error(`Error in Cast: failed to cast ${x.dtype} to ${dtype}`);\n    }\n}\nexport function reshapeTensor(x, shape) {\n    return ENGINE.makeTensorFromDataId(x.dataId, shape, x.dtype);\n}\nexport function linspaceImpl(start, stop, num) {\n    const step = (stop - start) / (num - 1);\n    const values = makeZerosTypedArray(num, 'float32');\n    values[0] = start;\n    for (let i = 1; i < values.length; i++) {\n        values[i] = values[i - 1] + step;\n    }\n    return tensor1d(values, 'float32');\n}\n//# sourceMappingURL=backend_util.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nexport const EPSILON_FLOAT32 = 1e-7;\nexport const EPSILON_FLOAT16 = 1e-4;\n/** Convenient class for storing tensor-related data. */\nexport class DataStorage {\n    constructor(backend, dataMover) {\n        this.backend = backend;\n        this.dataMover = dataMover;\n        this.data = new WeakMap();\n        this.dataIdsCount = 0;\n    }\n    get(dataId) {\n        if (!this.data.has(dataId)) {\n            this.dataMover.moveData(this.backend, dataId);\n        }\n        return this.data.get(dataId);\n    }\n    set(dataId, value) {\n        this.dataIdsCount++;\n        this.data.set(dataId, value);\n    }\n    has(dataId) {\n        return this.data.has(dataId);\n    }\n    delete(dataId) {\n        this.dataIdsCount--;\n        return this.data.delete(dataId);\n    }\n    numDataIds() {\n        return this.dataIdsCount;\n    }\n}\n/**\n * The interface that defines the kernels that should be implemented when\n * adding a new backend. New backends don't need to implement every one of the\n * methods, this can be done gradually (throw an error for unimplemented\n * methods).\n */\nexport class KernelBackend {\n    time(f) {\n        return notYetImplemented('time');\n    }\n    read(dataId) {\n        return notYetImplemented('read');\n    }\n    readSync(dataId) {\n        return notYetImplemented('readSync');\n    }\n    numDataIds() {\n        return notYetImplemented('numDataIds');\n    }\n    disposeData(dataId) {\n        return notYetImplemented('disposeData');\n    }\n    write(values, shape, dtype) {\n        return notYetImplemented('write');\n    }\n    move(dataId, values, shape, dtype) {\n        return notYetImplemented('move');\n    }\n    memory() {\n        return notYetImplemented('memory');\n    }\n    /** Returns the highest precision for floats in bits (e.g. 16 or 32) */\n    floatPrecision() {\n        return notYetImplemented('floatPrecision');\n    }\n    /** Returns the smallest representable number.  */\n    epsilon() {\n        return this.floatPrecision() === 32 ? EPSILON_FLOAT32 : EPSILON_FLOAT16;\n    }\n    batchMatMul(a, b, transposeA, transposeB) {\n        return notYetImplemented('batchMatMul');\n    }\n    fusedBatchMatMul({ a, b, transposeA, transposeB, bias, activation, preluActivationWeights }) {\n        return notYetImplemented('fusedBatchMatMul');\n    }\n    slice(x, begin, size) {\n        return notYetImplemented('slice');\n    }\n    stridedSlice(x, begin, end, strides) {\n        return notYetImplemented('stridedSlice');\n    }\n    unstack(x, axis) {\n        return notYetImplemented('unstack');\n    }\n    reverse(a, axis) {\n        return notYetImplemented('reverse');\n    }\n    concat(tensors, axis) {\n        return notYetImplemented('concat');\n    }\n    neg(a) {\n        return notYetImplemented('neg');\n    }\n    add(a, b) {\n        return notYetImplemented('add');\n    }\n    addN(tensors) {\n        return notYetImplemented('addN');\n    }\n    subtract(a, b) {\n        return notYetImplemented('subtract');\n    }\n    multiply(a, b) {\n        return notYetImplemented('multiply');\n    }\n    realDivide(a, b) {\n        return notYetImplemented('realDivide');\n    }\n    floorDiv(a, b) {\n        return notYetImplemented('floorDiv');\n    }\n    sum(x, axes) {\n        return notYetImplemented('sum');\n    }\n    prod(x, axes) {\n        return notYetImplemented('prod');\n    }\n    unsortedSegmentSum(x, segmentIds, numSegments) {\n        return notYetImplemented('unsortedSegmentSum');\n    }\n    argMin(x, axis) {\n        return notYetImplemented('argMin');\n    }\n    argMax(x, axis) {\n        return notYetImplemented('argMax');\n    }\n    equal(a, b) {\n        return notYetImplemented('equal');\n    }\n    notEqual(a, b) {\n        return notYetImplemented('notEqual');\n    }\n    less(a, b) {\n        return notYetImplemented('less');\n    }\n    lessEqual(a, b) {\n        return notYetImplemented('lessEqual');\n    }\n    greater(a, b) {\n        return notYetImplemented('greater');\n    }\n    greaterEqual(a, b) {\n        return notYetImplemented('greaterEqual');\n    }\n    logicalNot(a) {\n        return notYetImplemented('logicalNot');\n    }\n    logicalAnd(a, b) {\n        return notYetImplemented('logicalAnd');\n    }\n    logicalOr(a, b) {\n        return notYetImplemented('logicalOr');\n    }\n    where(condition) {\n        return notYetImplemented('where');\n    }\n    select(condition, a, b) {\n        return notYetImplemented('select');\n    }\n    topk(x, k, sorted) {\n        return notYetImplemented('topk');\n    }\n    min(x, axes) {\n        return notYetImplemented('min');\n    }\n    minimum(a, b) {\n        return notYetImplemented('minimum');\n    }\n    mod(a, b) {\n        return notYetImplemented('mod');\n    }\n    max(x, axes) {\n        return notYetImplemented('max');\n    }\n    maximum(a, b) {\n        return notYetImplemented('maximum');\n    }\n    all(x, axes) {\n        return notYetImplemented('all');\n    }\n    any(x, axes) {\n        return notYetImplemented('any');\n    }\n    squaredDifference(a, b) {\n        return notYetImplemented('squaredDifference');\n    }\n    ceil(x) {\n        return notYetImplemented('ceil');\n    }\n    floor(x) {\n        return notYetImplemented('floor');\n    }\n    round(x) {\n        return notYetImplemented('round');\n    }\n    sign(x) {\n        return notYetImplemented('sign');\n    }\n    isNaN(x) {\n        return notYetImplemented('isNaN');\n    }\n    isInf(x) {\n        return notYetImplemented('isInf');\n    }\n    isFinite(x) {\n        return notYetImplemented('isFinite');\n    }\n    pow(a, b) {\n        return notYetImplemented('pow');\n    }\n    exp(x) {\n        return notYetImplemented('exp');\n    }\n    expm1(x) {\n        return notYetImplemented('expm1');\n    }\n    softmax(x, dim) {\n        return notYetImplemented('softmax');\n    }\n    log(x) {\n        return notYetImplemented('log');\n    }\n    log1p(x) {\n        return notYetImplemented('log1p');\n    }\n    sqrt(x) {\n        return notYetImplemented('sqrt');\n    }\n    rsqrt(x) {\n        return notYetImplemented('rsqrt');\n    }\n    square(x) {\n        return notYetImplemented('square');\n    }\n    reciprocal(x) {\n        return notYetImplemented('reciprocal');\n    }\n    relu(x) {\n        return notYetImplemented('relu');\n    }\n    relu6(x) {\n        return notYetImplemented('relu6');\n    }\n    prelu(x, a) {\n        return notYetImplemented('prelu');\n    }\n    elu(x) {\n        return notYetImplemented('elu');\n    }\n    eluDer(dy, y) {\n        return notYetImplemented('eluDer');\n    }\n    selu(x) {\n        return notYetImplemented('selu');\n    }\n    int(x) {\n        return notYetImplemented('int');\n    }\n    clip(x, min, max) {\n        return notYetImplemented('clip');\n    }\n    abs(x) {\n        return notYetImplemented('abs');\n    }\n    complexAbs(x) {\n        return notYetImplemented('complexAbs');\n    }\n    sigmoid(x) {\n        return notYetImplemented('sigmoid');\n    }\n    softplus(x) {\n        return notYetImplemented('softplus');\n    }\n    sin(x) {\n        return notYetImplemented('sin');\n    }\n    cos(x) {\n        return notYetImplemented('cos');\n    }\n    tan(x) {\n        return notYetImplemented('tan');\n    }\n    asin(x) {\n        return notYetImplemented('asin');\n    }\n    acos(x) {\n        return notYetImplemented('acos');\n    }\n    atan(x) {\n        return notYetImplemented('atan');\n    }\n    atan2(a, b) {\n        return notYetImplemented('atan2');\n    }\n    sinh(x) {\n        return notYetImplemented('sinh');\n    }\n    cosh(x) {\n        return notYetImplemented('cosh');\n    }\n    tanh(x) {\n        return notYetImplemented('tanh');\n    }\n    asinh(x) {\n        return notYetImplemented('asinh');\n    }\n    acosh(x) {\n        return notYetImplemented('acosh');\n    }\n    atanh(x) {\n        return notYetImplemented('atanh');\n    }\n    erf(x) {\n        return notYetImplemented('erf');\n    }\n    step(x, alpha) {\n        return notYetImplemented('step');\n    }\n    fusedConv2d({ input, filter, convInfo, bias, activation, preluActivationWeights }) {\n        return notYetImplemented('fusedConv2d');\n    }\n    conv2d(x, filter, convInfo) {\n        return notYetImplemented('conv2d');\n    }\n    conv2dDerInput(dy, filter, convInfo) {\n        return notYetImplemented('conv2dDerInput');\n    }\n    conv2dDerFilter(x, dY, convInfo) {\n        return notYetImplemented('conv2dDerFilter');\n    }\n    fusedDepthwiseConv2D({ input, filter, convInfo, bias, activation, preluActivationWeights }) {\n        return notYetImplemented('fusedDepthwiseConv2D');\n    }\n    depthwiseConv2D(input, filter, convInfo) {\n        return notYetImplemented('depthwiseConv2D');\n    }\n    depthwiseConv2DDerInput(dy, filter, convInfo) {\n        return notYetImplemented('depthwiseConv2DDerInput');\n    }\n    depthwiseConv2DDerFilter(x, dY, convInfo) {\n        return notYetImplemented('depthwiseConv2DDerFilter');\n    }\n    conv3d(x, filter, convInfo) {\n        return notYetImplemented('conv3d');\n    }\n    conv3dDerInput(dy, filter, convInfo) {\n        return notYetImplemented('conv3dDerInput');\n    }\n    conv3dDerFilter(x, dY, convInfo) {\n        return notYetImplemented('conv3dDerFilter');\n    }\n    maxPool(x, convInfo) {\n        return notYetImplemented('maxPool');\n    }\n    maxPoolBackprop(dy, x, y, convInfo) {\n        return notYetImplemented('maxPoolBackprop');\n    }\n    avgPool(x, convInfo) {\n        return notYetImplemented('avgPool');\n    }\n    avgPoolBackprop(dy, x, convInfo) {\n        return notYetImplemented('avgPoolBackprop');\n    }\n    avgPool3d(x, convInfo) {\n        return notYetImplemented('avgPool3d');\n    }\n    avgPool3dBackprop(dy, x, convInfo) {\n        return notYetImplemented('avgPool3dBackprop');\n    }\n    maxPool3d(x, convInfo) {\n        return notYetImplemented('maxPool3d');\n    }\n    maxPool3dBackprop(dy, x, y, convInfo) {\n        return notYetImplemented('maxPool3dBackprop');\n    }\n    reshape(x, shape) {\n        return notYetImplemented('reshape');\n    }\n    cast(x, dtype) {\n        return notYetImplemented('cast');\n    }\n    tile(x, reps) {\n        return notYetImplemented('tile');\n    }\n    pad(x, paddings, constantValue) {\n        return notYetImplemented('pad');\n    }\n    transpose(x, perm) {\n        return notYetImplemented('transpose');\n    }\n    gather(x, indices, axis) {\n        return notYetImplemented('gather');\n    }\n    gatherND(x, indices) {\n        return notYetImplemented('gatherND');\n    }\n    scatterND(indices, updates, shape) {\n        return notYetImplemented('scatterND');\n    }\n    batchToSpaceND(x, blockShape, crops) {\n        return notYetImplemented('batchToSpaceND');\n    }\n    spaceToBatchND(x, blockShape, paddings) {\n        return notYetImplemented('spaceToBatchND');\n    }\n    resizeBilinear(x, newHeight, newWidth, alignCorners) {\n        return notYetImplemented('resizeBilinear');\n    }\n    resizeBilinearBackprop(dy, x, alignCorners) {\n        return notYetImplemented('resizeBilinearBackprop');\n    }\n    resizeNearestNeighbor(x, newHEight, newWidth, alignCorners) {\n        return notYetImplemented('resizeNearestNeighbor');\n    }\n    resizeNearestNeighborBackprop(dy, x, alignCorners) {\n        return notYetImplemented('resizeNearestNeighborBackprop');\n    }\n    batchNorm(x, mean, variance, offset, scale, varianceEpsilon) {\n        return notYetImplemented('batchNorm');\n    }\n    localResponseNormalization4D(x, radius, bias, alpha, beta) {\n        return notYetImplemented('localResponseNormalization4D');\n    }\n    LRNGrad(dy, inputImage, outputImage, radius, bias, alpha, beta) {\n        return notYetImplemented('LRNGrad');\n    }\n    multinomial(logits, normalized, numSamples, seed) {\n        return notYetImplemented('multinomial');\n    }\n    oneHot(indices, depth, onValue, offValue) {\n        return notYetImplemented('oneHot');\n    }\n    cumsum(x, axis, exclusive, reverse) {\n        return notYetImplemented('cumsum');\n    }\n    nonMaxSuppression(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold) {\n        return notYetImplemented('nonMaxSuppression');\n    }\n    fft(x) {\n        return notYetImplemented('fft');\n    }\n    ifft(x) {\n        return notYetImplemented('ifft');\n    }\n    complex(real, imag) {\n        return notYetImplemented('complex');\n    }\n    real(input) {\n        return notYetImplemented('real');\n    }\n    imag(input) {\n        return notYetImplemented('imag');\n    }\n    cropAndResize(image, boxes, boxIndex, cropSize, method, extrapolationValue) {\n        return notYetImplemented('cropAndResize');\n    }\n    depthToSpace(x, blockSize, dataFormat) {\n        return notYetImplemented('depthToSpace');\n    }\n    // Aligns with the \"SplitV\" kernel in TensorFlow.\n    split(value, sizeSplits, axis) {\n        return notYetImplemented('split');\n    }\n    sparseToDense(sparseIndices, sparseValues, outputShape, defaultValue) {\n        return notYetImplemented('sparseToDense');\n    }\n    diag(x) {\n        return notYetImplemented('diag');\n    }\n    fill(shape, value, dtype) {\n        return notYetImplemented('fill');\n    }\n    onesLike(x) {\n        return notYetImplemented('onesLike');\n    }\n    zerosLike(x) {\n        return notYetImplemented('zerosLike');\n    }\n    linspace(start, stop, num) {\n        return notYetImplemented('linspace');\n    }\n    dispose() {\n        return notYetImplemented('dispose');\n    }\n}\nfunction notYetImplemented(kernelName) {\n    throw new Error(`'${kernelName}' not yet implemented or not found in the registry. ` +\n        `Did you forget to import the kernel?`);\n}\n//# sourceMappingURL=backend.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { Environment, setEnvironmentGlobal } from './environment';\nimport { getGlobalNamespace } from './global_util';\nimport { Add, Cast } from './kernel_names';\nimport { getGradient, getKernel, getKernelsForBackend } from './kernel_registry';\nimport { Profiler } from './profiler';\nimport { backpropagateGradients, getFilteredNodesXToY } from './tape';\nimport { setTensorTracker, Tensor, Variable } from './tensor';\nimport { getTensorsInContainer } from './tensor_util';\nimport * as util from './util';\nimport { bytesFromStringArray, makeOnesTypedArray, now, sizeFromShape } from './util';\nclass EngineState {\n    constructor() {\n        // Public since optimizers will use it.\n        this.registeredVariables = {};\n        this.nextTapeNodeId = 0;\n        this.numBytes = 0;\n        this.numTensors = 0;\n        this.numStringTensors = 0;\n        this.numDataBuffers = 0;\n        // Number of nested tf.grad() statements when computing higher-order\n        // gradients. E.g. `1` for first-order gradients and `2` for second-order\n        // gradients. Used to track if the tape should be removed after a backprop.\n        this.gradientDepth = 0;\n        // Number of nested kernel calls. When kernel depth is greater than 1, we turn\n        // off the tape.\n        this.kernelDepth = 0;\n        this.scopeStack = [];\n        /**\n         * Keeps track of the number of data moves during a kernel execution. We\n         * maintain a stack since kernels can call other kernels, recursively.\n         */\n        this.numDataMovesStack = [];\n        this.nextScopeId = 0;\n        this.tensorInfo = new WeakMap();\n        this.profiling = false;\n        this.activeProfile = { newBytes: 0, newTensors: 0, peakBytes: 0, kernels: [], result: null };\n    }\n    dispose() {\n        for (const variableName in this.registeredVariables) {\n            this.registeredVariables[variableName].dispose();\n        }\n    }\n}\nexport class Engine {\n    constructor(ENV) {\n        this.ENV = ENV;\n        this.registry = {};\n        this.registryFactory = {};\n        this.pendingBackendInitId = 0;\n        this.state = new EngineState();\n    }\n    async ready() {\n        if (this.pendingBackendInit != null) {\n            return this.pendingBackendInit.then(() => { });\n        }\n        if (this.backendInstance != null) {\n            return;\n        }\n        const sortedBackends = this.getSortedBackends();\n        for (let i = 0; i < sortedBackends.length; i++) {\n            const backendName = sortedBackends[i];\n            const success = await this.initializeBackend(backendName).success;\n            if (success) {\n                await this.setBackend(backendName);\n                return;\n            }\n        }\n        throw new Error(`Could not initialize any backends, all backend initializations ` +\n            `failed.`);\n    }\n    get backend() {\n        if (this.pendingBackendInit != null) {\n            throw new Error(`Backend '${this.backendName}' has not yet been initialized. Make ` +\n                `sure to await tf.ready() or await tf.setBackend() before calling ` +\n                `other methods`);\n        }\n        if (this.backendInstance == null) {\n            const { name, asyncInit } = this.initializeBackendsAndReturnBest();\n            if (asyncInit) {\n                throw new Error(`The highest priority backend '${name}' has not yet been ` +\n                    `initialized. Make sure to await tf.ready() or ` +\n                    `await tf.setBackend() before calling other methods`);\n            }\n            this.setBackend(name);\n        }\n        return this.backendInstance;\n    }\n    backendNames() {\n        return Object.keys(this.registryFactory);\n    }\n    findBackend(backendName) {\n        if (!(backendName in this.registry)) {\n            // If the backend hasn't been initialized but we have a registry entry for\n            // it, initialize it and return it.\n            if (backendName in this.registryFactory) {\n                const { asyncInit } = this.initializeBackend(backendName);\n                if (asyncInit) {\n                    // Backend is not ready yet.\n                    return null;\n                }\n            }\n            else {\n                return null;\n            }\n        }\n        return this.registry[backendName];\n    }\n    findBackendFactory(backendName) {\n        if (!(backendName in this.registryFactory)) {\n            return null;\n        }\n        return this.registryFactory[backendName].factory;\n    }\n    registerBackend(backendName, factory, priority = 1) {\n        if (backendName in this.registryFactory) {\n            console.warn(`${backendName} backend was already registered. ` +\n                `Reusing existing backend factory.`);\n            return false;\n        }\n        this.registryFactory[backendName] = { factory, priority };\n        return true;\n    }\n    async setBackend(backendName) {\n        if (this.registryFactory[backendName] == null) {\n            throw new Error(`Backend name '${backendName}' not found in registry`);\n        }\n        this.backendName = backendName;\n        if (this.registry[backendName] == null) {\n            this.backendInstance = null;\n            const { success, asyncInit } = this.initializeBackend(backendName);\n            const result = asyncInit ? await success : success;\n            if (!result) {\n                return false;\n            }\n        }\n        this.backendInstance = this.registry[backendName];\n        this.setupRegisteredKernels();\n        // Reset the profiler.\n        this.profiler = new Profiler(this.backendInstance);\n        return true;\n    }\n    setupRegisteredKernels() {\n        const kernels = getKernelsForBackend(this.backendName);\n        kernels.forEach(kernel => {\n            if (kernel.setupFunc != null) {\n                kernel.setupFunc(this.backendInstance);\n            }\n        });\n    }\n    disposeRegisteredKernels(backendName) {\n        const kernels = getKernelsForBackend(backendName);\n        kernels.forEach(kernel => {\n            if (kernel.disposeFunc != null) {\n                kernel.disposeFunc(this.registry[backendName]);\n            }\n        });\n    }\n    /**\n     * Initializes a backend by looking up the backend name in the factory\n     * registry and calling the factory method. Returns a boolean representing\n     * whether the initialization of the backend suceeded. Throws an error if\n     * there is no backend in the factory registry.\n     */\n    initializeBackend(backendName) {\n        const registryFactoryEntry = this.registryFactory[backendName];\n        if (registryFactoryEntry == null) {\n            throw new Error(`Cannot initialize backend ${backendName}, no registration found.`);\n        }\n        try {\n            const backend = registryFactoryEntry.factory();\n            // Test if the factory returns a promise.\n            if (Promise.resolve(backend) === backend) {\n                const promiseId = ++this.pendingBackendInitId;\n                const success = backend\n                    .then(backendInstance => {\n                    // Outdated promise. Another backend was set in the meantime.\n                    if (promiseId < this.pendingBackendInitId) {\n                        return false;\n                    }\n                    this.registry[backendName] = backendInstance;\n                    this.pendingBackendInit = null;\n                    return true;\n                })\n                    .catch(err => {\n                    // Outdated promise. Another backend was set in the meantime.\n                    if (promiseId < this.pendingBackendInitId) {\n                        return false;\n                    }\n                    this.pendingBackendInit = null;\n                    console.warn(`Initialization of backend ${backendName} failed`);\n                    console.warn(err.stack || err.message);\n                    return false;\n                });\n                this.pendingBackendInit = success;\n                return { success, asyncInit: true };\n            }\n            else {\n                this.registry[backendName] = backend;\n                return { success: true, asyncInit: false };\n            }\n        }\n        catch (err) {\n            console.warn(`Initialization of backend ${backendName} failed`);\n            console.warn(err.stack || err.message);\n            return { success: false, asyncInit: false };\n        }\n    }\n    removeBackend(backendName) {\n        if (!(backendName in this.registryFactory)) {\n            throw new Error(`${backendName} backend not found in registry`);\n        }\n        if (this.backendName === backendName && this.pendingBackendInit != null) {\n            // There is a pending promise of the backend we want to remove. Make it\n            // obsolete.\n            this.pendingBackendInitId++;\n        }\n        if (backendName in this.registry) {\n            this.disposeRegisteredKernels(backendName);\n            this.registry[backendName].dispose();\n            delete this.registry[backendName];\n        }\n        delete this.registryFactory[backendName];\n        // Unset the backend if it is active.\n        if (this.backendName === backendName) {\n            this.pendingBackendInit = null;\n            this.backendName = null;\n            this.backendInstance = null;\n        }\n    }\n    getSortedBackends() {\n        if (Object.keys(this.registryFactory).length === 0) {\n            throw new Error('No backend found in registry.');\n        }\n        return Object.keys(this.registryFactory).sort((a, b) => {\n            // Highest priority comes first.\n            return this.registryFactory[b].priority -\n                this.registryFactory[a].priority;\n        });\n    }\n    initializeBackendsAndReturnBest() {\n        const sortedBackends = this.getSortedBackends();\n        for (let i = 0; i < sortedBackends.length; i++) {\n            const backendName = sortedBackends[i];\n            const { success, asyncInit } = this.initializeBackend(backendName);\n            if (asyncInit || success) {\n                return { name: backendName, asyncInit };\n            }\n        }\n        throw new Error(`Could not initialize any backends, all backend initializations ` +\n            `failed.`);\n    }\n    moveData(backend, dataId) {\n        const info = this.state.tensorInfo.get(dataId);\n        const srcBackend = info.backend;\n        const values = this.readSync(dataId);\n        // Delete the tensor from the old backend and move it to the new\n        // backend.\n        srcBackend.disposeData(dataId);\n        info.backend = backend;\n        backend.move(dataId, values, info.shape, info.dtype);\n        if (this.shouldCheckForMemLeaks()) {\n            // Track the number of moves during a kernel execution to correctly\n            // detect memory leaks.\n            this.state.numDataMovesStack[this.state.numDataMovesStack.length - 1]++;\n        }\n    }\n    tidy(nameOrFn, fn) {\n        let name = null;\n        if (fn == null) {\n            // Called with only 1 argument.\n            if (typeof nameOrFn !== 'function') {\n                throw new Error('Please provide a function to tidy()');\n            }\n            fn = nameOrFn;\n        }\n        else {\n            // Called with 2 arguments.\n            if (typeof nameOrFn !== 'string' && !(nameOrFn instanceof String)) {\n                throw new Error('When calling with two arguments, the first argument ' +\n                    'to tidy() must be a string');\n            }\n            if (typeof fn !== 'function') {\n                throw new Error('When calling with two arguments, the 2nd argument ' +\n                    'to tidy() must be a function');\n            }\n            name = nameOrFn;\n            // TODO(nsthorat,smilkov): Do operation logging and performance\n            // profiling.\n        }\n        let result;\n        return this.scopedRun(() => this.startScope(name), () => this.endScope(result), () => {\n            result = fn();\n            if (result instanceof Promise) {\n                console.error('Cannot return a Promise inside of tidy.');\n            }\n            return result;\n        });\n    }\n    scopedRun(start, end, f) {\n        start();\n        try {\n            const res = f();\n            end();\n            return res;\n        }\n        catch (ex) {\n            end();\n            throw ex;\n        }\n    }\n    nextTensorId() {\n        return Engine.nextTensorId++;\n    }\n    nextVariableId() {\n        return Engine.nextVariableId++;\n    }\n    /**\n     * This method is called instead of the public-facing tensor.clone() when\n     * saving a tensor for backwards pass. It makes sure to add the clone\n     * operation to the tape regardless of being called inside a kernel\n     * execution.\n     *\n     * This method will go away once all kernels are modularized since we won't\n     * need to turn off the tape inside runKernel().\n     */\n    clone(x) {\n        const y = this.makeTensorFromDataId(x.dataId, x.shape, x.dtype);\n        const inputs = { x };\n        const grad = (dy) => ({\n            x: () => {\n                const dtype = 'float32';\n                const gradInputs = { x: dy };\n                const attrs = { dtype };\n                return ENGINE.runKernelFunc(backend => backend.cast(dy, dtype), gradInputs, null /* grad */, Cast, attrs);\n            }\n        });\n        const saved = [];\n        this.addTapeNode(this.state.activeScope.name, inputs, [y], grad, saved, {});\n        return y;\n    }\n    /**\n     * Execute a kernel with the given name and return the output tensor.\n     *\n     * @param kernelName The name of the kernel to execute.\n     * @param inputs A map of input names to tensors.\n     * @param attrs A map of attribute names to their values. An attribute is a\n     *     primitive (non-tensor) input to the kernel.\n     * @param inputsToSave A list of tensors, inputs to save for the backprop\n     *     computation.\n     * @param outputsToSave A list of booleans, specifying which output to save\n     *     for the backprop computation. These are booleans since the output\n     * tensors are not visible to the user.\n     */\n    runKernel(kernelName, inputs, attrs, inputsToSave, outputsToSave) {\n        const forwardFunc = null;\n        const backwardsFunc = null;\n        // Call runKernel as a stop-gap until we modularize all kernels.\n        // Once we modularize all kernels, we will remove the existing\n        // `runKernelFunc`.\n        return this.runKernelFunc(forwardFunc, inputs, backwardsFunc, kernelName, attrs, inputsToSave, outputsToSave);\n    }\n    shouldCheckForMemLeaks() {\n        return this.ENV.getBool('IS_TEST');\n    }\n    checkKernelForMemLeak(kernelName, numDataIdsBefore, outInfos) {\n        const numDataIdsAfter = this.backend.numDataIds();\n        // Count the number of data ids associated with the result of the kernel.\n        let numOutputDataIds = 0;\n        outInfos.forEach(info => {\n            // Complex numbers allocate 3 data ids, one for 'real', one for\n            // 'imaginary', and one for the container that holds the former two.\n            numOutputDataIds += (info.dtype === 'complex64' ? 3 : 1);\n        });\n        // Account for the number of moves during kernel execution. A \"data move\"\n        // can happen in the middle of a kernel execution, placing a new (key,value)\n        // pair in the data storage. Since data moves have net zero effect (we\n        // always remove the data from the old backend), we have to cancel them out\n        // when detecting memory leaks.\n        const numMoves = this.state.numDataMovesStack[this.state.numDataMovesStack.length - 1];\n        const dataIdsLeaked = numDataIdsAfter - numDataIdsBefore - numOutputDataIds - numMoves;\n        if (dataIdsLeaked > 0) {\n            throw new Error(`Backend '${this.backendName}' has an internal memory leak ` +\n                `(${dataIdsLeaked} data ids) after running '${kernelName}'`);\n        }\n    }\n    /**\n     * @deprecated Use `runKernel` for newly added kernels. Keep using this method\n     *     only for kernels that are not yet fully modularized.\n     */\n    runKernelFunc(forwardFunc, inputs, backwardsFunc, kernelName, attrs, inputsToSave, outputsToSave) {\n        let outputs;\n        let saved = [];\n        const isTapeOn = this.isTapeOn();\n        if (kernelName == null) {\n            kernelName =\n                this.state.activeScope != null ? this.state.activeScope.name : '';\n        }\n        const startingBytecount = this.state.numBytes;\n        const startingNumTensors = this.state.numTensors;\n        if (this.shouldCheckForMemLeaks()) {\n            this.state.numDataMovesStack.push(0);\n        }\n        let kernelFunc;\n        const kernel = getKernel(kernelName, this.backendName);\n        let out;\n        if (kernel != null) {\n            kernelFunc = () => {\n                const numDataIdsBefore = this.backend.numDataIds();\n                out = kernel.kernelFunc({ inputs, attrs, backend: this.backend });\n                const outInfos = Array.isArray(out) ? out : [out];\n                if (this.shouldCheckForMemLeaks()) {\n                    this.checkKernelForMemLeak(kernelName, numDataIdsBefore, outInfos);\n                }\n                const outTensors = outInfos.map(({ dataId, shape, dtype }) => this.makeTensorFromDataId(dataId, shape, dtype));\n                // Save the inputs and outputs.\n                // Do not save unless we are recording to the tape. Otherwise it would\n                // cause a mem leak since we would never run backprop, which disposes\n                // the kept tensors.\n                if (isTapeOn) {\n                    let tensorsToSave = this.getTensorsForGradient(kernelName, inputs, outTensors);\n                    if (tensorsToSave == null) {\n                        // Fallback for ops that call runKernelFunc and pass in\n                        // inputsToSave and outputsToSave. Currently this is the set of ops\n                        // with kernel support in the WASM backend. Once those ops and\n                        // respective gradients are modularised we can remove this path.\n                        if (outputsToSave == null) {\n                            outputsToSave = [];\n                        }\n                        const outsToSave = outTensors.filter((_, i) => outputsToSave[i]);\n                        tensorsToSave = (inputsToSave || []).slice().concat(outsToSave);\n                    }\n                    saved = this.saveTensorsForBackwardMode(tensorsToSave);\n                }\n                return outTensors;\n            };\n        }\n        else {\n            const saveFunc = (tensors) => {\n                // Do not save unless we are recording to the tape. Otherwise it would\n                // cause a mem leak since we would never run backprop, which disposes\n                // the kept tensors.\n                if (!isTapeOn) {\n                    return;\n                }\n                saved = tensors.map(tensor => this.keep(this.clone(tensor)));\n            };\n            kernelFunc = () => {\n                const numDataIdsBefore = this.backend.numDataIds();\n                out = this.tidy(() => forwardFunc(this.backend, saveFunc));\n                const outs = (Array.isArray(out) ? out : [out]);\n                if (this.shouldCheckForMemLeaks()) {\n                    this.checkKernelForMemLeak(kernelName, numDataIdsBefore, outs);\n                }\n                return outs;\n            };\n        }\n        // Stop recording to a tape when running a kernel.\n        let kernelProfile;\n        this.scopedRun(() => this.state.kernelDepth++, () => this.state.kernelDepth--, () => {\n            if (!this.ENV.getBool('DEBUG') && !this.state.profiling) {\n                outputs = kernelFunc();\n            }\n            else {\n                kernelProfile = this.profiler.profileKernel(kernelName, inputs, () => kernelFunc());\n                if (this.ENV.getBool('DEBUG')) {\n                    this.profiler.logKernelProfile(kernelProfile);\n                }\n                outputs = kernelProfile.outputs;\n            }\n        });\n        if (isTapeOn) {\n            this.addTapeNode(kernelName, inputs, outputs, backwardsFunc, saved, attrs);\n        }\n        if (this.state.profiling) {\n            this.state.activeProfile.kernels.push({\n                name: kernelName,\n                bytesAdded: this.state.numBytes - startingBytecount,\n                totalBytesSnapshot: this.state.numBytes,\n                tensorsAdded: this.state.numTensors - startingNumTensors,\n                totalTensorsSnapshot: this.state.numTensors,\n                inputShapes: Object.keys(inputs).map(key => inputs[key] != null ? inputs[key].shape : null),\n                outputShapes: outputs.map(item => item.shape),\n                kernelTimeMs: kernelProfile.timeMs,\n                extraInfo: kernelProfile.extraInfo\n            });\n        }\n        return (Array.isArray(out) ? outputs : outputs[0]);\n    }\n    /**\n     * Saves tensors used in forward mode for use in backward mode.\n     *\n     * @param tensors the list of tensors to save.\n     */\n    saveTensorsForBackwardMode(tensors) {\n        const saved = tensors.map(tensor => this.keep(this.clone(tensor)));\n        return saved;\n    }\n    /**\n     * Returns a list of tensors to save for a given gradient calculation.\n     *\n     * Returns undefined if their is no registered gradient for this kernel in the\n     * gradient registry.\n     *\n     * @param kernelName name of kernel to look up gradient for.\n     * @param inputs a map of input tensors.\n     * @param outputs an array of output tensors from forward mode of kernel.\n     */\n    getTensorsForGradient(kernelName, inputs, outputs) {\n        const gradConfig = getGradient(kernelName);\n        if (gradConfig != null) {\n            const inputsToSave = gradConfig.inputsToSave || [];\n            const outputsToSave = gradConfig.outputsToSave || [];\n            // If saveAllInputs is true, all inputs will be saved. Otherwise, inputs\n            // specified in inputsToSave will be saved.\n            let inputTensorsToSave;\n            if (gradConfig.saveAllInputs) {\n                util.assert(Array.isArray(inputs), () => 'saveAllInputs is true, expected inputs to be an array.');\n                inputTensorsToSave = Object.keys(inputs).map((key) => inputs[key]);\n            }\n            else {\n                inputTensorsToSave = inputsToSave.map((inputName) => inputs[inputName]);\n            }\n            const outputTensorsToSave = outputs.filter((_, i) => outputsToSave[i]);\n            return inputTensorsToSave.concat(outputTensorsToSave);\n        }\n        // TODO(yassogba) throw exception here once all runkernelFunc calls with\n        // inputsToSave/outputsToSave are removed\n        return null;\n    }\n    /**\n     * Internal method used by public APIs for tensor creation. Makes a new\n     * tensor with the provided shape, dtype and values. It always\n     * creates a new data id and writes the values to the underlying backend.\n     */\n    makeTensor(values, shape, dtype, backend) {\n        if (values == null) {\n            throw new Error('Values passed to engine.makeTensor() are null');\n        }\n        dtype = dtype || 'float32';\n        backend = backend || this.backend;\n        let backendVals = values;\n        if (dtype === 'string' && util.isString(values[0])) {\n            backendVals = values.map(d => util.encodeString(d));\n        }\n        const dataId = backend.write(backendVals, shape, dtype);\n        const t = new Tensor(shape, dtype, dataId, this.nextTensorId());\n        this.incRef(t, backend);\n        // Count bytes for string tensors.\n        if (dtype === 'string') {\n            const info = this.state.tensorInfo.get(dataId);\n            const newBytes = bytesFromStringArray(backendVals);\n            this.state.numBytes += newBytes - info.bytes;\n            info.bytes = newBytes;\n        }\n        return t;\n    }\n    /**\n     * Internal method used by backends. Makes a new tensor\n     * that is a wrapper around an existing data id. It doesn't create\n     * a new data id, only increments the ref count used in memory tracking.\n     */\n    makeTensorFromDataId(dataId, shape, dtype, backend) {\n        dtype = dtype || 'float32';\n        const t = new Tensor(shape, dtype, dataId, this.nextTensorId());\n        this.incRef(t, backend);\n        return t;\n    }\n    makeVariable(initialValue, trainable = true, name, dtype) {\n        name = name || this.nextVariableId().toString();\n        if (dtype != null && dtype !== initialValue.dtype) {\n            initialValue = initialValue.cast(dtype);\n        }\n        const v = new Variable(initialValue, trainable, name, this.nextTensorId());\n        if (this.state.registeredVariables[v.name] != null) {\n            throw new Error(`Variable with name ${v.name} was already registered`);\n        }\n        this.state.registeredVariables[v.name] = v;\n        this.incRef(v, this.backend);\n        return v;\n    }\n    incRef(a, backend) {\n        const refCount = this.state.tensorInfo.has(a.dataId) ?\n            this.state.tensorInfo.get(a.dataId).refCount :\n            0;\n        this.state.numTensors++;\n        if (a.dtype === 'string') {\n            this.state.numStringTensors++;\n        }\n        if (refCount === 0) {\n            this.state.numDataBuffers++;\n            // Bytes for complex numbers are counted by their components. Bytes for\n            // string tensors are counted when writing values.\n            let bytes = 0;\n            if (a.dtype !== 'complex64' && a.dtype !== 'string') {\n                bytes = a.size * util.bytesPerElement(a.dtype);\n            }\n            this.state.tensorInfo.set(a.dataId, {\n                backend: backend || this.backend,\n                dtype: a.dtype,\n                shape: a.shape,\n                bytes,\n                refCount: 0\n            });\n            this.state.numBytes += bytes;\n        }\n        this.state.tensorInfo.get(a.dataId).refCount++;\n        if (!(a instanceof Variable)) {\n            this.track(a);\n        }\n    }\n    disposeTensor(a) {\n        if (!this.state.tensorInfo.has(a.dataId)) {\n            return;\n        }\n        this.state.numTensors--;\n        if (a.dtype === 'string') {\n            this.state.numStringTensors--;\n        }\n        const info = this.state.tensorInfo.get(a.dataId);\n        const refCount = info.refCount;\n        if (refCount <= 1) {\n            // Don't count bytes for complex numbers as they are counted by their\n            // components.\n            if (a.dtype !== 'complex64') {\n                this.state.numBytes -= info.bytes;\n            }\n            this.state.numDataBuffers--;\n            info.backend.disposeData(a.dataId);\n            this.state.tensorInfo.delete(a.dataId);\n        }\n        else {\n            this.state.tensorInfo.get(a.dataId).refCount--;\n        }\n        // TODO(nsthorat): Construct an error and save the stack trace for\n        // debugging when in debug mode. Creating a stack trace is too expensive\n        // to do unconditionally.\n    }\n    disposeVariables() {\n        for (const varName in this.state.registeredVariables) {\n            const v = this.state.registeredVariables[varName];\n            this.disposeVariable(v);\n        }\n    }\n    disposeVariable(v) {\n        this.disposeTensor(v);\n        if (this.state.registeredVariables[v.name] != null) {\n            delete this.state.registeredVariables[v.name];\n        }\n    }\n    memory() {\n        const info = this.backend.memory();\n        info.numTensors = this.state.numTensors;\n        info.numDataBuffers = this.state.numDataBuffers;\n        info.numBytes = this.state.numBytes;\n        if (this.state.numStringTensors > 0) {\n            info.unreliable = true;\n            if (info.reasons == null) {\n                info.reasons = [];\n            }\n            info.reasons.push('Memory usage by string tensors is approximate ' +\n                '(2 bytes per character)');\n        }\n        return info;\n    }\n    async profile(query) {\n        this.state.profiling = true;\n        const startBytes = this.state.numBytes;\n        const startNumTensors = this.state.numTensors;\n        this.state.activeProfile.kernels = [];\n        this.state.activeProfile.result = await query();\n        this.state.profiling = false;\n        this.state.activeProfile.peakBytes = Math.max(...this.state.activeProfile.kernels.map(d => d.totalBytesSnapshot));\n        this.state.activeProfile.newBytes = this.state.numBytes - startBytes;\n        this.state.activeProfile.newTensors =\n            this.state.numTensors - startNumTensors;\n        for (const kernel of this.state.activeProfile.kernels) {\n            kernel.kernelTimeMs = await kernel.kernelTimeMs;\n            kernel.extraInfo = await kernel.extraInfo;\n        }\n        return this.state.activeProfile;\n    }\n    isTapeOn() {\n        return this.state.gradientDepth > 0 && this.state.kernelDepth === 0;\n    }\n    addTapeNode(kernelName, inputs, outputs, gradientsFunc, saved, attrs) {\n        const tapeNode = { id: this.state.nextTapeNodeId++, kernelName, inputs, outputs, saved };\n        const gradConfig = getGradient(kernelName);\n        if (gradConfig != null) {\n            gradientsFunc = gradConfig.gradFunc;\n        }\n        if (gradientsFunc != null) {\n            tapeNode.gradient = (dys) => {\n                // TODO(smilkov): To optimize back-prop, pass dys that are not used in\n                // the backprop graph to the user as null instead of zeros\n                dys = dys.map((dy, i) => {\n                    if (dy == null) {\n                        const output = outputs[i];\n                        const vals = util.makeZerosTypedArray(output.size, output.dtype);\n                        return this.makeTensor(vals, output.shape, output.dtype);\n                    }\n                    return dy;\n                });\n                // Grad functions of ops with single outputs expect a dy, while ops\n                // with multiple outputs expect dys (array of dy).\n                return gradientsFunc(dys.length > 1 ? dys : dys[0], saved, attrs);\n            };\n        }\n        this.state.activeTape.push(tapeNode);\n    }\n    keep(result) {\n        result.kept = true;\n        return result;\n    }\n    startTape() {\n        if (this.state.gradientDepth === 0) {\n            this.state.activeTape = [];\n        }\n        this.state.gradientDepth++;\n    }\n    endTape() {\n        this.state.gradientDepth--;\n    }\n    /**\n     * Start a scope. Use this with endScope() to achieve the same functionality\n     * as scope() without the need for a function closure.\n     */\n    startScope(name) {\n        const scopeInfo = {\n            track: [],\n            name: 'unnamed scope',\n            id: this.state.nextScopeId++\n        };\n        if (name) {\n            scopeInfo.name = name;\n        }\n        this.state.scopeStack.push(scopeInfo);\n        this.state.activeScope = scopeInfo;\n    }\n    /**\n     * End a scope. Use this with startScope() to achieve the same functionality\n     * as scope() without the need for a function closure.\n     */\n    endScope(result) {\n        const tensorsToTrackInParent = getTensorsInContainer(result);\n        const tensorsToTrackInParentSet = new Set(tensorsToTrackInParent.map(t => t.id));\n        // Dispose the arrays tracked in this scope.\n        for (let i = 0; i < this.state.activeScope.track.length; i++) {\n            const tensor = this.state.activeScope.track[i];\n            if (!tensor.kept && !tensorsToTrackInParentSet.has(tensor.id)) {\n                tensor.dispose();\n            }\n        }\n        const oldScope = this.state.scopeStack.pop();\n        this.state.activeScope = this.state.scopeStack.length === 0 ?\n            null :\n            this.state.scopeStack[this.state.scopeStack.length - 1];\n        // Track the current result in the parent scope.\n        tensorsToTrackInParent.forEach(tensor => {\n            // Only track the tensor if was allocated in the inner scope and is not\n            // globally kept.\n            if (!tensor.kept && tensor.scopeId === oldScope.id) {\n                this.track(tensor);\n            }\n        });\n    }\n    /**\n     * Returns gradients of `f` with respect to each of the `xs`. The gradients\n     * returned are of the same length as `xs`, but some might be null if `f`\n     * was not a function of that `x`. It also takes optional dy to multiply the\n     * gradient, which defaults to `1`.\n     */\n    gradients(f, xs, dy, allowNoGradients = false) {\n        util.assert(xs.length > 0, () => 'gradients() received an empty list of xs.');\n        if (dy != null && dy.dtype !== 'float32') {\n            throw new Error(`dy must have 'float32' dtype, but has '${dy.dtype}'`);\n        }\n        const y = this.scopedRun(() => this.startTape(), () => this.endTape(), () => this.tidy('forward', f));\n        util.assert(y instanceof Tensor, () => 'The result y returned by f() must be a tensor.');\n        // Filter out the nodes that don't connect x => y.\n        const filteredTape = getFilteredNodesXToY(this.state.activeTape, xs, y);\n        if (!allowNoGradients && filteredTape.length === 0 && xs.length > 0) {\n            throw new Error('Cannot compute gradient of y=f(x) with respect to x. Make sure ' +\n                'that the f you passed encloses all operations that lead from x ' +\n                'to y.');\n        }\n        return this.tidy('backward', () => {\n            const accumulatedGradientMap = {};\n            accumulatedGradientMap[y.id] = (dy == null) ? ones(y.shape) : dy;\n            // Backprop gradients through the filtered nodes.\n            backpropagateGradients(accumulatedGradientMap, filteredTape, \n            // Pass the tidy function to avoid circular dep with `tape.ts`.\n            f => this.tidy(f), \n            // Pass an add function to avoide a circular dep with `tape.ts`.\n            add);\n            const grads = xs.map(x => accumulatedGradientMap[x.id]);\n            if (this.state.gradientDepth === 0) {\n                // This means that we are not computing higher-order gradients\n                // and can clean up the tape.\n                this.state.activeTape.forEach(node => {\n                    for (const tensor of node.saved) {\n                        tensor.dispose();\n                    }\n                });\n                this.state.activeTape = null;\n            }\n            return { value: y, grads };\n        });\n    }\n    customGrad(f) {\n        util.assert(util.isFunction(f), () => 'The f passed in customGrad(f) must be a function.');\n        return (...inputs) => {\n            util.assert(inputs.every(t => t instanceof Tensor), () => 'The args passed in customGrad(f)(x1, x2,...) must all be ' +\n                'tensors');\n            let res;\n            const inputMap = {};\n            inputs.forEach((input, i) => {\n                inputMap[i] = input;\n            });\n            return this.runKernelFunc((_, save) => {\n                res = f(...[...inputs, save]);\n                util.assert(res.value instanceof Tensor, () => 'The function f passed in customGrad(f) must return an ' +\n                    'object where `obj.value` is a tensor');\n                util.assert(util.isFunction(res.gradFunc), () => 'The function f passed in customGrad(f) must return an ' +\n                    'object where `obj.gradFunc` is a function.');\n                return res.value;\n            }, inputMap, (dy, saved) => {\n                const gradRes = res.gradFunc(dy, saved);\n                const grads = Array.isArray(gradRes) ? gradRes : [gradRes];\n                util.assert(grads.length === inputs.length, () => 'The function f passed in customGrad(f) must return an ' +\n                    'object where `obj.gradFunc` is a function that returns ' +\n                    'the same number of tensors as inputs passed to f(...).');\n                util.assert(grads.every(t => t instanceof Tensor), () => 'The function f passed in customGrad(f) must return an ' +\n                    'object where `obj.gradFunc` is a function that returns ' +\n                    'a list of only tensors.');\n                const gradMap = {};\n                grads.forEach((grad, i) => {\n                    gradMap[i] = () => grad;\n                });\n                return gradMap;\n            });\n        };\n    }\n    readSync(dataId) {\n        // Route the read to the correct backend.\n        const info = this.state.tensorInfo.get(dataId);\n        return info.backend.readSync(dataId);\n    }\n    read(dataId) {\n        // Route the read to the correct backend.\n        const info = this.state.tensorInfo.get(dataId);\n        return info.backend.read(dataId);\n    }\n    async time(query) {\n        const start = now();\n        const timingInfo = await this.backend.time(query);\n        timingInfo.wallMs = now() - start;\n        return timingInfo;\n    }\n    /**\n     * Tracks a Tensor in the current scope to be automatically cleaned up\n     * when the current scope ends, and returns the value.\n     *\n     * @param result The Tensor to track in the current scope.\n     */\n    track(result) {\n        if (this.state.activeScope != null) {\n            result.scopeId = this.state.activeScope.id;\n            this.state.activeScope.track.push(result);\n        }\n        return result;\n    }\n    get registeredVariables() {\n        return this.state.registeredVariables;\n    }\n    /**\n     * Resets the engine state. Removes all backends but does not remove\n     * registered backend factories.\n     */\n    reset() {\n        // Make any pending promise obsolete.\n        this.pendingBackendInitId++;\n        this.state.dispose();\n        this.ENV.reset();\n        this.state = new EngineState();\n        for (const backendName in this.registry) {\n            this.disposeRegisteredKernels(backendName);\n            this.registry[backendName].dispose();\n            delete this.registry[backendName];\n        }\n        this.backendName = null;\n        this.backendInstance = null;\n        this.pendingBackendInit = null;\n    }\n}\nEngine.nextTensorId = 0;\nEngine.nextVariableId = 0;\nfunction ones(shape) {\n    const values = makeOnesTypedArray(sizeFromShape(shape), 'float32');\n    return ENGINE.makeTensor(values, shape, 'float32');\n}\nexport function getOrMakeEngine() {\n    const ns = getGlobalNamespace();\n    if (ns._tfengine == null) {\n        const environment = new Environment(ns);\n        ns._tfengine = new Engine(environment);\n    }\n    setEnvironmentGlobal(ns._tfengine.ENV);\n    // Tell the current tensor interface that the global engine is responsible\n    // for tracking.\n    setTensorTracker(() => ns._tfengine);\n    return ns._tfengine;\n}\nexport const ENGINE = getOrMakeEngine();\n/**\n * A implementation of the add op for use within engine and tape.\n *\n * This allows us to avoid a circular dependency between add.ts and engine.\n * It is exported to be available in tape tests.\n */\nexport function add(a, b) {\n    // We duplicate Add here to avoid a circular dependency with add.ts.\n    const inputs = { a, b };\n    return ENGINE.runKernelFunc((backend, save) => {\n        const res = backend.add(a, b);\n        save([a, b]);\n        return res;\n    }, inputs, null /* gradient */, Add);\n}\n//# sourceMappingURL=engine.js.map","/**\n * @license\n * Copyright 2020 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n// Required side effectful code for tfjs-core\n// Set up Engine and ENV\nimport { getOrMakeEngine } from './engine';\ngetOrMakeEngine();\n// Register backend-agnostic flags.\nimport './flags';\n// Register platforms\nimport './platforms/platform_browser';\nimport './platforms/platform_node';\n// Set up OpHandler\nimport { buffer } from './ops/buffer';\nimport { cast } from './ops/cast';\nimport { clone } from './ops/clone';\nimport { print } from './ops/print';\nimport { setOpHandler } from './tensor';\nconst opHandler = {\n    buffer,\n    cast,\n    clone,\n    print\n};\nsetOpHandler(opHandler);\n//# sourceMappingURL=base_side_effects.js.map"],"sourceRoot":""}