{"version":3,"sources":["webpack:///./node_modules/@tensorflow/tfjs-core/dist/kernel_names.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/io/types.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/io/indexed_db.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/io/local_storage.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/io/browser_files.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/io/progress.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/io/weights_loader.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/io/http.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/io/passthrough.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/io/io_utils.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/io/router_registry.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/kernel_registry.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/io/model_management.js"],"names":["Abs","Acos","Acosh","Add","AddN","All","Any","ArgMax","ArgMin","Asin","Asinh","Atan","Atanh","Atan2","AvgPool","AvgPoolGrad","AvgPool3D","AvgPool3DGrad","BatchMatMul","BatchToSpaceND","Bincount","BroadcastTo","Cast","Ceil","ClipByValue","Complex","ComplexAbs","Concat","Conv2D","Conv2DBackpropFilter","Conv2DBackpropInput","Conv3D","Conv3DBackpropFilterV2","Conv3DBackpropInputV2","Cos","Cosh","Cumsum","CropAndResize","DenseBincount","DepthToSpace","DepthwiseConv2dNative","DepthwiseConv2dNativeBackpropFilter","DepthwiseConv2dNativeBackpropInput","Dilation2D","Dilation2DBackpropInput","Dilation2DBackpropFilter","RealDiv","Elu","EluGrad","Erf","Equal","Exp","ExpandDims","Expm1","FFT","Fill","FlipLeftRight","Floor","FloorDiv","FusedBatchNorm","GatherV2","GatherNd","Greater","GreaterEqual","Identity","IFFT","Imag","IsFinite","IsInf","IsNan","LeakyRelu","Less","LessEqual","LinSpace","Log","Log1p","LogicalAnd","LogicalNot","LogicalOr","LogSoftmax","LRN","LRNGrad","Max","Maximum","MaxPool","MaxPoolGrad","MaxPool3D","MaxPool3DGrad","MaxPoolWithArgmax","Mean","Min","Minimum","MirrorPad","Mod","Multinomial","Multiply","Neg","NotEqual","NonMaxSuppressionV3","NonMaxSuppressionV4","NonMaxSuppressionV5","OnesLike","OneHot","Pack","PadV2","Pow","Prelu","Prod","Range","Real","Reciprocal","Relu","Reshape","ResizeNearestNeighbor","ResizeNearestNeighborGrad","ResizeBilinear","ResizeBilinearGrad","Relu6","Reverse","Round","Rsqrt","ScatterNd","Select","Selu","Slice","Sin","Sinh","Sign","Sigmoid","Softplus","Sqrt","Sum","SpaceToBatchND","SplitV","Softmax","SquaredDifference","Square","Sub","SparseToDense","StridedSlice","Tan","Tanh","Tile","TopK","Transpose","Unique","Unpack","UnsortedSegmentSum","ZerosLike","Step","FromPixels","RotateWithOffset","_FusedMatMul","FusedConv2D","FusedDepthwiseConv2D","DTYPE_VALUE_SIZE_MAP","DATABASE_NAME","MODEL_STORE_NAME","INFO_STORE_NAME","getIndexedDBFactory","getBool","Error","theWindow","window","self","factory","indexedDB","mozIndexedDB","webkitIndexedDB","msIndexedDB","shimIndexedDB","setUpDatabase","openRequest","db","result","createObjectStore","keyPath","BrowserIndexedDB","modelPath","this","modelArtifacts","modelTopology","ArrayBuffer","databaseAction","Promise","resolve","reject","open","onupgradeneeded","onsuccess","modelTx","transaction","getRequest","objectStore","get","close","onerror","error","oncomplete","modelArtifactsInfo","infoTx","infoStore","putInfoRequest","put","putModelRequest","deleteInfoRequest","delete","URL_SCHEME","indexedDBRouter","url","Array","isArray","startsWith","slice","length","registerSaveRouter","registerLoadRouter","BrowserIndexedDBManager","tx","getAllInfoRequest","getAll","out","item","path","key","getInfoRequest","deleteModelData","deleteModelRequest","PATH_SEPARATOR","PATH_PREFIX","INFO_SUFFIX","MODEL_TOPOLOGY_SUFFIX","WEIGHT_SPECS_SUFFIX","WEIGHT_DATA_SUFFIX","MODEL_METADATA_SUFFIX","getModelKeys","info","join","topology","weightSpecs","weightData","modelMetadata","getModelPathFromKey","items","split","BrowserLocalStorage","localStorage","LS","keys","JSON","stringify","setItem","format","generatedBy","convertedBy","signature","userDefinedMetadata","modelInitializer","err","removeItem","modelTopologyBytes","weightSpecsBytes","weightDataBytes","parse","getItem","modelTopologyType","metadataString","metadata","weightDataBase64","localStorageRouter","BrowserLocalStorageManager","prefix","suffix","i","endsWith","defer","f","setTimeout","then","fileNamePrefix","modelTopologyFileName","weightDataFileName","weightsURL","URL","createObjectURL","Blob","type","weightsManifest","paths","weights","modelTopologyAndWeightManifest","modelTopologyAndWeightManifestURL","jsonAnchor","document","createElement","download","href","dispatchEvent","MouseEvent","weightDataAnchor","files","jsonFile","weightFiles","jsonReader","FileReader","onload","event","modelJSON","target","name","pathToFile","checkManifestAndWeightFiles","perFileBuffers","forEach","weightsGroup","push","weightFileReader","index","indexOf","readAsArrayBuffer","readAsText","manifest","basenames","fileNames","map","file","group","pathBasename","browserFiles","browserDownloads","monitorPromisesProgress","promises","onProgress","startFraction","endFraction","checkPromises","checkFraction","resolvedPromise","all","promise","value","fraction","async","loadWeightsAsArrayBuffer","fetchURLs","loadOptions","fetchFunc","platform","fetch","requests","fetchURL","requestInit","isBinary","bufferPromises","response","arrayBuffer","loadWeights","filePathPrefix","weightNames","weightsLoaderFactory","fetchUrls","fetchWeightsFunction","groupIndicesToFetchMap","groupWeightsToFetch","weightsFound","allManifestWeightNames","manifestGroupConfig","groupIndex","groupOffset","weightsEntry","rawDtype","quantization","dtype","weightsBytes","shape","enqueueWeightsForFetchingFn","manifestEntry","sizeBytes","weightName","weightIndex","every","found","weightsNotFound","filter","_","groupIndicesToFetch","reduce","accumulator","shouldFetch","filepath","fetchUrl","buffers","weightsTensorMap","bufferIndexOffset","numBuffers","groupBytes","byteLength","groupBuffer","groupByteBuffer","Uint8Array","groupBufferOffset","buffer","set","byteBuffer","nameToTensorMap","DEFAULT_METHOD","weightPathPrefix","weightUrlConverter","body","init","Object","assign","method","FormData","append","ok","responses","status","modelConfigRequest","modelConfig","json","e","message","results","artifacts","initializer","weightPath","lastSlash","lastIndexOf","lastSearchParam","substring","parseUrl","pathPrefix","entry","urlPromises","isHTTPScheme","match","URL_SCHEME_REGEX","httpRouter","isHTTP","urlItem","http","browserHTTPRequest","PassthroughLoader","PassthroughSaver","saveHandler","fromMemory","trainingConfig","arguments","console","warn","withSaveHandler","encodeWeights","tensors","specs","dataPromises","names","tensor","t","spec","utf8bytes","vals","bytes","totalNumBytes","p","c","offset","val","bytesOfLength","Uint32Array","data","concatenateTypedArrays","decodeWeights","float16Decode","size","values","quantizationSizeFactor","quantizedArray","Uint16Array","Float32Array","v","scale","min","undefined","getFloat16Decoder","Int32Array","Math","round","dtypeFactor","real","image","realTensor","imageTensor","dispose","xs","totalByteLength","normalizedXs","x","constructor","y","useNodeBuffer","Buffer","atob","btoa","stringByteLength","str","arrayBufferToBase64String","from","toString","buf","s","l","String","fromCharCode","base64StringToArrayBuffer","byteOffset","charCodeAt","concatenateArrayBuffers","temp","basename","trim","getModelArtifactsInfoForJSON","dateSaved","Date","mantisaTable","convertMantissa","m","computeFloat16MantisaTable","exponentTable","computeFloat16ExponentTable","offsetTable","computeFloat16OffsetTable","bufferUint32View","float16Bits","float32Bits","IORouterRegistry","saveRouters","loadRouters","instance","saveRouter","getInstance","loadRouter","getHandlers","handlerType","validHandlers","router","handler","loudRouter","getSaveHandlers","getLoadHandlers","kernelRegistry","Map","gradRegistry","getKernel","kernelName","backendName","makeKey","getGradient","getKernelsForBackend","it","entries","done","next","config","backend","registerKernel","has","registerGradient","URL_SCHEME_SUFFIX","ModelStoreManagerRegistry","managers","scheme","manager","registry","parseURL","getSchemes","cloneModelInternal","sourceURL","destURL","deleteSource","loadHandlers","loadHandler","saveHandlers","sourceScheme","sourcePath","sameMedium","load","getManager","removeModel","saveResult","save","listModels","schemes","schemeOut","schemeAndPath","copyModel","moveModel"],"mappings":";oJAAA,q2KAAO,MAAMA,EAAM,MACNC,EAAO,OACPC,EAAQ,QACRC,EAAM,MACNC,EAAO,OACPC,EAAM,MACNC,EAAM,MACNC,EAAS,SACTC,EAAS,SACTC,EAAO,OACPC,EAAQ,QACRC,EAAO,OACPC,EAAQ,QACRC,EAAQ,QACRC,EAAU,UACVC,EAAc,cACdC,EAAY,YACZC,EAAgB,gBAChBC,EAAc,cACdC,EAAiB,iBACjBC,EAAW,WACXC,EAAc,cACdC,EAAO,OACPC,EAAO,OACPC,EAAc,cACdC,EAAU,UACVC,EAAa,aACbC,EAAS,SACTC,EAAS,SACTC,EAAuB,uBACvBC,EAAsB,sBACtBC,EAAS,SACTC,EAAyB,yBACzBC,EAAwB,wBACxBC,EAAM,MACNC,EAAO,OACPC,EAAS,SACTC,EAAgB,gBAChBC,EAAgB,gBAChBC,EAAe,eACfC,EAAwB,wBACxBC,EAAsC,sCACtCC,EAAqC,qCAErCC,EAAa,aACbC,EAA0B,0BAC1BC,EAA2B,2BAC3BC,EAAU,UACVC,EAAM,MACNC,EAAU,UACVC,EAAM,MACNC,EAAQ,QACRC,GAAM,MACNC,GAAa,aACbC,GAAQ,QACRC,GAAM,MACNC,GAAO,OACPC,GAAgB,gBAChBC,GAAQ,QACRC,GAAW,WACXC,GAAiB,iBACjBC,GAAW,WACXC,GAAW,WACXC,GAAU,UACVC,GAAe,eACfC,GAAW,WACXC,GAAO,OACPC,GAAO,OACPC,GAAW,WACXC,GAAQ,QACRC,GAAQ,QACRC,GAAY,YACZC,GAAO,OACPC,GAAY,YACZC,GAAW,WACXC,GAAM,MACNC,GAAQ,QACRC,GAAa,aACbC,GAAa,aACbC,GAAY,YACZC,GAAa,aACbC,GAAM,MACNC,GAAU,UACVC,GAAM,MACNC,GAAU,UACVC,GAAU,UACVC,GAAc,cACdC,GAAY,YACZC,GAAgB,gBAChBC,GAAoB,oBACpBC,GAAO,OACPC,GAAM,MACNC,GAAU,UACVC,GAAY,YACZC,GAAM,MACNC,GAAc,cACdC,GAAW,WACXC,GAAM,MACNC,GAAW,WACXC,GAAsB,sBACtBC,GAAsB,sBACtBC,GAAsB,sBACtBC,GAAW,WACXC,GAAS,SACTC,GAAO,OACPC,GAAQ,QAERC,GAAM,MACNC,GAAQ,QACRC,GAAO,OACPC,GAAQ,QACRC,GAAO,OACPC,GAAa,aACbC,GAAO,OACPC,GAAU,UACVC,GAAwB,wBACxBC,GAA4B,4BAC5BC,GAAiB,iBACjBC,GAAqB,qBACrBC,GAAQ,QACRC,GAAU,UACVC,GAAQ,QACRC,GAAQ,QACRC,GAAY,YACZC,GAAS,SACTC,GAAO,OACPC,GAAQ,QACRC,GAAM,MACNC,GAAO,OACPC,GAAO,OACPC,GAAU,UACVC,GAAW,WACXC,GAAO,OACPC,GAAM,MACNC,GAAiB,iBACjBC,GAAS,SACTC,GAAU,UACVC,GAAoB,oBACpBC,GAAS,SACTC,GAAM,MACNC,GAAgB,gBAChBC,GAAe,eACfC,GAAM,MACNC,GAAO,OACPC,GAAO,OACPC,GAAO,OACPC,GAAY,YACZC,GAAS,SACTC,GAAS,SACTC,GAAqB,qBACrBC,GAAY,YAIZC,GAAO,OACPC,GAAa,aACbC,GAAmB,mBACnBC,GAAe,eACfC,GAAc,cACdC,GAAuB,wB,iCC/JpC,kCAoBO,MAAMC,EAAuB,CAChC,QAAW,EACX,QAAW,EACX,MAAS,EACT,OAAU,EACV,MAAS,EACT,KAAQ,EACR,UAAa,I,iCC3BjB,uGAoBA,MAAMC,EAAgB,eAKhBC,EAAmB,eAInBC,EAAkB,mBAYxB,SAASC,IACL,IAAK,cAAMC,QAAQ,cAIf,MAAM,IAAIC,MAAM,2FAIpB,MAAMC,EAA8B,oBAAXC,OAAyBC,KAAOD,OACnDE,EAAUH,EAAUI,WAAaJ,EAAUK,cAC7CL,EAAUM,iBAAmBN,EAAUO,aACvCP,EAAUQ,cACd,GAAe,MAAXL,EACA,MAAM,IAAIJ,MAAM,6DAEpB,OAAOI,EAEX,SAASM,EAAcC,GACnB,MAAMC,EAAKD,EAAYE,OACvBD,EAAGE,kBAAkBlB,EAAkB,CAAEmB,QAAS,cAClDH,EAAGE,kBAAkBjB,EAAiB,CAAEkB,QAAS,cAO9C,MAAMC,EACT,YAAYC,GAER,GADAC,KAAKb,UAAYP,IACA,MAAbmB,IAAsBA,EACtB,MAAM,IAAIjB,MAAM,kEAEpBkB,KAAKD,UAAYA,EAErB,WAAWE,GAEP,GAAIA,EAAeC,yBAAyBC,YACxC,MAAM,IAAIrB,MAAM,4FAGpB,OAAOkB,KAAKI,eAAeJ,KAAKD,UAAWE,GAE/C,aACI,OAAOD,KAAKI,eAAeJ,KAAKD,WAgBpC,eAAeA,EAAWE,GACtB,OAAO,IAAII,SAAQ,CAACC,EAASC,KACzB,MAAMd,EAAcO,KAAKb,UAAUqB,KAAK/B,EAnF3B,GAoFbgB,EAAYgB,gBAAkB,IAAMjB,EAAcC,GAClDA,EAAYiB,UAAY,KACpB,MAAMhB,EAAKD,EAAYE,OACvB,GAAsB,MAAlBM,EAAwB,CAExB,MAAMU,EAAUjB,EAAGkB,YAAYlC,EAAkB,YAE3CmC,EADaF,EAAQG,YAAYpC,GACTqC,IAAIf,KAAKD,WACvCc,EAAWH,UAAY,KACnB,GAAyB,MAArBG,EAAWlB,OAEX,OADAD,EAAGsB,QACIT,EAAO,IAAIzB,MAAM,gCAAgCkB,KAAKD,6BAI7DO,EAAQO,EAAWlB,OAAOM,iBAGlCY,EAAWI,QAAUC,IACjBxB,EAAGsB,QACIT,EAAOM,EAAWK,QAE7BP,EAAQQ,WAAa,IAAMzB,EAAGsB,YAE7B,CAED,MAAMI,EAAqB,YAA6BnB,GAElDoB,EAAS3B,EAAGkB,YAAYjC,EAAiB,aAC/C,IAAI2C,EAAYD,EAAOP,YAAYnC,GACnC,MAAM4C,EAAiBD,EAAUE,IAAI,CAAEzB,UAAWC,KAAKD,UAAWqB,uBAClE,IAAIT,EACJY,EAAeb,UAAY,KAEvBC,EAAUjB,EAAGkB,YAAYlC,EAAkB,aAC3C,MACM+C,EADad,EAAQG,YAAYpC,GACJ8C,IAAI,CACnCzB,UAAWC,KAAKD,UAChBE,iBACAmB,uBAEJK,EAAgBf,UAAY,IAAMJ,EAAQ,CAAEc,uBAC5CK,EAAgBR,QAAUC,IAGtBI,EAAYD,EAAOP,YAAYnC,GAC/B,MAAM+C,EAAoBJ,EAAUK,OAAO3B,KAAKD,WAChD2B,EAAkBhB,UAAY,KAC1BhB,EAAGsB,QACIT,EAAOkB,EAAgBP,QAElCQ,EAAkBT,QAAUC,IACxBxB,EAAGsB,QACIT,EAAOkB,EAAgBP,UAI1CK,EAAeN,QAAUC,IACrBxB,EAAGsB,QACIT,EAAOgB,EAAeL,QAEjCG,EAAOF,WAAa,KACD,MAAXR,EACAjB,EAAGsB,QAGHL,EAAQQ,WAAa,IAAMzB,EAAGsB,WAK9CvB,EAAYwB,QAAUC,GAASX,EAAOd,EAAYyB,WAI9DpB,EAAiB8B,WAAa,eACvB,MAAMC,EAAmBC,IAC5B,OAAK,cAAMjD,QAAQ,gBAIVkD,MAAMC,QAAQF,IAAQA,EAAIG,WAAWnC,EAAiB8B,aA2BlC7B,EA1BG+B,EAAII,MAAMpC,EAAiB8B,WAAWO,QA2B/D,IAAIrC,EAAiBC,IA/BjB,KA8BR,IAA0BA,GAnBjC,IAAiBqC,mBAAmBP,GACpC,IAAiBQ,mBAAmBR,GA0B7B,MAAMS,EACT,cACItC,KAAKb,UAAYP,IAErB,mBACI,OAAO,IAAIyB,SAAQ,CAACC,EAASC,KACzB,MAAMd,EAAcO,KAAKb,UAAUqB,KAAK/B,EA9M3B,GA+MbgB,EAAYgB,gBAAkB,IAAMjB,EAAcC,GAClDA,EAAYiB,UAAY,KACpB,MAAMhB,EAAKD,EAAYE,OACjB4C,EAAK7C,EAAGkB,YAAYjC,EAAiB,YAUrC6D,EATQD,EAAGzB,YAAYnC,GASG8D,SAChCD,EAAkB9B,UAAY,KAC1B,MAAMgC,EAAM,GACZ,IAAK,MAAMC,KAAQH,EAAkB7C,OACjC+C,EAAIC,EAAK5C,WAAa4C,EAAKvB,mBAE/Bd,EAAQoC,IAEZF,EAAkBvB,QAAUC,IACxBxB,EAAGsB,QACIT,EAAOiC,EAAkBtB,QAEpCqB,EAAGpB,WAAa,IAAMzB,EAAGsB,SAE7BvB,EAAYwB,QAAUC,GAASX,EAAOd,EAAYyB,UAG1D,kBAAkB0B,GA1CtB,IAA0BC,EA4ClB,OADAD,GA3CkBC,EA2CMD,GA1CjBX,WAAWnC,EAAiB8B,YACnCiB,EAAIX,MAAMpC,EAAiB8B,WAAWO,QACtCU,EAyCO,IAAIxC,SAAQ,CAACC,EAASC,KACzB,MAAMd,EAAcO,KAAKb,UAAUqB,KAAK/B,EAhP3B,GAiPbgB,EAAYgB,gBAAkB,IAAMjB,EAAcC,GAClDA,EAAYiB,UAAY,KACpB,MAAMhB,EAAKD,EAAYE,OACjB0B,EAAS3B,EAAGkB,YAAYjC,EAAiB,aACzC2C,EAAYD,EAAOP,YAAYnC,GAC/BmE,EAAiBxB,EAAUP,IAAI6B,GACrC,IAAIjC,EACJmC,EAAepC,UAAY,KACvB,GAA6B,MAAzBoC,EAAenD,OAEf,OADAD,EAAGsB,QACIT,EAAO,IAAIzB,MAAM,gCAAgC8D,qBAGvD,CAED,MAAMlB,EAAoBJ,EAAUK,OAAOiB,GACrCG,EAAkB,KAEpBpC,EAAUjB,EAAGkB,YAAYlC,EAAkB,aAC3C,MACMsE,EADarC,EAAQG,YAAYpC,GACDiD,OAAOiB,GAC7CI,EAAmBtC,UAAY,IAAMJ,EAAQwC,EAAenD,OAAOyB,oBACnE4B,EAAmB/B,QAAUC,GAASX,EAAOuC,EAAe5B,QAIhEQ,EAAkBhB,UAAYqC,EAC9BrB,EAAkBT,QAAUC,IACxB6B,IACArD,EAAGsB,QACIT,EAAOuC,EAAe5B,UAIzC4B,EAAe7B,QAAUC,IACrBxB,EAAGsB,QACIT,EAAOuC,EAAe5B,QAEjCG,EAAOF,WAAa,KACD,MAAXR,EACAjB,EAAGsB,QAGHL,EAAQQ,WAAa,IAAMzB,EAAGsB,UAI1CvB,EAAYwB,QAAUC,GAASX,EAAOd,EAAYyB,a,iCCrT9D,8GAqBA,MAAM+B,EAAiB,IACjBC,EAAc,sBACdC,EAAc,OACdC,EAAwB,iBACxBC,EAAsB,eACtBC,EAAqB,cACrBC,EAAwB,iBA2B9B,SAASC,EAAaZ,GAClB,MAAO,CACHa,KAAM,CAACP,EAAaN,EAAMO,GAAaO,KAAKT,GAC5CU,SAAU,CAACT,EAAaN,EAAMQ,GAAuBM,KAAKT,GAC1DW,YAAa,CAACV,EAAaN,EAAMS,GAAqBK,KAAKT,GAC3DY,WAAY,CAACX,EAAaN,EAAMU,GAAoBI,KAAKT,GACzDa,cAAe,CAACZ,EAAaN,EAAMW,GAAuBG,KAAKT,IAUvE,SAASc,EAAoBlB,GACzB,MAAMmB,EAAQnB,EAAIoB,MAAMhB,GACxB,GAAIe,EAAM7B,OAAS,EACf,MAAM,IAAIrD,MAAM,uBAAuB+D,KAE3C,OAAOmB,EAAM9B,MAAM,EAAG8B,EAAM7B,OAAS,GAAGuB,KAAKT,GAY1C,MAAMiB,EACT,YAAYnE,GACR,IAAK,cAAMlB,QAAQ,eAAmC,oBAAXG,aACR,IAAxBA,OAAOmF,aAKd,MAAM,IAAIrF,MAAM,2DAGpB,GADAkB,KAAKoE,GAAKpF,OAAOmF,aACA,MAAbpE,IAAsBA,EACtB,MAAM,IAAIjB,MAAM,sEAEpBkB,KAAKD,UAAYA,EACjBC,KAAKqE,KAAOb,EAAaxD,KAAKD,WAWlC,WAAWE,GACP,GAAIA,EAAeC,yBAAyBC,YACxC,MAAM,IAAIrB,MAAM,4FAGf,CACD,MAAM6E,EAAWW,KAAKC,UAAUtE,EAAeC,eACzC0D,EAAcU,KAAKC,UAAUtE,EAAe2D,aAC5CxC,EAAqB,YAA6BnB,GACxD,IACID,KAAKoE,GAAGI,QAAQxE,KAAKqE,KAAKZ,KAAMa,KAAKC,UAAUnD,IAC/CpB,KAAKoE,GAAGI,QAAQxE,KAAKqE,KAAKV,SAAUA,GACpC3D,KAAKoE,GAAGI,QAAQxE,KAAKqE,KAAKT,YAAaA,GACvC5D,KAAKoE,GAAGI,QAAQxE,KAAKqE,KAAKR,WAAY,YAA0B5D,EAAe4D,aAC/E,MAAMlE,EAAS,CACX8E,OAAQxE,EAAewE,OACvBC,YAAazE,EAAeyE,YAC5BC,YAAa1E,EAAe0E,aAYhC,OAVgC,MAA5B1E,EAAe2E,YACfjF,EAAOiF,UAAY3E,EAAe2E,WAEI,MAAtC3E,EAAe4E,sBACflF,EAAOkF,oBAAsB5E,EAAe4E,qBAET,MAAnC5E,EAAe6E,mBACfnF,EAAOmF,iBAAmB7E,EAAe6E,kBAE7C9E,KAAKoE,GAAGI,QAAQxE,KAAKqE,KAAKP,cAAeQ,KAAKC,UAAU5E,IACjD,CAAEyB,sBAEb,MAAO2D,GAOH,MALA/E,KAAKoE,GAAGY,WAAWhF,KAAKqE,KAAKZ,MAC7BzD,KAAKoE,GAAGY,WAAWhF,KAAKqE,KAAKV,UAC7B3D,KAAKoE,GAAGY,WAAWhF,KAAKqE,KAAKT,aAC7B5D,KAAKoE,GAAGY,WAAWhF,KAAKqE,KAAKR,YAC7B7D,KAAKoE,GAAGY,WAAWhF,KAAKqE,KAAKP,eACvB,IAAIhF,MAAM,yBAAyBkB,KAAKD,kHAEpBqB,EAAmB6D,wCACrB7D,EAAmB8D,qCACpB9D,EAAmB+D,sBAYtD,aACI,MAAM1B,EAAOa,KAAKc,MAAMpF,KAAKoE,GAAGiB,QAAQrF,KAAKqE,KAAKZ,OAClD,GAAY,MAARA,EACA,MAAM,IAAI3E,MAAM,kDAAkDkB,KAAKD,cAE3E,GAA+B,SAA3B0D,EAAK6B,kBACL,MAAM,IAAIxG,MAAM,6EAGpB,MAAM4D,EAAM,GAENiB,EAAWW,KAAKc,MAAMpF,KAAKoE,GAAGiB,QAAQrF,KAAKqE,KAAKV,WACtD,GAAgB,MAAZA,EACA,MAAM,IAAI7E,MAAM,4CAA4CkB,KAAKD,0BAGrE2C,EAAIxC,cAAgByD,EAEpB,MAAMC,EAAcU,KAAKc,MAAMpF,KAAKoE,GAAGiB,QAAQrF,KAAKqE,KAAKT,cACzD,GAAmB,MAAfA,EACA,MAAM,IAAI9E,MAAM,gDAAgDkB,KAAKD,2BAGzE2C,EAAIkB,YAAcA,EAElB,MAAM2B,EAAiBvF,KAAKoE,GAAGiB,QAAQrF,KAAKqE,KAAKP,eACjD,GAAsB,MAAlByB,EAAwB,CACxB,MAAMC,EAAWlB,KAAKc,MAAMG,GAC5B7C,EAAI+B,OAASe,EAAiB,OAC9B9C,EAAIgC,YAAcc,EAAsB,YACxC9C,EAAIiC,YAAca,EAAsB,YACX,MAAzBA,EAAoB,YACpB9C,EAAIkC,UAAYY,EAAoB,WAED,MAAnCA,EAA8B,sBAC9B9C,EAAImC,oBAAsBW,EAA8B,qBAExB,MAAhCA,EAA2B,mBAC3B9C,EAAIoC,iBAAmBU,EAA2B,kBAI1D,MAAMC,EAAmBzF,KAAKoE,GAAGiB,QAAQrF,KAAKqE,KAAKR,YACnD,GAAwB,MAApB4B,EACA,MAAM,IAAI3G,MACN,wDAAIkB,KAAKD,2BAGjB,OADA2C,EAAImB,WAAa,YAA0B4B,GACpC/C,GAGfwB,EAAoBtC,WAAa,kBAC1B,MAAM8D,EAAsB5D,IAC/B,OAAK,cAAMjD,QAAQ,gBAIVkD,MAAMC,QAAQF,IAAQA,EAAIG,WAAWiC,EAAoBtC,aAkClC7B,EAjCG+B,EAAII,MAAMgC,EAAoBtC,WAAWO,QAkCrE,IAAI+B,EAAoBnE,IAtCpB,KAqCR,IAA6BA,GA1BpC,IAAiBqC,mBAAmBsD,GACpC,IAAiBrD,mBAAmBqD,GA4B7B,MAAMC,EACT,cACI,YAAO,cAAM9G,QAAQ,eAAe,IAAM,6CAC1C,YAAyB,oBAAXG,aACqB,IAAxBA,OAAOmF,cAA8B,IAAM,4DACtDnE,KAAKoE,GAAKpF,OAAOmF,aAErB,mBACI,MAAMzB,EAAM,GACNkD,EAAS1C,EAAcD,EACvB4C,EAAS5C,EAAiBE,EAChC,IAAK,IAAI2C,EAAI,EAAGA,EAAI9F,KAAKoE,GAAGjC,SAAU2D,EAAG,CACrC,MAAMjD,EAAM7C,KAAKoE,GAAGvB,IAAIiD,GACxB,GAAIjD,EAAIZ,WAAW2D,IAAW/C,EAAIkD,SAASF,GAAS,CAEhDnD,EADkBqB,EAAoBlB,IACrByB,KAAKc,MAAMpF,KAAKoE,GAAGiB,QAAQxC,KAGpD,OAAOH,EAEX,kBAAkBE,GA5MtB,IAA0BC,EA8MlB,MAAMwB,EAAOb,EADbZ,GA7MkBC,EA6MMD,GA5MjBX,WAAWiC,EAAoBtC,YACtCiB,EAAIX,MAAMgC,EAAoBtC,WAAWO,QACzCU,GA4MA,GAAkC,MAA9B7C,KAAKoE,GAAGiB,QAAQhB,EAAKZ,MACrB,MAAM,IAAI3E,MAAM,8BAA8B8D,MAElD,MAAMa,EAAOa,KAAKc,MAAMpF,KAAKoE,GAAGiB,QAAQhB,EAAKZ,OAK7C,OAJAzD,KAAKoE,GAAGY,WAAWX,EAAKZ,MACxBzD,KAAKoE,GAAGY,WAAWX,EAAKV,UACxB3D,KAAKoE,GAAGY,WAAWX,EAAKT,aACxB5D,KAAKoE,GAAGY,WAAWX,EAAKR,YACjBJ,K,iiCCzQf,SAASuC,EAAMC,GACX,OAAO,IAAI5F,SAAQC,GAAW4F,WAAW5F,KAAU6F,KAAKF,GAErD,MAAM,EACT,YAAYG,GACR,IAAK,cAAMvH,QAAQ,cAGf,MAAM,IAAIC,MAAM,uFAGhBsH,EAAenE,WAAW,EAAiBL,cAC3CwE,EAAiBA,EAAelE,MAAM,EAAiBN,WAAWO,SAEhD,MAAlBiE,GAAoD,IAA1BA,EAAejE,SACzCiE,EAlBqB,SAoBzBpG,KAAKqG,sBAAwBD,EAnBD,QAoB5BpG,KAAKsG,mBACDF,EApB+B,eAsBvC,WAAWnG,GACP,GAA0B,oBAAf,SACP,MAAM,IAAInB,MAAM,2FAGpB,MAAMyH,EAAavH,OAAOwH,IAAIC,gBAAgB,IAAIC,KAAK,CAACzG,EAAe4D,YAAa,CAAE8C,KAAM,8BAC5F,GAAI1G,EAAeC,yBAAyBC,YACxC,MAAM,IAAIrB,MAAM,yFAGf,CACD,MAAM8H,EAAkB,CAAC,CACjBC,MAAO,CAAC,KAAO7G,KAAKsG,oBACpBQ,QAAS7G,EAAe2D,cAE1BmD,EAAiC,CACnC7G,cAAeD,EAAeC,cAC9BuE,OAAQxE,EAAewE,OACvBC,YAAazE,EAAeyE,YAC5BC,YAAa1E,EAAe0E,YAC5BiC,mBAE4B,MAA5B3G,EAAe2E,YACfmC,EAA+BnC,UAAY3E,EAAe2E,WAEpB,MAAtC3E,EAAe4E,sBACfkC,EAA+BlC,oBAC3B5E,EAAe4E,qBAEgB,MAAnC5E,EAAe6E,mBACfiC,EAA+BjC,iBAC3B7E,EAAe6E,kBAEvB,MAAMkC,EAAoChI,OAAOwH,IAAIC,gBAAgB,IAAIC,KAAK,CAACpC,KAAKC,UAAUwC,IAAkC,CAAEJ,KAAM,sBAGlIM,EAAgC,MAAnBjH,KAAKiH,WAAqBC,SAASC,cAAc,KAChEnH,KAAKiH,WAOT,GANAA,EAAWG,SAAWpH,KAAKqG,sBAC3BY,EAAWI,KAAOL,QAIZhB,GAAM,IAAMiB,EAAWK,cAAc,IAAIC,WAAW,YACzB,MAA7BtH,EAAe4D,WAAoB,CACnC,MAAM2D,EAA4C,MAAzBxH,KAAKwH,iBAC1BN,SAASC,cAAc,KACvBnH,KAAKwH,iBACTA,EAAiBJ,SAAWpH,KAAKsG,mBACjCkB,EAAiBH,KAAOd,QAClBP,GAAM,IAAMwB,EAAiBF,cAAc,IAAIC,WAAW,YAEpE,MAAO,CAAEnG,mBAAoB,YAA6BnB,MAItE,EAAiB2B,WAAa,eAC9B,MAAM,EACF,YAAY6F,GACR,GAAa,MAATA,GAAiBA,EAAMtF,OAAS,EAChC,MAAM,IAAIrD,MACN,wEAAgB2I,KAExBzH,KAAKyH,MAAQA,EAEjB,aACI,MAAMC,EAAW1H,KAAKyH,MAAM,GACtBE,EAAc3H,KAAKyH,MAAMvF,MAAM,GACrC,OAAO,IAAI7B,SAAQ,CAACC,EAASC,KACzB,MAAMqH,EAAa,IAAIC,WACvBD,EAAWE,OAAUC,IAEjB,MAAMC,EAAY1D,KAAKc,MAAM2C,EAAME,OAAOtI,QACpCO,EAAgB8H,EAAU9H,cAChC,GAAqB,MAAjBA,EAEA,YADAK,EAAO,IAAIzB,MAAM,4CAA4C4I,EAASQ,SAG/C,IAAvBP,EAAYxF,QACZ7B,EAAQ,CAAEJ,kBAEd,MAAM0G,EAAkBoB,EAAUpB,gBAClC,GAAuB,MAAnBA,EAEA,YADArG,EAAO,IAAIzB,MAAM,6CAA6C4I,EAASQ,SAG3E,IAAIC,EACJ,IACIA,EACInI,KAAKoI,4BAA4BxB,EAAiBe,GAE1D,MAAO5C,GAEH,YADAxE,EAAOwE,GAGX,MAAMnB,EAAc,GACdiD,EAAQ,GACRwB,EAAiB,GACvBzB,EAAgB0B,SAAQC,IACpBA,EAAa1B,MAAMyB,SAAQ1F,IACvBiE,EAAM2B,KAAK5F,GACXyF,EAAeG,KAAK,SAExB5E,EAAY4E,QAAQD,EAAazB,YAErCF,EAAgB0B,SAAQC,IACpBA,EAAa1B,MAAMyB,SAAQ1F,IACvB,MAAM6F,EAAmB,IAAIZ,WAC7BY,EAAiBX,OAAUC,IAEvB,MAAMlE,EAAakE,EAAME,OAAOtI,OAC1B+I,EAAQ7B,EAAM8B,QAAQ/F,GAE5B,GADAyF,EAAeK,GAAS7E,GACc,IAAlCwE,EAAeM,QAAQ,MAAc,CACrC,MAAMhJ,EAAS,CACXO,gBACA0D,cACAC,WAAY,YAAwBwE,GACpC5D,OAAQuD,EAAUvD,OAClBC,YAAasD,EAAUtD,YACvBC,YAAaqD,EAAUrD,aAEA,MAAvBqD,EAAUpD,YACVjF,EAAOiF,UAAYoD,EAAUpD,WAEI,MAAjCoD,EAAUnD,sBACVlF,EAAOkF,oBAAsBmD,EAAUnD,qBAET,MAA9BmD,EAAUlD,mBACVnF,EAAOmF,iBAAmBkD,EAAUlD,kBAExCxE,EAAQX,KAGhB8I,EAAiBxH,QAAUC,GAASX,EAAO,6CAA6CqC,OACxF6F,EAAiBG,kBAAkBT,EAAWvF,WAI1DgF,EAAW3G,QAAUC,GAASX,EAC1B,sEAAcmH,EAASQ,6EAE3BN,EAAWiB,WAAWnB,MAM9B,4BAA4BoB,EAAUrB,GAClC,MAAMsB,EAAY,GACZC,EAAYvB,EAAMwB,KAAIC,GAAQ,YAASA,EAAKhB,QAC5CC,EAAa,GACnB,IAAK,MAAMgB,KAASL,EAChBK,EAAMtC,MAAMyB,SAAQ1F,IAChB,MAAMwG,EAAe,YAASxG,GAC9B,IAAyC,IAArCmG,EAAUJ,QAAQS,GAClB,MAAM,IAAItK,MACN,uDAAIsK,MAGZ,GADAL,EAAUP,KAAKY,IAC0B,IAArCJ,EAAUL,QAAQS,GAClB,MAAM,IAAItK,MAAM,8BAA8BsK,uBAG9CjB,EAAWvF,GAAQ6E,EAAMuB,EAAUL,QAAQS,OAIvD,GAAIL,EAAU5G,SAAWsF,EAAMtF,OAC3B,MAAM,IAAIrD,MACN,wDAAIiK,EAAU5G,oDACVsF,EAAMtF,YAElB,OAAOgG,GAmGR,SAASkB,EAAa5B,GACzB,OAAO,IAAI,EAAaA,GApF5B,IAAiBrF,oBAbsBN,GAC9B,cAAMjD,QAAQ,gBAIVkD,MAAMC,QAAQF,IAAQA,EAAIG,WAAW,EAAiBL,YAgD5D,SAA0BwE,EAAiB,SAC9C,OAAO,IAAI,EAAiBA,GAhDbkD,CAAiBxH,EAAII,MAAM,EAAiBN,WAAWO,SAJ3D,O,WCzMR,SAASoH,EAAwBC,EAAUC,EAAYC,EAAeC,IAgBzE,SAAuBH,GACnB,YAAmB,MAAZA,GAAoBzH,MAAMC,QAAQwH,IAAaA,EAASrH,OAAS,GAAG,IAAM,wCAhBrFyH,CAAcJ,GAkBd,SAAuBE,EAAeC,GAClC,YAAOD,GAAiB,GAAKA,GAAiB,GAAG,IAC7C,oEAAqBA,MACzB,YAAOC,GAAe,GAAKA,GAAe,GAAG,IACzC,kEAAmBA,MACvB,YAAOA,GAAeD,GAAe,IACjC,yEAAqBA,qBAClBC,MAtBXE,CAFAH,EAAiC,MAAjBA,EAAwB,EAAIA,EAC5CC,EAA6B,MAAfA,EAAsB,EAAIA,GAExC,IAAIG,EAAkB,EAuBtB,OAAOzJ,QAAQ0J,IAAIP,EAASP,KAtBHe,IACrBA,EAAQ7D,MAAK8D,IACT,MAAMC,EAAWR,KACXI,EAAkBN,EAASrH,QAAUwH,EAAcD,GAGzD,OADAD,EAAWS,GACJD,KAEJD,M,aCPRG,eAAeC,EAAyBC,EAAWC,GACnC,MAAfA,IACAA,EAAc,IAElB,MAAMC,EAAqC,MAAzBD,EAAYC,UAAoB,cAAMC,SAASC,MAC7DH,EAAYC,UAEVG,EAAWL,EAAUpB,KAAI0B,GAAYJ,EAAUI,EAAUL,EAAYM,YAAa,CAAEC,UAAU,MAM9FC,GAHsC,MAA1BR,EAAYb,iBACpBpJ,QAAQ0J,IAAIW,SACZnB,EAAwBmB,EAAUJ,EAAYb,WAJ7B,EACF,KAIQR,KAAI8B,GAAYA,EAASC,gBAM1D,OAH0C,MAA1BV,EAAYb,iBAClBpJ,QAAQ0J,IAAIe,SACZvB,EAAwBuB,EAAgBR,EAAYb,WAJlC,GACF,GAevBU,eAAec,EAAYnC,EAAUoC,EAAiB,GAAIC,EAAaP,GAQ1E,OADoBQ,GADEC,GAAcjB,EAAyBiB,EAAW,CAAET,iBAEnEK,CAAYnC,EAAUoC,EAAgBC,GA0B1C,SAASC,EAAqBE,GACjC,OAAOnB,MAAOrB,EAAUoC,EAAiB,GAAIC,KAGzC,MAAMI,EAAyBzC,EAASG,KAAI,KAAM,IAC5CuC,EAAsB,GACtBC,EAA8B,MAAfN,EAAsBA,EAAYlC,KAAI,KAAM,IAAS,GACpEyC,EAAyB,GAmC/B,GAlCA5C,EAASR,SAAQ,CAACqD,EAAqBC,KACnC,IAAIC,EAAc,EAClBF,EAAoB7E,QAAQwB,SAAQwD,IAChC,MAAMC,EAAY,iBAAkBD,EAChCA,EAAaE,aAAaC,MAC1BH,EAAaG,MACXC,EAAe,IAAqBH,GACtC,IAAmBD,EAAaK,OAC9BC,EAA8B,KAChCb,EAAuBK,IAAc,EACE,MAAnCJ,EAAoBI,KACpBJ,EAAoBI,GAAc,IAEtCJ,EAAoBI,GAAYpD,KAAK,CACjC6D,cAAeP,EACfD,cACAS,UAAWJ,KAGA,MAAff,EACAA,EAAY7C,SAAQ,CAACiE,EAAYC,KACzBD,IAAeT,EAAa5D,OAC5BkE,IACAX,EAAae,IAAe,MAKpCJ,IAEJV,EAAuBlD,KAAKsD,EAAa5D,MACzC2D,GAAeK,SAGlBT,EAAagB,OAAMC,GAASA,IAAQ,CACrC,MAAMC,EAAkBxB,EAAYyB,QAAO,CAACC,EAAG/G,KAAO2F,EAAa3F,KACnE,MAAM,IAAIhH,MACN,kDAAG6N,EAAgBjJ,KAAK,kDAErBgI,EAAuBhI,KAAK,UAIvC,MAAMoJ,EAAsBvB,EAAuBwB,QAAO,CAACC,EAAaC,EAAanH,KAC7EmH,GACAD,EAAYxE,KAAK1C,GAEdkH,IACR,IACG3B,EAAY,GAClByB,EAAoBxE,SAAQxC,IACxBgD,EAAShD,GAAGe,MAAMyB,SAAQ4E,IACtB,MAAMC,EAAWjC,GACXA,EAAenF,SAAS,KAAa,GAAN,KAAYmH,EACjD7B,EAAU7C,KAAK2E,SAGvB,MAAMC,QAAgB9B,EAAqBD,GACrCgC,EAAmB,GACzB,IAAIC,EAAoB,EA0BxB,OAzBAR,EAAoBxE,SAAQxC,IACxB,MAAMyH,EAAazE,EAAShD,GAAGe,MAAM1E,OACrC,IAAIqL,EAAa,EACjB,IAAK,IAAI1H,EAAI,EAAGA,EAAIyH,EAAYzH,IAC5B0H,GAAcJ,EAAQE,EAAoBxH,GAAG2H,WAGjD,MAAMC,EAAc,IAAIvN,YAAYqN,GAC9BG,EAAkB,IAAIC,WAAWF,GACvC,IAAIG,EAAoB,EACxB,IAAK,IAAI/H,EAAI,EAAGA,EAAIyH,EAAYzH,IAAK,CACjC,MAAMgI,EAAS,IAAIF,WAAWR,EAAQE,EAAoBxH,IAC1D6H,EAAgBI,IAAID,EAAQD,GAC5BA,GAAqBC,EAAOL,WAETjC,EAAoB1F,GAC5BwC,SAAQwD,IACnB,MAAMkC,EAAaN,EAAYxL,MAAM4J,EAAaD,YAAaC,EAAaD,YAAcC,EAAaQ,WACjG2B,EAAkB,YAAcD,EAAY,CAAClC,EAAaO,gBAChE,IAAK,MAAMnE,KAAQ+F,EACfZ,EAAiBnF,GAAQ+F,EAAgB/F,MAGjDoF,GAAqBC,KAElBF,GCjKR,MAAM,EACT,YAAYzK,EAAM0H,GAwBd,GAvBAtK,KAAKkO,eAAiB,OACH,MAAf5D,IACAA,EAAc,IAElBtK,KAAKmO,iBAAmB7D,EAAY6D,iBACpCnO,KAAKyJ,WAAaa,EAAYb,WAC9BzJ,KAAKoO,mBAAqB9D,EAAY8D,mBACT,MAAzB9D,EAAYC,WACZ,YAAwC,mBAA1BD,EAAYC,WAA0B,IAAM,gIAG1DvK,KAAKyK,MAAQH,EAAYC,WAGzBvK,KAAKyK,MAAQ,cAAMD,SAASC,MAEhC,YAAe,MAAR7H,GAAgBA,EAAKT,OAAS,GAAG,IAAM,4DAE1CJ,MAAMC,QAAQY,IACd,YAAuB,IAAhBA,EAAKT,QAAc,IACtB,iEAAqBS,EAAKT,aAElCnC,KAAK4C,KAAOA,EACmB,MAA3B0H,EAAYM,aACoB,MAAhCN,EAAYM,YAAYyD,KACxB,MAAM,IAAIvP,MAAM,sEAEpBkB,KAAK4K,YAAcN,EAAYM,aAAe,GAElD,WAAW3K,GACP,GAAIA,EAAeC,yBAAyBC,YACxC,MAAM,IAAIrB,MAAM,2FAGpB,MAAMwP,EAAOC,OAAOC,OAAO,CAAEC,OAAQzO,KAAKkO,gBAAkBlO,KAAK4K,aACjE0D,EAAKD,KAAO,IAAIK,SAChB,MAAM9H,EAAkB,CAAC,CACjBC,MAAO,CAAC,uBACRC,QAAS7G,EAAe2D,cAE1BmD,EAAiC,CACnC7G,cAAeD,EAAeC,cAC9BuE,OAAQxE,EAAewE,OACvBC,YAAazE,EAAeyE,YAC5BC,YAAa1E,EAAe0E,YAC5BiC,mBAE4B,MAA5B3G,EAAe2E,YACfmC,EAA+BnC,UAAY3E,EAAe2E,WAEpB,MAAtC3E,EAAe4E,sBACfkC,EAA+BlC,oBAC3B5E,EAAe4E,qBAEgB,MAAnC5E,EAAe6E,mBACfiC,EAA+BjC,iBAC3B7E,EAAe6E,kBAEvBwJ,EAAKD,KAAKM,OAAO,aAAc,IAAIjI,KAAK,CAACpC,KAAKC,UAAUwC,IAAkC,CAAEJ,KA7DlF,qBA6DsG,cAC/E,MAA7B1G,EAAe4D,YACfyK,EAAKD,KAAKM,OAAO,oBAAqB,IAAIjI,KAAK,CAACzG,EAAe4D,YAAa,CAAE8C,KAhE3D,6BAgE4F,qBAEnH,MAAMoE,QAAiB/K,KAAKyK,MAAMzK,KAAK4C,KAAM0L,GAC7C,GAAIvD,EAAS6D,GACT,MAAO,CACHxN,mBAAoB,YAA6BnB,GACjD4O,UAAW,CAAC9D,IAIhB,MAAM,IAAIjM,MACN,gEAAGiM,EAAS+D,WAWxB,aACI,MAAMC,QAA2B/O,KAAKyK,MAAMzK,KAAK4C,KAAM5C,KAAK4K,aAC5D,IAAKmE,EAAmBH,GACpB,MAAM,IAAI9P,MAAM,cAAckB,KAAK4C,gCAC5BmM,EAAmBD,iFAG9B,IAAIE,EACJ,IACIA,QAAoBD,EAAmBE,OAE3C,MAAOC,GACH,IAAIC,EAAU,+CAA+CnP,KAAK4C,QAelE,MAZI5C,KAAK4C,KAAKmD,SAAS,OACnBoJ,GAAW,+UAQXA,GAAW,uEAGT,IAAIrQ,MAAMqQ,GAEpB,MAAMjP,EAAgB8O,EAAY9O,cAC5B0G,EAAkBoI,EAAYpI,gBAC9BlC,EAAcsK,EAAYtK,YAC1BC,EAAcqK,EAAYrK,YAC1BF,EAASuK,EAAYvK,OACrBG,EAAYoK,EAAYpK,UACxBC,EAAsBmK,EAAYnK,oBAExC,GAAqB,MAAjB3E,GAA4C,MAAnB0G,EACzB,MAAM,IAAI9H,MAAM,2BAA2BkB,KAAK4C,iEAGpD,IAAIgB,EACAC,EACJ,GAAuB,MAAnB+C,EAAyB,CACzB,MAAMwI,QAAgBpP,KAAKiL,YAAYrE,IACtChD,EAAaC,GAAcuL,EAEhC,MAAMC,EAAY,CACdnP,gBACA0D,cACAC,aACAa,cACAC,cACAF,UAEa,MAAbG,IACAyK,EAAUzK,UAAYA,GAEC,MAAvBC,IACAwK,EAAUxK,oBAAsBA,GAEpC,MAAMyK,EAAcN,EAAYlK,iBAIhC,OAHIwK,IACAD,EAAUvK,iBAAmBwK,GAE1BD,EAEX,kBAAkBzI,GACd,MAAM2I,EAAaxN,MAAMC,QAAQhC,KAAK4C,MAAQ5C,KAAK4C,KAAK,GAAK5C,KAAK4C,MAC3DgD,EAAQC,GAyChB,SAAkB/D,GACrB,MAAM0N,EAAY1N,EAAI2N,YAAY,KAC5BC,EAAkB5N,EAAI2N,YAAY,KAClC7J,EAAS9D,EAAI6N,UAAU,EAAGH,GAC1B3J,EAAS6J,EAAkBF,EAAY1N,EAAI6N,UAAUD,GAAmB,GAC9E,MAAO,CAAC9J,EAAS,IAAKC,GA9CO+J,CAASL,GAC5BM,EAAa7P,KAAKmO,kBAAoBvI,EACtChC,EAAc,GACpB,IAAK,MAAMkM,KAASlJ,EAChBhD,EAAY4E,QAAQsH,EAAMhJ,SAE9B,MAAMuD,EAAY,GACZ0F,EAAc,GACpB,IAAK,MAAMxH,KAAgB3B,EACvB,IAAK,MAAMhE,KAAQ2F,EAAa1B,MACG,MAA3B7G,KAAKoO,mBACL2B,EAAYvH,KAAKxI,KAAKoO,mBAAmBxL,IAGzCyH,EAAU7B,KAAKqH,EAAajN,EAAOiD,GAI3C7F,KAAKoO,oBACL/D,EAAU7B,cAAcnI,QAAQ0J,IAAIgG,IAExC,MAAM3C,QAAgBhD,EAAyBC,EAAW,CACtDO,YAAa5K,KAAK4K,YAClBL,UAAWvK,KAAKyK,MAChBhB,WAAYzJ,KAAKyJ,aAErB,MAAO,CAAC7F,EAAa,YAAwBwJ,KAsB9C,SAAS4C,EAAalO,GACzB,OAAkD,MAA3CA,EAAImO,MAAM,EAAYC,kBApBjC,EAAYA,iBAAmB,eAsBxB,MAAMC,EAAa,CAACrO,EAAKwI,KAC5B,GAAqB,oBAAVG,QACS,MAAfH,GAAgD,MAAzBA,EAAYC,WAIpC,OAAO,KAEN,CACD,IAAI6F,GAAS,EAOb,GALIA,EADArO,MAAMC,QAAQF,GACLA,EAAI2K,OAAM4D,GAAWL,EAAaK,KAGlCL,EAAalO,GAEtBsO,EACA,OAAOE,EAAKxO,EAAKwI,GAGzB,OAAO,MA0EJ,SAASgG,EAAK1N,EAAM0H,GACvB,OAAO,IAAI,EAAY1H,EAAM0H,GAO1B,SAASiG,EAAmB3N,EAAM0H,GACrC,OAAOgG,EAAK1N,EAAM0H,GAjFtB,IAAiBlI,mBAAmB+N,GACpC,IAAiB9N,mBAAmB8N,GC/OpC,MAAMK,EACF,YAAYvQ,GACRD,KAAKC,eAAiBA,EAE1B,aACI,OAAOD,KAAKC,gBAGpB,MAAMwQ,EACF,YAAYC,GACR1Q,KAAK0Q,YAAcA,EAEvB,WAAWzQ,GACP,OAAOD,KAAK0Q,YAAYzQ,IAwBzB,SAAS0Q,EAAW1Q,EAAgB2D,EAAaC,EAAY+M,GAChE,GAAyB,IAArBC,UAAU1O,OAAc,CAGxB,OAFyD,MAAhClC,EAAeC,eACN,MAA9BD,EAAe2D,YAER,IAAI4M,EAAkBvQ,IAK7B6Q,QAAQC,KAAK,yNAIN,IAAIP,EAAkB,CAAEtQ,cAAeD,KAUlD,OAJA6Q,QAAQC,KAAK,yNAIN,IAAIP,EAAkB,CACzBtQ,cAAeD,EACf2D,cACAC,aACA+M,mBAmBL,SAASI,EAAgBN,GAC5B,OAAO,IAAID,EAAiBC,G,8CCrGhC,+RAuCOvG,eAAe8G,EAAcC,EAAS/H,GAEzC,MAAMgI,EAAQ,GACRC,EAAe,GACfC,EAAQtP,MAAMC,QAAQkP,GACxBA,EAAQjI,KAAIqI,GAAUA,EAAOpJ,OAC7BqG,OAAOlK,KAAK6M,GAChB,IAAK,IAAIpL,EAAI,EAAGA,EAAIuL,EAAMlP,SAAU2D,EAAG,CACnC,MAAMoC,EAAOmJ,EAAMvL,GACbyL,EAAIxP,MAAMC,QAAQkP,GAAWA,EAAQpL,GAAGwL,OAASJ,EAAQhJ,GAC/D,GAAgB,YAAZqJ,EAAEtF,OAAmC,UAAZsF,EAAEtF,OAAiC,SAAZsF,EAAEtF,OACtC,WAAZsF,EAAEtF,OAAkC,cAAZsF,EAAEtF,MAC1B,MAAM,IAAInN,MAAM,gCAAgCoJ,OAAUqJ,EAAEtF,SAEhE,MAAMuF,EAAO,CAAEtJ,OAAMiE,MAAOoF,EAAEpF,MAAOF,MAAOsF,EAAEtF,OAC9C,GAAgB,WAAZsF,EAAEtF,MAAoB,CACtB,MAAMwF,EAAY,IAAIpR,SAAQ8J,MAAO7J,IACjC,MAAMoR,QAAaH,EAAEI,QACfC,EAAgBF,EAAK3E,QAAO,CAAC8E,EAAGC,IAAMD,EAAIC,EAAE3P,QAAQ,GApC1C,EAqCcuP,EAAKvP,OAC7BwP,EAAQ,IAAI/D,WAAWgE,GAC7B,IAAIG,EAAS,EACb,IAAK,IAAIjM,EAAI,EAAGA,EAAI4L,EAAKvP,OAAQ2D,IAAK,CAClC,MAAMkM,EAAMN,EAAK5L,GACXmM,EAAgB,IAAIrE,WAAW,IAAIsE,YAAY,CAACF,EAAI7P,SAAS2L,QACnE6D,EAAM5D,IAAIkE,EAAeF,GACzBA,GA5CY,EA6CZJ,EAAM5D,IAAIiE,EAAKD,GACfA,GAAUC,EAAI7P,OAElB7B,EAAQqR,MAEZP,EAAa5I,KAAKiJ,QAGlBL,EAAa5I,KAAK+I,EAAEY,QAEX,MAAThJ,IACAqI,EAAKrI,MAAQA,GAEjBgI,EAAM3I,KAAKgJ,GAGf,MAAO,CAAEW,KAAMC,QADY/R,QAAQ0J,IAAIqH,IACcD,SAiBlD,SAASkB,EAAcvE,EAAQqD,GAElC,MAAMzO,EAAM,GACZ,IAAI4P,EACAP,EAAS,EACb,IAAK,MAAMP,KAAQL,EAAO,CACtB,MAAMjJ,EAAOsJ,EAAKtJ,KACZ+D,EAAQuF,EAAKvF,MACbE,EAAQqF,EAAKrF,MACboG,EAAO,YAAcpG,GAC3B,IAAIqG,EACJ,GAAI,iBAAkBhB,EAAM,CACxB,MAAMxF,EAAewF,EAAKxF,aAC1B,GAA2B,UAAvBA,EAAaC,OAA4C,WAAvBD,EAAaC,OAC/C,KAAM,QAASD,MAAgB,UAAWA,GACtC,MAAM,IAAIlN,MAAM,UAAU0S,EAAKtJ,0BAA0B8D,EAAaC,gEAIzE,IAA2B,YAAvBD,EAAaC,MAOlB,MAAM,IAAInN,MAAM,UAAU0S,EAAKtJ,uCACL8D,EAAaC,+EAPvC,GAAc,YAAVA,EACA,MAAM,IAAInN,MAAM,UAAU0S,EAAKtJ,0BAA0B8D,EAAaC,yDACfA,MAS/D,MAAMwG,EAAyB,IAAqBzG,EAAaC,OAC3D+B,EAAaF,EAAO5L,MAAM6P,EAAQA,EAASQ,EAAOE,GAClDC,EAAyC,UAAvB1G,EAAaC,MACjC,IAAI2B,WAAWI,GACf,IAAI2E,YAAY3E,GACpB,GAAc,YAAV/B,EACA,GAA2B,UAAvBD,EAAaC,OAA4C,WAAvBD,EAAaC,MAAoB,CACnEuG,EAAS,IAAII,aAAaF,EAAevQ,QACzC,IAAK,IAAI2D,EAAI,EAAGA,EAAI4M,EAAevQ,OAAQ2D,IAAK,CAC5C,MAAM+M,EAAIH,EAAe5M,GACzB0M,EAAO1M,GAAK+M,EAAI7G,EAAa8G,MAAQ9G,EAAa+G,SAGrD,IAA2B,YAAvB/G,EAAaC,MAOlB,MAAM,IAAInN,MAAM,iCAAiCkN,EAAaC,uCANxC+G,IAAlBV,IACAA,EAAgBW,KAEpBT,EAASF,EAAcI,OAO1B,IAAc,UAAVzG,EAYL,MAAM,IAAInN,MAAM,gCAAgCoJ,OAAU+D,KAX1D,GAA2B,UAAvBD,EAAaC,OAA4C,WAAvBD,EAAaC,MAC/C,MAAM,IAAInN,MAAM,iCAAiCkN,EAAaC,gCAGlEuG,EAAS,IAAIU,WAAWR,EAAevQ,QACvC,IAAK,IAAI2D,EAAI,EAAGA,EAAI4M,EAAevQ,OAAQ2D,IAAK,CAC5C,MAAM+M,EAAIH,EAAe5M,GACzB0M,EAAO1M,GAAKqN,KAAKC,MAAMP,EAAI7G,EAAa8G,MAAQ9G,EAAa+G,MAMrEhB,GAAUQ,EAAOE,OAEhB,GAAc,WAAVxG,EAAoB,CACzB,MAAMsG,EAAO,YAAcf,EAAKrF,OAChCqG,EAAS,GACT,IAAK,IAAI1M,EAAI,EAAGA,EAAIyM,EAAMzM,IAAK,CAC3B,MAAM2H,EAAa,IAAIyE,YAAYpE,EAAO5L,MAAM6P,EAAQA,EAzJxC,IAyJ2E,GAC3FA,GA1JgB,EA2JhB,MAAMJ,EAAQ,IAAI/D,WAAWE,EAAO5L,MAAM6P,EAAQA,EAAStE,IAC3D+E,EAAOhK,KAAKmJ,GACZI,GAAUtE,OAGb,CACD,MAAM4F,EAAc,IAAqBpH,GACnC+B,EAAaF,EAAO5L,MAAM6P,EAAQA,EAASQ,EAAOc,GACxD,GAAc,YAAVpH,EACAuG,EAAS,IAAII,aAAa5E,QAEzB,GAAc,UAAV/B,EACLuG,EAAS,IAAIU,WAAWlF,QAEvB,GAAc,SAAV/B,EACLuG,EAAS,IAAI5E,WAAWI,OAEvB,IAAc,cAAV/B,EAeL,MAAM,IAAInN,MAAM,gCAAgCoJ,OAAU+D,KAf9B,CAC5BuG,EAAS,IAAII,aAAa5E,GAC1B,MAAMsF,EAAO,IAAIV,aAAaJ,EAAOrQ,OAAS,GACxCoR,EAAQ,IAAIX,aAAaJ,EAAOrQ,OAAS,GAC/C,IAAK,IAAI2D,EAAI,EAAGA,EAAIwN,EAAKnR,OAAQ2D,IAC7BwN,EAAKxN,GAAK0M,EAAW,EAAJ1M,GACjByN,EAAMzN,GAAK0M,EAAW,EAAJ1M,EAAQ,GAE9B,MAAM0N,EAAa,YAAOF,EAAMnH,EAAO,WACjCsH,EAAc,YAAOF,EAAOpH,EAAO,WACzCzJ,EAAIwF,GAAQ,YAAQsL,EAAYC,GAChCD,EAAWE,UACXD,EAAYC,WAKhB3B,GAAUQ,EAAOc,EAEP,cAAVpH,IACAvJ,EAAIwF,GAAQ,YAAOsK,EAAQrG,EAAOF,IAG1C,OAAOvJ,EAKJ,SAAS0P,EAAuBuB,GAEnC,GAAW,OAAPA,EACA,MAAM,IAAI7U,MAAM,wBAAwBwF,KAAKC,UAAUoP,MAE3D,IAAIC,EAAkB,EAQtB,MAAMC,EAAe,GACrBF,EAAGrL,SAASwL,IAKR,GAJAF,GAAmBE,EAAErG,WAErBoG,EAAarL,KAAKsL,EAAErG,aAAeqG,EAAEhG,OAAOL,WAAaqG,EACrD,IAAIA,EAAEC,YAAYD,MAChBA,aAAalB,cAAgBkB,aAAaZ,YAC5CY,aAAalG,YACb,MAAM,IAAI9O,MAAM,mCAAmCgV,EAAEC,YAAY7L,WAIzE,MAAM8L,EAAI,IAAIpG,WAAWgG,GACzB,IAAI7B,EAAS,EAKb,OAJA8B,EAAavL,SAASwL,IAClBE,EAAEjG,IAAI,IAAIH,WAAWkG,EAAEhG,QAASiE,GAChCA,GAAU+B,EAAErG,cAETuG,EAAElG,OAGb,MAAMmG,OAAkC,IAAXC,IACR,oBAATxN,MAAwC,oBAATyN,MACnB,oBAATC,MAUR,SAASC,EAAiBC,GAC7B,OAAIL,EACOC,EAAOzG,WAAW6G,GAEtB,IAAI5N,KAAK,CAAC4N,IAAM/B,KAQpB,SAASgC,EAA0BzG,GACtC,GAAImG,EACA,OAAOC,EAAOM,KAAK1G,GAAQ2G,SAAS,UAExC,MAAMC,EAAM,IAAI9G,WAAWE,GAC3B,IAAI6G,EAAI,GACR,IAAK,IAAI7O,EAAI,EAAG8O,EAAIF,EAAIvS,OAAQ2D,EAAI8O,EAAG9O,IACnC6O,GAAKE,OAAOC,aAAaJ,EAAI5O,IAEjC,OAAOsO,KAAKO,GAQT,SAASI,EAA0BT,GACtC,GAAIL,EAAe,CACf,MAAMS,EAAMR,EAAOM,KAAKF,EAAK,UAC7B,OAAOI,EAAI5G,OAAO5L,MAAMwS,EAAIM,WAAYN,EAAIM,WAAaN,EAAIjH,YAEjE,MAAMkH,EAAIR,KAAKG,GACTxG,EAAS,IAAIF,WAAW+G,EAAExS,QAChC,IAAK,IAAI2D,EAAI,EAAGA,EAAI6O,EAAExS,SAAU2D,EAC5BgI,EAAOC,IAAI,CAAC4G,EAAEM,WAAWnP,IAAKA,GAElC,OAAOgI,EAAOA,OAQX,SAASoH,EAAwB9H,GACpC,GAAuB,IAAnBA,EAAQjL,OACR,OAAOiL,EAAQ,GAEnB,IAAIwG,EAAkB,EACtBxG,EAAQ9E,SAASwF,IACb8F,GAAmB9F,EAAOL,cAE9B,MAAM0H,EAAO,IAAIvH,WAAWgG,GAC5B,IAAI7B,EAAS,EAKb,OAJA3E,EAAQ9E,SAASwF,IACbqH,EAAKpH,IAAI,IAAIH,WAAWE,GAASiE,GACjCA,GAAUjE,EAAOL,cAEd0H,EAAKrH,OAST,SAASsH,EAASxS,GAGrB,IADAA,EAAOA,EAAKyS,OACLzS,EAAKmD,SAFM,MAGdnD,EAAOA,EAAKV,MAAM,EAAGU,EAAKT,OAAS,GAEvC,MAAM6B,EAAQpB,EAAKqB,MALD,KAMlB,OAAOD,EAAMA,EAAM7B,OAAS,GAOzB,SAASmT,EAA6BrV,GACzC,GAAIA,EAAeC,yBAAyBC,YACxC,MAAM,IAAIrB,MAAM,uDAEpB,MAAO,CACHyW,UAAW,IAAIC,KACflQ,kBAAmB,OACnBL,mBAAoD,MAAhChF,EAAeC,cAC/B,EACAmU,EAAiB/P,KAAKC,UAAUtE,EAAeC,gBACnDgF,iBAAgD,MAA9BjF,EAAe2D,YAC7B,EACAyQ,EAAiB/P,KAAKC,UAAUtE,EAAe2D,cACnDuB,gBAA8C,MAA7BlF,EAAe4D,WAC5B,EACA5D,EAAe4D,WAAW4J,YAwE/B,SAASwF,IAIZ,MAAMwC,EAnEV,WACI,MAAMC,EAAmB5P,IACrB,IAAI6P,EAAI7P,GAAK,GACToJ,EAAI,EACR,KAA4B,IAAhB,QAAJyG,IACJzG,GAAK,QACLyG,IAAM,EAIV,OAFAA,IAAK,QACLzG,GAAK,UACEyG,EAAIzG,GAETuG,EAAe,IAAIvD,YAAY,MACrCuD,EAAa,GAAK,EAClB,IAAK,IAAI3P,EAAI,EAAGA,EAAI,KAAMA,IACtB2P,EAAa3P,GAAK4P,EAAgB5P,GAEtC,IAAK,IAAIA,EAAI,KAAMA,EAAI,KAAMA,IACzB2P,EAAa3P,GAAK,WAAeA,EAAI,MAAS,IAElD,OAAO2P,EA+CcG,GACfC,EAxCV,WACI,MAAMA,EAAgB,IAAI3D,YAAY,IACtC2D,EAAc,GAAK,EACnBA,EAAc,IAAM,WACpBA,EAAc,IAAM,WACpBA,EAAc,IAAM,WACpB,IAAK,IAAI/P,EAAI,EAAGA,EAAI,GAAIA,IACpB+P,EAAc/P,GAAKA,GAAK,GAE5B,IAAK,IAAIA,EAAI,GAAIA,EAAI,GAAIA,IACrB+P,EAAc/P,GAAK,YAAeA,EAAI,IAAO,IAEjD,OAAO+P,EA4BeC,GAChBC,EArBV,WACI,MAAMA,EAAc,IAAI7D,YAAY,IACpC,IAAK,IAAIpM,EAAI,EAAGA,EAAI,GAAIA,IACpBiQ,EAAYjQ,GAAK,KAGrB,OADAiQ,EAAY,GAAKA,EAAY,IAAM,EAC5BA,EAeaC,GACpB,OAAQtD,IACJ,MAAM5E,EAAS,IAAI3N,YAAY,EAAIuS,EAAevQ,QAC5C8T,EAAmB,IAAI/D,YAAYpE,GACzC,IAAK,IAAIpF,EAAQ,EAAGA,EAAQgK,EAAevQ,OAAQuG,IAAS,CACxD,MAAMwN,EAAcxD,EAAehK,GAC7ByN,EAAcV,EAAaM,EAAYG,GAAe,KAAqB,KAAdA,IAC/DL,EAAcK,GAAe,IACjCD,EAAiBvN,GAASyN,EAE9B,OAAO,IAAIvD,aAAa9E,O,0DCtchC,0KAgBO,MAAMsI,EACT,cACIpW,KAAKqW,YAAc,GACnBrW,KAAKsW,YAAc,GAEvB,qBAII,OAHiC,MAA7BF,EAAiBG,WACjBH,EAAiBG,SAAW,IAAIH,GAE7BA,EAAiBG,SAQ5B,0BAA0BC,GACtBJ,EAAiBK,cAAcJ,YAAY7N,KAAKgO,GAQpD,0BAA0BE,GACtBN,EAAiBK,cAAcH,YAAY9N,KAAKkO,GAUpD,uBAAuB5U,GACnB,OAAOsU,EAAiBO,YAAY7U,EAAK,QAU7C,uBAAuBA,EAAKwI,GACxB,OAAO8L,EAAiBO,YAAY7U,EAAK,OAAQwI,GAErD,mBAAmBxI,EAAK8U,EAAatM,GACjC,MAAMuM,EAAgB,GAUtB,OATgC,SAAhBD,EACZR,EAAiBK,cAAcH,YAC/BF,EAAiBK,cAAcJ,aAC3B/N,SAAQwO,IACZ,MAAMC,EAAUD,EAAOhV,EAAKwI,GACZ,OAAZyM,GACAF,EAAcrO,KAAKuO,MAGpBF,GAGR,MAAMzU,EAAsB4U,GAAeZ,EAAiBhU,mBAAmB4U,GACzE3U,EAAsB2U,GAAeZ,EAAiB/T,mBAAmB2U,GACzEC,EAAmBnV,GAAQsU,EAAiBa,gBAAgBnV,GAC5DoV,EAAkB,CAACpV,EAAKwI,IAAgB8L,EAAiBc,gBAAgBpV,EAAKwI,I,gCCpF3F,+LAkBA,MAAM6M,EAAiB,YAAU,kBAAkB,IAAM,IAAIC,MACvDC,EAAe,YAAU,gBAAgB,IAAM,IAAID,MAOlD,SAASE,EAAUC,EAAYC,GAClC,MAAM3U,EAAM4U,EAAQF,EAAYC,GAChC,OAAOL,EAAepW,IAAI8B,GAMvB,SAAS6U,EAAYH,GACxB,OAAOF,EAAatW,IAAIwW,GAErB,SAASI,EAAqBH,GACjC,MAAMI,EAAKT,EAAeU,UACpBlY,EAAS,GACf,OAAa,CACT,MAAM,KAAEmY,EAAI,MAAE7N,GAAU2N,EAAGG,OAC3B,GAAID,EACA,MAEJ,MAAOjV,EAAKmV,GAAU/N,GACfgO,GAAYpV,EAAIoB,MAAM,KACzBgU,IAAYT,GACZ7X,EAAO6I,KAAKwP,GAGpB,OAAOrY,EAaJ,SAASuY,EAAeF,GAC3B,MAAM,WAAET,EAAU,YAAEC,GAAgBQ,EAC9BnV,EAAM4U,EAAQF,EAAYC,GAC5BL,EAAegB,IAAItV,IACnBiO,QAAQC,KAAK,eAAewG,mBACpBC,4BAEZL,EAAepJ,IAAIlL,EAAKmV,GAUrB,SAASI,EAAiBJ,GAC7B,MAAM,WAAET,GAAeS,EACnBX,EAAac,IAAIZ,IAGb,cAAM1Y,QAAQ,UACdiS,QAAQC,KAAK,gCAAgCwG,MAGrDF,EAAatJ,IAAIwJ,EAAYS,GAqCjC,SAASP,EAAQF,EAAYC,GACzB,MAAO,GAAGA,KAAeD,M,gCChI7B,6LA4BA,MAAMc,EAAoB,MACnB,MAAMC,EACT,cACItY,KAAKuY,SAAW,GAEpB,qBAII,OAH0C,MAAtCD,EAA0B/B,WAC1B+B,EAA0B/B,SAAW,IAAI+B,GAEtCA,EAA0B/B,SAQrC,uBAAuBiC,EAAQC,GAC3B,YAAiB,MAAVD,GAAgB,IAAM,0CACzBA,EAAOzS,SAASsS,KAChBG,EAASA,EAAOtW,MAAM,EAAGsW,EAAO7P,QAAQ0P,KAE5C,YAAOG,EAAOrW,OAAS,GAAG,IAAM,wCAChC,MAAMuW,EAAWJ,EAA0B7B,cAC3C,YAAoC,MAA7BiC,EAASH,SAASC,IAAiB,IAAM,2DAA2DA,QAC3GE,EAASH,SAASC,GAAUC,EAEhC,kBAAkBD,GACd,MAAMC,EAAUzY,KAAKyW,cAAc8B,SAASC,GAC5C,GAAe,MAAXC,EACA,MAAM,IAAI3Z,MAAM,yCAAyC0Z,MAE7D,OAAOC,EAEX,oBACI,OAAOlK,OAAOlK,KAAKrE,KAAKyW,cAAc8B,WAW9C,SAASI,EAAS7W,GACd,IAAwC,IAApCA,EAAI6G,QAAQ0P,GACZ,MAAM,IAAIvZ,MAEN,6EAAGwZ,EAA0BM,aAAalV,KAAK,QAEvD,MAAO,CACH8U,OAAQ1W,EAAImC,MAAMoU,GAAmB,GACrCzV,KAAMd,EAAImC,MAAMoU,GAAmB,IAG3ClO,eAAe0O,EAAmBC,EAAWC,EAASC,GAAe,GACjE,YAAOF,IAAcC,GAAS,IAAM,wCAAwCD,OAC5E,MAAMG,EAAe,IAAiB/B,gBAAgB4B,GACtD,YAAOG,EAAa9W,OAAS,GAAG,IAAM,kEAAkE2W,OACxG,YAAOG,EAAa9W,OAAS,GAAG,IAAM,yCAAyC8W,EAAa9W,wCACxD2W,OACpC,MAAMI,EAAcD,EAAa,GAC3BE,EAAe,IAAiBlC,gBAAgB8B,GACtD,YAAOI,EAAahX,OAAS,GAAG,IAC5B,uEAAO4W,OACX,YAAOI,EAAahX,OAAS,GAAG,IAAM,yCAAyC8W,EAAa9W,6CACnD4W,OACzC,MAAMrI,EAAcyI,EAAa,GAC3BC,EAAeT,EAASG,GAAWN,OACnCa,EAAaV,EAASG,GAAWlW,KACjC0W,EAAaF,IAAiBT,EAASG,GAAWN,OAClDvY,QAAuBiZ,EAAYK,OAIrCP,GAAgBM,SACVhB,EAA0BkB,WAAWJ,GACtCK,YAAYJ,GAErB,MAAMK,QAAmBhJ,EAAYiJ,KAAK1Z,GAQ1C,OAJI+Y,IAAiBM,SACXhB,EAA0BkB,WAAWJ,GACtCK,YAAYJ,GAEdK,EAAWtY,mBAqCtB+I,eAAeyP,IACX,MAAMC,EAAUvB,EAA0BM,aACpClW,EAAM,GACZ,IAAK,MAAM8V,KAAUqB,EAAS,CAC1B,MAAMC,QAAkBxB,EAA0BkB,WAAWhB,GAAQoB,aACrE,IAAK,MAAMhX,KAAQkX,EAAW,CAE1BpX,EADY8V,EAASH,EAAoBzV,GAC9BkX,EAAUlX,IAG7B,OAAOF,EAmCXyH,eAAesP,EAAY3X,GACvB,MAAMiY,EAAgBpB,EAAS7W,GAE/B,OADgBwW,EAA0BkB,WAAWO,EAAcvB,QACpDiB,YAAYM,EAAcnX,MAiD7CuH,eAAe6P,EAAUlB,EAAWC,GAEhC,OAAOF,EAAmBC,EAAWC,GADhB,GAiDzB5O,eAAe8P,EAAUnB,EAAWC,GAEhC,OAAOF,EAAmBC,EAAWC,GADhB","file":"js/bundle~bundle~18ffb1da.1f08549e.js","sourcesContent":["export const Abs = 'Abs';\nexport const Acos = 'Acos';\nexport const Acosh = 'Acosh';\nexport const Add = 'Add';\nexport const AddN = 'AddN';\nexport const All = 'All';\nexport const Any = 'Any';\nexport const ArgMax = 'ArgMax';\nexport const ArgMin = 'ArgMin';\nexport const Asin = 'Asin';\nexport const Asinh = 'Asinh';\nexport const Atan = 'Atan';\nexport const Atanh = 'Atanh';\nexport const Atan2 = 'Atan2';\nexport const AvgPool = 'AvgPool';\nexport const AvgPoolGrad = 'AvgPoolGrad';\nexport const AvgPool3D = 'AvgPool3D';\nexport const AvgPool3DGrad = 'AvgPool3DGrad';\nexport const BatchMatMul = 'BatchMatMul';\nexport const BatchToSpaceND = 'BatchToSpaceND';\nexport const Bincount = 'Bincount';\nexport const BroadcastTo = 'BroadcastTo';\nexport const Cast = 'Cast';\nexport const Ceil = 'Ceil';\nexport const ClipByValue = 'ClipByValue';\nexport const Complex = 'Complex';\nexport const ComplexAbs = 'ComplexAbs';\nexport const Concat = 'Concat';\nexport const Conv2D = 'Conv2D';\nexport const Conv2DBackpropFilter = 'Conv2DBackpropFilter';\nexport const Conv2DBackpropInput = 'Conv2DBackpropInput';\nexport const Conv3D = 'Conv3D';\nexport const Conv3DBackpropFilterV2 = 'Conv3DBackpropFilterV2';\nexport const Conv3DBackpropInputV2 = 'Conv3DBackpropInputV2';\nexport const Cos = 'Cos';\nexport const Cosh = 'Cosh';\nexport const Cumsum = 'Cumsum';\nexport const CropAndResize = 'CropAndResize';\nexport const DenseBincount = 'DenseBincount';\nexport const DepthToSpace = 'DepthToSpace';\nexport const DepthwiseConv2dNative = 'DepthwiseConv2dNative';\nexport const DepthwiseConv2dNativeBackpropFilter = 'DepthwiseConv2dNativeBackpropFilter';\nexport const DepthwiseConv2dNativeBackpropInput = 'DepthwiseConv2dNativeBackpropInput';\nexport const Diag = 'Diag';\nexport const Dilation2D = 'Dilation2D';\nexport const Dilation2DBackpropInput = 'Dilation2DBackpropInput';\nexport const Dilation2DBackpropFilter = 'Dilation2DBackpropFilter';\nexport const RealDiv = 'RealDiv';\nexport const Elu = 'Elu';\nexport const EluGrad = 'EluGrad';\nexport const Erf = 'Erf';\nexport const Equal = 'Equal';\nexport const Exp = 'Exp';\nexport const ExpandDims = 'ExpandDims';\nexport const Expm1 = 'Expm1';\nexport const FFT = 'FFT';\nexport const Fill = 'Fill';\nexport const FlipLeftRight = 'FlipLeftRight';\nexport const Floor = 'Floor';\nexport const FloorDiv = 'FloorDiv';\nexport const FusedBatchNorm = 'FusedBatchNorm';\nexport const GatherV2 = 'GatherV2';\nexport const GatherNd = 'GatherNd';\nexport const Greater = 'Greater';\nexport const GreaterEqual = 'GreaterEqual';\nexport const Identity = 'Identity';\nexport const IFFT = 'IFFT';\nexport const Imag = 'Imag';\nexport const IsFinite = 'IsFinite';\nexport const IsInf = 'IsInf';\nexport const IsNan = 'IsNan';\nexport const LeakyRelu = 'LeakyRelu';\nexport const Less = 'Less';\nexport const LessEqual = 'LessEqual';\nexport const LinSpace = 'LinSpace';\nexport const Log = 'Log';\nexport const Log1p = 'Log1p';\nexport const LogicalAnd = 'LogicalAnd';\nexport const LogicalNot = 'LogicalNot';\nexport const LogicalOr = 'LogicalOr';\nexport const LogSoftmax = 'LogSoftmax';\nexport const LRN = 'LRN';\nexport const LRNGrad = 'LRNGrad';\nexport const Max = 'Max';\nexport const Maximum = 'Maximum';\nexport const MaxPool = 'MaxPool';\nexport const MaxPoolGrad = 'MaxPoolGrad';\nexport const MaxPool3D = 'MaxPool3D';\nexport const MaxPool3DGrad = 'MaxPool3DGrad';\nexport const MaxPoolWithArgmax = 'MaxPoolWithArgmax';\nexport const Mean = 'Mean';\nexport const Min = 'Min';\nexport const Minimum = 'Minimum';\nexport const MirrorPad = 'MirrorPad';\nexport const Mod = 'Mod';\nexport const Multinomial = 'Multinomial';\nexport const Multiply = 'Multiply';\nexport const Neg = 'Neg';\nexport const NotEqual = 'NotEqual';\nexport const NonMaxSuppressionV3 = 'NonMaxSuppressionV3';\nexport const NonMaxSuppressionV4 = 'NonMaxSuppressionV4';\nexport const NonMaxSuppressionV5 = 'NonMaxSuppressionV5';\nexport const OnesLike = 'OnesLike';\nexport const OneHot = 'OneHot';\nexport const Pack = 'Pack';\nexport const PadV2 = 'PadV2';\nexport const Pool = 'Pool';\nexport const Pow = 'Pow';\nexport const Prelu = 'Prelu';\nexport const Prod = 'Prod';\nexport const Range = 'Range';\nexport const Real = 'Real';\nexport const Reciprocal = 'Reciprocal';\nexport const Relu = 'Relu';\nexport const Reshape = 'Reshape';\nexport const ResizeNearestNeighbor = 'ResizeNearestNeighbor';\nexport const ResizeNearestNeighborGrad = 'ResizeNearestNeighborGrad';\nexport const ResizeBilinear = 'ResizeBilinear';\nexport const ResizeBilinearGrad = 'ResizeBilinearGrad';\nexport const Relu6 = 'Relu6';\nexport const Reverse = 'Reverse';\nexport const Round = 'Round';\nexport const Rsqrt = 'Rsqrt';\nexport const ScatterNd = 'ScatterNd';\nexport const Select = 'Select';\nexport const Selu = 'Selu';\nexport const Slice = 'Slice';\nexport const Sin = 'Sin';\nexport const Sinh = 'Sinh';\nexport const Sign = 'Sign';\nexport const Sigmoid = 'Sigmoid';\nexport const Softplus = 'Softplus';\nexport const Sqrt = 'Sqrt';\nexport const Sum = 'Sum';\nexport const SpaceToBatchND = 'SpaceToBatchND';\nexport const SplitV = 'SplitV';\nexport const Softmax = 'Softmax';\nexport const SquaredDifference = 'SquaredDifference';\nexport const Square = 'Square';\nexport const Sub = 'Sub';\nexport const SparseToDense = 'SparseToDense';\nexport const StridedSlice = 'StridedSlice';\nexport const Tan = 'Tan';\nexport const Tanh = 'Tanh';\nexport const Tile = 'Tile';\nexport const TopK = 'TopK';\nexport const Transpose = 'Transpose';\nexport const Unique = 'Unique';\nexport const Unpack = 'Unpack';\nexport const UnsortedSegmentSum = 'UnsortedSegmentSum';\nexport const ZerosLike = 'ZerosLike';\n/**\n * TensorFlow.js-only kernels\n */\nexport const Step = 'Step';\nexport const FromPixels = 'FromPixels';\nexport const RotateWithOffset = 'RotateWithOffset';\nexport const _FusedMatMul = '_FusedMatMul';\nexport const FusedConv2D = 'FusedConv2D';\nexport const FusedDepthwiseConv2D = 'FusedDepthwiseConv2D';\n//# sourceMappingURL=kernel_names.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n/* Type definitions for exporting and importing of models. */\n/**\n * A map from Tensor dtype to number of bytes per element of the Tensor.\n */\nexport const DTYPE_VALUE_SIZE_MAP = {\n    'float32': 4,\n    'float16': 2,\n    'int32': 4,\n    'uint16': 2,\n    'uint8': 1,\n    'bool': 1,\n    'complex64': 8\n};\n//# sourceMappingURL=types.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport '../flags';\nimport { env } from '../environment';\nimport { getModelArtifactsInfoForJSON } from './io_utils';\nimport { IORouterRegistry } from './router_registry';\nconst DATABASE_NAME = 'tensorflowjs';\nconst DATABASE_VERSION = 1;\n// Model data and ModelArtifactsInfo (metadata) are stored in two separate\n// stores for efficient access of the list of stored models and their metadata.\n// 1. The object store for model data: topology, weights and weight manifests.\nconst MODEL_STORE_NAME = 'models_store';\n// 2. The object store for ModelArtifactsInfo, including meta-information such\n//    as the type of topology (JSON vs binary), byte size of the topology, byte\n//    size of the weights, etc.\nconst INFO_STORE_NAME = 'model_info_store';\n/**\n * Delete the entire database for tensorflow.js, including the models store.\n */\nexport async function deleteDatabase() {\n    const idbFactory = getIndexedDBFactory();\n    return new Promise((resolve, reject) => {\n        const deleteRequest = idbFactory.deleteDatabase(DATABASE_NAME);\n        deleteRequest.onsuccess = () => resolve();\n        deleteRequest.onerror = error => reject(error);\n    });\n}\nfunction getIndexedDBFactory() {\n    if (!env().getBool('IS_BROWSER')) {\n        // TODO(cais): Add more info about what IOHandler subtypes are available.\n        //   Maybe point to a doc page on the web and/or automatically determine\n        //   the available IOHandlers and print them in the error message.\n        throw new Error('Failed to obtain IndexedDB factory because the current environment' +\n            'is not a web browser.');\n    }\n    // tslint:disable-next-line:no-any\n    const theWindow = typeof window === 'undefined' ? self : window;\n    const factory = theWindow.indexedDB || theWindow.mozIndexedDB ||\n        theWindow.webkitIndexedDB || theWindow.msIndexedDB ||\n        theWindow.shimIndexedDB;\n    if (factory == null) {\n        throw new Error('The current browser does not appear to support IndexedDB.');\n    }\n    return factory;\n}\nfunction setUpDatabase(openRequest) {\n    const db = openRequest.result;\n    db.createObjectStore(MODEL_STORE_NAME, { keyPath: 'modelPath' });\n    db.createObjectStore(INFO_STORE_NAME, { keyPath: 'modelPath' });\n}\n/**\n * IOHandler subclass: Browser IndexedDB.\n *\n * See the doc string of `browserIndexedDB` for more details.\n */\nexport class BrowserIndexedDB {\n    constructor(modelPath) {\n        this.indexedDB = getIndexedDBFactory();\n        if (modelPath == null || !modelPath) {\n            throw new Error('For IndexedDB, modelPath must not be null, undefined or empty.');\n        }\n        this.modelPath = modelPath;\n    }\n    async save(modelArtifacts) {\n        // TODO(cais): Support saving GraphDef models.\n        if (modelArtifacts.modelTopology instanceof ArrayBuffer) {\n            throw new Error('BrowserLocalStorage.save() does not support saving model topology ' +\n                'in binary formats yet.');\n        }\n        return this.databaseAction(this.modelPath, modelArtifacts);\n    }\n    async load() {\n        return this.databaseAction(this.modelPath);\n    }\n    /**\n     * Perform database action to put model artifacts into or read model artifacts\n     * from IndexedDB object store.\n     *\n     * Whether the action is put or get depends on whether `modelArtifacts` is\n     * specified. If it is specified, the action will be put; otherwise the action\n     * will be get.\n     *\n     * @param modelPath A unique string path for the model.\n     * @param modelArtifacts If specified, it will be the model artifacts to be\n     *   stored in IndexedDB.\n     * @returns A `Promise` of `SaveResult`, if the action is put, or a `Promise`\n     *   of `ModelArtifacts`, if the action is get.\n     */\n    databaseAction(modelPath, modelArtifacts) {\n        return new Promise((resolve, reject) => {\n            const openRequest = this.indexedDB.open(DATABASE_NAME, DATABASE_VERSION);\n            openRequest.onupgradeneeded = () => setUpDatabase(openRequest);\n            openRequest.onsuccess = () => {\n                const db = openRequest.result;\n                if (modelArtifacts == null) {\n                    // Read model out from object store.\n                    const modelTx = db.transaction(MODEL_STORE_NAME, 'readonly');\n                    const modelStore = modelTx.objectStore(MODEL_STORE_NAME);\n                    const getRequest = modelStore.get(this.modelPath);\n                    getRequest.onsuccess = () => {\n                        if (getRequest.result == null) {\n                            db.close();\n                            return reject(new Error(`Cannot find model with path '${this.modelPath}' ` +\n                                `in IndexedDB.`));\n                        }\n                        else {\n                            resolve(getRequest.result.modelArtifacts);\n                        }\n                    };\n                    getRequest.onerror = error => {\n                        db.close();\n                        return reject(getRequest.error);\n                    };\n                    modelTx.oncomplete = () => db.close();\n                }\n                else {\n                    // Put model into object store.\n                    const modelArtifactsInfo = getModelArtifactsInfoForJSON(modelArtifacts);\n                    // First, put ModelArtifactsInfo into info store.\n                    const infoTx = db.transaction(INFO_STORE_NAME, 'readwrite');\n                    let infoStore = infoTx.objectStore(INFO_STORE_NAME);\n                    const putInfoRequest = infoStore.put({ modelPath: this.modelPath, modelArtifactsInfo });\n                    let modelTx;\n                    putInfoRequest.onsuccess = () => {\n                        // Second, put model data into model store.\n                        modelTx = db.transaction(MODEL_STORE_NAME, 'readwrite');\n                        const modelStore = modelTx.objectStore(MODEL_STORE_NAME);\n                        const putModelRequest = modelStore.put({\n                            modelPath: this.modelPath,\n                            modelArtifacts,\n                            modelArtifactsInfo\n                        });\n                        putModelRequest.onsuccess = () => resolve({ modelArtifactsInfo });\n                        putModelRequest.onerror = error => {\n                            // If the put-model request fails, roll back the info entry as\n                            // well.\n                            infoStore = infoTx.objectStore(INFO_STORE_NAME);\n                            const deleteInfoRequest = infoStore.delete(this.modelPath);\n                            deleteInfoRequest.onsuccess = () => {\n                                db.close();\n                                return reject(putModelRequest.error);\n                            };\n                            deleteInfoRequest.onerror = error => {\n                                db.close();\n                                return reject(putModelRequest.error);\n                            };\n                        };\n                    };\n                    putInfoRequest.onerror = error => {\n                        db.close();\n                        return reject(putInfoRequest.error);\n                    };\n                    infoTx.oncomplete = () => {\n                        if (modelTx == null) {\n                            db.close();\n                        }\n                        else {\n                            modelTx.oncomplete = () => db.close();\n                        }\n                    };\n                }\n            };\n            openRequest.onerror = error => reject(openRequest.error);\n        });\n    }\n}\nBrowserIndexedDB.URL_SCHEME = 'indexeddb://';\nexport const indexedDBRouter = (url) => {\n    if (!env().getBool('IS_BROWSER')) {\n        return null;\n    }\n    else {\n        if (!Array.isArray(url) && url.startsWith(BrowserIndexedDB.URL_SCHEME)) {\n            return browserIndexedDB(url.slice(BrowserIndexedDB.URL_SCHEME.length));\n        }\n        else {\n            return null;\n        }\n    }\n};\nIORouterRegistry.registerSaveRouter(indexedDBRouter);\nIORouterRegistry.registerLoadRouter(indexedDBRouter);\n/**\n * Creates a browser IndexedDB IOHandler for saving and loading models.\n *\n * ```js\n * const model = tf.sequential();\n * model.add(\n *     tf.layers.dense({units: 1, inputShape: [100], activation: 'sigmoid'}));\n *\n * const saveResult = await model.save('indexeddb://MyModel'));\n * console.log(saveResult);\n * ```\n *\n * @param modelPath A unique identifier for the model to be saved. Must be a\n *   non-empty string.\n * @returns An instance of `BrowserIndexedDB` (sublcass of `IOHandler`),\n *   which can be used with, e.g., `tf.Model.save`.\n */\nexport function browserIndexedDB(modelPath) {\n    return new BrowserIndexedDB(modelPath);\n}\nfunction maybeStripScheme(key) {\n    return key.startsWith(BrowserIndexedDB.URL_SCHEME) ?\n        key.slice(BrowserIndexedDB.URL_SCHEME.length) :\n        key;\n}\nexport class BrowserIndexedDBManager {\n    constructor() {\n        this.indexedDB = getIndexedDBFactory();\n    }\n    async listModels() {\n        return new Promise((resolve, reject) => {\n            const openRequest = this.indexedDB.open(DATABASE_NAME, DATABASE_VERSION);\n            openRequest.onupgradeneeded = () => setUpDatabase(openRequest);\n            openRequest.onsuccess = () => {\n                const db = openRequest.result;\n                const tx = db.transaction(INFO_STORE_NAME, 'readonly');\n                const store = tx.objectStore(INFO_STORE_NAME);\n                // tslint:disable:max-line-length\n                // Need to cast `store` as `any` here because TypeScript's DOM\n                // library does not have the `getAll()` method even though the\n                // method is supported in the latest version of most mainstream\n                // browsers:\n                // https://developer.mozilla.org/en-US/docs/Web/API/IDBObjectStore/getAll\n                // tslint:enable:max-line-length\n                // tslint:disable-next-line:no-any\n                const getAllInfoRequest = store.getAll();\n                getAllInfoRequest.onsuccess = () => {\n                    const out = {};\n                    for (const item of getAllInfoRequest.result) {\n                        out[item.modelPath] = item.modelArtifactsInfo;\n                    }\n                    resolve(out);\n                };\n                getAllInfoRequest.onerror = error => {\n                    db.close();\n                    return reject(getAllInfoRequest.error);\n                };\n                tx.oncomplete = () => db.close();\n            };\n            openRequest.onerror = error => reject(openRequest.error);\n        });\n    }\n    async removeModel(path) {\n        path = maybeStripScheme(path);\n        return new Promise((resolve, reject) => {\n            const openRequest = this.indexedDB.open(DATABASE_NAME, DATABASE_VERSION);\n            openRequest.onupgradeneeded = () => setUpDatabase(openRequest);\n            openRequest.onsuccess = () => {\n                const db = openRequest.result;\n                const infoTx = db.transaction(INFO_STORE_NAME, 'readwrite');\n                const infoStore = infoTx.objectStore(INFO_STORE_NAME);\n                const getInfoRequest = infoStore.get(path);\n                let modelTx;\n                getInfoRequest.onsuccess = () => {\n                    if (getInfoRequest.result == null) {\n                        db.close();\n                        return reject(new Error(`Cannot find model with path '${path}' ` +\n                            `in IndexedDB.`));\n                    }\n                    else {\n                        // First, delete the entry in the info store.\n                        const deleteInfoRequest = infoStore.delete(path);\n                        const deleteModelData = () => {\n                            // Second, delete the entry in the model store.\n                            modelTx = db.transaction(MODEL_STORE_NAME, 'readwrite');\n                            const modelStore = modelTx.objectStore(MODEL_STORE_NAME);\n                            const deleteModelRequest = modelStore.delete(path);\n                            deleteModelRequest.onsuccess = () => resolve(getInfoRequest.result.modelArtifactsInfo);\n                            deleteModelRequest.onerror = error => reject(getInfoRequest.error);\n                        };\n                        // Proceed with deleting model data regardless of whether deletion\n                        // of info data succeeds or not.\n                        deleteInfoRequest.onsuccess = deleteModelData;\n                        deleteInfoRequest.onerror = error => {\n                            deleteModelData();\n                            db.close();\n                            return reject(getInfoRequest.error);\n                        };\n                    }\n                };\n                getInfoRequest.onerror = error => {\n                    db.close();\n                    return reject(getInfoRequest.error);\n                };\n                infoTx.oncomplete = () => {\n                    if (modelTx == null) {\n                        db.close();\n                    }\n                    else {\n                        modelTx.oncomplete = () => db.close();\n                    }\n                };\n            };\n            openRequest.onerror = error => reject(openRequest.error);\n        });\n    }\n}\n//# sourceMappingURL=indexed_db.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport '../flags';\nimport { env } from '../environment';\nimport { assert } from '../util';\nimport { arrayBufferToBase64String, base64StringToArrayBuffer, getModelArtifactsInfoForJSON } from './io_utils';\nimport { IORouterRegistry } from './router_registry';\nconst PATH_SEPARATOR = '/';\nconst PATH_PREFIX = 'tensorflowjs_models';\nconst INFO_SUFFIX = 'info';\nconst MODEL_TOPOLOGY_SUFFIX = 'model_topology';\nconst WEIGHT_SPECS_SUFFIX = 'weight_specs';\nconst WEIGHT_DATA_SUFFIX = 'weight_data';\nconst MODEL_METADATA_SUFFIX = 'model_metadata';\n/**\n * Purge all tensorflow.js-saved model artifacts from local storage.\n *\n * @returns Paths of the models purged.\n */\nexport function purgeLocalStorageArtifacts() {\n    if (!env().getBool('IS_BROWSER') || typeof window === 'undefined' ||\n        typeof window.localStorage === 'undefined') {\n        throw new Error('purgeLocalStorageModels() cannot proceed because local storage is ' +\n            'unavailable in the current environment.');\n    }\n    const LS = window.localStorage;\n    const purgedModelPaths = [];\n    for (let i = 0; i < LS.length; ++i) {\n        const key = LS.key(i);\n        const prefix = PATH_PREFIX + PATH_SEPARATOR;\n        if (key.startsWith(prefix) && key.length > prefix.length) {\n            LS.removeItem(key);\n            const modelName = getModelPathFromKey(key);\n            if (purgedModelPaths.indexOf(modelName) === -1) {\n                purgedModelPaths.push(modelName);\n            }\n        }\n    }\n    return purgedModelPaths;\n}\nfunction getModelKeys(path) {\n    return {\n        info: [PATH_PREFIX, path, INFO_SUFFIX].join(PATH_SEPARATOR),\n        topology: [PATH_PREFIX, path, MODEL_TOPOLOGY_SUFFIX].join(PATH_SEPARATOR),\n        weightSpecs: [PATH_PREFIX, path, WEIGHT_SPECS_SUFFIX].join(PATH_SEPARATOR),\n        weightData: [PATH_PREFIX, path, WEIGHT_DATA_SUFFIX].join(PATH_SEPARATOR),\n        modelMetadata: [PATH_PREFIX, path, MODEL_METADATA_SUFFIX].join(PATH_SEPARATOR)\n    };\n}\n/**\n * Get model path from a local-storage key.\n *\n * E.g., 'tensorflowjs_models/my/model/1/info' --> 'my/model/1'\n *\n * @param key\n */\nfunction getModelPathFromKey(key) {\n    const items = key.split(PATH_SEPARATOR);\n    if (items.length < 3) {\n        throw new Error(`Invalid key format: ${key}`);\n    }\n    return items.slice(1, items.length - 1).join(PATH_SEPARATOR);\n}\nfunction maybeStripScheme(key) {\n    return key.startsWith(BrowserLocalStorage.URL_SCHEME) ?\n        key.slice(BrowserLocalStorage.URL_SCHEME.length) :\n        key;\n}\n/**\n * IOHandler subclass: Browser Local Storage.\n *\n * See the doc string to `browserLocalStorage` for more details.\n */\nexport class BrowserLocalStorage {\n    constructor(modelPath) {\n        if (!env().getBool('IS_BROWSER') || typeof window === 'undefined' ||\n            typeof window.localStorage === 'undefined') {\n            // TODO(cais): Add more info about what IOHandler subtypes are\n            // available.\n            //   Maybe point to a doc page on the web and/or automatically determine\n            //   the available IOHandlers and print them in the error message.\n            throw new Error('The current environment does not support local storage.');\n        }\n        this.LS = window.localStorage;\n        if (modelPath == null || !modelPath) {\n            throw new Error('For local storage, modelPath must not be null, undefined or empty.');\n        }\n        this.modelPath = modelPath;\n        this.keys = getModelKeys(this.modelPath);\n    }\n    /**\n     * Save model artifacts to browser local storage.\n     *\n     * See the documentation to `browserLocalStorage` for details on the saved\n     * artifacts.\n     *\n     * @param modelArtifacts The model artifacts to be stored.\n     * @returns An instance of SaveResult.\n     */\n    async save(modelArtifacts) {\n        if (modelArtifacts.modelTopology instanceof ArrayBuffer) {\n            throw new Error('BrowserLocalStorage.save() does not support saving model topology ' +\n                'in binary formats yet.');\n        }\n        else {\n            const topology = JSON.stringify(modelArtifacts.modelTopology);\n            const weightSpecs = JSON.stringify(modelArtifacts.weightSpecs);\n            const modelArtifactsInfo = getModelArtifactsInfoForJSON(modelArtifacts);\n            try {\n                this.LS.setItem(this.keys.info, JSON.stringify(modelArtifactsInfo));\n                this.LS.setItem(this.keys.topology, topology);\n                this.LS.setItem(this.keys.weightSpecs, weightSpecs);\n                this.LS.setItem(this.keys.weightData, arrayBufferToBase64String(modelArtifacts.weightData));\n                const result = {\n                    format: modelArtifacts.format,\n                    generatedBy: modelArtifacts.generatedBy,\n                    convertedBy: modelArtifacts.convertedBy\n                };\n                if (modelArtifacts.signature != null) {\n                    result.signature = modelArtifacts.signature;\n                }\n                if (modelArtifacts.userDefinedMetadata != null) {\n                    result.userDefinedMetadata = modelArtifacts.userDefinedMetadata;\n                }\n                if (modelArtifacts.modelInitializer != null) {\n                    result.modelInitializer = modelArtifacts.modelInitializer;\n                }\n                this.LS.setItem(this.keys.modelMetadata, JSON.stringify(result));\n                return { modelArtifactsInfo };\n            }\n            catch (err) {\n                // If saving failed, clean up all items saved so far.\n                this.LS.removeItem(this.keys.info);\n                this.LS.removeItem(this.keys.topology);\n                this.LS.removeItem(this.keys.weightSpecs);\n                this.LS.removeItem(this.keys.weightData);\n                this.LS.removeItem(this.keys.modelMetadata);\n                throw new Error(`Failed to save model '${this.modelPath}' to local storage: ` +\n                    `size quota being exceeded is a possible cause of this failure: ` +\n                    `modelTopologyBytes=${modelArtifactsInfo.modelTopologyBytes}, ` +\n                    `weightSpecsBytes=${modelArtifactsInfo.weightSpecsBytes}, ` +\n                    `weightDataBytes=${modelArtifactsInfo.weightDataBytes}.`);\n            }\n        }\n    }\n    /**\n     * Load a model from local storage.\n     *\n     * See the documentation to `browserLocalStorage` for details on the saved\n     * artifacts.\n     *\n     * @returns The loaded model (if loading succeeds).\n     */\n    async load() {\n        const info = JSON.parse(this.LS.getItem(this.keys.info));\n        if (info == null) {\n            throw new Error(`In local storage, there is no model with name '${this.modelPath}'`);\n        }\n        if (info.modelTopologyType !== 'JSON') {\n            throw new Error('BrowserLocalStorage does not support loading non-JSON model ' +\n                'topology yet.');\n        }\n        const out = {};\n        // Load topology.\n        const topology = JSON.parse(this.LS.getItem(this.keys.topology));\n        if (topology == null) {\n            throw new Error(`In local storage, the topology of model '${this.modelPath}' ` +\n                `is missing.`);\n        }\n        out.modelTopology = topology;\n        // Load weight specs.\n        const weightSpecs = JSON.parse(this.LS.getItem(this.keys.weightSpecs));\n        if (weightSpecs == null) {\n            throw new Error(`In local storage, the weight specs of model '${this.modelPath}' ` +\n                `are missing.`);\n        }\n        out.weightSpecs = weightSpecs;\n        // Load meta-data fields.\n        const metadataString = this.LS.getItem(this.keys.modelMetadata);\n        if (metadataString != null) {\n            const metadata = JSON.parse(metadataString);\n            out.format = metadata['format'];\n            out.generatedBy = metadata['generatedBy'];\n            out.convertedBy = metadata['convertedBy'];\n            if (metadata['signature'] != null) {\n                out.signature = metadata['signature'];\n            }\n            if (metadata['userDefinedMetadata'] != null) {\n                out.userDefinedMetadata = metadata['userDefinedMetadata'];\n            }\n            if (metadata['modelInitializer'] != null) {\n                out.modelInitializer = metadata['modelInitializer'];\n            }\n        }\n        // Load weight data.\n        const weightDataBase64 = this.LS.getItem(this.keys.weightData);\n        if (weightDataBase64 == null) {\n            throw new Error(`In local storage, the binary weight values of model ` +\n                `'${this.modelPath}' are missing.`);\n        }\n        out.weightData = base64StringToArrayBuffer(weightDataBase64);\n        return out;\n    }\n}\nBrowserLocalStorage.URL_SCHEME = 'localstorage://';\nexport const localStorageRouter = (url) => {\n    if (!env().getBool('IS_BROWSER')) {\n        return null;\n    }\n    else {\n        if (!Array.isArray(url) && url.startsWith(BrowserLocalStorage.URL_SCHEME)) {\n            return browserLocalStorage(url.slice(BrowserLocalStorage.URL_SCHEME.length));\n        }\n        else {\n            return null;\n        }\n    }\n};\nIORouterRegistry.registerSaveRouter(localStorageRouter);\nIORouterRegistry.registerLoadRouter(localStorageRouter);\n/**\n * Factory function for local storage IOHandler.\n *\n * This `IOHandler` supports both `save` and `load`.\n *\n * For each model's saved artifacts, four items are saved to local storage.\n *   - `${PATH_SEPARATOR}/${modelPath}/info`: Contains meta-info about the\n *     model, such as date saved, type of the topology, size in bytes, etc.\n *   - `${PATH_SEPARATOR}/${modelPath}/topology`: Model topology. For Keras-\n *     style models, this is a stringized JSON.\n *   - `${PATH_SEPARATOR}/${modelPath}/weight_specs`: Weight specs of the\n *     model, can be used to decode the saved binary weight values (see\n *     item below).\n *   - `${PATH_SEPARATOR}/${modelPath}/weight_data`: Concatenated binary\n *     weight values, stored as a base64-encoded string.\n *\n * Saving may throw an `Error` if the total size of the artifacts exceed the\n * browser-specific quota.\n *\n * @param modelPath A unique identifier for the model to be saved. Must be a\n *   non-empty string.\n * @returns An instance of `IOHandler`, which can be used with, e.g.,\n *   `tf.Model.save`.\n */\nexport function browserLocalStorage(modelPath) {\n    return new BrowserLocalStorage(modelPath);\n}\nexport class BrowserLocalStorageManager {\n    constructor() {\n        assert(env().getBool('IS_BROWSER'), () => 'Current environment is not a web browser');\n        assert(typeof window === 'undefined' ||\n            typeof window.localStorage !== 'undefined', () => 'Current browser does not appear to support localStorage');\n        this.LS = window.localStorage;\n    }\n    async listModels() {\n        const out = {};\n        const prefix = PATH_PREFIX + PATH_SEPARATOR;\n        const suffix = PATH_SEPARATOR + INFO_SUFFIX;\n        for (let i = 0; i < this.LS.length; ++i) {\n            const key = this.LS.key(i);\n            if (key.startsWith(prefix) && key.endsWith(suffix)) {\n                const modelPath = getModelPathFromKey(key);\n                out[modelPath] = JSON.parse(this.LS.getItem(key));\n            }\n        }\n        return out;\n    }\n    async removeModel(path) {\n        path = maybeStripScheme(path);\n        const keys = getModelKeys(path);\n        if (this.LS.getItem(keys.info) == null) {\n            throw new Error(`Cannot find model at path '${path}'`);\n        }\n        const info = JSON.parse(this.LS.getItem(keys.info));\n        this.LS.removeItem(keys.info);\n        this.LS.removeItem(keys.topology);\n        this.LS.removeItem(keys.weightSpecs);\n        this.LS.removeItem(keys.weightData);\n        return info;\n    }\n}\n//# sourceMappingURL=local_storage.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n/**\n * IOHandlers related to files, such as browser-triggered file downloads,\n * user-selected files in browser.\n */\nimport '../flags';\nimport { env } from '../environment';\nimport { basename, concatenateArrayBuffers, getModelArtifactsInfoForJSON } from './io_utils';\nimport { IORouterRegistry } from './router_registry';\nconst DEFAULT_FILE_NAME_PREFIX = 'model';\nconst DEFAULT_JSON_EXTENSION_NAME = '.json';\nconst DEFAULT_WEIGHT_DATA_EXTENSION_NAME = '.weights.bin';\nfunction defer(f) {\n    return new Promise(resolve => setTimeout(resolve)).then(f);\n}\nexport class BrowserDownloads {\n    constructor(fileNamePrefix) {\n        if (!env().getBool('IS_BROWSER')) {\n            // TODO(cais): Provide info on what IOHandlers are available under the\n            //   current environment.\n            throw new Error('browserDownloads() cannot proceed because the current environment ' +\n                'is not a browser.');\n        }\n        if (fileNamePrefix.startsWith(BrowserDownloads.URL_SCHEME)) {\n            fileNamePrefix = fileNamePrefix.slice(BrowserDownloads.URL_SCHEME.length);\n        }\n        if (fileNamePrefix == null || fileNamePrefix.length === 0) {\n            fileNamePrefix = DEFAULT_FILE_NAME_PREFIX;\n        }\n        this.modelTopologyFileName = fileNamePrefix + DEFAULT_JSON_EXTENSION_NAME;\n        this.weightDataFileName =\n            fileNamePrefix + DEFAULT_WEIGHT_DATA_EXTENSION_NAME;\n    }\n    async save(modelArtifacts) {\n        if (typeof (document) === 'undefined') {\n            throw new Error('Browser downloads are not supported in ' +\n                'this environment since `document` is not present');\n        }\n        const weightsURL = window.URL.createObjectURL(new Blob([modelArtifacts.weightData], { type: 'application/octet-stream' }));\n        if (modelArtifacts.modelTopology instanceof ArrayBuffer) {\n            throw new Error('BrowserDownloads.save() does not support saving model topology ' +\n                'in binary formats yet.');\n        }\n        else {\n            const weightsManifest = [{\n                    paths: ['./' + this.weightDataFileName],\n                    weights: modelArtifacts.weightSpecs\n                }];\n            const modelTopologyAndWeightManifest = {\n                modelTopology: modelArtifacts.modelTopology,\n                format: modelArtifacts.format,\n                generatedBy: modelArtifacts.generatedBy,\n                convertedBy: modelArtifacts.convertedBy,\n                weightsManifest\n            };\n            if (modelArtifacts.signature != null) {\n                modelTopologyAndWeightManifest.signature = modelArtifacts.signature;\n            }\n            if (modelArtifacts.userDefinedMetadata != null) {\n                modelTopologyAndWeightManifest.userDefinedMetadata =\n                    modelArtifacts.userDefinedMetadata;\n            }\n            if (modelArtifacts.modelInitializer != null) {\n                modelTopologyAndWeightManifest.modelInitializer =\n                    modelArtifacts.modelInitializer;\n            }\n            const modelTopologyAndWeightManifestURL = window.URL.createObjectURL(new Blob([JSON.stringify(modelTopologyAndWeightManifest)], { type: 'application/json' }));\n            // If anchor elements are not provided, create them without attaching them\n            // to parents, so that the downloaded file names can be controlled.\n            const jsonAnchor = this.jsonAnchor == null ? document.createElement('a') :\n                this.jsonAnchor;\n            jsonAnchor.download = this.modelTopologyFileName;\n            jsonAnchor.href = modelTopologyAndWeightManifestURL;\n            // Trigger downloads by evoking a click event on the download anchors.\n            // When multiple downloads are started synchronously, Firefox will only\n            // save the last one.\n            await defer(() => jsonAnchor.dispatchEvent(new MouseEvent('click')));\n            if (modelArtifacts.weightData != null) {\n                const weightDataAnchor = this.weightDataAnchor == null ?\n                    document.createElement('a') :\n                    this.weightDataAnchor;\n                weightDataAnchor.download = this.weightDataFileName;\n                weightDataAnchor.href = weightsURL;\n                await defer(() => weightDataAnchor.dispatchEvent(new MouseEvent('click')));\n            }\n            return { modelArtifactsInfo: getModelArtifactsInfoForJSON(modelArtifacts) };\n        }\n    }\n}\nBrowserDownloads.URL_SCHEME = 'downloads://';\nclass BrowserFiles {\n    constructor(files) {\n        if (files == null || files.length < 1) {\n            throw new Error(`When calling browserFiles, at least 1 file is required, ` +\n                `but received ${files}`);\n        }\n        this.files = files;\n    }\n    async load() {\n        const jsonFile = this.files[0];\n        const weightFiles = this.files.slice(1);\n        return new Promise((resolve, reject) => {\n            const jsonReader = new FileReader();\n            jsonReader.onload = (event) => {\n                // tslint:disable-next-line:no-any\n                const modelJSON = JSON.parse(event.target.result);\n                const modelTopology = modelJSON.modelTopology;\n                if (modelTopology == null) {\n                    reject(new Error(`modelTopology field is missing from file ${jsonFile.name}`));\n                    return;\n                }\n                if (weightFiles.length === 0) {\n                    resolve({ modelTopology });\n                }\n                const weightsManifest = modelJSON.weightsManifest;\n                if (weightsManifest == null) {\n                    reject(new Error(`weightManifest field is missing from file ${jsonFile.name}`));\n                    return;\n                }\n                let pathToFile;\n                try {\n                    pathToFile =\n                        this.checkManifestAndWeightFiles(weightsManifest, weightFiles);\n                }\n                catch (err) {\n                    reject(err);\n                    return;\n                }\n                const weightSpecs = [];\n                const paths = [];\n                const perFileBuffers = [];\n                weightsManifest.forEach(weightsGroup => {\n                    weightsGroup.paths.forEach(path => {\n                        paths.push(path);\n                        perFileBuffers.push(null);\n                    });\n                    weightSpecs.push(...weightsGroup.weights);\n                });\n                weightsManifest.forEach(weightsGroup => {\n                    weightsGroup.paths.forEach(path => {\n                        const weightFileReader = new FileReader();\n                        weightFileReader.onload = (event) => {\n                            // tslint:disable-next-line:no-any\n                            const weightData = event.target.result;\n                            const index = paths.indexOf(path);\n                            perFileBuffers[index] = weightData;\n                            if (perFileBuffers.indexOf(null) === -1) {\n                                const result = {\n                                    modelTopology,\n                                    weightSpecs,\n                                    weightData: concatenateArrayBuffers(perFileBuffers),\n                                    format: modelJSON.format,\n                                    generatedBy: modelJSON.generatedBy,\n                                    convertedBy: modelJSON.convertedBy\n                                };\n                                if (modelJSON.signature != null) {\n                                    result.signature = modelJSON.signature;\n                                }\n                                if (modelJSON.userDefinedMetadata != null) {\n                                    result.userDefinedMetadata = modelJSON.userDefinedMetadata;\n                                }\n                                if (modelJSON.modelInitializer != null) {\n                                    result.modelInitializer = modelJSON.modelInitializer;\n                                }\n                                resolve(result);\n                            }\n                        };\n                        weightFileReader.onerror = error => reject(`Failed to weights data from file of path '${path}'.`);\n                        weightFileReader.readAsArrayBuffer(pathToFile[path]);\n                    });\n                });\n            };\n            jsonReader.onerror = error => reject(`Failed to read model topology and weights manifest JSON ` +\n                `from file '${jsonFile.name}'. BrowserFiles supports loading ` +\n                `Keras-style tf.Model artifacts only.`);\n            jsonReader.readAsText(jsonFile);\n        });\n    }\n    /**\n     * Check the compatibility between weights manifest and weight files.\n     */\n    checkManifestAndWeightFiles(manifest, files) {\n        const basenames = [];\n        const fileNames = files.map(file => basename(file.name));\n        const pathToFile = {};\n        for (const group of manifest) {\n            group.paths.forEach(path => {\n                const pathBasename = basename(path);\n                if (basenames.indexOf(pathBasename) !== -1) {\n                    throw new Error(`Duplicate file basename found in weights manifest: ` +\n                        `'${pathBasename}'`);\n                }\n                basenames.push(pathBasename);\n                if (fileNames.indexOf(pathBasename) === -1) {\n                    throw new Error(`Weight file with basename '${pathBasename}' is not provided.`);\n                }\n                else {\n                    pathToFile[path] = files[fileNames.indexOf(pathBasename)];\n                }\n            });\n        }\n        if (basenames.length !== files.length) {\n            throw new Error(`Mismatch in the number of files in weights manifest ` +\n                `(${basenames.length}) and the number of weight files provided ` +\n                `(${files.length}).`);\n        }\n        return pathToFile;\n    }\n}\nexport const browserDownloadsRouter = (url) => {\n    if (!env().getBool('IS_BROWSER')) {\n        return null;\n    }\n    else {\n        if (!Array.isArray(url) && url.startsWith(BrowserDownloads.URL_SCHEME)) {\n            return browserDownloads(url.slice(BrowserDownloads.URL_SCHEME.length));\n        }\n        else {\n            return null;\n        }\n    }\n};\nIORouterRegistry.registerSaveRouter(browserDownloadsRouter);\n/**\n * Creates an IOHandler that triggers file downloads from the browser.\n *\n * The returned `IOHandler` instance can be used as model exporting methods such\n * as `tf.Model.save` and supports only saving.\n *\n * ```js\n * const model = tf.sequential();\n * model.add(tf.layers.dense(\n *     {units: 1, inputShape: [10], activation: 'sigmoid'}));\n * const saveResult = await model.save('downloads://mymodel');\n * // This will trigger downloading of two files:\n * //   'mymodel.json' and 'mymodel.weights.bin'.\n * console.log(saveResult);\n * ```\n *\n * @param fileNamePrefix Prefix name of the files to be downloaded. For use with\n *   `tf.Model`, `fileNamePrefix` should follow either of the following two\n *   formats:\n *   1. `null` or `undefined`, in which case the default file\n *      names will be used:\n *      - 'model.json' for the JSON file containing the model topology and\n *        weights manifest.\n *      - 'model.weights.bin' for the binary file containing the binary weight\n *        values.\n *   2. A single string or an Array of a single string, as the file name prefix.\n *      For example, if `'foo'` is provided, the downloaded JSON\n *      file and binary weights file will be named 'foo.json' and\n *      'foo.weights.bin', respectively.\n * @param config Additional configuration for triggering downloads.\n * @returns An instance of `BrowserDownloads` `IOHandler`.\n *\n * @doc {\n *   heading: 'Models',\n *   subheading: 'Loading',\n *   namespace: 'io',\n *   ignoreCI: true\n * }\n */\nexport function browserDownloads(fileNamePrefix = 'model') {\n    return new BrowserDownloads(fileNamePrefix);\n}\n/**\n * Creates an IOHandler that loads model artifacts from user-selected files.\n *\n * This method can be used for loading from files such as user-selected files\n * in the browser.\n * When used in conjunction with `tf.loadLayersModel`, an instance of\n * `tf.LayersModel` (Keras-style) can be constructed from the loaded artifacts.\n *\n * ```js\n * // Note: This code snippet won't run properly without the actual file input\n * //   elements in the HTML DOM.\n *\n * // Suppose there are two HTML file input (`<input type=\"file\" ...>`)\n * // elements.\n * const uploadJSONInput = document.getElementById('upload-json');\n * const uploadWeightsInput = document.getElementById('upload-weights');\n * const model = await tf.loadLayersModel(tf.io.browserFiles(\n *     [uploadJSONInput.files[0], uploadWeightsInput.files[0]]));\n * ```\n *\n * @param files `File`s to load from. Currently, this function supports only\n *   loading from files that contain Keras-style models (i.e., `tf.Model`s), for\n *   which an `Array` of `File`s is expected (in that order):\n *   - A JSON file containing the model topology and weight manifest.\n *   - Optionally, One or more binary files containing the binary weights.\n *     These files must have names that match the paths in the `weightsManifest`\n *     contained by the aforementioned JSON file, or errors will be thrown\n *     during loading. These weights files have the same format as the ones\n *     generated by `tensorflowjs_converter` that comes with the `tensorflowjs`\n *     Python PIP package. If no weights files are provided, only the model\n *     topology will be loaded from the JSON file above.\n * @returns An instance of `Files` `IOHandler`.\n *\n * @doc {\n *   heading: 'Models',\n *   subheading: 'Loading',\n *   namespace: 'io',\n *   ignoreCI: true\n * }\n */\nexport function browserFiles(files) {\n    return new BrowserFiles(files);\n}\n//# sourceMappingURL=browser_files.js.map","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { assert } from '../util';\n/**\n * Monitor Promise.all progress, fire onProgress callback function.\n *\n * @param promises Promise list going to be monitored\n * @param onProgress Callback function. Fired when a promise resolved.\n * @param startFraction Optional fraction start. Default to 0.\n * @param endFraction Optional fraction end. Default to 1.\n */\nexport function monitorPromisesProgress(promises, onProgress, startFraction, endFraction) {\n    checkPromises(promises);\n    startFraction = startFraction == null ? 0 : startFraction;\n    endFraction = endFraction == null ? 1 : endFraction;\n    checkFraction(startFraction, endFraction);\n    let resolvedPromise = 0;\n    const registerMonitor = (promise) => {\n        promise.then(value => {\n            const fraction = startFraction +\n                ++resolvedPromise / promises.length * (endFraction - startFraction);\n            // pass fraction as parameter to callback function.\n            onProgress(fraction);\n            return value;\n        });\n        return promise;\n    };\n    function checkPromises(promises) {\n        assert(promises != null && Array.isArray(promises) && promises.length > 0, () => 'promises must be a none empty array');\n    }\n    function checkFraction(startFraction, endFraction) {\n        assert(startFraction >= 0 && startFraction <= 1, () => `Progress fraction must be in range [0, 1], but ` +\n            `got startFraction ${startFraction}`);\n        assert(endFraction >= 0 && endFraction <= 1, () => `Progress fraction must be in range [0, 1], but ` +\n            `got endFraction ${endFraction}`);\n        assert(endFraction >= startFraction, () => `startFraction must be no more than endFraction, but ` +\n            `got startFraction ${startFraction} and endFraction ` +\n            `${endFraction}`);\n    }\n    return Promise.all(promises.map(registerMonitor));\n}\n//# sourceMappingURL=progress.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { env } from '../environment';\nimport * as util from '../util';\nimport { decodeWeights } from './io_utils';\nimport { monitorPromisesProgress } from './progress';\nimport { DTYPE_VALUE_SIZE_MAP } from './types';\n/**\n * Reads binary weights data from a number of URLs.\n *\n * @param fetchURLs URLs to send the HTTP requests at, using `fetch` calls.\n * @param requestOptions RequestInit (options) for the HTTP requests.\n * @param fetchFunc Optional overriding value for the `window.fetch` function.\n * @param onProgress Optional, progress callback function, fired periodically\n *   before the load is completed.\n * @returns A `Promise` of an Array of `ArrayBuffer`. The Array has the same\n *   length as `fetchURLs`.\n */\nexport async function loadWeightsAsArrayBuffer(fetchURLs, loadOptions) {\n    if (loadOptions == null) {\n        loadOptions = {};\n    }\n    const fetchFunc = loadOptions.fetchFunc == null ? env().platform.fetch :\n        loadOptions.fetchFunc;\n    // Create the requests for all of the weights in parallel.\n    const requests = fetchURLs.map(fetchURL => fetchFunc(fetchURL, loadOptions.requestInit, { isBinary: true }));\n    const fetchStartFraction = 0;\n    const fetchEndFraction = 0.5;\n    const responses = loadOptions.onProgress == null ?\n        await Promise.all(requests) :\n        await monitorPromisesProgress(requests, loadOptions.onProgress, fetchStartFraction, fetchEndFraction);\n    const bufferPromises = responses.map(response => response.arrayBuffer());\n    const bufferStartFraction = 0.5;\n    const bufferEndFraction = 1;\n    const buffers = loadOptions.onProgress == null ?\n        await Promise.all(bufferPromises) :\n        await monitorPromisesProgress(bufferPromises, loadOptions.onProgress, bufferStartFraction, bufferEndFraction);\n    return buffers;\n}\n/**\n * Reads a weights manifest JSON configuration, fetches the weights and\n * returns them as `Tensor`s.\n *\n * @param manifest The weights manifest JSON.\n * @param filePathPrefix The path prefix for filenames given in the manifest.\n *     Defaults to the empty string.\n * @param weightNames The names of the weights to be fetched.\n */\nexport async function loadWeights(manifest, filePathPrefix = '', weightNames, requestInit) {\n    // TODO(nsthorat): Groups are currently fetched atomically. If you need a\n    // single weight from a group, the whole group will be fetched. At a future\n    // date, we should support fetching only the individual shards within a\n    // group that are needed to reconstruct the requested weight.\n    // TODO(cais): Use `decodeWeights` for implementation.\n    const fetchWeights = (fetchUrls) => loadWeightsAsArrayBuffer(fetchUrls, { requestInit });\n    const loadWeights = weightsLoaderFactory(fetchWeights);\n    return loadWeights(manifest, filePathPrefix, weightNames);\n}\n/**\n * Creates a function, which reads a weights manifest JSON configuration,\n * fetches the weight files using the specified function and returns them as\n * `Tensor`s.\n *\n * ```js\n * // example for creating a nodejs weight loader, which reads the weight files\n * // from disk using fs.readFileSync\n *\n * import * as fs from 'fs'\n *\n * const fetchWeightsFromDisk = (filePaths: string[]) =>\n *   filePaths.map(filePath => fs.readFileSync(filePath).buffer)\n *\n * const loadWeights = tf.io.weightsLoaderFactory(fetchWeightsFromDisk)\n *\n * const manifest = JSON.parse(\n *   fs.readFileSync('./my_model-weights_manifest').toString()\n * )\n * const weightMap = await loadWeights(manifest, './')\n * ```\n * @param fetchWeightsFunction The function used for fetching the weight files.\n * @returns Weight loading function.\n */\nexport function weightsLoaderFactory(fetchWeightsFunction) {\n    return async (manifest, filePathPrefix = '', weightNames) => {\n        // Collect all the groups, weights, and their relative offsets to be\n        // fetched.\n        const groupIndicesToFetchMap = manifest.map(() => false);\n        const groupWeightsToFetch = {};\n        const weightsFound = weightNames != null ? weightNames.map(() => false) : [];\n        const allManifestWeightNames = [];\n        manifest.forEach((manifestGroupConfig, groupIndex) => {\n            let groupOffset = 0;\n            manifestGroupConfig.weights.forEach(weightsEntry => {\n                const rawDtype = ('quantization' in weightsEntry) ?\n                    weightsEntry.quantization.dtype :\n                    weightsEntry.dtype;\n                const weightsBytes = DTYPE_VALUE_SIZE_MAP[rawDtype] *\n                    util.sizeFromShape(weightsEntry.shape);\n                const enqueueWeightsForFetchingFn = () => {\n                    groupIndicesToFetchMap[groupIndex] = true;\n                    if (groupWeightsToFetch[groupIndex] == null) {\n                        groupWeightsToFetch[groupIndex] = [];\n                    }\n                    groupWeightsToFetch[groupIndex].push({\n                        manifestEntry: weightsEntry,\n                        groupOffset,\n                        sizeBytes: weightsBytes\n                    });\n                };\n                if (weightNames != null) {\n                    weightNames.forEach((weightName, weightIndex) => {\n                        if (weightName === weightsEntry.name) {\n                            enqueueWeightsForFetchingFn();\n                            weightsFound[weightIndex] = true;\n                        }\n                    });\n                }\n                else {\n                    enqueueWeightsForFetchingFn();\n                }\n                allManifestWeightNames.push(weightsEntry.name);\n                groupOffset += weightsBytes;\n            });\n        });\n        if (!weightsFound.every(found => found)) {\n            const weightsNotFound = weightNames.filter((_, i) => !weightsFound[i]);\n            throw new Error(`Could not find weights in manifest with names: ` +\n                `${weightsNotFound.join(', ')}. \\n` +\n                `Manifest JSON has weights with names: ` +\n                `${allManifestWeightNames.join(', ')}.`);\n        }\n        // Convert the one-hot boolean groupId => shouldFetch map to a list of group\n        // IDs.\n        const groupIndicesToFetch = groupIndicesToFetchMap.reduce((accumulator, shouldFetch, i) => {\n            if (shouldFetch) {\n                accumulator.push(i);\n            }\n            return accumulator;\n        }, []);\n        const fetchUrls = [];\n        groupIndicesToFetch.forEach(i => {\n            manifest[i].paths.forEach(filepath => {\n                const fetchUrl = filePathPrefix +\n                    (!filePathPrefix.endsWith('/') ? '/' : '') + filepath;\n                fetchUrls.push(fetchUrl);\n            });\n        });\n        const buffers = await fetchWeightsFunction(fetchUrls);\n        const weightsTensorMap = {};\n        let bufferIndexOffset = 0;\n        groupIndicesToFetch.forEach(i => {\n            const numBuffers = manifest[i].paths.length;\n            let groupBytes = 0;\n            for (let i = 0; i < numBuffers; i++) {\n                groupBytes += buffers[bufferIndexOffset + i].byteLength;\n            }\n            // Create a buffer for the whole group.\n            const groupBuffer = new ArrayBuffer(groupBytes);\n            const groupByteBuffer = new Uint8Array(groupBuffer);\n            let groupBufferOffset = 0;\n            for (let i = 0; i < numBuffers; i++) {\n                const buffer = new Uint8Array(buffers[bufferIndexOffset + i]);\n                groupByteBuffer.set(buffer, groupBufferOffset);\n                groupBufferOffset += buffer.byteLength;\n            }\n            const weightsEntries = groupWeightsToFetch[i];\n            weightsEntries.forEach(weightsEntry => {\n                const byteBuffer = groupBuffer.slice(weightsEntry.groupOffset, weightsEntry.groupOffset + weightsEntry.sizeBytes);\n                const nameToTensorMap = decodeWeights(byteBuffer, [weightsEntry.manifestEntry]);\n                for (const name in nameToTensorMap) {\n                    weightsTensorMap[name] = nameToTensorMap[name];\n                }\n            });\n            bufferIndexOffset += numBuffers;\n        });\n        return weightsTensorMap;\n    };\n}\n//# sourceMappingURL=weights_loader.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n/**\n * IOHandler implementations based on HTTP requests in the web browser.\n *\n * Uses [`fetch`](https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API).\n */\nimport { env } from '../environment';\nimport { assert } from '../util';\nimport { concatenateArrayBuffers, getModelArtifactsInfoForJSON } from './io_utils';\nimport { IORouterRegistry } from './router_registry';\nimport { loadWeightsAsArrayBuffer } from './weights_loader';\nconst OCTET_STREAM_MIME_TYPE = 'application/octet-stream';\nconst JSON_TYPE = 'application/json';\nexport class HTTPRequest {\n    constructor(path, loadOptions) {\n        this.DEFAULT_METHOD = 'POST';\n        if (loadOptions == null) {\n            loadOptions = {};\n        }\n        this.weightPathPrefix = loadOptions.weightPathPrefix;\n        this.onProgress = loadOptions.onProgress;\n        this.weightUrlConverter = loadOptions.weightUrlConverter;\n        if (loadOptions.fetchFunc != null) {\n            assert(typeof loadOptions.fetchFunc === 'function', () => 'Must pass a function that matches the signature of ' +\n                '`fetch` (see ' +\n                'https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API)');\n            this.fetch = loadOptions.fetchFunc;\n        }\n        else {\n            this.fetch = env().platform.fetch;\n        }\n        assert(path != null && path.length > 0, () => 'URL path for http must not be null, undefined or ' +\n            'empty.');\n        if (Array.isArray(path)) {\n            assert(path.length === 2, () => 'URL paths for http must have a length of 2, ' +\n                `(actual length is ${path.length}).`);\n        }\n        this.path = path;\n        if (loadOptions.requestInit != null &&\n            loadOptions.requestInit.body != null) {\n            throw new Error('requestInit is expected to have no pre-existing body, but has one.');\n        }\n        this.requestInit = loadOptions.requestInit || {};\n    }\n    async save(modelArtifacts) {\n        if (modelArtifacts.modelTopology instanceof ArrayBuffer) {\n            throw new Error('BrowserHTTPRequest.save() does not support saving model topology ' +\n                'in binary formats yet.');\n        }\n        const init = Object.assign({ method: this.DEFAULT_METHOD }, this.requestInit);\n        init.body = new FormData();\n        const weightsManifest = [{\n                paths: ['./model.weights.bin'],\n                weights: modelArtifacts.weightSpecs,\n            }];\n        const modelTopologyAndWeightManifest = {\n            modelTopology: modelArtifacts.modelTopology,\n            format: modelArtifacts.format,\n            generatedBy: modelArtifacts.generatedBy,\n            convertedBy: modelArtifacts.convertedBy,\n            weightsManifest\n        };\n        if (modelArtifacts.signature != null) {\n            modelTopologyAndWeightManifest.signature = modelArtifacts.signature;\n        }\n        if (modelArtifacts.userDefinedMetadata != null) {\n            modelTopologyAndWeightManifest.userDefinedMetadata =\n                modelArtifacts.userDefinedMetadata;\n        }\n        if (modelArtifacts.modelInitializer != null) {\n            modelTopologyAndWeightManifest.modelInitializer =\n                modelArtifacts.modelInitializer;\n        }\n        init.body.append('model.json', new Blob([JSON.stringify(modelTopologyAndWeightManifest)], { type: JSON_TYPE }), 'model.json');\n        if (modelArtifacts.weightData != null) {\n            init.body.append('model.weights.bin', new Blob([modelArtifacts.weightData], { type: OCTET_STREAM_MIME_TYPE }), 'model.weights.bin');\n        }\n        const response = await this.fetch(this.path, init);\n        if (response.ok) {\n            return {\n                modelArtifactsInfo: getModelArtifactsInfoForJSON(modelArtifacts),\n                responses: [response],\n            };\n        }\n        else {\n            throw new Error(`BrowserHTTPRequest.save() failed due to HTTP response status ` +\n                `${response.status}.`);\n        }\n    }\n    /**\n     * Load model artifacts via HTTP request(s).\n     *\n     * See the documentation to `tf.io.http` for details on the saved\n     * artifacts.\n     *\n     * @returns The loaded model artifacts (if loading succeeds).\n     */\n    async load() {\n        const modelConfigRequest = await this.fetch(this.path, this.requestInit);\n        if (!modelConfigRequest.ok) {\n            throw new Error(`Request to ${this.path} failed with status code ` +\n                `${modelConfigRequest.status}. Please verify this URL points to ` +\n                `the model JSON of the model to load.`);\n        }\n        let modelConfig;\n        try {\n            modelConfig = await modelConfigRequest.json();\n        }\n        catch (e) {\n            let message = `Failed to parse model JSON of response from ${this.path}.`;\n            // TODO(nsthorat): Remove this after some time when we're comfortable that\n            // .pb files are mostly gone.\n            if (this.path.endsWith('.pb')) {\n                message += ' Your path contains a .pb file extension. ' +\n                    'Support for .pb models have been removed in TensorFlow.js 1.0 ' +\n                    'in favor of .json models. You can re-convert your Python ' +\n                    'TensorFlow model using the TensorFlow.js 1.0 conversion scripts ' +\n                    'or you can convert your.pb models with the \\'pb2json\\'' +\n                    'NPM script in the tensorflow/tfjs-converter repository.';\n            }\n            else {\n                message += ' Please make sure the server is serving valid ' +\n                    'JSON for this request.';\n            }\n            throw new Error(message);\n        }\n        const modelTopology = modelConfig.modelTopology;\n        const weightsManifest = modelConfig.weightsManifest;\n        const generatedBy = modelConfig.generatedBy;\n        const convertedBy = modelConfig.convertedBy;\n        const format = modelConfig.format;\n        const signature = modelConfig.signature;\n        const userDefinedMetadata = modelConfig.userDefinedMetadata;\n        // We do not allow both modelTopology and weightsManifest to be missing.\n        if (modelTopology == null && weightsManifest == null) {\n            throw new Error(`The JSON from HTTP path ${this.path} contains neither model ` +\n                `topology or manifest for weights.`);\n        }\n        let weightSpecs;\n        let weightData;\n        if (weightsManifest != null) {\n            const results = await this.loadWeights(weightsManifest);\n            [weightSpecs, weightData] = results;\n        }\n        const artifacts = {\n            modelTopology,\n            weightSpecs,\n            weightData,\n            generatedBy,\n            convertedBy,\n            format\n        };\n        if (signature != null) {\n            artifacts.signature = signature;\n        }\n        if (userDefinedMetadata != null) {\n            artifacts.userDefinedMetadata = userDefinedMetadata;\n        }\n        const initializer = modelConfig.modelInitializer;\n        if (initializer) {\n            artifacts.modelInitializer = initializer;\n        }\n        return artifacts;\n    }\n    async loadWeights(weightsManifest) {\n        const weightPath = Array.isArray(this.path) ? this.path[1] : this.path;\n        const [prefix, suffix] = parseUrl(weightPath);\n        const pathPrefix = this.weightPathPrefix || prefix;\n        const weightSpecs = [];\n        for (const entry of weightsManifest) {\n            weightSpecs.push(...entry.weights);\n        }\n        const fetchURLs = [];\n        const urlPromises = [];\n        for (const weightsGroup of weightsManifest) {\n            for (const path of weightsGroup.paths) {\n                if (this.weightUrlConverter != null) {\n                    urlPromises.push(this.weightUrlConverter(path));\n                }\n                else {\n                    fetchURLs.push(pathPrefix + path + suffix);\n                }\n            }\n        }\n        if (this.weightUrlConverter) {\n            fetchURLs.push(...await Promise.all(urlPromises));\n        }\n        const buffers = await loadWeightsAsArrayBuffer(fetchURLs, {\n            requestInit: this.requestInit,\n            fetchFunc: this.fetch,\n            onProgress: this.onProgress\n        });\n        return [weightSpecs, concatenateArrayBuffers(buffers)];\n    }\n}\nHTTPRequest.URL_SCHEME_REGEX = /^https?:\\/\\//;\n/**\n * Extract the prefix and suffix of the url, where the prefix is the path before\n * the last file, and suffix is the search params after the last file.\n * ```\n * const url = 'http://tfhub.dev/model/1/tensorflowjs_model.pb?tfjs-format=file'\n * [prefix, suffix] = parseUrl(url)\n * // prefix = 'http://tfhub.dev/model/1/'\n * // suffix = '?tfjs-format=file'\n * ```\n * @param url the model url to be parsed.\n */\nexport function parseUrl(url) {\n    const lastSlash = url.lastIndexOf('/');\n    const lastSearchParam = url.lastIndexOf('?');\n    const prefix = url.substring(0, lastSlash);\n    const suffix = lastSearchParam > lastSlash ? url.substring(lastSearchParam) : '';\n    return [prefix + '/', suffix];\n}\nexport function isHTTPScheme(url) {\n    return url.match(HTTPRequest.URL_SCHEME_REGEX) != null;\n}\nexport const httpRouter = (url, loadOptions) => {\n    if (typeof fetch === 'undefined' &&\n        (loadOptions == null || loadOptions.fetchFunc == null)) {\n        // `http` uses `fetch` or `node-fetch`, if one wants to use it in\n        // an environment that is not the browser or node they have to setup a\n        // global fetch polyfill.\n        return null;\n    }\n    else {\n        let isHTTP = true;\n        if (Array.isArray(url)) {\n            isHTTP = url.every(urlItem => isHTTPScheme(urlItem));\n        }\n        else {\n            isHTTP = isHTTPScheme(url);\n        }\n        if (isHTTP) {\n            return http(url, loadOptions);\n        }\n    }\n    return null;\n};\nIORouterRegistry.registerSaveRouter(httpRouter);\nIORouterRegistry.registerLoadRouter(httpRouter);\n/**\n * Creates an IOHandler subtype that sends model artifacts to HTTP server.\n *\n * An HTTP request of the `multipart/form-data` mime type will be sent to the\n * `path` URL. The form data includes artifacts that represent the topology\n * and/or weights of the model. In the case of Keras-style `tf.Model`, two\n * blobs (files) exist in form-data:\n *   - A JSON file consisting of `modelTopology` and `weightsManifest`.\n *   - A binary weights file consisting of the concatenated weight values.\n * These files are in the same format as the one generated by\n * [tfjs_converter](https://js.tensorflow.org/tutorials/import-keras.html).\n *\n * The following code snippet exemplifies the client-side code that uses this\n * function:\n *\n * ```js\n * const model = tf.sequential();\n * model.add(\n *     tf.layers.dense({units: 1, inputShape: [100], activation: 'sigmoid'}));\n *\n * const saveResult = await model.save(tf.io.http(\n *     'http://model-server:5000/upload', {requestInit: {method: 'PUT'}}));\n * console.log(saveResult);\n * ```\n *\n * If the default `POST` method is to be used, without any custom parameters\n * such as headers, you can simply pass an HTTP or HTTPS URL to `model.save`:\n *\n * ```js\n * const saveResult = await model.save('http://model-server:5000/upload');\n * ```\n *\n * The following GitHub Gist\n * https://gist.github.com/dsmilkov/1b6046fd6132d7408d5257b0976f7864\n * implements a server based on [flask](https://github.com/pallets/flask) that\n * can receive the request. Upon receiving the model artifacts via the requst,\n * this particular server reconsistutes instances of [Keras\n * Models](https://keras.io/models/model/) in memory.\n *\n *\n * @param path A URL path to the model.\n *   Can be an absolute HTTP path (e.g.,\n *   'http://localhost:8000/model-upload)') or a relative path (e.g.,\n *   './model-upload').\n * @param requestInit Request configurations to be used when sending\n *    HTTP request to server using `fetch`. It can contain fields such as\n *    `method`, `credentials`, `headers`, `mode`, etc. See\n *    https://developer.mozilla.org/en-US/docs/Web/API/Request/Request\n *    for more information. `requestInit` must not have a body, because the\n * body will be set by TensorFlow.js. File blobs representing the model\n * topology (filename: 'model.json') and the weights of the model (filename:\n * 'model.weights.bin') will be appended to the body. If `requestInit` has a\n * `body`, an Error will be thrown.\n * @param loadOptions Optional configuration for the loading. It includes the\n *   following fields:\n *   - weightPathPrefix Optional, this specifies the path prefix for weight\n *     files, by default this is calculated from the path param.\n *   - fetchFunc Optional, custom `fetch` function. E.g., in Node.js,\n *     the `fetch` from node-fetch can be used here.\n *   - onProgress Optional, progress callback function, fired periodically\n *     before the load is completed.\n * @returns An instance of `IOHandler`.\n *\n * @doc {\n *   heading: 'Models',\n *   subheading: 'Loading',\n *   namespace: 'io',\n *   ignoreCI: true\n * }\n */\nexport function http(path, loadOptions) {\n    return new HTTPRequest(path, loadOptions);\n}\n/**\n * Deprecated. Use `tf.io.http`.\n * @param path\n * @param loadOptions\n */\nexport function browserHTTPRequest(path, loadOptions) {\n    return http(path, loadOptions);\n}\n//# sourceMappingURL=http.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nclass PassthroughLoader {\n    constructor(modelArtifacts) {\n        this.modelArtifacts = modelArtifacts;\n    }\n    async load() {\n        return this.modelArtifacts;\n    }\n}\nclass PassthroughSaver {\n    constructor(saveHandler) {\n        this.saveHandler = saveHandler;\n    }\n    async save(modelArtifacts) {\n        return this.saveHandler(modelArtifacts);\n    }\n}\n/**\n * Creates an IOHandler that loads model artifacts from memory.\n *\n * When used in conjunction with `tf.loadLayersModel`, an instance of\n * `tf.LayersModel` (Keras-style) can be constructed from the loaded artifacts.\n *\n * ```js\n * const model = await tf.loadLayersModel(tf.io.fromMemory(\n *     modelTopology, weightSpecs, weightData));\n * ```\n *\n * @param modelArtifacts a object containing model topology (i.e., parsed from\n *   the JSON format).\n * @param weightSpecs An array of `WeightsManifestEntry` objects describing the\n *   names, shapes, types, and quantization of the weight data.\n * @param weightData A single `ArrayBuffer` containing the weight data,\n *   concatenated in the order described by the weightSpecs.\n * @param trainingConfig Model training configuration. Optional.\n *\n * @returns A passthrough `IOHandler` that simply loads the provided data.\n */\nexport function fromMemory(modelArtifacts, weightSpecs, weightData, trainingConfig) {\n    if (arguments.length === 1) {\n        const isModelArtifacts = modelArtifacts.modelTopology != null ||\n            modelArtifacts.weightSpecs != null;\n        if (isModelArtifacts) {\n            return new PassthroughLoader(modelArtifacts);\n        }\n        else {\n            // Legacy support: with only modelTopology.\n            // TODO(cais): Remove this deprecated API.\n            console.warn('Please call tf.io.fromMemory() with only one argument. ' +\n                'The argument should be of type ModelArtifacts. ' +\n                'The multi-argument signature of tf.io.fromMemory() has been ' +\n                'deprecated and will be removed in a future release.');\n            return new PassthroughLoader({ modelTopology: modelArtifacts });\n        }\n    }\n    else {\n        // Legacy support.\n        // TODO(cais): Remove this deprecated API.\n        console.warn('Please call tf.io.fromMemory() with only one argument. ' +\n            'The argument should be of type ModelArtifacts. ' +\n            'The multi-argument signature of tf.io.fromMemory() has been ' +\n            'deprecated and will be removed in a future release.');\n        return new PassthroughLoader({\n            modelTopology: modelArtifacts,\n            weightSpecs,\n            weightData,\n            trainingConfig\n        });\n    }\n}\n/**\n * Creates an IOHandler that passes saved model artifacts to a callback.\n *\n * ```js\n * function handleSave(artifacts) {\n *   // ... do something with the artifacts ...\n *   return {modelArtifactsInfo: {...}, ...};\n * }\n *\n * const saveResult = model.save(tf.io.withSaveHandler(handleSave));\n * ```\n *\n * @param saveHandler A function that accepts a `ModelArtifacts` and returns a\n *     `SaveResult`.\n */\nexport function withSaveHandler(saveHandler) {\n    return new PassthroughSaver(saveHandler);\n}\n//# sourceMappingURL=passthrough.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { complex } from '../ops/complex';\nimport { tensor } from '../ops/tensor';\nimport { sizeFromShape } from '../util';\nimport { DTYPE_VALUE_SIZE_MAP } from './types';\n/** Number of bytes reserved for the length of the string. (32bit integer). */\nconst NUM_BYTES_STRING_LENGTH = 4;\n/**\n * Encode a map from names to weight values as an ArrayBuffer, along with an\n * `Array` of `WeightsManifestEntry` as specification of the encoded weights.\n *\n * This function does not perform sharding.\n *\n * This function is the reverse of `decodeWeights`.\n *\n * @param tensors A map (\"dict\") from names to tensors.\n * @param group Group to which the weights belong (optional).\n * @returns A `Promise` of\n *   - A flat `ArrayBuffer` with all the binary values of the `Tensor`s\n *     concatenated.\n *   - An `Array` of `WeightManifestEntry`s, carrying information including\n *     tensor names, `dtype`s and shapes.\n * @throws Error: on unsupported tensor `dtype`.\n */\nexport async function encodeWeights(tensors, group) {\n    // TODO(adarob, cais): Support quantization.\n    const specs = [];\n    const dataPromises = [];\n    const names = Array.isArray(tensors) ?\n        tensors.map(tensor => tensor.name) :\n        Object.keys(tensors);\n    for (let i = 0; i < names.length; ++i) {\n        const name = names[i];\n        const t = Array.isArray(tensors) ? tensors[i].tensor : tensors[name];\n        if (t.dtype !== 'float32' && t.dtype !== 'int32' && t.dtype !== 'bool' &&\n            t.dtype !== 'string' && t.dtype !== 'complex64') {\n            throw new Error(`Unsupported dtype in weight '${name}': ${t.dtype}`);\n        }\n        const spec = { name, shape: t.shape, dtype: t.dtype };\n        if (t.dtype === 'string') {\n            const utf8bytes = new Promise(async (resolve) => {\n                const vals = await t.bytes();\n                const totalNumBytes = vals.reduce((p, c) => p + c.length, 0) +\n                    NUM_BYTES_STRING_LENGTH * vals.length;\n                const bytes = new Uint8Array(totalNumBytes);\n                let offset = 0;\n                for (let i = 0; i < vals.length; i++) {\n                    const val = vals[i];\n                    const bytesOfLength = new Uint8Array(new Uint32Array([val.length]).buffer);\n                    bytes.set(bytesOfLength, offset);\n                    offset += NUM_BYTES_STRING_LENGTH;\n                    bytes.set(val, offset);\n                    offset += val.length;\n                }\n                resolve(bytes);\n            });\n            dataPromises.push(utf8bytes);\n        }\n        else {\n            dataPromises.push(t.data());\n        }\n        if (group != null) {\n            spec.group = group;\n        }\n        specs.push(spec);\n    }\n    const tensorValues = await Promise.all(dataPromises);\n    return { data: concatenateTypedArrays(tensorValues), specs };\n}\n/**\n * Decode flat ArrayBuffer as weights.\n *\n * This function does not handle sharding.\n *\n * This function is the reverse of `encodeWeights`.\n *\n * @param buffer A flat ArrayBuffer carrying the binary values of the tensors\n *   concatenated in the order specified in `specs`.\n * @param specs Specifications of the names, dtypes and shapes of the tensors\n *   whose value are encoded by `buffer`.\n * @return A map from tensor name to tensor value, with the names corresponding\n *   to names in `specs`.\n * @throws Error, if any of the tensors has unsupported dtype.\n */\nexport function decodeWeights(buffer, specs) {\n    // TODO(adarob, cais): Support quantization.\n    const out = {};\n    let float16Decode;\n    let offset = 0;\n    for (const spec of specs) {\n        const name = spec.name;\n        const dtype = spec.dtype;\n        const shape = spec.shape;\n        const size = sizeFromShape(shape);\n        let values;\n        if ('quantization' in spec) {\n            const quantization = spec.quantization;\n            if (quantization.dtype === 'uint8' || quantization.dtype === 'uint16') {\n                if (!('min' in quantization && 'scale' in quantization)) {\n                    throw new Error(`Weight ${spec.name} with quantization ${quantization.dtype} ` +\n                        `doesn't have corresponding metadata min and scale.`);\n                }\n            }\n            else if (quantization.dtype === 'float16') {\n                if (dtype !== 'float32') {\n                    throw new Error(`Weight ${spec.name} is quantized with ${quantization.dtype} ` +\n                        `which only supports weights of type float32 not ${dtype}.`);\n                }\n            }\n            else {\n                throw new Error(`Weight ${spec.name} has unknown ` +\n                    `quantization dtype ${quantization.dtype}. ` +\n                    `Supported quantization dtypes are: ` +\n                    `'uint8', 'uint16', and 'float16'.`);\n            }\n            const quantizationSizeFactor = DTYPE_VALUE_SIZE_MAP[quantization.dtype];\n            const byteBuffer = buffer.slice(offset, offset + size * quantizationSizeFactor);\n            const quantizedArray = (quantization.dtype === 'uint8') ?\n                new Uint8Array(byteBuffer) :\n                new Uint16Array(byteBuffer);\n            if (dtype === 'float32') {\n                if (quantization.dtype === 'uint8' || quantization.dtype === 'uint16') {\n                    values = new Float32Array(quantizedArray.length);\n                    for (let i = 0; i < quantizedArray.length; i++) {\n                        const v = quantizedArray[i];\n                        values[i] = v * quantization.scale + quantization.min;\n                    }\n                }\n                else if (quantization.dtype === 'float16') {\n                    if (float16Decode === undefined) {\n                        float16Decode = getFloat16Decoder();\n                    }\n                    values = float16Decode(quantizedArray);\n                }\n                else {\n                    throw new Error(`Unsupported quantization type ${quantization.dtype} ` +\n                        `for weight type float32.`);\n                }\n            }\n            else if (dtype === 'int32') {\n                if (quantization.dtype !== 'uint8' && quantization.dtype !== 'uint16') {\n                    throw new Error(`Unsupported quantization type ${quantization.dtype} ` +\n                        `for weight type int32.`);\n                }\n                values = new Int32Array(quantizedArray.length);\n                for (let i = 0; i < quantizedArray.length; i++) {\n                    const v = quantizedArray[i];\n                    values[i] = Math.round(v * quantization.scale + quantization.min);\n                }\n            }\n            else {\n                throw new Error(`Unsupported dtype in weight '${name}': ${dtype}`);\n            }\n            offset += size * quantizationSizeFactor;\n        }\n        else if (dtype === 'string') {\n            const size = sizeFromShape(spec.shape);\n            values = [];\n            for (let i = 0; i < size; i++) {\n                const byteLength = new Uint32Array(buffer.slice(offset, offset + NUM_BYTES_STRING_LENGTH))[0];\n                offset += NUM_BYTES_STRING_LENGTH;\n                const bytes = new Uint8Array(buffer.slice(offset, offset + byteLength));\n                values.push(bytes);\n                offset += byteLength;\n            }\n        }\n        else {\n            const dtypeFactor = DTYPE_VALUE_SIZE_MAP[dtype];\n            const byteBuffer = buffer.slice(offset, offset + size * dtypeFactor);\n            if (dtype === 'float32') {\n                values = new Float32Array(byteBuffer);\n            }\n            else if (dtype === 'int32') {\n                values = new Int32Array(byteBuffer);\n            }\n            else if (dtype === 'bool') {\n                values = new Uint8Array(byteBuffer);\n            }\n            else if (dtype === 'complex64') {\n                values = new Float32Array(byteBuffer);\n                const real = new Float32Array(values.length / 2);\n                const image = new Float32Array(values.length / 2);\n                for (let i = 0; i < real.length; i++) {\n                    real[i] = values[i * 2];\n                    image[i] = values[i * 2 + 1];\n                }\n                const realTensor = tensor(real, shape, 'float32');\n                const imageTensor = tensor(image, shape, 'float32');\n                out[name] = complex(realTensor, imageTensor);\n                realTensor.dispose();\n                imageTensor.dispose();\n            }\n            else {\n                throw new Error(`Unsupported dtype in weight '${name}': ${dtype}`);\n            }\n            offset += size * dtypeFactor;\n        }\n        if (dtype !== 'complex64') {\n            out[name] = tensor(values, shape, dtype);\n        }\n    }\n    return out;\n}\n/**\n * Concatenate TypedArrays into an ArrayBuffer.\n */\nexport function concatenateTypedArrays(xs) {\n    // TODO(adarob, cais): Support quantization.\n    if (xs === null) {\n        throw new Error(`Invalid input value: ${JSON.stringify(xs)}`);\n    }\n    let totalByteLength = 0;\n    // `normalizedXs` is here for this reason: a `TypedArray`'s `buffer'\n    // can have a different byte length from that of the `TypedArray` itself,\n    // for example, when the `TypedArray` is created from an offset in an\n    // `ArrayBuffer`. `normliazedXs` holds `TypedArray`s whose `buffer`s match\n    // the `TypedArray` in byte length. If an element of `xs` does not show\n    // this property, a new `TypedArray` that satisfy this property will be\n    // constructed and pushed into `normalizedXs`.\n    const normalizedXs = [];\n    xs.forEach((x) => {\n        totalByteLength += x.byteLength;\n        // tslint:disable:no-any\n        normalizedXs.push(x.byteLength === x.buffer.byteLength ? x :\n            new x.constructor(x));\n        if (!(x instanceof Float32Array || x instanceof Int32Array ||\n            x instanceof Uint8Array)) {\n            throw new Error(`Unsupported TypedArray subtype: ${x.constructor.name}`);\n        }\n        // tslint:enable:no-any\n    });\n    const y = new Uint8Array(totalByteLength);\n    let offset = 0;\n    normalizedXs.forEach((x) => {\n        y.set(new Uint8Array(x.buffer), offset);\n        offset += x.byteLength;\n    });\n    return y.buffer;\n}\n// Use Buffer on Node.js instead of Blob/atob/btoa\nconst useNodeBuffer = typeof Buffer !== 'undefined' &&\n    (typeof Blob === 'undefined' || typeof atob === 'undefined' ||\n        typeof btoa === 'undefined');\n/**\n * Calculate the byte length of a JavaScript string.\n *\n * Note that a JavaScript string can contain wide characters, therefore the\n * length of the string is not necessarily equal to the byte length.\n *\n * @param str Input string.\n * @returns Byte length.\n */\nexport function stringByteLength(str) {\n    if (useNodeBuffer) {\n        return Buffer.byteLength(str);\n    }\n    return new Blob([str]).size;\n}\n/**\n * Encode an ArrayBuffer as a base64 encoded string.\n *\n * @param buffer `ArrayBuffer` to be converted.\n * @returns A string that base64-encodes `buffer`.\n */\nexport function arrayBufferToBase64String(buffer) {\n    if (useNodeBuffer) {\n        return Buffer.from(buffer).toString('base64');\n    }\n    const buf = new Uint8Array(buffer);\n    let s = '';\n    for (let i = 0, l = buf.length; i < l; i++) {\n        s += String.fromCharCode(buf[i]);\n    }\n    return btoa(s);\n}\n/**\n * Decode a base64 string as an ArrayBuffer.\n *\n * @param str Base64 string.\n * @returns Decoded `ArrayBuffer`.\n */\nexport function base64StringToArrayBuffer(str) {\n    if (useNodeBuffer) {\n        const buf = Buffer.from(str, 'base64');\n        return buf.buffer.slice(buf.byteOffset, buf.byteOffset + buf.byteLength);\n    }\n    const s = atob(str);\n    const buffer = new Uint8Array(s.length);\n    for (let i = 0; i < s.length; ++i) {\n        buffer.set([s.charCodeAt(i)], i);\n    }\n    return buffer.buffer;\n}\n/**\n * Concatenate a number of ArrayBuffers into one.\n *\n * @param buffers A number of array buffers to concatenate.\n * @returns Result of concatenating `buffers` in order.\n */\nexport function concatenateArrayBuffers(buffers) {\n    if (buffers.length === 1) {\n        return buffers[0];\n    }\n    let totalByteLength = 0;\n    buffers.forEach((buffer) => {\n        totalByteLength += buffer.byteLength;\n    });\n    const temp = new Uint8Array(totalByteLength);\n    let offset = 0;\n    buffers.forEach((buffer) => {\n        temp.set(new Uint8Array(buffer), offset);\n        offset += buffer.byteLength;\n    });\n    return temp.buffer;\n}\n/**\n * Get the basename of a path.\n *\n * Behaves in a way analogous to Linux's basename command.\n *\n * @param path\n */\nexport function basename(path) {\n    const SEPARATOR = '/';\n    path = path.trim();\n    while (path.endsWith(SEPARATOR)) {\n        path = path.slice(0, path.length - 1);\n    }\n    const items = path.split(SEPARATOR);\n    return items[items.length - 1];\n}\n/**\n * Populate ModelArtifactsInfo fields for a model with JSON topology.\n * @param modelArtifacts\n * @returns A ModelArtifactsInfo object.\n */\nexport function getModelArtifactsInfoForJSON(modelArtifacts) {\n    if (modelArtifacts.modelTopology instanceof ArrayBuffer) {\n        throw new Error('Expected JSON model topology, received ArrayBuffer.');\n    }\n    return {\n        dateSaved: new Date(),\n        modelTopologyType: 'JSON',\n        modelTopologyBytes: modelArtifacts.modelTopology == null ?\n            0 :\n            stringByteLength(JSON.stringify(modelArtifacts.modelTopology)),\n        weightSpecsBytes: modelArtifacts.weightSpecs == null ?\n            0 :\n            stringByteLength(JSON.stringify(modelArtifacts.weightSpecs)),\n        weightDataBytes: modelArtifacts.weightData == null ?\n            0 :\n            modelArtifacts.weightData.byteLength,\n    };\n}\n/**\n * Computes mantisa table for casting Float16 to Float32\n * See http://www.fox-toolkit.org/ftp/fasthalffloatconversion.pdf\n *\n * @returns Uint32Array, 2048 mantissa lookup values.\n */\nfunction computeFloat16MantisaTable() {\n    const convertMantissa = (i) => {\n        let m = i << 13;\n        let e = 0;\n        while ((m & 0x00800000) === 0) {\n            e -= 0x00800000;\n            m <<= 1;\n        }\n        m &= ~0x00800000;\n        e += 0x38800000;\n        return m | e;\n    };\n    const mantisaTable = new Uint32Array(2048);\n    mantisaTable[0] = 0;\n    for (let i = 1; i < 1024; i++) {\n        mantisaTable[i] = convertMantissa(i);\n    }\n    for (let i = 1024; i < 2048; i++) {\n        mantisaTable[i] = 0x38000000 + ((i - 1024) << 13);\n    }\n    return mantisaTable;\n}\n/**\n * Computes exponent table for casting Float16 to Float32\n * See http://www.fox-toolkit.org/ftp/fasthalffloatconversion.pdf\n *\n * @returns Uint32Array, 64 exponent lookup values.\n */\nfunction computeFloat16ExponentTable() {\n    const exponentTable = new Uint32Array(64);\n    exponentTable[0] = 0;\n    exponentTable[31] = 0x47800000;\n    exponentTable[32] = 0x80000000;\n    exponentTable[63] = 0xc7800000;\n    for (let i = 1; i < 31; i++) {\n        exponentTable[i] = i << 23;\n    }\n    for (let i = 33; i < 63; i++) {\n        exponentTable[i] = 0x80000000 + ((i - 32) << 23);\n    }\n    return exponentTable;\n}\n/**\n * Computes offset table for casting Float16 to Float32\n * See http://www.fox-toolkit.org/ftp/fasthalffloatconversion.pdf\n *\n * @returns Uint32Array, 6d offset values.\n */\nfunction computeFloat16OffsetTable() {\n    const offsetTable = new Uint32Array(64);\n    for (let i = 0; i < 64; i++) {\n        offsetTable[i] = 1024;\n    }\n    offsetTable[0] = offsetTable[32] = 0;\n    return offsetTable;\n}\n/**\n * Retrieve a Float16 decoder which will decode a ByteArray of Float16 values\n * to a Float32Array.\n *\n * @returns Function (buffer: Uint16Array) => Float32Array which decodes\n *          the Uint16Array of Float16 bytes to a Float32Array.\n */\nexport function getFloat16Decoder() {\n    // Algorithm is based off of\n    // http://www.fox-toolkit.org/ftp/fasthalffloatconversion.pdf\n    // Cache lookup tables\n    const mantisaTable = computeFloat16MantisaTable();\n    const exponentTable = computeFloat16ExponentTable();\n    const offsetTable = computeFloat16OffsetTable();\n    return (quantizedArray) => {\n        const buffer = new ArrayBuffer(4 * quantizedArray.length);\n        const bufferUint32View = new Uint32Array(buffer);\n        for (let index = 0; index < quantizedArray.length; index++) {\n            const float16Bits = quantizedArray[index];\n            const float32Bits = mantisaTable[offsetTable[float16Bits >> 10] + (float16Bits & 0x3ff)] +\n                exponentTable[float16Bits >> 10];\n            bufferUint32View[index] = float32Bits;\n        }\n        return new Float32Array(buffer);\n    };\n}\n//# sourceMappingURL=io_utils.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nexport class IORouterRegistry {\n    constructor() {\n        this.saveRouters = [];\n        this.loadRouters = [];\n    }\n    static getInstance() {\n        if (IORouterRegistry.instance == null) {\n            IORouterRegistry.instance = new IORouterRegistry();\n        }\n        return IORouterRegistry.instance;\n    }\n    /**\n     * Register a save-handler router.\n     *\n     * @param saveRouter A function that maps a URL-like string onto an instance\n     * of `IOHandler` with the `save` method defined or `null`.\n     */\n    static registerSaveRouter(saveRouter) {\n        IORouterRegistry.getInstance().saveRouters.push(saveRouter);\n    }\n    /**\n     * Register a load-handler router.\n     *\n     * @param loadRouter A function that maps a URL-like string onto an instance\n     * of `IOHandler` with the `load` method defined or `null`.\n     */\n    static registerLoadRouter(loadRouter) {\n        IORouterRegistry.getInstance().loadRouters.push(loadRouter);\n    }\n    /**\n     * Look up IOHandler for saving, given a URL-like string.\n     *\n     * @param url\n     * @returns If only one match is found, an instance of IOHandler with the\n     * `save` method defined. If no match is found, `null`.\n     * @throws Error, if more than one match is found.\n     */\n    static getSaveHandlers(url) {\n        return IORouterRegistry.getHandlers(url, 'save');\n    }\n    /**\n     * Look up IOHandler for loading, given a URL-like string.\n     *\n     * @param url\n     * @param loadOptions Optional, custom load options.\n     * @returns All valid handlers for `url`, given the currently registered\n     *   handler routers.\n     */\n    static getLoadHandlers(url, loadOptions) {\n        return IORouterRegistry.getHandlers(url, 'load', loadOptions);\n    }\n    static getHandlers(url, handlerType, loadOptions) {\n        const validHandlers = [];\n        const routers = handlerType === 'load' ?\n            IORouterRegistry.getInstance().loadRouters :\n            IORouterRegistry.getInstance().saveRouters;\n        routers.forEach(router => {\n            const handler = router(url, loadOptions);\n            if (handler !== null) {\n                validHandlers.push(handler);\n            }\n        });\n        return validHandlers;\n    }\n}\nexport const registerSaveRouter = (loudRouter) => IORouterRegistry.registerSaveRouter(loudRouter);\nexport const registerLoadRouter = (loudRouter) => IORouterRegistry.registerLoadRouter(loudRouter);\nexport const getSaveHandlers = (url) => IORouterRegistry.getSaveHandlers(url);\nexport const getLoadHandlers = (url, loadOptions) => IORouterRegistry.getLoadHandlers(url, loadOptions);\n//# sourceMappingURL=router_registry.js.map","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { env } from './environment';\nimport { getGlobal } from './global_util';\nconst kernelRegistry = getGlobal('kernelRegistry', () => new Map());\nconst gradRegistry = getGlobal('gradRegistry', () => new Map());\n/**\n * Returns the kernel function (code) associated with the provided names.\n *\n * @param kernelName The official name of the kernel.\n * @param backendName The official name of the backend.\n */\nexport function getKernel(kernelName, backendName) {\n    const key = makeKey(kernelName, backendName);\n    return kernelRegistry.get(key);\n}\n/**\n * Returns the registered gradient info associated with the provided kernel.\n * @param kernelName The official TF kernel name.\n */\nexport function getGradient(kernelName) {\n    return gradRegistry.get(kernelName);\n}\nexport function getKernelsForBackend(backendName) {\n    const it = kernelRegistry.entries();\n    const result = [];\n    while (true) {\n        const { done, value } = it.next();\n        if (done) {\n            break;\n        }\n        const [key, config] = value;\n        const [backend,] = key.split('_');\n        if (backend === backendName) {\n            result.push(config);\n        }\n    }\n    return result;\n}\n/**\n * Registers the function (forward pass) for the kernel in a global registry.\n *\n * @param config A config object with the following properties:\n * - `kernelName` The official name of the kernel.\n * - `backendName` The official name of the backend.\n * - `kernelFunc` The function to run during the forward pass of the kernel.\n * - `setupFunc` Optional. Gets called once, after the backend initializes.\n * - `disposeFunc` Optional. Gets called once, right before the backend is\n * disposed.\n */\nexport function registerKernel(config) {\n    const { kernelName, backendName } = config;\n    const key = makeKey(kernelName, backendName);\n    if (kernelRegistry.has(key)) {\n        console.warn(`The kernel '${kernelName}' for backend ` +\n            `'${backendName}' is already registered`);\n    }\n    kernelRegistry.set(key, config);\n}\n/**\n * Registers a gradient function for a given kernel in the global registry,\n * to be used during the back-propagation of that kernel.\n *\n * @param config An object with the following properties:\n * - `kernelName` The name of the kernel that the gradient function is for.\n * - `gradFunc` The function to run during back-propagation.\n */\nexport function registerGradient(config) {\n    const { kernelName } = config;\n    if (gradRegistry.has(kernelName)) {\n        // TODO (yassogba) after 3.0 assess whether we need to keep this gated\n        // to debug mode.\n        if (env().getBool('DEBUG')) {\n            console.warn(`Overriding the gradient for '${kernelName}'`);\n        }\n    }\n    gradRegistry.set(kernelName, config);\n}\n/**\n * Removes the kernel function from the registry.\n *\n * @param kernelName The official name of the kernel.\n * @param backendName The official name of the backend.\n *\n */\nexport function unregisterKernel(kernelName, backendName) {\n    const key = makeKey(kernelName, backendName);\n    if (!kernelRegistry.has(key)) {\n        throw new Error(`The kernel '${kernelName}' for backend ` +\n            `'${backendName}' is not registered`);\n    }\n    kernelRegistry.delete(key);\n}\n/** Removes the registered gradient from the global registry. */\nexport function unregisterGradient(kernelName) {\n    if (!gradRegistry.has(kernelName)) {\n        throw new Error(`The gradient '${kernelName}' for backend is not registered`);\n    }\n    gradRegistry.delete(kernelName);\n}\n/**\n * Finds kernels that have already been registered to a backend and re-registers\n * them for a new backend. Useful for registering custom backends.\n * @param registeredBackendName Already registered backend.\n * @param newBackendName New backend.\n */\nexport function copyRegisteredKernels(registeredBackendName, newBackendName) {\n    const kernels = getKernelsForBackend(registeredBackendName);\n    kernels.forEach(kernelConfig => {\n        const newKernelConfig = Object.assign({}, kernelConfig, { backendName: newBackendName });\n        registerKernel(newKernelConfig);\n    });\n}\nfunction makeKey(kernelName, backendName) {\n    return `${backendName}_${kernelName}`;\n}\n//# sourceMappingURL=kernel_registry.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n/**\n * Classes and functions for model management across multiple storage mediums.\n *\n * Supported client actions:\n * - Listing models on all registered storage mediums.\n * - Remove model by URL from any registered storage mediums, by using URL\n *   string.\n * - Moving or copying model from one path to another in the same medium or from\n *   one medium to another, by using URL strings.\n */\nimport { assert } from '../util';\nimport { IORouterRegistry } from './router_registry';\nconst URL_SCHEME_SUFFIX = '://';\nexport class ModelStoreManagerRegistry {\n    constructor() {\n        this.managers = {};\n    }\n    static getInstance() {\n        if (ModelStoreManagerRegistry.instance == null) {\n            ModelStoreManagerRegistry.instance = new ModelStoreManagerRegistry();\n        }\n        return ModelStoreManagerRegistry.instance;\n    }\n    /**\n     * Register a save-handler router.\n     *\n     * @param saveRouter A function that maps a URL-like string onto an instance\n     * of `IOHandler` with the `save` method defined or `null`.\n     */\n    static registerManager(scheme, manager) {\n        assert(scheme != null, () => 'scheme must not be undefined or null.');\n        if (scheme.endsWith(URL_SCHEME_SUFFIX)) {\n            scheme = scheme.slice(0, scheme.indexOf(URL_SCHEME_SUFFIX));\n        }\n        assert(scheme.length > 0, () => 'scheme must not be an empty string.');\n        const registry = ModelStoreManagerRegistry.getInstance();\n        assert(registry.managers[scheme] == null, () => `A model store manager is already registered for scheme '${scheme}'.`);\n        registry.managers[scheme] = manager;\n    }\n    static getManager(scheme) {\n        const manager = this.getInstance().managers[scheme];\n        if (manager == null) {\n            throw new Error(`Cannot find model manager for scheme '${scheme}'`);\n        }\n        return manager;\n    }\n    static getSchemes() {\n        return Object.keys(this.getInstance().managers);\n    }\n}\n/**\n * Helper method for parsing a URL string into a scheme and a path.\n *\n * @param url E.g., 'localstorage://my-model'\n * @returns A dictionary with two fields: scheme and path.\n *   Scheme: e.g., 'localstorage' in the example above.\n *   Path: e.g., 'my-model' in the example above.\n */\nfunction parseURL(url) {\n    if (url.indexOf(URL_SCHEME_SUFFIX) === -1) {\n        throw new Error(`The url string provided does not contain a scheme. ` +\n            `Supported schemes are: ` +\n            `${ModelStoreManagerRegistry.getSchemes().join(',')}`);\n    }\n    return {\n        scheme: url.split(URL_SCHEME_SUFFIX)[0],\n        path: url.split(URL_SCHEME_SUFFIX)[1],\n    };\n}\nasync function cloneModelInternal(sourceURL, destURL, deleteSource = false) {\n    assert(sourceURL !== destURL, () => `Old path and new path are the same: '${sourceURL}'`);\n    const loadHandlers = IORouterRegistry.getLoadHandlers(sourceURL);\n    assert(loadHandlers.length > 0, () => `Copying failed because no load handler is found for source URL ${sourceURL}.`);\n    assert(loadHandlers.length < 2, () => `Copying failed because more than one (${loadHandlers.length}) ` +\n        `load handlers for source URL ${sourceURL}.`);\n    const loadHandler = loadHandlers[0];\n    const saveHandlers = IORouterRegistry.getSaveHandlers(destURL);\n    assert(saveHandlers.length > 0, () => `Copying failed because no save handler is found for destination ` +\n        `URL ${destURL}.`);\n    assert(saveHandlers.length < 2, () => `Copying failed because more than one (${loadHandlers.length}) ` +\n        `save handlers for destination URL ${destURL}.`);\n    const saveHandler = saveHandlers[0];\n    const sourceScheme = parseURL(sourceURL).scheme;\n    const sourcePath = parseURL(sourceURL).path;\n    const sameMedium = sourceScheme === parseURL(sourceURL).scheme;\n    const modelArtifacts = await loadHandler.load();\n    // If moving within the same storage medium, remove the old model as soon as\n    // the loading is done. Without doing this, it is possible that the combined\n    // size of the two models will cause the cloning to fail.\n    if (deleteSource && sameMedium) {\n        await ModelStoreManagerRegistry.getManager(sourceScheme)\n            .removeModel(sourcePath);\n    }\n    const saveResult = await saveHandler.save(modelArtifacts);\n    // If moving between mediums, the deletion is done after the save succeeds.\n    // This guards against the case in which saving to the destination medium\n    // fails.\n    if (deleteSource && !sameMedium) {\n        await ModelStoreManagerRegistry.getManager(sourceScheme)\n            .removeModel(sourcePath);\n    }\n    return saveResult.modelArtifactsInfo;\n}\n/**\n * List all models stored in registered storage mediums.\n *\n * For a web browser environment, the registered mediums are Local Storage and\n * IndexedDB.\n *\n * ```js\n * // First create and save a model.\n * const model = tf.sequential();\n * model.add(tf.layers.dense(\n *     {units: 1, inputShape: [10], activation: 'sigmoid'}));\n * await model.save('localstorage://demo/management/model1');\n *\n * // Then list existing models.\n * console.log(JSON.stringify(await tf.io.listModels()));\n *\n * // Delete the model.\n * await tf.io.removeModel('localstorage://demo/management/model1');\n *\n * // List models again.\n * console.log(JSON.stringify(await tf.io.listModels()));\n * ```\n *\n * @returns A `Promise` of a dictionary mapping URLs of existing models to\n * their model artifacts info. URLs include medium-specific schemes, e.g.,\n *   'indexeddb://my/model/1'. Model artifacts info include type of the\n * model's topology, byte sizes of the topology, weights, etc.\n *\n * @doc {\n *   heading: 'Models',\n *   subheading: 'Management',\n *   namespace: 'io',\n *   ignoreCI: true\n * }\n */\nasync function listModels() {\n    const schemes = ModelStoreManagerRegistry.getSchemes();\n    const out = {};\n    for (const scheme of schemes) {\n        const schemeOut = await ModelStoreManagerRegistry.getManager(scheme).listModels();\n        for (const path in schemeOut) {\n            const url = scheme + URL_SCHEME_SUFFIX + path;\n            out[url] = schemeOut[path];\n        }\n    }\n    return out;\n}\n/**\n * Remove a model specified by URL from a reigstered storage medium.\n *\n * ```js\n * // First create and save a model.\n * const model = tf.sequential();\n * model.add(tf.layers.dense(\n *     {units: 1, inputShape: [10], activation: 'sigmoid'}));\n * await model.save('localstorage://demo/management/model1');\n *\n * // Then list existing models.\n * console.log(JSON.stringify(await tf.io.listModels()));\n *\n * // Delete the model.\n * await tf.io.removeModel('localstorage://demo/management/model1');\n *\n * // List models again.\n * console.log(JSON.stringify(await tf.io.listModels()));\n * ```\n *\n * @param url A URL to a stored model, with a scheme prefix, e.g.,\n *   'localstorage://my-model-1', 'indexeddb://my/model/2'.\n * @returns ModelArtifactsInfo of the deleted model (if and only if deletion\n *   is successful).\n * @throws Error if deletion fails, e.g., if no model exists at `path`.\n *\n * @doc {\n *   heading: 'Models',\n *   subheading: 'Management',\n *   namespace: 'io',\n *   ignoreCI: true\n * }\n */\nasync function removeModel(url) {\n    const schemeAndPath = parseURL(url);\n    const manager = ModelStoreManagerRegistry.getManager(schemeAndPath.scheme);\n    return manager.removeModel(schemeAndPath.path);\n}\n/**\n * Copy a model from one URL to another.\n *\n * This function supports:\n *\n * 1. Copying within a storage medium, e.g.,\n *    `tf.io.copyModel('localstorage://model-1', 'localstorage://model-2')`\n * 2. Copying between two storage mediums, e.g.,\n *    `tf.io.copyModel('localstorage://model-1', 'indexeddb://model-1')`\n *\n * ```js\n * // First create and save a model.\n * const model = tf.sequential();\n * model.add(tf.layers.dense(\n *     {units: 1, inputShape: [10], activation: 'sigmoid'}));\n * await model.save('localstorage://demo/management/model1');\n *\n * // Then list existing models.\n * console.log(JSON.stringify(await tf.io.listModels()));\n *\n * // Copy the model, from Local Storage to IndexedDB.\n * await tf.io.copyModel(\n *     'localstorage://demo/management/model1',\n *     'indexeddb://demo/management/model1');\n *\n * // List models again.\n * console.log(JSON.stringify(await tf.io.listModels()));\n *\n * // Remove both models.\n * await tf.io.removeModel('localstorage://demo/management/model1');\n * await tf.io.removeModel('indexeddb://demo/management/model1');\n * ```\n *\n * @param sourceURL Source URL of copying.\n * @param destURL Destination URL of copying.\n * @returns ModelArtifactsInfo of the copied model (if and only if copying\n *   is successful).\n * @throws Error if copying fails, e.g., if no model exists at `sourceURL`, or\n *   if `oldPath` and `newPath` are identical.\n *\n * @doc {\n *   heading: 'Models',\n *   subheading: 'Management',\n *   namespace: 'io',\n *   ignoreCI: true\n * }\n */\nasync function copyModel(sourceURL, destURL) {\n    const deleteSource = false;\n    return cloneModelInternal(sourceURL, destURL, deleteSource);\n}\n/**\n * Move a model from one URL to another.\n *\n * This function supports:\n *\n * 1. Moving within a storage medium, e.g.,\n *    `tf.io.moveModel('localstorage://model-1', 'localstorage://model-2')`\n * 2. Moving between two storage mediums, e.g.,\n *    `tf.io.moveModel('localstorage://model-1', 'indexeddb://model-1')`\n *\n * ```js\n * // First create and save a model.\n * const model = tf.sequential();\n * model.add(tf.layers.dense(\n *     {units: 1, inputShape: [10], activation: 'sigmoid'}));\n * await model.save('localstorage://demo/management/model1');\n *\n * // Then list existing models.\n * console.log(JSON.stringify(await tf.io.listModels()));\n *\n * // Move the model, from Local Storage to IndexedDB.\n * await tf.io.moveModel(\n *     'localstorage://demo/management/model1',\n *     'indexeddb://demo/management/model1');\n *\n * // List models again.\n * console.log(JSON.stringify(await tf.io.listModels()));\n *\n * // Remove the moved model.\n * await tf.io.removeModel('indexeddb://demo/management/model1');\n * ```\n *\n * @param sourceURL Source URL of moving.\n * @param destURL Destination URL of moving.\n * @returns ModelArtifactsInfo of the copied model (if and only if copying\n *   is successful).\n * @throws Error if moving fails, e.g., if no model exists at `sourceURL`, or\n *   if `oldPath` and `newPath` are identical.\n *\n * @doc {\n *   heading: 'Models',\n *   subheading: 'Management',\n *   namespace: 'io',\n *   ignoreCI: true\n * }\n */\nasync function moveModel(sourceURL, destURL) {\n    const deleteSource = true;\n    return cloneModelInternal(sourceURL, destURL, deleteSource);\n}\nexport { moveModel, copyModel, removeModel, listModels };\n//# sourceMappingURL=model_management.js.map"],"sourceRoot":""}