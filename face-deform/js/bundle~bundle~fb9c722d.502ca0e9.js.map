{"version":3,"sources":["webpack:///./node_modules/@tensorflow/tfjs-core/dist/base_side_effects.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/io/browser_files.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/io/progress.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/io/weights_loader.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/io/http.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/io/passthrough.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/complex_util.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/einsum_util.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/backend_util.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/non_max_suppression_util.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/non_max_suppression_impl.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/flags.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/backend.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/io/types.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/device_util.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/globals.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/io/indexed_db.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/io/local_storage.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/hash_util.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/io/io_utils.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/gradients.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/engine.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/io/router_registry.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/kernel_registry.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/kernel_names.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/io/model_management.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/global_util.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/environment.js"],"names":["opHandler","buffer","cast","clone","print","defer","f","Promise","resolve","setTimeout","then","fileNamePrefix","getBool","Error","startsWith","URL_SCHEME","slice","length","this","modelTopologyFileName","weightDataFileName","modelArtifacts","weightsURL","window","URL","createObjectURL","Blob","weightData","type","modelTopology","ArrayBuffer","weightsManifest","paths","weights","weightSpecs","modelTopologyAndWeightManifest","format","generatedBy","convertedBy","signature","userDefinedMetadata","modelInitializer","modelTopologyAndWeightManifestURL","JSON","stringify","jsonAnchor","document","createElement","download","href","dispatchEvent","MouseEvent","weightDataAnchor","modelArtifactsInfo","files","jsonFile","weightFiles","reject","jsonReader","FileReader","onload","event","modelJSON","parse","target","result","name","pathToFile","checkManifestAndWeightFiles","err","perFileBuffers","forEach","weightsGroup","path","push","weightFileReader","index","indexOf","onerror","error","readAsArrayBuffer","readAsText","manifest","basenames","fileNames","map","file","group","pathBasename","browserFiles","registerSaveRouter","url","Array","isArray","browserDownloads","monitorPromisesProgress","promises","onProgress","startFraction","endFraction","checkPromises","checkFraction","resolvedPromise","all","promise","value","fraction","async","loadWeightsAsArrayBuffer","fetchURLs","loadOptions","fetchFunc","platform","fetch","requests","fetchURL","requestInit","isBinary","bufferPromises","response","arrayBuffer","loadWeights","filePathPrefix","weightNames","weightsLoaderFactory","fetchUrls","fetchWeightsFunction","groupIndicesToFetchMap","groupWeightsToFetch","weightsFound","allManifestWeightNames","manifestGroupConfig","groupIndex","groupOffset","weightsEntry","rawDtype","quantization","dtype","weightsBytes","shape","enqueueWeightsForFetchingFn","manifestEntry","sizeBytes","weightName","weightIndex","every","found","weightsNotFound","filter","_","i","join","groupIndicesToFetch","reduce","accumulator","shouldFetch","filepath","fetchUrl","endsWith","buffers","weightsTensorMap","bufferIndexOffset","numBuffers","groupBytes","byteLength","groupBuffer","groupByteBuffer","Uint8Array","groupBufferOffset","set","byteBuffer","nameToTensorMap","DEFAULT_METHOD","weightPathPrefix","weightUrlConverter","body","init","Object","assign","method","FormData","append","ok","responses","status","modelConfigRequest","modelConfig","json","e","message","results","artifacts","initializer","weightPath","prefix","suffix","lastSlash","lastIndexOf","lastSearchParam","substring","parseUrl","pathPrefix","entry","urlPromises","isHTTPScheme","match","URL_SCHEME_REGEX","httpRouter","isHTTP","urlItem","http","browserHTTPRequest","registerLoadRouter","PassthroughLoader","PassthroughSaver","saveHandler","fromMemory","trainingConfig","arguments","console","warn","withSaveHandler","mergeRealAndImagArrays","real","imag","Float32Array","splitRealAndImagArrays","complex","complexWithEvenIndex","len","Math","ceil","floor","complexWithOddIndex","getComplexWithIndex","assignToTypedArray","data","exponents","n","inverse","x","PI","cos","sin","exponent","k","ARROW","ARROW_REGEX","decodeEinsumEquation","equation","numTensors","numArrows","replace","inputString","outputString","split","inputTerms","numInputs","allDims","dimName","some","inputTerm","idDims","Set","size","j","numDims","summedDims","getEinsumPermutation","nDims","permutationIndices","fill","expandDims","d","checkEinsumDimSizes","tensors","dimSizes","undefined","getEinsumComputePath","steps","nSteps","computedTermIndices","termIndices","findTermsWithDim","termIndex","isIdentityPermutation","perm","dim","fromUint8ToStringArray","vals","val","fromStringArrayToUint8","strings","s","binaryInsert","arr","element","comparator","left","right","middle","compareResult","binarySearch_","defaultComparator","binarySearch","insertionPoint","splice","a","b","nonMaxSuppressionV3Impl","boxes","scores","maxOutputSize","iouThreshold","scoreThreshold","nonMaxSuppressionImpl_","nonMaxSuppressionV4Impl","padToMaxOutputSize","nonMaxSuppressionV5Impl","softNmsSigma","returnScoresTensor","returnValidOutputs","candidates","score","boxIndex","suppressBeginIndex","sort","ascendingComparator","scale","selectedIndices","selectedScores","candidate","pop","originalScore","ignoreCandidate","iou","intersectionOverUnion","suppressWeight","validOutputs","elemsToPad","iCoord","subarray","jCoord","yminI","min","xminI","ymaxI","max","xmaxI","yminJ","xminJ","ymaxJ","xmaxJ","areaI","areaJ","intersectionYmin","intersectionXmin","intersectionYmax","intersectionXmax","intersectionArea","weight","exp","c1","c2","ENV","registerFlag","debugValue","process","versions","node","navigator","userAgent","test","vendor","DataStorage","backend","dataMover","WeakMap","dataIdsCount","dataId","has","moveData","get","delete","KernelBackend","notYetImplemented","force","values","refCount","floatPrecision","kernelName","DTYPE_VALUE_SIZE_MAP","isBrowser","WorkerGlobalScope","deprecationWarn","msg","engine","tidy","nameOrFn","fn","dispose","container","tensor","keep","setBackend","backendName","getBackend","registerBackend","factory","priority","DATABASE_NAME","MODEL_STORE_NAME","INFO_STORE_NAME","getIndexedDBFactory","theWindow","self","indexedDB","mozIndexedDB","webkitIndexedDB","msIndexedDB","shimIndexedDB","setUpDatabase","openRequest","db","createObjectStore","keyPath","BrowserIndexedDB","modelPath","databaseAction","open","onupgradeneeded","onsuccess","modelTx","transaction","getRequest","objectStore","close","oncomplete","infoTx","infoStore","putInfoRequest","put","putModelRequest","deleteInfoRequest","indexedDBRouter","BrowserIndexedDBManager","tx","getAllInfoRequest","getAll","out","item","key","getInfoRequest","deleteModelData","deleteModelRequest","PATH_SEPARATOR","PATH_PREFIX","INFO_SUFFIX","MODEL_TOPOLOGY_SUFFIX","WEIGHT_SPECS_SUFFIX","WEIGHT_DATA_SUFFIX","MODEL_METADATA_SUFFIX","getModelKeys","info","topology","modelMetadata","getModelPathFromKey","items","BrowserLocalStorage","localStorage","LS","keys","setItem","removeItem","modelTopologyBytes","weightSpecsBytes","weightDataBytes","getItem","modelTopologyType","metadataString","metadata","weightDataBase64","localStorageRouter","BrowserLocalStorageManager","Long","hexToLong","hex","fromString","k0","k1","k2","shiftMix","xor","shru","offset","numBytes","bytes","fromBytes","from","fetch64","fetch32","rotate64","shift","or","shl","hashLen16","u","v","mul","weakHashLen32WithSeedsStr","w","y","z","add","c","weakHashLen32WithSeeds","fingerPrint64","seed","fromNumber","hashLen0to16","hashLen17to32","g","h","hashLen33to64","UZERO","end","last64","and","encodeWeights","specs","dataPromises","names","t","spec","utf8bytes","totalNumBytes","p","bytesOfLength","Uint32Array","concatenateTypedArrays","decodeWeights","float16Decode","quantizationSizeFactor","quantizedArray","Uint16Array","getFloat16Decoder","Int32Array","round","dtypeFactor","image","realTensor","imageTensor","xs","totalByteLength","normalizedXs","constructor","useNodeBuffer","Buffer","atob","btoa","stringByteLength","str","arrayBufferToBase64String","toString","buf","l","String","fromCharCode","base64StringToArrayBuffer","byteOffset","charCodeAt","concatenateArrayBuffers","temp","basename","trim","getModelArtifactsInfoForJSON","dateSaved","Date","mantisaTable","convertMantissa","m","computeFloat16MantisaTable","exponentTable","computeFloat16ExponentTable","offsetTable","computeFloat16OffsetTable","bufferUint32View","float16Bits","float32Bits","customGrad","isRegisteredKernelInvocation","kernelInvocation","EngineState","registeredVariables","nextTapeNodeId","numStringTensors","numDataBuffers","gradientDepth","kernelDepth","scopeStack","numDataMovesStack","nextScopeId","tensorInfo","profiling","activeProfile","newBytes","newTensors","peakBytes","kernels","variableName","Engine","registry","registryFactory","pendingBackendInitId","state","pendingBackendInit","backendInstance","sortedBackends","getSortedBackends","initializeBackend","success","asyncInit","initializeBackendsAndReturnBest","setupRegisteredKernels","profiler","kernel","setupFunc","disposeFunc","registryFactoryEntry","promiseId","catch","stack","disposeRegisteredKernels","srcBackend","readSync","disposeData","move","shouldCheckForMemLeaks","scopedRun","startScope","endScope","start","res","ex","nextTensorId","nextVariableId","ENGINE","runKernel","inputs","addTapeNode","activeScope","dy","gradInputs","attrs","runKernelFunc","numDataIdsBefore","outInfos","numDataIdsAfter","numDataIds","numOutputDataIds","numMoves","dataIdsLeaked","kernelParams","outputs","saved","isTapeOn","startingBytecount","startingNumTensors","kernelFunc","kernelOrScopeName","checkKernelForMemLeak","outTensors","outInfo","rank","makeTensorFromDataId","tensorsToSave","getTensorsForGradient","saveTensorsForBackwardMode","forwardFunc","saveFunc","outs","backwardsFunc","kernelProfile","profileKernel","logKernelProfile","bytesAdded","totalBytesSnapshot","tensorsAdded","totalTensorsSnapshot","inputShapes","outputShapes","kernelTimeMs","timeMs","extraInfo","gradConfig","inputsToSave","outputsToSave","inputTensorsToSave","saveAllInputs","inputName","outputTensorsToSave","concat","backendVals","write","trackTensor","initialValue","trainable","incRef","track","removeDataId","varName","disposeVariable","disposeTensor","memory","unreliable","reasons","query","startBytes","startNumTensors","gradientsFunc","tapeNode","id","gradFunc","gradient","dys","output","makeTensor","activeTape","kept","scopeInfo","tensorsToTrackInParent","tensorsToTrackInParentSet","oldScope","scopeId","allowNoGradients","startTape","endTape","filteredTape","accumulatedGradientMap","ones","grads","inputMap","input","save","gradRes","gradMap","grad","read","timingInfo","time","wallMs","reset","getOrMakeEngine","ns","_tfengine","environment","IORouterRegistry","saveRouters","loadRouters","instance","saveRouter","getInstance","loadRouter","getHandlers","handlerType","validHandlers","router","handler","loudRouter","getSaveHandlers","getLoadHandlers","kernelRegistry","Map","gradRegistry","getKernel","makeKey","getGradient","getKernelsForBackend","it","entries","done","next","config","registerKernel","Abs","Acos","Acosh","Add","AddN","All","Any","ArgMax","ArgMin","Asin","Asinh","Atan","Atanh","Atan2","AvgPool","AvgPool3D","BatchMatMul","BatchToSpaceND","Bincount","Cast","Ceil","ClipByValue","Complex","ComplexAbs","Concat","Conv2D","Conv2DBackpropFilter","Conv2DBackpropInput","Conv3D","Cos","Cosh","Cumsum","CropAndResize","DenseBincount","DepthToSpace","DepthwiseConv2dNative","DepthwiseConv2dNativeBackpropFilter","DepthwiseConv2dNativeBackpropInput","Dilation2D","RealDiv","Einsum","Elu","Erf","Equal","Exp","ExpandDims","Expm1","FFT","Fill","FlipLeftRight","Floor","FloorDiv","FusedBatchNorm","GatherV2","GatherNd","Greater","GreaterEqual","Identity","IFFT","Imag","IsNan","LeakyRelu","Less","LessEqual","LinSpace","Log","Log1p","LogicalAnd","LogicalNot","LogicalOr","LRN","Max","Maximum","MaxPool","MaxPool3D","MaxPoolWithArgmax","Mean","Min","Minimum","MirrorPad","Mod","Multinomial","Multiply","Neg","NotEqual","NonMaxSuppressionV3","NonMaxSuppressionV4","NonMaxSuppressionV5","OnesLike","OneHot","Pack","PadV2","Pow","Prelu","Prod","Range","Real","Reciprocal","Relu","Reshape","ResizeNearestNeighbor","ResizeBilinear","Relu6","Reverse","Round","Rsqrt","ScatterNd","Select","Selu","Slice","Sin","Sinh","Sign","Sigmoid","Softplus","Sqrt","Sum","SpaceToBatchND","SplitV","Softmax","SparseFillEmptyRows","SparseReshape","SparseSegmentMean","SparseSegmentSum","SparseToDense","SquaredDifference","Square","StridedSlice","StringNGrams","StringSplit","StringToHashBucketFast","Sub","Tan","Tanh","Tile","TopK","Transform","Transpose","Unique","Unpack","ZerosLike","Step","FromPixels","RotateWithOffset","_FusedMatMul","FusedConv2D","FusedDepthwiseConv2D","URL_SCHEME_SUFFIX","ModelStoreManagerRegistry","managers","scheme","manager","parseURL","getSchemes","cloneModelInternal","sourceURL","destURL","deleteSource","loadHandlers","loadHandler","saveHandlers","sourceScheme","sourcePath","sameMedium","load","getManager","removeModel","saveResult","listModels","schemes","schemeOut","schemeAndPath","copyModel","moveModel","globalNameSpace","getGlobalNamespace","global","getGlobal","globalMap","_tfGlobals","getGlobalMap","singleton","TENSORFLOWJS_FLAGS_PREFIX","Environment","flags","flagRegistry","urlFlags","getQueryParams","populateURLFlags","platformName","flagName","evaluationFn","setHook","flagValue","evaluateFlag","location","search","urlParams","keyValue","toLowerCase","parseValue","queryString","params","decodeURIComponent","decodeParam","env","setEnvironmentGlobal"],"mappings":";o9SAmBA,cAYA,MAAMA,EAAY,CACdC,SAAA,EACAC,OAAA,EACAC,QAAA,EACAC,QAAA,GAEJ,YAAaJ,G,yCCVb,SAASK,EAAMC,GACX,OAAO,IAAIC,SAAQC,GAAWC,WAAWD,KAAUE,KAAKJ,GAErD,MAAM,EACT,YAAYK,GACR,IAAK,cAAMC,QAAQ,cAGf,MAAM,IAAIC,MAAM,uFAGhBF,EAAeG,WAAW,EAAiBC,cAC3CJ,EAAiBA,EAAeK,MAAM,EAAiBD,WAAWE,SAEhD,MAAlBN,GAAoD,IAA1BA,EAAeM,SACzCN,EAlBqB,SAoBzBO,KAAKC,sBAAwBR,EAnBD,QAoB5BO,KAAKE,mBACDT,EApB+B,eAsBvC,WAAWU,GACP,GAA0B,oBAAf,SACP,MAAM,IAAIR,MAAM,2FAGpB,MAAMS,EAAaC,OAAOC,IAAIC,gBAAgB,IAAIC,KAAK,CAACL,EAAeM,YAAa,CAAEC,KAAM,8BAC5F,GAAIP,EAAeQ,yBAAyBC,YACxC,MAAM,IAAIjB,MAAM,yFAGf,CACD,MAAMkB,EAAkB,CAAC,CACjBC,MAAO,CAAC,KAAOd,KAAKE,oBACpBa,QAASZ,EAAea,cAE1BC,EAAiC,CACnCN,cAAeR,EAAeQ,cAC9BO,OAAQf,EAAee,OACvBC,YAAahB,EAAegB,YAC5BC,YAAajB,EAAeiB,YAC5BP,mBAE4B,MAA5BV,EAAekB,YACfJ,EAA+BI,UAAYlB,EAAekB,WAEpB,MAAtClB,EAAemB,sBACfL,EAA+BK,oBAC3BnB,EAAemB,qBAEgB,MAAnCnB,EAAeoB,mBACfN,EAA+BM,iBAC3BpB,EAAeoB,kBAEvB,MAAMC,EAAoCnB,OAAOC,IAAIC,gBAAgB,IAAIC,KAAK,CAACiB,KAAKC,UAAUT,IAAkC,CAAEP,KAAM,sBAGlIiB,EAAgC,MAAnB3B,KAAK2B,WAAqBC,SAASC,cAAc,KAChE7B,KAAK2B,WAOT,GANAA,EAAWG,SAAW9B,KAAKC,sBAC3B0B,EAAWI,KAAOP,QAIZrC,GAAM,IAAMwC,EAAWK,cAAc,IAAIC,WAAW,YACzB,MAA7B9B,EAAeM,WAAoB,CACnC,MAAMyB,EAA4C,MAAzBlC,KAAKkC,iBAC1BN,SAASC,cAAc,KACvB7B,KAAKkC,iBACTA,EAAiBJ,SAAW9B,KAAKE,mBACjCgC,EAAiBH,KAAO3B,QAClBjB,GAAM,IAAM+C,EAAiBF,cAAc,IAAIC,WAAW,YAEpE,MAAO,CAAEE,mBAAoB,YAA6BhC,MAItE,EAAiBN,WAAa,eAC9B,MAAM,EACF,YAAYuC,GACR,GAAa,MAATA,GAAiBA,EAAMrC,OAAS,EAChC,MAAM,IAAIJ,MACN,wEAAgByC,KAExBpC,KAAKoC,MAAQA,EAEjB,aACI,MAAMC,EAAWrC,KAAKoC,MAAM,GACtBE,EAActC,KAAKoC,MAAMtC,MAAM,GACrC,OAAO,IAAIT,SAAQ,CAACC,EAASiD,KACzB,MAAMC,EAAa,IAAIC,WACvBD,EAAWE,OAAUC,IAEjB,MAAMC,EAAYnB,KAAKoB,MAAMF,EAAMG,OAAOC,QACpCpC,EAAgBiC,EAAUjC,cAChC,GAAqB,MAAjBA,EAEA,YADA4B,EAAO,IAAI5C,MAAM,4CAA4C0C,EAASW,SAG/C,IAAvBV,EAAYvC,QACZT,EAAQ,CAAEqB,kBAEd,MAAME,EAAkB+B,EAAU/B,gBAClC,GAAuB,MAAnBA,EAEA,YADA0B,EAAO,IAAI5C,MAAM,6CAA6C0C,EAASW,SAG3E,IAAIC,EACJ,IACIA,EACIjD,KAAKkD,4BAA4BrC,EAAiByB,GAE1D,MAAOa,GAEH,YADAZ,EAAOY,GAGX,MAAMnC,EAAc,GACdF,EAAQ,GACRsC,EAAiB,GACvBvC,EAAgBwC,SAAQC,IACpBA,EAAaxC,MAAMuC,SAAQE,IACvBzC,EAAM0C,KAAKD,GACXH,EAAeI,KAAK,SAExBxC,EAAYwC,QAAQF,EAAavC,YAErCF,EAAgBwC,SAAQC,IACpBA,EAAaxC,MAAMuC,SAAQE,IACvB,MAAME,EAAmB,IAAIhB,WAC7BgB,EAAiBf,OAAUC,IAEvB,MAAMlC,EAAakC,EAAMG,OAAOC,OAC1BW,EAAQ5C,EAAM6C,QAAQJ,GAE5B,GADAH,EAAeM,GAASjD,GACc,IAAlC2C,EAAeO,QAAQ,MAAc,CACrC,MAAMZ,EAAS,CACXpC,gBACAK,cACAP,WAAY,YAAwB2C,GACpClC,OAAQ0B,EAAU1B,OAClBC,YAAayB,EAAUzB,YACvBC,YAAawB,EAAUxB,aAEA,MAAvBwB,EAAUvB,YACV0B,EAAO1B,UAAYuB,EAAUvB,WAEI,MAAjCuB,EAAUtB,sBACVyB,EAAOzB,oBAAsBsB,EAAUtB,qBAET,MAA9BsB,EAAUrB,mBACVwB,EAAOxB,iBAAmBqB,EAAUrB,kBAExCjC,EAAQyD,KAGhBU,EAAiBG,QAAUC,GAAStB,EAAO,6CAA6CgB,OACxFE,EAAiBK,kBAAkBb,EAAWM,WAI1Df,EAAWoB,QAAUC,GAAStB,EAC1B,sEAAcF,EAASW,6EAE3BR,EAAWuB,WAAW1B,MAM9B,4BAA4B2B,EAAU5B,GAClC,MAAM6B,EAAY,GACZC,EAAY9B,EAAM+B,KAAIC,GAAQ,YAASA,EAAKpB,QAC5CC,EAAa,GACnB,IAAK,MAAMoB,KAASL,EAChBK,EAAMvD,MAAMuC,SAAQE,IAChB,MAAMe,EAAe,YAASf,GAC9B,IAAyC,IAArCU,EAAUN,QAAQW,GAClB,MAAM,IAAI3E,MACN,uDAAI2E,MAGZ,GADAL,EAAUT,KAAKc,IAC0B,IAArCJ,EAAUP,QAAQW,GAClB,MAAM,IAAI3E,MAAM,8BAA8B2E,uBAG9CrB,EAAWM,GAAQnB,EAAM8B,EAAUP,QAAQW,OAIvD,GAAIL,EAAUlE,SAAWqC,EAAMrC,OAC3B,MAAM,IAAIJ,MACN,wDAAIsE,EAAUlE,oDACVqC,EAAMrC,YAElB,OAAOkD,GAmGR,SAASsB,EAAanC,GACzB,OAAO,IAAI,EAAaA,GApF5B,IAAiBoC,oBAbsBC,GAC9B,cAAM/E,QAAQ,gBAIVgF,MAAMC,QAAQF,IAAQA,EAAI7E,WAAW,EAAiBC,YAgD5D,SAA0BJ,EAAiB,SAC9C,OAAO,IAAI,EAAiBA,GAhDbmF,CAAiBH,EAAI3E,MAAM,EAAiBD,WAAWE,SAJ3D,O,WCzMR,SAAS8E,EAAwBC,EAAUC,EAAYC,EAAeC,IAgBzE,SAAuBH,GACnB,YAAmB,MAAZA,GAAoBJ,MAAMC,QAAQG,IAAaA,EAAS/E,OAAS,GAAG,IAAM,wCAhBrFmF,CAAcJ,GAkBd,SAAuBE,EAAeC,GAClC,YAAOD,GAAiB,GAAKA,GAAiB,GAAG,IAC7C,oEAAqBA,MACzB,YAAOC,GAAe,GAAKA,GAAe,GAAG,IACzC,kEAAmBA,MACvB,YAAOA,GAAeD,GAAe,IACjC,yEAAqBA,qBAClBC,MAtBXE,CAFAH,EAAiC,MAAjBA,EAAwB,EAAIA,EAC5CC,EAA6B,MAAfA,EAAsB,EAAIA,GAExC,IAAIG,EAAkB,EAuBtB,OAAO/F,QAAQgG,IAAIP,EAASX,KAtBHmB,IACrBA,EAAQ9F,MAAK+F,IACT,MAAMC,EAAWR,KACXI,EAAkBN,EAAS/E,QAAUkF,EAAcD,GAGzD,OADAD,EAAWS,GACJD,KAEJD,M,aCPRG,eAAeC,EAAyBC,EAAWC,GACnC,MAAfA,IACAA,EAAc,IAElB,MAAMC,EAAqC,MAAzBD,EAAYC,UAAoB,cAAMC,SAASC,MAC7DH,EAAYC,UAEVG,EAAWL,EAAUxB,KAAI8B,GAAYJ,EAAUI,EAAUL,EAAYM,YAAa,CAAEC,UAAU,MAM9FC,GAHsC,MAA1BR,EAAYb,iBACpB1F,QAAQgG,IAAIW,SACZnB,EAAwBmB,EAAUJ,EAAYb,WAJ7B,EACF,KAIQZ,KAAIkC,GAAYA,EAASC,gBAM1D,OAH0C,MAA1BV,EAAYb,iBAClB1F,QAAQgG,IAAIe,SACZvB,EAAwBuB,EAAgBR,EAAYb,WAJlC,GACF,GAevBU,eAAec,EAAYvC,EAAUwC,EAAiB,GAAIC,EAAaP,GAQ1E,OADoBQ,GADEC,GAAcjB,EAAyBiB,EAAW,CAAET,iBAEnEK,CAAYvC,EAAUwC,EAAgBC,GA0B1C,SAASC,EAAqBE,GACjC,OAAOnB,MAAOzB,EAAUwC,EAAiB,GAAIC,KAGzC,MAAMI,EAAyB7C,EAASG,KAAI,KAAM,IAC5C2C,EAAsB,GACtBC,EAA8B,MAAfN,EAAsBA,EAAYtC,KAAI,KAAM,IAAS,GACpE6C,EAAyB,GAmC/B,GAlCAhD,EAASX,SAAQ,CAAC4D,EAAqBC,KACnC,IAAIC,EAAc,EAClBF,EAAoBlG,QAAQsC,SAAQ+D,IAChC,MAAMC,EAAY,iBAAkBD,EAChCA,EAAaE,aAAaC,MAC1BH,EAAaG,MACXC,EAAe,IAAqBH,GACtC,IAAmBD,EAAaK,OAC9BC,EAA8B,KAChCb,EAAuBK,IAAc,EACE,MAAnCJ,EAAoBI,KACpBJ,EAAoBI,GAAc,IAEtCJ,EAAoBI,GAAY1D,KAAK,CACjCmE,cAAeP,EACfD,cACAS,UAAWJ,KAGA,MAAff,EACAA,EAAYpD,SAAQ,CAACwE,EAAYC,KACzBD,IAAeT,EAAapE,OAC5B0E,IACAX,EAAae,IAAe,MAKpCJ,IAEJV,EAAuBxD,KAAK4D,EAAapE,MACzCmE,GAAeK,SAGlBT,EAAagB,OAAMC,GAASA,IAAQ,CACrC,MAAMC,EAAkBxB,EAAYyB,QAAO,CAACC,EAAGC,KAAOrB,EAAaqB,KACnE,MAAM,IAAIzI,MACN,kDAAGsI,EAAgBI,KAAK,kDAErBrB,EAAuBqB,KAAK,UAIvC,MAAMC,EAAsBzB,EAAuB0B,QAAO,CAACC,EAAaC,EAAaL,KAC7EK,GACAD,EAAYhF,KAAK4E,GAEdI,IACR,IACG7B,EAAY,GAClB2B,EAAoBjF,SAAQ+E,IACxBpE,EAASoE,GAAGtH,MAAMuC,SAAQqF,IACtB,MAAMC,EAAWnC,GACXA,EAAeoC,SAAS,KAAa,GAAN,KAAYF,EACjD/B,EAAUnD,KAAKmF,SAGvB,MAAME,QAAgBjC,EAAqBD,GACrCmC,EAAmB,GACzB,IAAIC,EAAoB,EA0BxB,OAzBAT,EAAoBjF,SAAQ+E,IACxB,MAAMY,EAAahF,EAASoE,GAAGtH,MAAMf,OACrC,IAAIkJ,EAAa,EACjB,IAAK,IAAIb,EAAI,EAAGA,EAAIY,EAAYZ,IAC5Ba,GAAcJ,EAAQE,EAAoBX,GAAGc,WAGjD,MAAMC,EAAc,IAAIvI,YAAYqI,GAC9BG,EAAkB,IAAIC,WAAWF,GACvC,IAAIG,EAAoB,EACxB,IAAK,IAAIlB,EAAI,EAAGA,EAAIY,EAAYZ,IAAK,CACjC,MAAMrJ,EAAS,IAAIsK,WAAWR,EAAQE,EAAoBX,IAC1DgB,EAAgBG,IAAIxK,EAAQuK,GAC5BA,GAAqBvK,EAAOmK,WAETpC,EAAoBsB,GAC5B/E,SAAQ+D,IACnB,MAAMoC,EAAaL,EAAYrJ,MAAMsH,EAAaD,YAAaC,EAAaD,YAAcC,EAAaQ,WACjG6B,EAAkB,YAAcD,EAAY,CAACpC,EAAaO,gBAChE,IAAK,MAAM3E,KAAQyG,EACfX,EAAiB9F,GAAQyG,EAAgBzG,MAGjD+F,GAAqBC,KAElBF,GCjKR,MAAM,EACT,YAAYvF,EAAMqC,GAwBd,GAvBA5F,KAAK0J,eAAiB,OACH,MAAf9D,IACAA,EAAc,IAElB5F,KAAK2J,iBAAmB/D,EAAY+D,iBACpC3J,KAAK+E,WAAaa,EAAYb,WAC9B/E,KAAK4J,mBAAqBhE,EAAYgE,mBACT,MAAzBhE,EAAYC,WACZ,YAAwC,mBAA1BD,EAAYC,WAA0B,IAAM,gIAG1D7F,KAAK+F,MAAQH,EAAYC,WAGzB7F,KAAK+F,MAAQ,cAAMD,SAASC,MAEhC,YAAe,MAARxC,GAAgBA,EAAKxD,OAAS,GAAG,IAAM,4DAE1C2E,MAAMC,QAAQpB,IACd,YAAuB,IAAhBA,EAAKxD,QAAc,IACtB,iEAAqBwD,EAAKxD,aAElCC,KAAKuD,KAAOA,EACmB,MAA3BqC,EAAYM,aACoB,MAAhCN,EAAYM,YAAY2D,KACxB,MAAM,IAAIlK,MAAM,sEAEpBK,KAAKkG,YAAcN,EAAYM,aAAe,GAElD,WAAW/F,GACP,GAAIA,EAAeQ,yBAAyBC,YACxC,MAAM,IAAIjB,MAAM,2FAGpB,MAAMmK,EAAOC,OAAOC,OAAO,CAAEC,OAAQjK,KAAK0J,gBAAkB1J,KAAKkG,aACjE4D,EAAKD,KAAO,IAAIK,SAChB,MAAMrJ,EAAkB,CAAC,CACjBC,MAAO,CAAC,uBACRC,QAASZ,EAAea,cAE1BC,EAAiC,CACnCN,cAAeR,EAAeQ,cAC9BO,OAAQf,EAAee,OACvBC,YAAahB,EAAegB,YAC5BC,YAAajB,EAAeiB,YAC5BP,mBAE4B,MAA5BV,EAAekB,YACfJ,EAA+BI,UAAYlB,EAAekB,WAEpB,MAAtClB,EAAemB,sBACfL,EAA+BK,oBAC3BnB,EAAemB,qBAEgB,MAAnCnB,EAAeoB,mBACfN,EAA+BM,iBAC3BpB,EAAeoB,kBAEvBuI,EAAKD,KAAKM,OAAO,aAAc,IAAI3J,KAAK,CAACiB,KAAKC,UAAUT,IAAkC,CAAEP,KA7DlF,qBA6DsG,cAC/E,MAA7BP,EAAeM,YACfqJ,EAAKD,KAAKM,OAAO,oBAAqB,IAAI3J,KAAK,CAACL,EAAeM,YAAa,CAAEC,KAhE3D,6BAgE4F,qBAEnH,MAAM2F,QAAiBrG,KAAK+F,MAAM/F,KAAKuD,KAAMuG,GAC7C,GAAIzD,EAAS+D,GACT,MAAO,CACHjI,mBAAoB,YAA6BhC,GACjDkK,UAAW,CAAChE,IAIhB,MAAM,IAAI1G,MACN,gEAAG0G,EAASiE,WAWxB,aACI,MAAMC,QAA2BvK,KAAK+F,MAAM/F,KAAKuD,KAAMvD,KAAKkG,aAC5D,IAAKqE,EAAmBH,GACpB,MAAM,IAAIzK,MAAM,cAAcK,KAAKuD,gCAC5BgH,EAAmBD,iFAG9B,IAAIE,EACJ,IACIA,QAAoBD,EAAmBE,OAE3C,MAAOC,GACH,IAAIC,EAAU,+CAA+C3K,KAAKuD,QAelE,MAZIvD,KAAKuD,KAAKqF,SAAS,OACnB+B,GAAW,+UAQXA,GAAW,uEAGT,IAAIhL,MAAMgL,GAEpB,MAAMhK,EAAgB6J,EAAY7J,cAC5BE,EAAkB2J,EAAY3J,gBAC9BM,EAAcqJ,EAAYrJ,YAC1BC,EAAcoJ,EAAYpJ,YAC1BF,EAASsJ,EAAYtJ,OACrBG,EAAYmJ,EAAYnJ,UACxBC,EAAsBkJ,EAAYlJ,oBAExC,GAAqB,MAAjBX,GAA4C,MAAnBE,EACzB,MAAM,IAAIlB,MAAM,2BAA2BK,KAAKuD,iEAGpD,IAAIvC,EACAP,EACJ,GAAuB,MAAnBI,EAAyB,CACzB,MAAM+J,QAAgB5K,KAAKuG,YAAY1F,IACtCG,EAAaP,GAAcmK,EAEhC,MAAMC,EAAY,CACdlK,gBACAK,cACAP,aACAU,cACAC,cACAF,UAEa,MAAbG,IACAwJ,EAAUxJ,UAAYA,GAEC,MAAvBC,IACAuJ,EAAUvJ,oBAAsBA,GAEpC,MAAMwJ,EAAcN,EAAYjJ,iBAIhC,OAHIuJ,IACAD,EAAUtJ,iBAAmBuJ,GAE1BD,EAEX,kBAAkBhK,GACd,MAAMkK,EAAarG,MAAMC,QAAQ3E,KAAKuD,MAAQvD,KAAKuD,KAAK,GAAKvD,KAAKuD,MAC3DyH,EAAQC,GAyChB,SAAkBxG,GACrB,MAAMyG,EAAYzG,EAAI0G,YAAY,KAC5BC,EAAkB3G,EAAI0G,YAAY,KAClCH,EAASvG,EAAI4G,UAAU,EAAGH,GAC1BD,EAASG,EAAkBF,EAAYzG,EAAI4G,UAAUD,GAAmB,GAC9E,MAAO,CAACJ,EAAS,IAAKC,GA9COK,CAASP,GAC5BQ,EAAavL,KAAK2J,kBAAoBqB,EACtChK,EAAc,GACpB,IAAK,MAAMwK,KAAS3K,EAChBG,EAAYwC,QAAQgI,EAAMzK,SAE9B,MAAM4E,EAAY,GACZ8F,EAAc,GACpB,IAAK,MAAMnI,KAAgBzC,EACvB,IAAK,MAAM0C,KAAQD,EAAaxC,MACG,MAA3Bd,KAAK4J,mBACL6B,EAAYjI,KAAKxD,KAAK4J,mBAAmBrG,IAGzCoC,EAAUnC,KAAK+H,EAAahI,EAAO0H,GAI3CjL,KAAK4J,oBACLjE,EAAUnC,cAAcnE,QAAQgG,IAAIoG,IAExC,MAAM5C,QAAgBnD,EAAyBC,EAAW,CACtDO,YAAalG,KAAKkG,YAClBL,UAAW7F,KAAK+F,MAChBhB,WAAY/E,KAAK+E,aAErB,MAAO,CAAC/D,EAAa,YAAwB6H,KAsB9C,SAAS6C,EAAajH,GACzB,OAAkD,MAA3CA,EAAIkH,MAAM,EAAYC,kBApBjC,EAAYA,iBAAmB,eAsBxB,MAAMC,EAAa,CAACpH,EAAKmB,KAC5B,GAAqB,oBAAVG,QACS,MAAfH,GAAgD,MAAzBA,EAAYC,WAIpC,OAAO,KAEN,CACD,IAAIiG,GAAS,EAOb,GALIA,EADApH,MAAMC,QAAQF,GACLA,EAAIsD,OAAMgE,GAAWL,EAAaK,KAGlCL,EAAajH,GAEtBqH,EACA,OAAOE,EAAKvH,EAAKmB,GAGzB,OAAO,MA0EJ,SAASoG,EAAKzI,EAAMqC,GACvB,OAAO,IAAI,EAAYrC,EAAMqC,GAO1B,SAASqG,EAAmB1I,EAAMqC,GACrC,OAAOoG,EAAKzI,EAAMqC,GAjFtB,IAAiBpB,mBAAmBqH,GACpC,IAAiBK,mBAAmBL,GC/OpC,MAAMM,EACF,YAAYhM,GACRH,KAAKG,eAAiBA,EAE1B,aACI,OAAOH,KAAKG,gBAGpB,MAAMiM,EACF,YAAYC,GACRrM,KAAKqM,YAAcA,EAEvB,WAAWlM,GACP,OAAOH,KAAKqM,YAAYlM,IAwBzB,SAASmM,EAAWnM,EAAgBa,EAAaP,EAAY8L,GAChE,GAAyB,IAArBC,UAAUzM,OAAc,CAGxB,OAFyD,MAAhCI,EAAeQ,eACN,MAA9BR,EAAea,YAER,IAAImL,EAAkBhM,IAK7BsM,QAAQC,KAAK,yNAIN,IAAIP,EAAkB,CAAExL,cAAeR,KAUlD,OAJAsM,QAAQC,KAAK,yNAIN,IAAIP,EAAkB,CACzBxL,cAAeR,EACfa,cACAP,aACA8L,mBAmBL,SAASI,EAAgBN,GAC5B,OAAO,IAAID,EAAiBC,G,yLCvEzB,SAASO,GAAuBC,EAAMC,GACzC,GAAID,EAAK9M,SAAW+M,EAAK/M,OACrB,MAAM,IAAIJ,MACN,gEAAGkN,EAAK9M,iBAAiB+M,EAAK/M,WAEtC,MAAMgD,EAAS,IAAIgK,aAA2B,EAAdF,EAAK9M,QACrC,IAAK,IAAIqI,EAAI,EAAGA,EAAIrF,EAAOhD,OAAQqI,GAAK,EACpCrF,EAAOqF,GAAKyE,EAAKzE,EAAI,GACrBrF,EAAOqF,EAAI,GAAK0E,EAAK1E,EAAI,GAE7B,OAAOrF,EAgBJ,SAASiK,GAAuBC,GACnC,MAAMJ,EAAO,IAAIE,aAAaE,EAAQlN,OAAS,GACzC+M,EAAO,IAAIC,aAAaE,EAAQlN,OAAS,GAC/C,IAAK,IAAIqI,EAAI,EAAGA,EAAI6E,EAAQlN,OAAQqI,GAAK,EACrCyE,EAAKzE,EAAI,GAAK6E,EAAQ7E,GACtB0E,EAAK1E,EAAI,GAAK6E,EAAQ7E,EAAI,GAE9B,MAAO,CAAEyE,OAAMC,QAMZ,SAASI,GAAqBD,GACjC,MAAME,EAAMC,KAAKC,KAAKJ,EAAQlN,OAAS,GACjC8M,EAAO,IAAIE,aAAaI,GACxBL,EAAO,IAAIC,aAAaI,GAC9B,IAAK,IAAI/E,EAAI,EAAGA,EAAI6E,EAAQlN,OAAQqI,GAAK,EACrCyE,EAAKO,KAAKE,MAAMlF,EAAI,IAAM6E,EAAQ7E,GAClC0E,EAAKM,KAAKE,MAAMlF,EAAI,IAAM6E,EAAQ7E,EAAI,GAE1C,MAAO,CAAEyE,OAAMC,QAMZ,SAASS,GAAoBN,GAChC,MAAME,EAAMC,KAAKE,MAAML,EAAQlN,OAAS,GAClC8M,EAAO,IAAIE,aAAaI,GACxBL,EAAO,IAAIC,aAAaI,GAC9B,IAAK,IAAI/E,EAAI,EAAGA,EAAI6E,EAAQlN,OAAQqI,GAAK,EACrCyE,EAAKO,KAAKE,MAAMlF,EAAI,IAAM6E,EAAQ7E,GAClC0E,EAAKM,KAAKE,MAAMlF,EAAI,IAAM6E,EAAQ7E,EAAI,GAE1C,MAAO,CAAEyE,OAAMC,QAOZ,SAASU,GAAoBP,EAASvJ,GAGzC,MAAO,CAAEmJ,KAFII,EAAgB,EAARvJ,GAENoJ,KADFG,EAAgB,EAARvJ,EAAY,IAS9B,SAAS+J,GAAmBC,EAAMb,EAAMC,EAAMpJ,GACjDgK,EAAa,EAARhK,GAAamJ,EAClBa,EAAa,EAARhK,EAAY,GAAKoJ,EAKnB,SAASa,GAAUC,EAAGC,GACzB,MAAMhB,EAAO,IAAIE,aAAaa,EAAI,GAC5Bd,EAAO,IAAIC,aAAaa,EAAI,GAClC,IAAK,IAAIxF,EAAI,EAAGA,EAAIgF,KAAKC,KAAKO,EAAI,GAAIxF,IAAK,CACvC,MAAM0F,GAAKD,EAAU,GAAK,GAAKT,KAAKW,IAAM3F,EAAIwF,GAC9Cf,EAAKzE,GAAKgF,KAAKY,IAAIF,GACnBhB,EAAK1E,GAAKgF,KAAKa,IAAIH,GAEvB,MAAO,CAAEjB,OAAMC,QAKZ,SAASoB,GAASC,EAAGP,EAAGC,GAC3B,MAAMC,GAAKD,EAAU,GAAK,GAAKT,KAAKW,IAAMI,EAAIP,GAG9C,MAAO,CAAEf,KAFIO,KAAKY,IAAIF,GAEPhB,KADFM,KAAKa,IAAIH,ICnH1B,MAAMM,GAAQ,KACRC,GAAc,MAgBb,SAASC,GAAqBC,EAAUC,GAE3C,MAAMC,IADNF,EAAWA,EAASG,QAAQ,MAAO,KACP3O,OAASwO,EAASG,QAAQL,GAAa,IAAItO,QACnEqO,GAAMrO,OACV,GAAI0O,EAAY,EACZ,MAAM,IAAI9O,MAAM,iDAEf,GAAI8O,EAAY,EACjB,MAAM,IAAI9O,MAAM,mDAEpB,MAAOgP,EAAaC,GAAgBL,EAASM,MAAMT,IACnD,aAA0C,IAAnCO,EAAYhL,QAzBN,QAyBgC,IAAM,wDACnD,MAAMmL,EAAaH,EAAYE,MA3BrB,KA4BJE,EAAYD,EAAW/O,OAC7B,GAAIyO,IAAeO,EACf,MAAM,IAAIpP,MAAM,YAAYoP,6BAAqCP,KAErE,GAAIO,EAAY,EACZ,MAAM,IAAIpP,MAAM,iEAEpB,MAAMqP,EAAU,GAChB,IAAK,IAAI5G,EAAI,EAAGA,EAAIwG,EAAa7O,SAAUqI,EAAG,CAC1C,MAAM6G,EAAUL,EAAaxG,GAC7B,IAAK0G,EAAWI,MAAKC,IAA6C,IAAhCA,EAAUxL,QAAQsL,KAChD,MAAM,IAAItP,MAAM,uCAAuCsP,2CAGzB,IAA9BD,EAAQrL,QAAQsL,IAChBD,EAAQxL,KAAKyL,GAGrB,IAAK,IAAI7G,EAAI,EAAGA,EAAIuG,EAAY5O,SAAUqI,EAAG,CACzC,MAAM6G,EAAUN,EAAYvG,IACM,IAA9B4G,EAAQrL,QAAQsL,IAhDd,MAgDiCA,GACnCD,EAAQxL,KAAKyL,GAGrB,MAAMG,EAAS,IAAI1K,MAAMoK,EAAW/O,QACpC,IAAK,IAAIqI,EAAI,EAAGA,EAAI2G,IAAa3G,EAAG,CAChC,GAAI,IAAIiH,IAAIP,EAAW1G,GAAGyG,MAAM,KAAKS,OAASR,EAAW1G,GAAGrI,OACxD,MAAM,IAAIJ,MAAM,2CAA2CmP,EAAW1G,mEAG1EgH,EAAOhH,GAAK,GACZ,IAAK,IAAImH,EAAI,EAAGA,EAAIT,EAAW1G,GAAGrI,SAAUwP,EACxCH,EAAOhH,GAAG5E,KAAKwL,EAAQrL,QAAQmL,EAAW1G,GAAGmH,KAGrD,MAAMC,EAAUR,EAAQjP,OAElB0P,EAAa,GACnB,IAAK,IAAIrH,EAFUwG,EAAa7O,OAEPqI,EAAIoH,IAAWpH,EACpCqH,EAAWjM,KAAK4E,GAEpB,MAAO,CAAE4G,UAASS,aAAYL,UAa3B,SAASM,GAAqBC,EAAOP,GACxC,IAAIQ,EAAqB,IAAIlL,MAAMiL,GACnCC,EAAmBC,MAAM,GACzB,IAAK,IAAIzH,EAAI,EAAGA,EAAIgH,EAAOrP,SAAUqI,EACjCwH,EAAmBR,EAAOhH,IAAMA,EAEpC,MAAM0H,EAAa,GACnB,IAAK,IAAI1H,EAAI,EAAGA,EAAIuH,IAASvH,GACM,IAA3BwH,EAAmBxH,IACnB0H,EAAWtM,KAAK4E,GAIxB,OADAwH,EAAqBA,EAAmB1H,QAAO6H,IAAY,IAAPA,IAC7C,CAAEH,qBAAoBE,cAM1B,SAASE,GAAoBL,EAAOP,EAAQa,GAC/C,MAAMC,EAAW,IAAIxL,MAAMiL,GAC3B,IAAK,IAAIvH,EAAI,EAAGA,EAAI6H,EAAQlQ,SAAUqI,EAAG,CACrC,MAAMX,EAAQwI,EAAQ7H,GAAGX,MACzB,IAAK,IAAI8H,EAAI,EAAGA,EAAIH,EAAOhH,GAAGrI,SAAUwP,OACLY,IAA3BD,EAASd,EAAOhH,GAAGmH,IACnBW,EAASd,EAAOhH,GAAGmH,IAAM9H,EAAM8H,GAG/B,YAAOW,EAASd,EAAOhH,GAAGmH,MAAQ9H,EAAM8H,IAAI,IAAM,sBAAsBW,EAASd,EAAOhH,GAAGmH,eAAeA,qBACnF9N,KAAKC,UAAU+F,yBACbA,EAAM8H,QAoBxC,SAASa,GAAqBX,EAAYL,GAC7C,MAAM7L,EAAOkM,EACPY,EAAQ,GACd,IAAIC,EAAS,EACa,IAAtBb,EAAW1P,QAEXwD,EAAKC,MAAM,GAEf8M,EAASb,EAAW1P,OAAS,EAC7B,IAAK,IAAIqI,EAAI,EAAGA,EAAIkI,IAAUlI,EAC1BiI,EAAM7M,KAAK,IAEf,MAAM+M,EAAsB,GAC5B,IAAK,IAAInI,EAAI,EAAGA,EAAI7E,EAAKxD,SAAUqI,EAAG,CAClC,MACMoI,EAAcC,GAAiBrB,EADnB7L,EAAK6E,IAEvB,IAAK,MAAMsI,KAAaF,GAC4B,IAA5CD,EAAoB5M,QAAQ+M,KAC5BL,EAAMjI,GAAG5E,KAAKkN,GACdH,EAAoB/M,KAAKkN,IAIrC,MAAO,CAAEnN,OAAM8M,SAGZ,SAASM,GAAsBC,GAClC,OAAOA,EAAK7I,OAAM,CAAC8I,EAAKnN,IAAUmN,IAAQnN,IAE9C,SAAS+M,GAAiBrB,EAAQyB,GAC9B,MAAML,EAAc,GACpB,IAAK,IAAIpI,EAAI,EAAGA,EAAIgH,EAAOrP,SAAUqI,EACR,IAArBgH,EAAOhH,GAAGrI,SAA4C,IAA5BqP,EAAOhH,GAAGzE,QAAQkN,KAAwB,IAATA,GAC3DL,EAAYhN,KAAK4E,GAGzB,OAAOoI,E,wBCnJJ,SAASM,GAAuBC,GACnC,IAEI,OAAOA,EAAK5M,KAAI6M,GAAO,uBAAaA,KAExC,MAAO7N,GACH,MAAM,IAAIxD,MAAM,4DAA4DwD,MAG7E,SAAS8N,GAAuBC,GACnC,OAAOA,EAAQ/M,KAAIgN,GAAK,uBAAaA,K,wDCrBlC,SAASC,EAAaC,EAAKC,EAASC,GACvC,MAAM7N,EAmBH,SAAsB2N,EAAKvO,EAAQyO,GACtC,OAYJ,SAAuBF,EAAKvO,EAAQyO,GAChC,IAAIC,EAAO,EACPC,EAAQJ,EAAItR,OACZ2R,EAAS,EACT1J,GAAQ,EACZ,KAAOwJ,EAAOC,GAAO,CACjBC,EAASF,GAASC,EAAQD,IAAU,GACpC,MAAMG,EAAgBJ,EAAWzO,EAAQuO,EAAIK,IACzCC,EAAgB,EAChBH,EAAOE,EAAS,GAGhBD,EAAQC,EAGR1J,GAAS2J,GAGjB,OAAO3J,EAAQwJ,GAAQA,EAAO,EA9BvBI,CAAcP,EAAKvO,EAAQyO,GAAcM,GApBlCC,CAAaT,EAAKC,EAASC,GACnCQ,EAAiBrO,EAAQ,IAAMA,EAAQ,GAAKA,EAClD2N,EAAIW,OAAOD,EAAgB,EAAGT,GA2BlC,SAASO,EAAkBI,EAAGC,GAC1B,OAAOD,EAAIC,EAAI,EAAID,EAAIC,GAAK,EAAI,EC3C7B,SAASC,EAAwBC,EAAOC,EAAQC,EAAeC,EAAcC,GAChF,OAAOC,EAAuBL,EAAOC,EAAQC,EAAeC,EAAcC,EAAgB,GAEvF,SAASE,EAAwBN,EAAOC,EAAQC,EAAeC,EAAcC,EAAgBG,GAChG,OAAOF,EAAuBL,EAAOC,EAAQC,EAAeC,EAAcC,EAAgB,GAAsB,EAAgCG,GAA6C,GAG1L,SAASC,EAAwBR,EAAOC,EAAQC,EAAeC,EAAcC,EAAgBK,GAChG,OAAOJ,EAAuBL,EAAOC,EAAQC,EAAeC,EAAcC,EAAgBK,GAAc,GAE5G,SAASJ,EAAuBL,EAAOC,EAAQC,EAAeC,EAAcC,EAAgBK,EAAcC,GAAqB,EAAOH,GAAqB,EAAOI,GAAqB,GAGnL,MAAMC,EAAa,GACnB,IAAK,IAAI5K,EAAI,EAAGA,EAAIiK,EAAOtS,OAAQqI,IAC3BiK,EAAOjK,GAAKoK,GACZQ,EAAWxP,KAAK,CAAEyP,MAAOZ,EAAOjK,GAAI8K,SAAU9K,EAAG+K,mBAAoB,IAG7EH,EAAWI,KAAKC,GAGhB,MAAMC,EAAQT,EAAe,GAAM,GAAMA,EAAgB,EACnDU,EAAkB,GAClBC,EAAiB,GACvB,KAAOD,EAAgBxT,OAASuS,GAAiBU,EAAWjT,OAAS,GAAG,CACpE,MAAM0T,EAAYT,EAAWU,OACrBT,MAAOU,EAAa,SAAET,EAAQ,mBAAEC,GAAuBM,EAC/D,GAAIE,EAAgBnB,EAChB,MAQJ,IAAIoB,GAAkB,EACtB,IAAK,IAAIrE,EAAIgE,EAAgBxT,OAAS,EAAGwP,GAAK4D,IAAsB5D,EAAG,CACnE,MAAMsE,EAAMC,EAAsB1B,EAAOc,EAAUK,EAAgBhE,IACnE,GAAIsE,GAAOtB,EAAc,CACrBqB,GAAkB,EAClB,MAIJ,GAFAH,EAAUR,MACNQ,EAAUR,MAAQc,EAAexB,EAAce,EAAOO,GACtDJ,EAAUR,OAAST,EACnB,MAURiB,EAAUN,mBAAqBI,EAAgBxT,OAC1C6T,IAGGH,EAAUR,QAAUU,GACpBJ,EAAgB/P,KAAK0P,GACrBM,EAAehQ,KAAKiQ,EAAUR,QAEzBQ,EAAUR,MAAQT,GAGvBpB,EAAa4B,EAAYS,EAAWJ,IAKhD,MAAMW,EAAeT,EAAgBxT,OAC/BkU,EAAa3B,EAAgB0B,EAC/BrB,GAAsBsB,EAAa,IACnCV,EAAgB/P,QAAQ,IAAIkB,MAAMuP,GAAYpE,KAAK,IACnD2D,EAAehQ,QAAQ,IAAIkB,MAAMuP,GAAYpE,KAAK,KAEtD,MAAM9M,EAAS,CAAEwQ,mBAOjB,OANIT,IACA/P,EAAuB,eAAIyQ,GAE3BT,IACAhQ,EAAqB,aAAIiR,GAEtBjR,EAEX,SAAS+Q,EAAsB1B,EAAOhK,EAAGmH,GACrC,MAAM2E,EAAS9B,EAAM+B,SAAa,EAAJ/L,EAAW,EAAJA,EAAQ,GACvCgM,EAAShC,EAAM+B,SAAa,EAAJ5E,EAAW,EAAJA,EAAQ,GACvC8E,EAAQjH,KAAKkH,IAAIJ,EAAO,GAAIA,EAAO,IACnCK,EAAQnH,KAAKkH,IAAIJ,EAAO,GAAIA,EAAO,IACnCM,EAAQpH,KAAKqH,IAAIP,EAAO,GAAIA,EAAO,IACnCQ,EAAQtH,KAAKqH,IAAIP,EAAO,GAAIA,EAAO,IACnCS,EAAQvH,KAAKkH,IAAIF,EAAO,GAAIA,EAAO,IACnCQ,EAAQxH,KAAKkH,IAAIF,EAAO,GAAIA,EAAO,IACnCS,EAAQzH,KAAKqH,IAAIL,EAAO,GAAIA,EAAO,IACnCU,EAAQ1H,KAAKqH,IAAIL,EAAO,GAAIA,EAAO,IACnCW,GAASP,EAAQH,IAAUK,EAAQH,GACnCS,GAASH,EAAQF,IAAUG,EAAQF,GACzC,GAAIG,GAAS,GAAKC,GAAS,EACvB,OAAO,EAEX,MAAMC,EAAmB7H,KAAKqH,IAAIJ,EAAOM,GACnCO,EAAmB9H,KAAKqH,IAAIF,EAAOK,GACnCO,EAAmB/H,KAAKkH,IAAIE,EAAOK,GACnCO,EAAmBhI,KAAKkH,IAAII,EAAOI,GACnCO,EAAmBjI,KAAKqH,IAAIU,EAAmBF,EAAkB,GACnE7H,KAAKqH,IAAIW,EAAmBF,EAAkB,GAClD,OAAOG,GAAoBN,EAAQC,EAAQK,GAM/C,SAAStB,EAAexB,EAAce,EAAOO,GACzC,MAAMyB,EAASlI,KAAKmI,IAAIjC,EAAQO,EAAMA,GACtC,OAAOA,GAAOtB,EAAe+C,EAAS,EAE1C,SAASjC,EAAoBmC,EAAIC,GAK7B,OAAQD,EAAGvC,MAAQwC,EAAGxC,OAChBuC,EAAGvC,QAAUwC,EAAGxC,OAAWwC,EAAGvC,SAAWsC,EAAGtC,S,yIC/ItD,qCAmBA,MAAMwC,EAAM,cAKZA,EAAIC,aAAa,SAAS,KAAM,IAAOC,IAC/BA,GACAnJ,QAAQC,KAAK,kJAMrBgJ,EAAIC,aAAa,cAAc,IAAM,QAErCD,EAAIC,aAAa,WAAW,IAA0B,oBAAZE,GACT,oBAArBA,EAAQC,UACkB,oBAA1BD,EAAQC,SAASC,OAE7BL,EAAIC,aAAa,aAAa,IAA2B,oBAAdK,WAA0C,MAAbA,WAC7C,MAAvBA,UAAUC,WAAqB,SAASC,KAAKF,UAAUC,YACvD,aAAaC,KAAKF,UAAUG,UAKhCT,EAAIC,aAAa,QAAQ,KAAM,IAK/BD,EAAIC,aAAa,sCAAsC,IAAMD,EAAIhW,QAAQ,WAEzEgW,EAAIC,aAAa,gCAAgC,KAAM,IAEvDD,EAAIC,aAAa,WAAW,KAAM,IAElCD,EAAIC,aAAa,gCAAgC,KAAM,IAEvDD,EAAIC,aAAa,uBAAuB,KAAM,M,oDC1D9C,oEAmBO,MAAMS,EACT,YAAYC,EAASC,GACjBtW,KAAKqW,QAAUA,EACfrW,KAAKsW,UAAYA,EACjBtW,KAAK0N,KAAO,IAAI6I,QAChBvW,KAAKwW,aAAe,EAExB,IAAIC,GAIA,OAHKzW,KAAK0N,KAAKgJ,IAAID,IACfzW,KAAKsW,UAAUK,SAAS3W,KAAKqW,QAASI,GAEnCzW,KAAK0N,KAAKkJ,IAAIH,GAEzB,IAAIA,EAAQlR,GACRvF,KAAKwW,eACLxW,KAAK0N,KAAKnE,IAAIkN,EAAQlR,GAE1B,IAAIkR,GACA,OAAOzW,KAAK0N,KAAKgJ,IAAID,GAEzB,OAAOA,GAEH,OADAzW,KAAKwW,eACExW,KAAK0N,KAAKmJ,OAAOJ,GAE5B,aACI,OAAOzW,KAAKwW,cASb,MAAMM,EACT,SAASL,GACL,OAAOM,EAAkB,YAE7B,OAAON,GACH,OAAOM,EAAkB,UAE7B,iBACI,OAAO,EAEX,KAAK3X,GACD,OAAO2X,EAAkB,QAE7B,KAAKN,GACD,OAAOM,EAAkB,QAE7B,SAASN,GACL,OAAOM,EAAkB,YAE7B,aACI,OAAOA,EAAkB,cAE7B,YAAYN,EAAQO,GAChB,OAAOD,EAAkB,eAE7B,MAAME,EAAQxP,EAAOF,GACjB,OAAOwP,EAAkB,SAE7B,KAAKN,EAAQQ,EAAQxP,EAAOF,EAAO2P,GAC/B,OAAOH,EAAkB,QAE7B,SACI,OAAOA,EAAkB,UAG7B,iBACI,OAAOA,EAAkB,kBAG7B,UACI,OAAiC,KAA1B/W,KAAKmX,iBA7EW,KACA,KA8E3B,UACI,OAAOJ,EAAkB,YAGjC,SAASA,EAAkBK,GACvB,MAAM,IAAIzX,MAAM,IAAIyX,+H,iCCpGxB,kCAoBO,MAAMC,EAAuB,CAChC,QAAW,EACX,QAAW,EACX,MAAS,EACT,OAAU,EACV,MAAS,EACT,KAAQ,EACR,UAAa,I,iCCYV,SAASC,IACZ,MAA0B,oBAAXjX,QAA6C,MAAnBA,OAAOuB,UAEd,oBAAtB2V,kBA1ChB,mC,iCCAA,kTAoDO,SAASC,EAAgBC,GACxB,cAAM/X,QAAQ,iCACd+M,QAAQC,KAAK+K,iFAkBd,SAASC,IACZ,OAAO,IAoGJ,SAASC,EAAKC,EAAUC,GAC3B,OAAO,IAAOF,KAAKC,EAAUC,GAa1B,SAASC,EAAQC,GACJ,YAAsBA,GAC9B1U,SAAQ2U,GAAUA,EAAOF,YAkC9B,SAASG,EAAKlV,GACjB,OAAO,IAAOkV,KAAKlV,GA6ChB,SAASmV,EAAWC,GACvB,OAAO,IAAOD,WAAWC,GAkBtB,SAASC,IACZ,OAAO,IAAOD,YAwCX,SAASE,EAAgBrV,EAAMsV,EAASC,EAAW,GACtD,OAAO,IAAOF,gBAAgBrV,EAAMsV,EAASC,GAhRjD,YAAwBf,I,iCC1DxB,sGAoBA,MAAMgB,EAAgB,eAKhBC,EAAmB,eAInBC,EAAkB,mBAYxB,SAASC,IACL,IAAK,cAAMjZ,QAAQ,cAIf,MAAM,IAAIC,MAAM,2FAIpB,MAAMiZ,EAA8B,oBAAXvY,OAAyBwY,KAAOxY,OACnDiY,EAAUM,EAAUE,WAAaF,EAAUG,cAC7CH,EAAUI,iBAAmBJ,EAAUK,aACvCL,EAAUM,cACd,GAAe,MAAXZ,EACA,MAAM,IAAI3Y,MAAM,6DAEpB,OAAO2Y,EAEX,SAASa,EAAcC,GACnB,MAAMC,EAAKD,EAAYrW,OACvBsW,EAAGC,kBAAkBb,EAAkB,CAAEc,QAAS,cAClDF,EAAGC,kBAAkBZ,EAAiB,CAAEa,QAAS,cAO9C,MAAMC,EACT,YAAYC,GAER,GADAzZ,KAAK8Y,UAAYH,IACA,MAAbc,IAAsBA,EACtB,MAAM,IAAI9Z,MAAM,kEAEpBK,KAAKyZ,UAAYA,EAErB,WAAWtZ,GAEP,GAAIA,EAAeQ,yBAAyBC,YACxC,MAAM,IAAIjB,MAAM,4FAGpB,OAAOK,KAAK0Z,eAAe1Z,KAAKyZ,UAAWtZ,GAE/C,aACI,OAAOH,KAAK0Z,eAAe1Z,KAAKyZ,WAgBpC,eAAeA,EAAWtZ,GACtB,OAAO,IAAId,SAAQ,CAACC,EAASiD,KACzB,MAAM6W,EAAcpZ,KAAK8Y,UAAUa,KAAKnB,EAnF3B,GAoFbY,EAAYQ,gBAAkB,IAAMT,EAAcC,GAClDA,EAAYS,UAAY,KACpB,MAAMR,EAAKD,EAAYrW,OACvB,GAAsB,MAAlB5C,EAAwB,CAExB,MAAM2Z,EAAUT,EAAGU,YAAYtB,EAAkB,YAE3CuB,EADaF,EAAQG,YAAYxB,GACT7B,IAAI5W,KAAKyZ,WACvCO,EAAWH,UAAY,KACnB,GAAyB,MAArBG,EAAWjX,OAEX,OADAsW,EAAGa,QACI3X,EAAO,IAAI5C,MAAM,gCAAgCK,KAAKyZ,6BAI7Dna,EAAQ0a,EAAWjX,OAAO5C,iBAGlC6Z,EAAWpW,QAAUC,IACjBwV,EAAGa,QACI3X,EAAOyX,EAAWnW,QAE7BiW,EAAQK,WAAa,IAAMd,EAAGa,YAE7B,CAED,MAAM/X,EAAqB,YAA6BhC,GAElDia,EAASf,EAAGU,YAAYrB,EAAiB,aAC/C,IAAI2B,EAAYD,EAAOH,YAAYvB,GACnC,MAAM4B,EAAiBD,EAAUE,IAAI,CAAEd,UAAWzZ,KAAKyZ,UAAWtX,uBAClE,IAAI2X,EACJQ,EAAeT,UAAY,KAEvBC,EAAUT,EAAGU,YAAYtB,EAAkB,aAC3C,MACM+B,EADaV,EAAQG,YAAYxB,GACJ8B,IAAI,CACnCd,UAAWzZ,KAAKyZ,UAChBtZ,iBACAgC,uBAEJqY,EAAgBX,UAAY,IAAMva,EAAQ,CAAE6C,uBAC5CqY,EAAgB5W,QAAUC,IAGtBwW,EAAYD,EAAOH,YAAYvB,GAC/B,MAAM+B,EAAoBJ,EAAUxD,OAAO7W,KAAKyZ,WAChDgB,EAAkBZ,UAAY,KAC1BR,EAAGa,QACI3X,EAAOiY,EAAgB3W,QAElC4W,EAAkB7W,QAAUC,IACxBwV,EAAGa,QACI3X,EAAOiY,EAAgB3W,UAI1CyW,EAAe1W,QAAUC,IACrBwV,EAAGa,QACI3X,EAAO+X,EAAezW,QAEjCuW,EAAOD,WAAa,KACD,MAAXL,EACAT,EAAGa,QAGHJ,EAAQK,WAAa,IAAMd,EAAGa,WAK9Cd,EAAYxV,QAAUC,GAAStB,EAAO6W,EAAYvV,WAI9D2V,EAAiB3Z,WAAa,eACvB,MAAM6a,EAAmBjW,IAC5B,OAAK,cAAM/E,QAAQ,gBAIVgF,MAAMC,QAAQF,IAAQA,EAAI7E,WAAW4Z,EAAiB3Z,aA2BlC4Z,EA1BGhV,EAAI3E,MAAM0Z,EAAiB3Z,WAAWE,QA2B/D,IAAIyZ,EAAiBC,IA/BjB,KA8BR,IAA0BA,GAnBjC,IAAiBjV,mBAAmBkW,GACpC,IAAiBxO,mBAAmBwO,GA0B7B,MAAMC,EACT,cACI3a,KAAK8Y,UAAYH,IAErB,mBACI,OAAO,IAAItZ,SAAQ,CAACC,EAASiD,KACzB,MAAM6W,EAAcpZ,KAAK8Y,UAAUa,KAAKnB,EA9M3B,GA+MbY,EAAYQ,gBAAkB,IAAMT,EAAcC,GAClDA,EAAYS,UAAY,KACpB,MAAMR,EAAKD,EAAYrW,OACjB6X,EAAKvB,EAAGU,YAAYrB,EAAiB,YAUrCmC,EATQD,EAAGX,YAAYvB,GASGoC,SAChCD,EAAkBhB,UAAY,KAC1B,MAAMkB,EAAM,GACZ,IAAK,MAAMC,KAAQH,EAAkB9X,OACjCgY,EAAIC,EAAKvB,WAAauB,EAAK7Y,mBAE/B7C,EAAQyb,IAEZF,EAAkBjX,QAAUC,IACxBwV,EAAGa,QACI3X,EAAOsY,EAAkBhX,QAEpC+W,EAAGT,WAAa,IAAMd,EAAGa,SAE7Bd,EAAYxV,QAAUC,GAAStB,EAAO6W,EAAYvV,UAG1D,kBAAkBN,GA1CtB,IAA0B0X,EA4ClB,OADA1X,GA3CkB0X,EA2CM1X,GA1CjB3D,WAAW4Z,EAAiB3Z,YACnCob,EAAInb,MAAM0Z,EAAiB3Z,WAAWE,QACtCkb,EAyCO,IAAI5b,SAAQ,CAACC,EAASiD,KACzB,MAAM6W,EAAcpZ,KAAK8Y,UAAUa,KAAKnB,EAhP3B,GAiPbY,EAAYQ,gBAAkB,IAAMT,EAAcC,GAClDA,EAAYS,UAAY,KACpB,MAAMR,EAAKD,EAAYrW,OACjBqX,EAASf,EAAGU,YAAYrB,EAAiB,aACzC2B,EAAYD,EAAOH,YAAYvB,GAC/BwC,EAAiBb,EAAUzD,IAAIrT,GACrC,IAAIuW,EACJoB,EAAerB,UAAY,KACvB,GAA6B,MAAzBqB,EAAenY,OAEf,OADAsW,EAAGa,QACI3X,EAAO,IAAI5C,MAAM,gCAAgC4D,qBAGvD,CAED,MAAMkX,EAAoBJ,EAAUxD,OAAOtT,GACrC4X,EAAkB,KAEpBrB,EAAUT,EAAGU,YAAYtB,EAAkB,aAC3C,MACM2C,EADatB,EAAQG,YAAYxB,GACD5B,OAAOtT,GAC7C6X,EAAmBvB,UAAY,IAAMva,EAAQ4b,EAAenY,OAAOZ,oBACnEiZ,EAAmBxX,QAAUC,GAAStB,EAAO2Y,EAAerX,QAIhE4W,EAAkBZ,UAAYsB,EAC9BV,EAAkB7W,QAAUC,IACxBsX,IACA9B,EAAGa,QACI3X,EAAO2Y,EAAerX,UAIzCqX,EAAetX,QAAUC,IACrBwV,EAAGa,QACI3X,EAAO2Y,EAAerX,QAEjCuW,EAAOD,WAAa,KACD,MAAXL,EACAT,EAAGa,QAGHJ,EAAQK,WAAa,IAAMd,EAAGa,UAI1Cd,EAAYxV,QAAUC,GAAStB,EAAO6W,EAAYvV,a,iCCrT9D,6GAqBA,MAAMwX,EAAiB,IACjBC,EAAc,sBACdC,EAAc,OACdC,EAAwB,iBACxBC,EAAsB,eACtBC,EAAqB,cACrBC,EAAwB,iBA2B9B,SAASC,EAAarY,GAClB,MAAO,CACHsY,KAAM,CAACP,EAAa/X,EAAMgY,GAAalT,KAAKgT,GAC5CS,SAAU,CAACR,EAAa/X,EAAMiY,GAAuBnT,KAAKgT,GAC1Dra,YAAa,CAACsa,EAAa/X,EAAMkY,GAAqBpT,KAAKgT,GAC3D5a,WAAY,CAAC6a,EAAa/X,EAAMmY,GAAoBrT,KAAKgT,GACzDU,cAAe,CAACT,EAAa/X,EAAMoY,GAAuBtT,KAAKgT,IAUvE,SAASW,EAAoBf,GACzB,MAAMgB,EAAQhB,EAAIpM,MAAMwM,GACxB,GAAIY,EAAMlc,OAAS,EACf,MAAM,IAAIJ,MAAM,uBAAuBsb,KAE3C,OAAOgB,EAAMnc,MAAM,EAAGmc,EAAMlc,OAAS,GAAGsI,KAAKgT,GAY1C,MAAMa,EACT,YAAYzC,GACR,IAAK,cAAM/Z,QAAQ,eAAmC,oBAAXW,QACR,oBAAxBA,OAAO8b,aAKd,MAAM,IAAIxc,MAAM,2DAGpB,GADAK,KAAKoc,GAAK/b,OAAO8b,aACA,MAAb1C,IAAsBA,EACtB,MAAM,IAAI9Z,MAAM,sEAEpBK,KAAKyZ,UAAYA,EACjBzZ,KAAKqc,KAAOT,EAAa5b,KAAKyZ,WAWlC,WAAWtZ,GACP,GAAIA,EAAeQ,yBAAyBC,YACxC,MAAM,IAAIjB,MAAM,4FAGf,CACD,MAAMmc,EAAWra,KAAKC,UAAUvB,EAAeQ,eACzCK,EAAcS,KAAKC,UAAUvB,EAAea,aAC5CmB,EAAqB,YAA6BhC,GACxD,IACIH,KAAKoc,GAAGE,QAAQtc,KAAKqc,KAAKR,KAAMpa,KAAKC,UAAUS,IAC/CnC,KAAKoc,GAAGE,QAAQtc,KAAKqc,KAAKP,SAAUA,GACpC9b,KAAKoc,GAAGE,QAAQtc,KAAKqc,KAAKrb,YAAaA,GACvChB,KAAKoc,GAAGE,QAAQtc,KAAKqc,KAAK5b,WAAY,YAA0BN,EAAeM,aAC/E,MAAMsC,EAAS,CACX7B,OAAQf,EAAee,OACvBC,YAAahB,EAAegB,YAC5BC,YAAajB,EAAeiB,aAYhC,OAVgC,MAA5BjB,EAAekB,YACf0B,EAAO1B,UAAYlB,EAAekB,WAEI,MAAtClB,EAAemB,sBACfyB,EAAOzB,oBAAsBnB,EAAemB,qBAET,MAAnCnB,EAAeoB,mBACfwB,EAAOxB,iBAAmBpB,EAAeoB,kBAE7CvB,KAAKoc,GAAGE,QAAQtc,KAAKqc,KAAKN,cAAeta,KAAKC,UAAUqB,IACjD,CAAEZ,sBAEb,MAAOgB,GAOH,MALAnD,KAAKoc,GAAGG,WAAWvc,KAAKqc,KAAKR,MAC7B7b,KAAKoc,GAAGG,WAAWvc,KAAKqc,KAAKP,UAC7B9b,KAAKoc,GAAGG,WAAWvc,KAAKqc,KAAKrb,aAC7BhB,KAAKoc,GAAGG,WAAWvc,KAAKqc,KAAK5b,YAC7BT,KAAKoc,GAAGG,WAAWvc,KAAKqc,KAAKN,eACvB,IAAIpc,MAAM,yBAAyBK,KAAKyZ,kHAEpBtX,EAAmBqa,wCACrBra,EAAmBsa,qCACpBta,EAAmBua,sBAYtD,aACI,MAAMb,EAAOpa,KAAKoB,MAAM7C,KAAKoc,GAAGO,QAAQ3c,KAAKqc,KAAKR,OAClD,GAAY,MAARA,EACA,MAAM,IAAIlc,MAAM,kDAAkDK,KAAKyZ,cAE3E,GAA+B,SAA3BoC,EAAKe,kBACL,MAAM,IAAIjd,MAAM,6EAGpB,MAAMob,EAAM,GAENe,EAAWra,KAAKoB,MAAM7C,KAAKoc,GAAGO,QAAQ3c,KAAKqc,KAAKP,WACtD,GAAgB,MAAZA,EACA,MAAM,IAAInc,MAAM,4CAA4CK,KAAKyZ,0BAGrEsB,EAAIpa,cAAgBmb,EAEpB,MAAM9a,EAAcS,KAAKoB,MAAM7C,KAAKoc,GAAGO,QAAQ3c,KAAKqc,KAAKrb,cACzD,GAAmB,MAAfA,EACA,MAAM,IAAIrB,MAAM,gDAAgDK,KAAKyZ,2BAGzEsB,EAAI/Z,YAAcA,EAElB,MAAM6b,EAAiB7c,KAAKoc,GAAGO,QAAQ3c,KAAKqc,KAAKN,eACjD,GAAsB,MAAlBc,EAAwB,CACxB,MAAMC,EAAWrb,KAAKoB,MAAMga,GAC5B9B,EAAI7Z,OAAS4b,EAAiB,OAC9B/B,EAAI5Z,YAAc2b,EAAsB,YACxC/B,EAAI3Z,YAAc0b,EAAsB,YACX,MAAzBA,EAAoB,YACpB/B,EAAI1Z,UAAYyb,EAAoB,WAED,MAAnCA,EAA8B,sBAC9B/B,EAAIzZ,oBAAsBwb,EAA8B,qBAExB,MAAhCA,EAA2B,mBAC3B/B,EAAIxZ,iBAAmBub,EAA2B,kBAI1D,MAAMC,EAAmB/c,KAAKoc,GAAGO,QAAQ3c,KAAKqc,KAAK5b,YACnD,GAAwB,MAApBsc,EACA,MAAM,IAAIpd,MACN,wDAAIK,KAAKyZ,2BAGjB,OADAsB,EAAIta,WAAa,YAA0Bsc,GACpChC,GAGfmB,EAAoBrc,WAAa,kBAC1B,MAAMmd,EAAsBvY,IAC/B,OAAK,cAAM/E,QAAQ,gBAIVgF,MAAMC,QAAQF,IAAQA,EAAI7E,WAAWsc,EAAoBrc,aAkClC4Z,EAjCGhV,EAAI3E,MAAMoc,EAAoBrc,WAAWE,QAkCrE,IAAImc,EAAoBzC,IAtCpB,KAqCR,IAA6BA,GA1BpC,IAAiBjV,mBAAmBwY,GACpC,IAAiB9Q,mBAAmB8Q,GA4B7B,MAAMC,EACT,cACI,YAAO,cAAMvd,QAAQ,eAAe,IAAM,6CAC1C,YAAyB,oBAAXW,QACqB,oBAAxBA,OAAO8b,cAA8B,IAAM,4DACtDnc,KAAKoc,GAAK/b,OAAO8b,aAErB,mBACI,MAAMpB,EAAM,GACN/P,EAASsQ,EAAcD,EACvBpQ,EAASoQ,EAAiBE,EAChC,IAAK,IAAInT,EAAI,EAAGA,EAAIpI,KAAKoc,GAAGrc,SAAUqI,EAAG,CACrC,MAAM6S,EAAMjb,KAAKoc,GAAGnB,IAAI7S,GACxB,GAAI6S,EAAIrb,WAAWoL,IAAWiQ,EAAIrS,SAASqC,GAAS,CAEhD8P,EADkBiB,EAAoBf,IACrBxZ,KAAKoB,MAAM7C,KAAKoc,GAAGO,QAAQ1B,KAGpD,OAAOF,EAEX,kBAAkBxX,GA5MtB,IAA0B0X,EA8MlB,MAAMoB,EAAOT,EADbrY,GA7MkB0X,EA6MM1X,GA5MjB3D,WAAWsc,EAAoBrc,YACtCob,EAAInb,MAAMoc,EAAoBrc,WAAWE,QACzCkb,GA4MA,GAAkC,MAA9Bjb,KAAKoc,GAAGO,QAAQN,EAAKR,MACrB,MAAM,IAAIlc,MAAM,8BAA8B4D,MAElD,MAAMsY,EAAOpa,KAAKoB,MAAM7C,KAAKoc,GAAGO,QAAQN,EAAKR,OAK7C,OAJA7b,KAAKoc,GAAGG,WAAWF,EAAKR,MACxB7b,KAAKoc,GAAGG,WAAWF,EAAKP,UACxB9b,KAAKoc,GAAGG,WAAWF,EAAKrb,aACxBhB,KAAKoc,GAAGG,WAAWF,EAAK5b,YACjBob,K,iCCpSf,iFAoBA,MAAMqB,EApBN,OAsBA,GAAuB,EAChB,SAASC,EAAUC,GACtB,OAAOF,EAAKG,WAAWD,GAAK,EAAM,IAItC,MAAME,EAAKH,EAAU,oBAEfI,EAAKJ,EAAU,oBAEfK,EAAKL,EAAU,oBACrB,SAASM,EAASzM,GACd,OAAOA,EAAI0M,IAAI1M,EAAI2M,KAAK,KAE5B,SAAS5X,EAAMoL,EAAGyM,EAAQC,GACtB,MAAMC,EAAQ3M,EAAErR,MAAM8d,EAAQA,EAASC,GACvC,OAAOX,EAAKa,UAAUrZ,MAAMsZ,KAAKF,IAAQ,GAAM,GAEnD,SAASG,EAAQ9M,EAAGyM,GAChB,OAAO7X,EAAMoL,EAAGyM,EAAQ,GAE5B,SAASM,EAAQ/M,EAAGyM,GAChB,OAAO7X,EAAMoL,EAAGyM,EAAQ,GAE5B,SAASO,EAASnN,EAAKoN,GAEnB,OAAiB,IAAVA,EAAcpN,EAAMA,EAAI2M,KAAKS,GAAOC,GAAGrN,EAAIsN,IAAI,GAAKF,IAE/D,SAASG,EAAUC,EAAGC,EAAGC,EAAMvB,EAAU,qBAErC,IAAIlL,EAAIuM,EAAEd,IAAIe,GAAGC,IAAIA,GACrBzM,EAAIA,EAAEyL,IAAIzL,EAAE0L,KAAK,KACjB,IAAIzL,EAAIuM,EAAEf,IAAIzL,GAAGyM,IAAIA,GAGrB,OAFAxM,EAAIA,EAAEwL,IAAIxL,EAAEyL,KAAK,KACjBzL,EAAIA,EAAEwM,IAAIA,GACHxM,EAaX,SAASyM,EAA0BxN,EAAGyM,EAAQ3L,EAAGC,GAC7C,OAVJ,SAAgC0M,EAAG9Q,EAAG+Q,EAAGC,EAAG7M,EAAGC,GAC3CD,EAAIA,EAAE8M,IAAIH,GACV1M,EAAIiM,EAASjM,EAAE6M,IAAI9M,GAAG8M,IAAID,GAAI,IAC9B,MAAME,EAAI/M,EAIV,OAFAA,GADAA,EAAIA,EAAE8M,IAAIjR,IACJiR,IAAIF,GACV3M,EAAIA,EAAE6M,IAAIZ,EAASlM,EAAG,KACf,CAACA,EAAE8M,IAAID,GAAI5M,EAAE6M,IAAIC,IAGjBC,CAAuBhB,EAAQ9M,EAAGyM,GAASK,EAAQ9M,EAAGyM,EAAS,GAAIK,EAAQ9M,EAAGyM,EAAS,IAAKK,EAAQ9M,EAAGyM,EAAS,IAAK3L,EAAGC,GAgD5H,SAASgN,EAAc/N,EAAGhE,EAAMgE,EAAEpR,QACrC,MAAMof,EAAOjC,EAAKkC,WAAW,IAAI,GACjC,GAAIjS,GAAO,GACP,OAAIA,GAAO,GAjDnB,SAAsBgE,EAAGhE,EAAMgE,EAAEpR,QAC7B,GAAIoN,GAAO,EAAG,CACV,MAAMuR,EAAMlB,EAAGuB,IAAU,EAAN5R,GACb8E,EAAIgM,EAAQ9M,EAAG,GAAG4N,IAAIvB,GACtBtL,EAAI+L,EAAQ9M,EAAGhE,EAAM,GAG3B,OAAOoR,EAFGJ,EAASjM,EAAG,IAAIwM,IAAIA,GAAKK,IAAI9M,GAC7BkM,EAASlM,EAAG,IAAI8M,IAAI7M,GAAGwM,IAAIA,GACdA,GAE3B,GAAIvR,GAAO,EAAG,CACV,MAAMuR,EAAMlB,EAAGuB,IAAU,EAAN5R,GAEnB,OAAOoR,EADGL,EAAQ/M,EAAG,GACFmN,IAAI,GAAGS,IAAI5R,GAAM+Q,EAAQ/M,EAAGhE,EAAM,GAAIuR,GAE7D,GAAIvR,EAAM,EAAG,CACT,MAGM0R,EAHI1N,EAAE,IACFA,EAAEhE,GAAO,IAEC,GACd2R,EAAI3R,GAFAgE,EAAEhE,EAAM,IAEI,GACtB,OAAOsQ,EAASD,EAAGkB,IAAIG,GAAGnB,IAAIJ,EAAGoB,IAAII,KAAKJ,IAAIlB,GAElD,OAAOA,EA4BQ6B,CAAalO,EAAGhE,GA1BnC,SAAuBgE,EAAGhE,EAAMgE,EAAEpR,QAC9B,MAAM2e,EAAMlB,EAAGuB,IAAU,EAAN5R,GACb8E,EAAIgM,EAAQ9M,EAAG,GAAGuN,IAAInB,GACtBrL,EAAI+L,EAAQ9M,EAAG,GACf6N,EAAIf,EAAQ9M,EAAGhE,EAAM,GAAGuR,IAAIA,GAC5B3O,EAAIkO,EAAQ9M,EAAGhE,EAAM,IAAIuR,IAAIlB,GACnC,OAAOe,EAAUJ,EAASlM,EAAE8M,IAAI7M,GAAI,IAAI6M,IAAIZ,EAASa,EAAG,KAAKD,IAAIhP,GAAIkC,EAAE8M,IAAIZ,EAASjM,EAAE6M,IAAIvB,GAAK,KAAKuB,IAAIC,GAAIN,GAuB7FY,CAAcnO,EAAGhE,GAG3B,GAAIA,GAAO,GACZ,OAzBR,SAAuBgE,EAAGhE,EAAMgE,EAAEpR,QAC9B,MAAM2e,EAAMlB,EAAGuB,IAAU,EAAN5R,GACb8E,EAAIgM,EAAQ9M,EAAG,GAAGuN,IAAIlB,GACtBtL,EAAI+L,EAAQ9M,EAAG,GACf6N,EAAIf,EAAQ9M,EAAGhE,EAAM,GAAGuR,IAAIA,GAC5B3O,EAAIkO,EAAQ9M,EAAGhE,EAAM,IAAIuR,IAAIlB,GAC7BqB,EAAIV,EAASlM,EAAE8M,IAAI7M,GAAI,IAAI6M,IAAIZ,EAASa,EAAG,KAAKD,IAAIhP,GACpD+O,EAAIP,EAAUM,EAAG5M,EAAE8M,IAAIZ,EAASjM,EAAE6M,IAAIvB,GAAK,KAAKuB,IAAIC,GAAIN,GACxDhU,EAAIuT,EAAQ9M,EAAG,IAAIuN,IAAIA,GACvBtf,EAAI6e,EAAQ9M,EAAG,IACfoO,EAAIV,EAAEE,IAAId,EAAQ9M,EAAGhE,EAAM,KAAKuR,IAAIA,GACpCc,EAAIV,EAAEC,IAAId,EAAQ9M,EAAGhE,EAAM,KAAKuR,IAAIA,GAC1C,OAAOH,EAAUJ,EAASzT,EAAEqU,IAAI3f,GAAI,IAAI2f,IAAIZ,EAASoB,EAAG,KAAKR,IAAIS,GAAI9U,EAAEqU,IAAIZ,EAAS/e,EAAE2f,IAAI9M,GAAI,KAAK8M,IAAIQ,GAAIb,GAahGe,CAActO,EAAGhE,GAI5B,IAAIW,EAAIqR,EACJN,EAAIM,EAAKT,IAAInB,GAAIwB,IAAI,KACrBD,EAAIrB,EAASoB,EAAEH,IAAIlB,GAAIuB,IAAI,MAAML,IAAIlB,GACrCiB,EAAI,CAACvB,EAAKwC,MAAOxC,EAAKwC,OACtBd,EAAI,CAAC1B,EAAKwC,MAAOxC,EAAKwC,OAC1B5R,EAAIA,EAAE4Q,IAAIlB,GAAIuB,IAAId,EAAQ9M,EAAG,IAC7B,IAAIyM,EAAS,EAEb,MAAM+B,EAAyB,IAAjBxS,EAAM,GAAM,GACpByS,EAASD,GAAQxS,EAAM,EAAK,IAAM,GACxC,GACIW,EAAIqQ,EAASrQ,EAAEiR,IAAIF,GAAGE,IAAIN,EAAE,IAAIM,IAAId,EAAQ9M,EAAGyM,EAAS,IAAK,IAAIc,IAAInB,GACrEsB,EAAIV,EAASU,EAAEE,IAAIN,EAAE,IAAIM,IAAId,EAAQ9M,EAAGyM,EAAS,KAAM,IAAIc,IAAInB,GAC/DzP,EAAIA,EAAE4P,IAAIkB,EAAE,IACZC,EAAIA,EAAEE,IAAIN,EAAE,IAAIM,IAAId,EAAQ9M,EAAGyM,EAAS,KACxCkB,EAAIX,EAASW,EAAEC,IAAIH,EAAE,IAAK,IAAIF,IAAInB,GAClCkB,EAAIE,EAA0BxN,EAAGyM,EAAQa,EAAE,GAAGC,IAAInB,GAAKzP,EAAEiR,IAAIH,EAAE,KAC/DA,EAAID,EAA0BxN,EAAGyM,EAAS,GAAIkB,EAAEC,IAAIH,EAAE,IAAKC,EAAEE,IAAId,EAAQ9M,EAAGyM,EAAS,OACpFkB,EAAGhR,GAAK,CAACA,EAAGgR,GACblB,GAAU,SACLA,IAAW+B,GACpB,MAAMjB,EAAMnB,EAAGwB,IAAID,EAAEe,IAAI,KAAMvB,IAAI,IAcnC,OAZAV,EAASgC,EACThB,EAAE,GAAKA,EAAE,GAAGG,IAAK5R,EAAM,EAAK,IAC5BsR,EAAE,GAAKA,EAAE,GAAGM,IAAIH,EAAE,IAClBA,EAAE,GAAKA,EAAE,GAAGG,IAAIN,EAAE,IAClB3Q,EAAIqQ,EAASrQ,EAAEiR,IAAIF,GAAGE,IAAIN,EAAE,IAAIM,IAAId,EAAQ9M,EAAGyM,EAAS,IAAK,IAAIc,IAAIA,GACrEG,EAAIV,EAASU,EAAEE,IAAIN,EAAE,IAAIM,IAAId,EAAQ9M,EAAGyM,EAAS,KAAM,IAAIc,IAAIA,GAC/D5Q,EAAIA,EAAE4P,IAAIkB,EAAE,GAAGF,IAAI,IACnBG,EAAIA,EAAEE,IAAIN,EAAE,GAAGC,IAAI,GAAGK,IAAId,EAAQ9M,EAAGyM,EAAS,MAC9CkB,EAAIX,EAASW,EAAEC,IAAIH,EAAE,IAAK,IAAIF,IAAIA,GAClCD,EAAIE,EAA0BxN,EAAGyM,EAAQa,EAAE,GAAGC,IAAIA,GAAM5Q,EAAEiR,IAAIH,EAAE,KAChEA,EAAID,EAA0BxN,EAAGyM,EAAS,GAAIkB,EAAEC,IAAIH,EAAE,IAAKC,EAAEE,IAAId,EAAQ9M,EAAGyM,EAAS,OACpFkB,EAAGhR,GAAK,CAACA,EAAGgR,GACNP,EAAUA,EAAUE,EAAE,GAAIG,EAAE,GAAIF,GAAKK,IAAItB,EAASoB,GAAGH,IAAIpB,IAAKyB,IAAID,GAAIP,EAAUE,EAAE,GAAIG,EAAE,GAAIF,GAAKK,IAAIjR,GAAI4Q,K,iCCzKpH,8RAuCOjZ,eAAeqa,EAAc7P,EAAS5L,GAEzC,MAAM0b,EAAQ,GACRC,EAAe,GACfC,EAAQvb,MAAMC,QAAQsL,GACxBA,EAAQ9L,KAAI6T,GAAUA,EAAOhV,OAC7B+G,OAAOsS,KAAKpM,GAChB,IAAK,IAAI7H,EAAI,EAAGA,EAAI6X,EAAMlgB,SAAUqI,EAAG,CACnC,MAAMpF,EAAOid,EAAM7X,GACb8X,EAAIxb,MAAMC,QAAQsL,GAAWA,EAAQ7H,GAAG4P,OAAS/H,EAAQjN,GAC/D,GAAgB,YAAZkd,EAAE3Y,OAAmC,UAAZ2Y,EAAE3Y,OAAiC,SAAZ2Y,EAAE3Y,OACtC,WAAZ2Y,EAAE3Y,OAAkC,cAAZ2Y,EAAE3Y,MAC1B,MAAM,IAAI5H,MAAM,gCAAgCqD,OAAUkd,EAAE3Y,SAEhE,MAAM4Y,EAAO,CAAEnd,OAAMyE,MAAOyY,EAAEzY,MAAOF,MAAO2Y,EAAE3Y,OAC9C,GAAgB,WAAZ2Y,EAAE3Y,MAAoB,CACtB,MAAM6Y,EAAY,IAAI/gB,SAAQoG,MAAOnG,IACjC,MAAMyR,QAAamP,EAAEpC,QACfuC,EAAgBtP,EAAKxI,QAAO,CAAC+X,EAAGtB,IAAMsB,EAAItB,EAAEjf,QAAQ,GApC1C,EAqCcgR,EAAKhR,OAC7B+d,EAAQ,IAAIzU,WAAWgX,GAC7B,IAAIzC,EAAS,EACb,IAAK,IAAIxV,EAAI,EAAGA,EAAI2I,EAAKhR,OAAQqI,IAAK,CAClC,MAAM4I,EAAMD,EAAK3I,GACXmY,EAAgB,IAAIlX,WAAW,IAAImX,YAAY,CAACxP,EAAIjR,SAAShB,QACnE+e,EAAMvU,IAAIgX,EAAe3C,GACzBA,GA5CY,EA6CZE,EAAMvU,IAAIyH,EAAK4M,GACfA,GAAU5M,EAAIjR,OAElBT,EAAQwe,MAEZkC,EAAaxc,KAAK4c,QAGlBJ,EAAaxc,KAAK0c,EAAExS,QAEX,MAATrJ,IACA8b,EAAK9b,MAAQA,GAEjB0b,EAAMvc,KAAK2c,GAGf,MAAO,CAAEzS,KAAM+S,QADYphB,QAAQgG,IAAI2a,IACcD,SAiBlD,SAASW,EAAc3hB,EAAQghB,GAElC,MAAMhF,EAAM,GACZ,IAAI4F,EACA/C,EAAS,EACb,IAAK,MAAMuC,KAAQJ,EAAO,CACtB,MAAM/c,EAAOmd,EAAKnd,KACZuE,EAAQ4Y,EAAK5Y,MACbE,EAAQ0Y,EAAK1Y,MACb6H,EAAO,YAAc7H,GAC3B,IAAIwP,EACJ,GAAI,iBAAkBkJ,EAAM,CACxB,MAAM7Y,EAAe6Y,EAAK7Y,aAC1B,GAA2B,UAAvBA,EAAaC,OAA4C,WAAvBD,EAAaC,OAC/C,KAAM,QAASD,MAAgB,UAAWA,GACtC,MAAM,IAAI3H,MAAM,UAAUwgB,EAAKnd,0BAA0BsE,EAAaC,gEAIzE,IAA2B,YAAvBD,EAAaC,MAOlB,MAAM,IAAI5H,MAAM,UAAUwgB,EAAKnd,uCACLsE,EAAaC,+EAPvC,GAAc,YAAVA,EACA,MAAM,IAAI5H,MAAM,UAAUwgB,EAAKnd,0BAA0BsE,EAAaC,yDACfA,MAS/D,MAAMqZ,EAAyB,IAAqBtZ,EAAaC,OAC3DiC,EAAazK,EAAOe,MAAM8d,EAAQA,EAAStO,EAAOsR,GAClDC,EAAyC,UAAvBvZ,EAAaC,MACjC,IAAI8B,WAAWG,GACf,IAAIsX,YAAYtX,GACpB,GAAc,YAAVjC,EACA,GAA2B,UAAvBD,EAAaC,OAA4C,WAAvBD,EAAaC,MAAoB,CACnE0P,EAAS,IAAIlK,aAAa8T,EAAe9gB,QACzC,IAAK,IAAIqI,EAAI,EAAGA,EAAIyY,EAAe9gB,OAAQqI,IAAK,CAC5C,MAAMqW,EAAIoC,EAAezY,GACzB6O,EAAO7O,GAAKqW,EAAInX,EAAagM,MAAQhM,EAAagN,SAGrD,IAA2B,YAAvBhN,EAAaC,MAOlB,MAAM,IAAI5H,MAAM,iCAAiC2H,EAAaC,uCANxC4I,IAAlBwQ,IACAA,EAAgBI,KAEpB9J,EAAS0J,EAAcE,OAO1B,IAAc,UAAVtZ,EAYL,MAAM,IAAI5H,MAAM,gCAAgCqD,OAAUuE,KAX1D,GAA2B,UAAvBD,EAAaC,OAA4C,WAAvBD,EAAaC,MAC/C,MAAM,IAAI5H,MAAM,iCAAiC2H,EAAaC,gCAGlE0P,EAAS,IAAI+J,WAAWH,EAAe9gB,QACvC,IAAK,IAAIqI,EAAI,EAAGA,EAAIyY,EAAe9gB,OAAQqI,IAAK,CAC5C,MAAMqW,EAAIoC,EAAezY,GACzB6O,EAAO7O,GAAKgF,KAAK6T,MAAMxC,EAAInX,EAAagM,MAAQhM,EAAagN,MAMrEsJ,GAAUtO,EAAOsR,OAEhB,GAAc,WAAVrZ,EAAoB,CACzB,MAAM+H,EAAO,YAAc6Q,EAAK1Y,OAChCwP,EAAS,GACT,IAAK,IAAI7O,EAAI,EAAGA,EAAIkH,EAAMlH,IAAK,CAC3B,MAAMc,EAAa,IAAIsX,YAAYzhB,EAAOe,MAAM8d,EAAQA,EAzJxC,IAyJ2E,GAC3FA,GA1JgB,EA2JhB,MAAME,EAAQ,IAAIzU,WAAWtK,EAAOe,MAAM8d,EAAQA,EAAS1U,IAC3D+N,EAAOzT,KAAKsa,GACZF,GAAU1U,OAGb,CACD,MAAMgY,EAAc,IAAqB3Z,GACnCiC,EAAazK,EAAOe,MAAM8d,EAAQA,EAAStO,EAAO4R,GACxD,GAAc,YAAV3Z,EACA0P,EAAS,IAAIlK,aAAavD,QAEzB,GAAc,UAAVjC,EACL0P,EAAS,IAAI+J,WAAWxX,QAEvB,GAAc,SAAVjC,EACL0P,EAAS,IAAI5N,WAAWG,OAEvB,IAAc,cAAVjC,EAeL,MAAM,IAAI5H,MAAM,gCAAgCqD,OAAUuE,KAf9B,CAC5B0P,EAAS,IAAIlK,aAAavD,GAC1B,MAAMqD,EAAO,IAAIE,aAAakK,EAAOlX,OAAS,GACxCohB,EAAQ,IAAIpU,aAAakK,EAAOlX,OAAS,GAC/C,IAAK,IAAIqI,EAAI,EAAGA,EAAIyE,EAAK9M,OAAQqI,IAC7ByE,EAAKzE,GAAK6O,EAAW,EAAJ7O,GACjB+Y,EAAM/Y,GAAK6O,EAAW,EAAJ7O,EAAQ,GAE9B,MAAMgZ,EAAa,YAAOvU,EAAMpF,EAAO,WACjC4Z,EAAc,YAAOF,EAAO1Z,EAAO,WACzCsT,EAAI/X,GAAQ,YAAQoe,EAAYC,GAChCD,EAAWtJ,UACXuJ,EAAYvJ,WAKhB8F,GAAUtO,EAAO4R,EAEP,cAAV3Z,IACAwT,EAAI/X,GAAQ,YAAOiU,EAAQxP,EAAOF,IAG1C,OAAOwT,EAKJ,SAAS0F,EAAuBa,GAEnC,GAAW,OAAPA,EACA,MAAM,IAAI3hB,MAAM,wBAAwB8B,KAAKC,UAAU4f,MAE3D,IAAIC,EAAkB,EAQtB,MAAMC,EAAe,GACrBF,EAAGje,SAASyK,IAKR,GAJAyT,GAAmBzT,EAAE5E,WAErBsY,EAAahe,KAAKsK,EAAE5E,aAAe4E,EAAE/O,OAAOmK,WAAa4E,EACrD,IAAIA,EAAE2T,YAAY3T,MAChBA,aAAaf,cAAgBe,aAAakT,YAC5ClT,aAAazE,YACb,MAAM,IAAI1J,MAAM,mCAAmCmO,EAAE2T,YAAYze,WAIzE,MAAM6b,EAAI,IAAIxV,WAAWkY,GACzB,IAAI3D,EAAS,EAKb,OAJA4D,EAAane,SAASyK,IAClB+Q,EAAEtV,IAAI,IAAIF,WAAWyE,EAAE/O,QAAS6e,GAChCA,GAAU9P,EAAE5E,cAET2V,EAAE9f,OAGb,MAAM2iB,EAAkC,oBAAXC,IACR,oBAATnhB,MAAwC,oBAATohB,MACnB,oBAATC,MAUR,SAASC,EAAiBC,GAC7B,OAAIL,EACOC,EAAOzY,WAAW6Y,GAEtB,IAAIvhB,KAAK,CAACuhB,IAAMzS,KAQpB,SAAS0S,EAA0BjjB,GACtC,GAAI2iB,EACA,OAAOC,EAAO3D,KAAKjf,GAAQkjB,SAAS,UAExC,MAAMC,EAAM,IAAI7Y,WAAWtK,GAC3B,IAAIoS,EAAI,GACR,IAAK,IAAI/I,EAAI,EAAG+Z,EAAID,EAAIniB,OAAQqI,EAAI+Z,EAAG/Z,IACnC+I,GAAKiR,OAAOC,aAAaH,EAAI9Z,IAEjC,OAAOyZ,KAAK1Q,GAQT,SAASmR,EAA0BP,GACtC,GAAIL,EAAe,CACf,MAAMQ,EAAMP,EAAO3D,KAAK+D,EAAK,UAC7B,OAAOG,EAAInjB,OAAOe,MAAMoiB,EAAIK,WAAYL,EAAIK,WAAaL,EAAIhZ,YAEjE,MAAMiI,EAAIyQ,KAAKG,GACThjB,EAAS,IAAIsK,WAAW8H,EAAEpR,QAChC,IAAK,IAAIqI,EAAI,EAAGA,EAAI+I,EAAEpR,SAAUqI,EAC5BrJ,EAAOwK,IAAI,CAAC4H,EAAEqR,WAAWpa,IAAKA,GAElC,OAAOrJ,EAAOA,OAQX,SAAS0jB,EAAwB5Z,GACpC,GAAuB,IAAnBA,EAAQ9I,OACR,OAAO8I,EAAQ,GAEnB,IAAI0Y,EAAkB,EACtB1Y,EAAQxF,SAAStE,IACbwiB,GAAmBxiB,EAAOmK,cAE9B,MAAMwZ,EAAO,IAAIrZ,WAAWkY,GAC5B,IAAI3D,EAAS,EAKb,OAJA/U,EAAQxF,SAAStE,IACb2jB,EAAKnZ,IAAI,IAAIF,WAAWtK,GAAS6e,GACjCA,GAAU7e,EAAOmK,cAEdwZ,EAAK3jB,OAST,SAAS4jB,EAASpf,GAGrB,IADAA,EAAOA,EAAKqf,OACLrf,EAAKqF,SAFM,MAGdrF,EAAOA,EAAKzD,MAAM,EAAGyD,EAAKxD,OAAS,GAEvC,MAAMkc,EAAQ1Y,EAAKsL,MALD,KAMlB,OAAOoN,EAAMA,EAAMlc,OAAS,GAOzB,SAAS8iB,EAA6B1iB,GACzC,GAAIA,EAAeQ,yBAAyBC,YACxC,MAAM,IAAIjB,MAAM,uDAEpB,MAAO,CACHmjB,UAAW,IAAIC,KACfnG,kBAAmB,OACnBJ,mBAAoD,MAAhCrc,EAAeQ,cAC/B,EACAmhB,EAAiBrgB,KAAKC,UAAUvB,EAAeQ,gBACnD8b,iBAAgD,MAA9Btc,EAAea,YAC7B,EACA8gB,EAAiBrgB,KAAKC,UAAUvB,EAAea,cACnD0b,gBAA8C,MAA7Bvc,EAAeM,WAC5B,EACAN,EAAeM,WAAWyI,YAwE/B,SAAS6X,IAIZ,MAAMiC,EAnEV,WACI,MAAMC,EAAmB7a,IACrB,IAAI8a,EAAI9a,GAAK,GACTsC,EAAI,EACR,KAA4B,IAAhB,QAAJwY,IACJxY,GAAK,QACLwY,IAAM,EAIV,OAFAA,IAAK,QACLxY,GAAK,UACEwY,EAAIxY,GAETsY,EAAe,IAAIxC,YAAY,MACrCwC,EAAa,GAAK,EAClB,IAAK,IAAI5a,EAAI,EAAGA,EAAI,KAAMA,IACtB4a,EAAa5a,GAAK6a,EAAgB7a,GAEtC,IAAK,IAAIA,EAAI,KAAMA,EAAI,KAAMA,IACzB4a,EAAa5a,GAAK,WAAeA,EAAI,MAAS,IAElD,OAAO4a,EA+CcG,GACfC,EAxCV,WACI,MAAMA,EAAgB,IAAI5C,YAAY,IACtC4C,EAAc,GAAK,EACnBA,EAAc,IAAM,WACpBA,EAAc,IAAM,WACpBA,EAAc,IAAM,WACpB,IAAK,IAAIhb,EAAI,EAAGA,EAAI,GAAIA,IACpBgb,EAAchb,GAAKA,GAAK,GAE5B,IAAK,IAAIA,EAAI,GAAIA,EAAI,GAAIA,IACrBgb,EAAchb,GAAK,YAAeA,EAAI,IAAO,IAEjD,OAAOgb,EA4BeC,GAChBC,EArBV,WACI,MAAMA,EAAc,IAAI9C,YAAY,IACpC,IAAK,IAAIpY,EAAI,EAAGA,EAAI,GAAIA,IACpBkb,EAAYlb,GAAK,KAGrB,OADAkb,EAAY,GAAKA,EAAY,IAAM,EAC5BA,EAeaC,GACpB,OAAQ1C,IACJ,MAAM9hB,EAAS,IAAI6B,YAAY,EAAIigB,EAAe9gB,QAC5CyjB,EAAmB,IAAIhD,YAAYzhB,GACzC,IAAK,IAAI2E,EAAQ,EAAGA,EAAQmd,EAAe9gB,OAAQ2D,IAAS,CACxD,MAAM+f,EAAc5C,EAAend,GAC7BggB,EAAcV,EAAaM,EAAYG,GAAe,KAAqB,KAAdA,IAC/DL,EAAcK,GAAe,IACjCD,EAAiB9f,GAASggB,EAE9B,OAAO,IAAI3W,aAAahO,O,0DCtchC,6DAsTA,SAAS4kB,EAAWvkB,GAChB,OAAO,IAAOukB,WAAWvkB,K,+BCvT7B,+JA2BA,SAASwkB,EAA6BC,GAClC,OAAsC,MAA/BA,EAAiBzM,WAE5B,MAAM0M,EACF,cAEI9jB,KAAK+jB,oBAAsB,GAC3B/jB,KAAKgkB,eAAiB,EACtBhkB,KAAK6d,SAAW,EAChB7d,KAAKwO,WAAa,EAClBxO,KAAKikB,iBAAmB,EACxBjkB,KAAKkkB,eAAiB,EAItBlkB,KAAKmkB,cAAgB,EAGrBnkB,KAAKokB,YAAc,EACnBpkB,KAAKqkB,WAAa,GAKlBrkB,KAAKskB,kBAAoB,GACzBtkB,KAAKukB,YAAc,EACnBvkB,KAAKwkB,WAAa,IAAIjO,QACtBvW,KAAKykB,WAAY,EACjBzkB,KAAK0kB,cAAgB,CACjBC,SAAU,EACVC,WAAY,EACZC,UAAW,EACXC,QAAS,GACT/hB,OAAQ,KACR,kBACI,OAAO2B,MAAMsZ,KAAK,IAAI3O,IAAIrP,KAAK8kB,QAAQ3gB,KAAIgK,GAAKA,EAAEnL,WAI9D,UACI,IAAK,MAAM+hB,KAAgB/kB,KAAK+jB,oBAC5B/jB,KAAK+jB,oBAAoBgB,GAAcjN,WAI5C,MAAMkN,EACT,YAAYtP,GACR1V,KAAK0V,IAAMA,EACX1V,KAAKilB,SAAW,GAChBjlB,KAAKklB,gBAAkB,GACvBllB,KAAKmlB,qBAAuB,EAC5BnlB,KAAKolB,MAAQ,IAAItB,EAErB,cACI,GAA+B,MAA3B9jB,KAAKqlB,mBACL,OAAOrlB,KAAKqlB,mBAAmB7lB,MAAK,SAExC,GAA4B,MAAxBQ,KAAKslB,gBACL,OAEJ,MAAMC,EAAiBvlB,KAAKwlB,oBAC5B,IAAK,IAAIpd,EAAI,EAAGA,EAAImd,EAAexlB,OAAQqI,IAAK,CAC5C,MAAM+P,EAAcoN,EAAend,GAEnC,SADsBpI,KAAKylB,kBAAkBtN,GAAauN,QAGtD,kBADM1lB,KAAKkY,WAAWC,GAI9B,MAAM,IAAIxY,MAAM,0EAGpB,cACI,GAA+B,MAA3BK,KAAKqlB,mBACL,MAAM,IAAI1lB,MAAM,YAAYK,KAAKmY,kIAIrC,GAA4B,MAAxBnY,KAAKslB,gBAAyB,CAC9B,MAAM,KAAEtiB,EAAI,UAAE2iB,GAAc3lB,KAAK4lB,kCACjC,GAAID,EACA,MAAM,IAAIhmB,MAAM,iCAAiCqD,wHAIrDhD,KAAKkY,WAAWlV,GAEpB,OAAOhD,KAAKslB,gBAEhB,eACI,OAAOvb,OAAOsS,KAAKrc,KAAKklB,iBAE5B,YAAY/M,GACR,KAAMA,KAAenY,KAAKilB,UAAW,CAGjC,KAAI9M,KAAenY,KAAKklB,iBAQpB,OAAO,KAR8B,CACrC,MAAM,UAAES,GAAc3lB,KAAKylB,kBAAkBtN,GAC7C,GAAIwN,EAEA,OAAO,MAOnB,OAAO3lB,KAAKilB,SAAS9M,GAEzB,mBAAmBA,GACf,OAAMA,KAAenY,KAAKklB,gBAGnBllB,KAAKklB,gBAAgB/M,GAAaG,QAF9B,KAIf,gBAAgBH,EAAaG,EAASC,EAAW,GAC7C,OAAIJ,KAAenY,KAAKklB,iBACpBzY,QAAQC,KAAK,GAAGyL,wEAET,IAEXnY,KAAKklB,gBAAgB/M,GAAe,CAAEG,UAASC,aACxC,GAEX,iBAAiBJ,GACb,GAAyC,MAArCnY,KAAKklB,gBAAgB/M,GACrB,MAAM,IAAIxY,MAAM,iBAAiBwY,4BAGrC,GADAnY,KAAKmY,YAAcA,EACe,MAA9BnY,KAAKilB,SAAS9M,GAAsB,CACpCnY,KAAKslB,gBAAkB,KACvB,MAAM,QAAEI,EAAO,UAAEC,GAAc3lB,KAAKylB,kBAAkBtN,GAEtD,KADewN,QAAkBD,EAAUA,GAEvC,OAAO,EAOf,OAJA1lB,KAAKslB,gBAAkBtlB,KAAKilB,SAAS9M,GACrCnY,KAAK6lB,yBAEL7lB,KAAK8lB,SAAW,IAAI,IAAS9lB,KAAKslB,kBAC3B,EAEX,yBACoB,YAAqBtlB,KAAKmY,aAClC9U,SAAQ0iB,IACY,MAApBA,EAAOC,WACPD,EAAOC,UAAUhmB,KAAKslB,oBAIlC,yBAAyBnN,GACL,YAAqBA,GAC7B9U,SAAQ0iB,IACc,MAAtBA,EAAOE,aACPF,EAAOE,YAAYjmB,KAAKilB,SAAS9M,OAU7C,kBAAkBA,GACd,MAAM+N,EAAuBlmB,KAAKklB,gBAAgB/M,GAClD,GAA4B,MAAxB+N,EACA,MAAM,IAAIvmB,MAAM,6BAA6BwY,6BAEjD,IACI,MAAM9B,EAAU6P,EAAqB5N,UAMrC,IAAIjC,GAAaA,aAAmB,KACR,mBAAjBA,EAAQ7W,KA2Bf,OADAQ,KAAKilB,SAAS9M,GAAe9B,EACtB,CAAEqP,SAAS,EAAMC,WAAW,GA3BC,CACpC,MAAMQ,IAAcnmB,KAAKmlB,qBACnBO,EAAUrP,EACX7W,MAAK8lB,KAEFa,EAAYnmB,KAAKmlB,wBAGrBnlB,KAAKilB,SAAS9M,GAAemN,EAC7BtlB,KAAKqlB,mBAAqB,MACnB,KAENe,OAAMjjB,IAEHgjB,EAAYnmB,KAAKmlB,uBAGrBnlB,KAAKqlB,mBAAqB,KAC1B5Y,QAAQC,KAAK,6BAA6ByL,YAC1C1L,QAAQC,KAAKvJ,EAAIkjB,OAASljB,EAAIwH,WAJnB,KAQf,OADA3K,KAAKqlB,mBAAqBK,EACnB,CAAEA,UAASC,WAAW,IAOrC,MAAOxiB,GAGH,OAFAsJ,QAAQC,KAAK,6BAA6ByL,YAC1C1L,QAAQC,KAAKvJ,EAAIkjB,OAASljB,EAAIwH,SACvB,CAAE+a,SAAS,EAAOC,WAAW,IAG5C,cAAcxN,GACV,KAAMA,KAAenY,KAAKklB,iBACtB,MAAM,IAAIvlB,MAAM,GAAGwY,mCAEnBnY,KAAKmY,cAAgBA,GAA0C,MAA3BnY,KAAKqlB,oBAGzCrlB,KAAKmlB,uBAELhN,KAAenY,KAAKilB,WACpBjlB,KAAKsmB,yBAAyBnO,GAC9BnY,KAAKilB,SAAS9M,GAAaL,iBACpB9X,KAAKilB,SAAS9M,WAElBnY,KAAKklB,gBAAgB/M,GAExBnY,KAAKmY,cAAgBA,IACrBnY,KAAKqlB,mBAAqB,KAC1BrlB,KAAKmY,YAAc,KACnBnY,KAAKslB,gBAAkB,MAG/B,oBACI,GAAiD,IAA7Cvb,OAAOsS,KAAKrc,KAAKklB,iBAAiBnlB,OAClC,MAAM,IAAIJ,MAAM,iCAEpB,OAAOoK,OAAOsS,KAAKrc,KAAKklB,iBAAiB9R,MAAK,CAACnB,EAAGC,IAEvClS,KAAKklB,gBAAgBhT,GAAGqG,SAC3BvY,KAAKklB,gBAAgBjT,GAAGsG,WAGpC,kCACI,MAAMgN,EAAiBvlB,KAAKwlB,oBAC5B,IAAK,IAAIpd,EAAI,EAAGA,EAAImd,EAAexlB,OAAQqI,IAAK,CAC5C,MAAM+P,EAAcoN,EAAend,IAC7B,QAAEsd,EAAO,UAAEC,GAAc3lB,KAAKylB,kBAAkBtN,GACtD,GAAIwN,GAAaD,EACb,MAAO,CAAE1iB,KAAMmV,EAAawN,aAGpC,MAAM,IAAIhmB,MAAM,0EAGpB,SAAS0W,EAASI,GACd,MAAMoF,EAAO7b,KAAKolB,MAAMZ,WAAW5N,IAAIH,GACjC8P,EAAa1K,EAAKxF,QAClBY,EAASjX,KAAKwmB,SAAS/P,GACvBS,EAAWqP,EAAWrP,SAAST,GAGrC8P,EAAWE,YAAYhQ,GAAQ,GAC/BoF,EAAKxF,QAAUA,EACfA,EAAQqQ,KAAKjQ,EAAQQ,EAAQ4E,EAAKpU,MAAOoU,EAAKtU,MAAO2P,GACjDlX,KAAK2mB,0BAGL3mB,KAAKolB,MAAMd,kBAAkBtkB,KAAKolB,MAAMd,kBAAkBvkB,OAAS,KAG3E,KAAK6X,EAAUC,GACX,IAsBI9U,EAtBAC,EAAO,KACX,GAAU,MAAN6U,EAAY,CAEZ,GAAwB,mBAAbD,EACP,MAAM,IAAIjY,MAAM,uCAEpBkY,EAAKD,MAEJ,CAED,GAAwB,iBAAbA,KAA2BA,aAAoBwK,QACtD,MAAM,IAAIziB,MAAM,kFAGpB,GAAkB,mBAAPkY,EACP,MAAM,IAAIlY,MAAM,kFAGpBqD,EAAO4U,EAKX,OAAO5X,KAAK4mB,WAAU,IAAM5mB,KAAK6mB,WAAW7jB,KAAO,IAAMhD,KAAK8mB,SAAS/jB,KAAS,KAC5EA,EAAS8U,IACL9U,aAAkB1D,SAClBoN,QAAQ5I,MAAM,2CAEXd,KAGf,UAAUgkB,EAAOpH,EAAKvgB,GAClB2nB,IACA,IACI,MAAMC,EAAM5nB,IAEZ,OADAugB,IACOqH,EAEX,MAAOC,GAEH,MADAtH,IACMsH,GAGd,eACI,OAAOjC,EAAOkC,eAElB,iBACI,OAAOlC,EAAOmC,iBAQlB,MAAMrZ,GACF,MAAM+Q,EAAIuI,EAAOC,UAAU,KAAU,CAAEvZ,MACjCwZ,EAAS,CAAExZ,KAajB,OADA9N,KAAKunB,YAAYvnB,KAAKolB,MAAMoC,YAAYxkB,KAAMskB,EAAQ,CAACzI,IAXzC4I,IAAO,CACjB3Z,EAAG,KACC,MACM4Z,EAAa,CAAE5Z,EAAG2Z,GAClBE,EAAQ,CAAEpgB,MAFF,WAGd,OAAO6f,EAAOC,UAAU,IAAMK,EAE9BC,OAGM,GAC0D,IACjE9I,EAeX,UAAUzH,EAAYkQ,EAAQK,GAE1B,KAD6D,MAA3C,YAAUvQ,EAAYpX,KAAKmY,cAEzC,MAAM,IAAIxY,MAAM,WAAWyX,kCAA2CpX,KAAKmY,gBAE/E,OAAOnY,KAAK4nB,cAAc,CAAExQ,aAAYkQ,SAAQK,UAEpD,yBACI,OAAO3nB,KAAK0V,IAAIhW,QAAQ,WAE5B,sBAAsB0X,EAAYyQ,EAAkBC,GAChD,MAAMC,EAAkB/nB,KAAKqW,QAAQ2R,aAErC,IAAIC,EAAmB,EACvBH,EAASzkB,SAAQwY,IAGboM,GAAoC,cAAfpM,EAAKtU,MAAwB,EAAI,KAO1D,MAAM2gB,EAAWloB,KAAKolB,MAAMd,kBAAkBtkB,KAAKolB,MAAMd,kBAAkBvkB,OAAS,GAC9EooB,EAAgBJ,EAAkBF,EAAmBI,EAAmBC,EAC9E,GAAIC,EAAgB,EAChB,MAAM,IAAIxoB,MAAM,YAAYK,KAAKmY,6CACzBgQ,8BAA0C/Q,MAQ1D,cAAcgR,GACV,IAAIC,EACAC,EAAQ,GACZ,MAAMC,EAAWvoB,KAAKuoB,WAChBC,EAAoBxoB,KAAKolB,MAAMvH,SAC/B4K,EAAqBzoB,KAAKolB,MAAM5W,WAItC,IAAIka,EASA3N,EAZA/a,KAAK2mB,0BACL3mB,KAAKolB,MAAMd,kBAAkB9gB,KAAK,GAGd,MAApBxD,KAAKmY,aAMLnY,KAAKqW,QAGT,MAAMsS,EAAoB/E,EAA6BwE,GACnDA,EAAahR,WACa,MAA1BpX,KAAKolB,MAAMoC,YAAsBxnB,KAAKolB,MAAMoC,YAAYxkB,KAAO,GAInE,GAAI4gB,EAA6BwE,GAAe,CAC5C,MAAM,WAAEhR,EAAU,OAAEkQ,EAAM,MAAEK,GAAUS,EACd,MAApBpoB,KAAKmY,aAMLnY,KAAKqW,QAET,MAAM0P,EAAS,YAAU3O,EAAYpX,KAAKmY,aAC1C,IAAsB,MAAV4N,GAAgB,IAAM,kCAAkC3O,mBAA4BpX,KAAKmY,iBACrGuQ,EAAa,KACT,MAAMb,EAAmB7nB,KAAKqW,QAAQ2R,aACtCjN,EAAMgL,EAAO2C,WAAW,CAAEpB,SAAQK,QAAOtR,QAASrW,KAAKqW,UACvD,MAAMyR,EAAWpjB,MAAMC,QAAQoW,GAAOA,EAAM,CAACA,GACzC/a,KAAK2mB,0BACL3mB,KAAK4oB,sBAAsBxR,EAAYyQ,EAAkBC,GAE7D,MAAMe,EAAaf,EAAS3jB,KAAK2kB,IAI7B,GAAoB,MAAhBA,EAAQC,KACR,OAAOD,EAEX,MAAM,OAAErS,EAAM,MAAEhP,EAAK,MAAEF,GAAUuhB,EACjC,OAAO9oB,KAAKgpB,qBAAqBvS,EAAQhP,EAAOF,MAMpD,GAAIghB,EAAU,CACV,MAAMU,EAAgBjpB,KAAKkpB,sBAAsB9R,EAAYkQ,EAAQuB,GACrEP,EAAQtoB,KAAKmpB,2BAA2BF,GAE5C,OAAOJ,OAGV,CACD,MAAM,YAAEO,GAAgBhB,EAElBiB,EAAYpZ,IAITsY,IAGLD,EAAQrY,EAAQ9L,KAAI6T,GAAUhY,KAAKiY,KAAKjY,KAAKf,MAAM+Y,QAEvD0Q,EAAa,KACT,MAAMb,EAAmB7nB,KAAKqW,QAAQ2R,aACtCjN,EAAM/a,KAAK2X,MAAK,IAAMyR,EAAYppB,KAAKqW,QAASgT,KAChD,MAAMC,EAAQ5kB,MAAMC,QAAQoW,GAAOA,EAAM,CAACA,GAK1C,OAJI/a,KAAK2mB,0BAEL3mB,KAAK4oB,sBAAsBD,EAAmBd,EAAkByB,GAE7DA,GAMf,MAAM,OAAEhC,EAAM,MAAEK,GAAUS,EACpBmB,EAAgB3F,EAA6BwE,GAC/C,KACAA,EAAamB,cACjB,IAAIC,EA+BJ,OA9BAxpB,KAAK4mB,WAEL,IAAM5mB,KAAKolB,MAAMhB,gBAAe,IAAMpkB,KAAKolB,MAAMhB,gBAAe,KACvDpkB,KAAK0V,IAAIhW,QAAQ,UAAaM,KAAKolB,MAAMX,WAI1C+E,EAAgBxpB,KAAK8lB,SAAS2D,cAAcd,EAAmBrB,GAAQ,IAAMoB,MACzE1oB,KAAK0V,IAAIhW,QAAQ,UACjBM,KAAK8lB,SAAS4D,iBAAiBF,GAEnCnB,EAAUmB,EAAcnB,SAPxBA,EAAUK,OAUdH,GACAvoB,KAAKunB,YAAYoB,EAAmBrB,EAAQe,EAASkB,EAAejB,EAAOX,GAE3E3nB,KAAKolB,MAAMX,WACXzkB,KAAKolB,MAAMV,cAAcI,QAAQthB,KAAK,CAClCR,KAAM2lB,EACNgB,WAAY3pB,KAAKolB,MAAMvH,SAAW2K,EAClCoB,mBAAoB5pB,KAAKolB,MAAMvH,SAC/BgM,aAAc7pB,KAAKolB,MAAM5W,WAAaia,EACtCqB,qBAAsB9pB,KAAKolB,MAAM5W,WACjCub,YAAahgB,OAAOsS,KAAKiL,GAAQnjB,KAAI8W,GAAsB,MAAfqM,EAAOrM,GAAeqM,EAAOrM,GAAKxT,MAAQ,OACtFuiB,aAAc3B,EAAQlkB,KAAI6W,GAAQA,EAAKvT,QACvCwiB,aAAcT,EAAcU,OAC5BC,UAAWX,EAAcW,YAGzBzlB,MAAMC,QAAQoW,GAAOsN,EAAUA,EAAQ,GAOnD,2BAA2BpY,GAEvB,OADcA,EAAQ9L,KAAI6T,GAAUhY,KAAKiY,KAAKjY,KAAKf,MAAM+Y,MAU7D,sBAAsBZ,EAAYkQ,EAAQe,GACtC,MAAM+B,EAAa,YAAYhT,GAC/B,GAAkB,MAAdgT,EAAoB,CACpB,MAAMC,EAAeD,EAAWC,cAAgB,GAC1CC,EAAgBF,EAAWE,eAAiB,GAGlD,IAAIC,EACAH,EAAWI,eACX,IAAY9lB,MAAMC,QAAQ2iB,IAAS,IAAM,2DACzCiD,EAAqBxgB,OAAOsS,KAAKiL,GAAQnjB,KAAK8W,GAAQqM,EAAOrM,MAG7DsP,EAAqBF,EAAalmB,KAAKsmB,GAAcnD,EAAOmD,KAEhE,MAAMC,EAAsBrC,EAAQngB,QAAO,CAACC,EAAGC,IAAMkiB,EAAcliB,KACnE,OAAOmiB,EAAmBI,OAAOD,GAQrC,MAAO,GAOX,WAAWzT,EAAQxP,EAAOF,EAAO8O,GAC7B,GAAc,MAAVY,EACA,MAAM,IAAItX,MAAM,iDAEpB4H,EAAQA,GAAS,UACjB8O,EAAUA,GAAWrW,KAAKqW,QAC1B,IAAIuU,EAAc3T,EACJ,WAAV1P,GAAsB,IAAc0P,EAAO,MAC3C2T,EAAc3T,EAAO9S,KAAI4L,GAAK,eAAkBA,MAEpD,MAAM0G,EAASJ,EAAQwU,MAAMD,EAAanjB,EAAOF,GAC3C2Y,EAAI,IAAI,IAAOzY,EAAOF,EAAOkP,EAAQzW,KAAKknB,gBAGhD,GAFAlnB,KAAK8qB,YAAY5K,EAAG7J,GAEN,WAAV9O,EAAoB,CACpB,MAAMsU,EAAO7b,KAAKolB,MAAMZ,WAAW5N,IAAIH,GACjCkO,EAAW,YAAqBiG,GACtC5qB,KAAKolB,MAAMvH,UAAY8G,EAAW9I,EAAKiC,MACvCjC,EAAKiC,MAAQ6G,EAEjB,OAAOzE,EAOX,qBAAqBzJ,EAAQhP,EAAOF,EAAO8O,GACvC9O,EAAQA,GAAS,UACjB,MAAM2Y,EAAI,IAAI,IAAOzY,EAAOF,EAAOkP,EAAQzW,KAAKknB,gBAEhD,OADAlnB,KAAK8qB,YAAY5K,EAAG7J,GACb6J,EAEX,aAAa6K,EAAcC,GAAY,EAAMhoB,EAAMuE,GAC/CvE,EAAOA,GAAQhD,KAAKmnB,iBAAiBlF,WACxB,MAAT1a,GAAiBA,IAAUwjB,EAAaxjB,QACxCwjB,EAAeA,EAAa/rB,KAAKuI,IAErC,MAAMkX,EAAI,IAAI,IAASsM,EAAcC,EAAWhoB,EAAMhD,KAAKknB,gBAC3D,GAA8C,MAA1ClnB,KAAKolB,MAAMrB,oBAAoBtF,EAAEzb,MACjC,MAAM,IAAIrD,MAAM,sBAAsB8e,EAAEzb,+BAI5C,OAFAhD,KAAKolB,MAAMrB,oBAAoBtF,EAAEzb,MAAQyb,EACzCze,KAAKirB,OAAOxM,EAAGze,KAAKqW,SACboI,EAEX,YAAYxM,EAAGoE,GACXrW,KAAKolB,MAAM5W,aACK,WAAZyD,EAAE1K,OACFvH,KAAKolB,MAAMnB,mBAIf,IAAInG,EAAQ,EACI,cAAZ7L,EAAE1K,OAAqC,WAAZ0K,EAAE1K,QAC7BuW,EAAQ7L,EAAE3C,KAAO,IAAqB2C,EAAE1K,QAE5CvH,KAAKolB,MAAMvH,UAAYC,EAClB9d,KAAKolB,MAAMZ,WAAW9N,IAAIzE,EAAEwE,UAC7BzW,KAAKolB,MAAMlB,iBACXlkB,KAAKolB,MAAMZ,WAAWjb,IAAI0I,EAAEwE,OAAQ,CAChCJ,QAASA,GAAWrW,KAAKqW,QACzB9O,MAAO0K,EAAE1K,MACTE,MAAOwK,EAAExK,MACTqW,WAGF7L,aAAa,KACfjS,KAAKkrB,MAAMjZ,GAQnB,OAAOA,EAAGoE,GACNrW,KAAK8qB,YAAY7Y,EAAGoE,GACpBrW,KAAKqW,QAAQ4U,OAAOhZ,EAAEwE,QAE1B,aAAaA,EAAQJ,GACbrW,KAAKolB,MAAMZ,WAAW9N,IAAID,IAC1BzW,KAAKolB,MAAMZ,WAAW5N,IAAIH,GAAQJ,UAAYA,IAC9CrW,KAAKolB,MAAMZ,WAAW3N,OAAOJ,GAC7BzW,KAAKolB,MAAMlB,kBAGnB,cAAcjS,GACV,IAAKjS,KAAKolB,MAAMZ,WAAW9N,IAAIzE,EAAEwE,QAC7B,OAEJ,MAAMoF,EAAO7b,KAAKolB,MAAMZ,WAAW5N,IAAI3E,EAAEwE,QAQzC,GAPAzW,KAAKolB,MAAM5W,aACK,WAAZyD,EAAE1K,QACFvH,KAAKolB,MAAMnB,mBACXjkB,KAAKolB,MAAMvH,UAAYhC,EAAKiC,OAIhB,cAAZ7L,EAAE1K,OAAqC,WAAZ0K,EAAE1K,MAAoB,CACjD,MAAMuW,EAAQ7L,EAAE3C,KAAO,IAAqB2C,EAAE1K,OAC9CvH,KAAKolB,MAAMvH,UAAYC,EAGvBjC,EAAKxF,QAAQoQ,YAAYxU,EAAEwE,SAC3BzW,KAAKmrB,aAAalZ,EAAEwE,OAAQoF,EAAKxF,SAMzC,mBACI,IAAK,MAAM+U,KAAWprB,KAAKolB,MAAMrB,oBAAqB,CAClD,MAAMtF,EAAIze,KAAKolB,MAAMrB,oBAAoBqH,GACzCprB,KAAKqrB,gBAAgB5M,IAG7B,gBAAgBA,GACZze,KAAKsrB,cAAc7M,GAC2B,MAA1Cze,KAAKolB,MAAMrB,oBAAoBtF,EAAEzb,cAC1BhD,KAAKolB,MAAMrB,oBAAoBtF,EAAEzb,MAGhD,SACI,MAAM6Y,EAAO7b,KAAKqW,QAAQkV,SAY1B,OAXA1P,EAAKrN,WAAaxO,KAAKolB,MAAM5W,WAC7BqN,EAAKqI,eAAiBlkB,KAAKolB,MAAMlB,eACjCrI,EAAKgC,SAAW7d,KAAKolB,MAAMvH,SACvB7d,KAAKolB,MAAMnB,iBAAmB,IAC9BpI,EAAK2P,YAAa,EACE,MAAhB3P,EAAK4P,UACL5P,EAAK4P,QAAU,IAEnB5P,EAAK4P,QAAQjoB,KAAK,0EAGfqY,EAEX,cAAc6P,GACV1rB,KAAKolB,MAAMX,WAAY,EACvB,MAAMkH,EAAa3rB,KAAKolB,MAAMvH,SACxB+N,EAAkB5rB,KAAKolB,MAAM5W,WACnCxO,KAAKolB,MAAMV,cAAcI,QAAU,GACnC9kB,KAAKolB,MAAMV,cAAc3hB,aAAe2oB,IACxC1rB,KAAKolB,MAAMX,WAAY,EACvBzkB,KAAKolB,MAAMV,cAAcG,UAAYzX,KAAKqH,OAAOzU,KAAKolB,MAAMV,cAAcI,QAAQ3gB,KAAI4L,GAAKA,EAAE6Z,sBAC7F5pB,KAAKolB,MAAMV,cAAcC,SAAW3kB,KAAKolB,MAAMvH,SAAW8N,EAC1D3rB,KAAKolB,MAAMV,cAAcE,WACrB5kB,KAAKolB,MAAM5W,WAAaod,EAC5B,IAAK,MAAM7F,KAAU/lB,KAAKolB,MAAMV,cAAcI,QAC1CiB,EAAOkE,mBAAqBlE,EAAOkE,aACnClE,EAAOoE,gBAAkBpE,EAAOoE,UAEpC,OAAOnqB,KAAKolB,MAAMV,cAEtB,WACI,OAAO1kB,KAAKolB,MAAMjB,cAAgB,GAAgC,IAA3BnkB,KAAKolB,MAAMhB,YAEtD,YAAYhN,EAAYkQ,EAAQe,EAASwD,EAAevD,EAAOX,GAC3D,MAAMmE,EAAW,CAAEC,GAAI/rB,KAAKolB,MAAMpB,iBAAkB5M,aAAYkQ,SAAQe,UAASC,SAC3E8B,EAAa,YAAYhT,GACb,MAAdgT,IACAyB,EAAgBzB,EAAW4B,UAEV,MAAjBH,IACAC,EAASG,SAAYC,IAGjBA,EAAMA,EAAI/nB,KAAI,CAACsjB,EAAIrf,KACf,GAAU,MAANqf,EAAY,CACZ,MAAM0E,EAAS9D,EAAQjgB,GACjB2I,EAAO,IAAyBob,EAAO7c,KAAM6c,EAAO5kB,OAC1D,OAAOvH,KAAKosB,WAAWrb,EAAMob,EAAO1kB,MAAO0kB,EAAO5kB,OAEtD,OAAOkgB,KAIJoE,EAAcK,EAAInsB,OAAS,EAAImsB,EAAMA,EAAI,GAAI5D,EAAOX,KAGnE3nB,KAAKolB,MAAMiH,WAAW7oB,KAAKsoB,GAE/B,KAAK/oB,GAED,OADAA,EAAOupB,MAAO,EACPvpB,EAEX,YACqC,IAA7B/C,KAAKolB,MAAMjB,gBACXnkB,KAAKolB,MAAMiH,WAAa,IAE5BrsB,KAAKolB,MAAMjB,gBAEf,UACInkB,KAAKolB,MAAMjB,gBAMf,WAAWnhB,GACP,MAAMupB,EAAY,CACdrB,MAAO,GACPloB,KAAM,gBACN+oB,GAAI/rB,KAAKolB,MAAMb,eAEfvhB,IACAupB,EAAUvpB,KAAOA,GAErBhD,KAAKolB,MAAMf,WAAW7gB,KAAK+oB,GAC3BvsB,KAAKolB,MAAMoC,YAAc+E,EAM7B,SAASxpB,GACL,MAAMypB,EAAyB,YAAsBzpB,GAC/C0pB,EAA4B,IAAIpd,IAAImd,EAAuBroB,KAAI+b,GAAKA,EAAE6L,MAE5E,IAAK,IAAI3jB,EAAI,EAAGA,EAAIpI,KAAKolB,MAAMoC,YAAY0D,MAAMnrB,OAAQqI,IAAK,CAC1D,MAAM4P,EAAShY,KAAKolB,MAAMoC,YAAY0D,MAAM9iB,GACvC4P,EAAOsU,MAASG,EAA0B/V,IAAIsB,EAAO+T,KACtD/T,EAAOF,UAGf,MAAM4U,EAAW1sB,KAAKolB,MAAMf,WAAW3Q,MACvC1T,KAAKolB,MAAMoC,YAA+C,IAAjCxnB,KAAKolB,MAAMf,WAAWtkB,OAC3C,KACAC,KAAKolB,MAAMf,WAAWrkB,KAAKolB,MAAMf,WAAWtkB,OAAS,GAEzDysB,EAAuBnpB,SAAQ2U,IAGtBA,EAAOsU,MAAQtU,EAAO2U,UAAYD,EAASX,IAC5C/rB,KAAKkrB,MAAMlT,MAUvB,UAAU5Y,EAAGkiB,EAAImG,EAAImF,GAAmB,GAEpC,GADA,IAAYtL,EAAGvhB,OAAS,GAAG,IAAM,8CACvB,MAAN0nB,GAA2B,YAAbA,EAAGlgB,MACjB,MAAM,IAAI5H,MAAM,0CAA0C8nB,EAAGlgB,UAEjE,MAAMsX,EAAI7e,KAAK4mB,WAAU,IAAM5mB,KAAK6sB,cAAa,IAAM7sB,KAAK8sB,YAAW,IAAM9sB,KAAK2X,KAAK,UAAWvY,KAClG,IAAYyf,aAAa,KAAQ,IAAM,mDAEvC,MAAMkO,EAAe,YAAqB/sB,KAAKolB,MAAMiH,WAAY/K,EAAIzC,GACrE,IAAK+N,GAA4C,IAAxBG,EAAahtB,QAAgBuhB,EAAGvhB,OAAS,EAC9D,MAAM,IAAIJ,MAAM,uIAIpB,OAAOK,KAAK2X,KAAK,YAAY,KACzB,MAAMqV,EAAyB,GAC/BA,EAAuBnO,EAAEkN,IAAa,MAANtE,EAmH5C,SAAchgB,GACV,MAAMwP,EAAS,YAAmB,YAAcxP,GAAQ,WACxD,OAAO2f,EAAOgF,WAAWnV,EAAQxP,EAAO,WArHcwlB,CAAKpO,EAAEpX,OAASggB,EAE9D,YAAuBuF,EAAwBD,GAE/C3tB,GAAKY,KAAK2X,KAAKvY,IAEf2f,GACA,MAAMmO,EAAQ5L,EAAGnd,KAAI2J,GAAKkf,EAAuBlf,EAAEie,MAWnD,OAViC,IAA7B/rB,KAAKolB,MAAMjB,gBAGXnkB,KAAKolB,MAAMiH,WAAWhpB,SAAQ0S,IAC1B,IAAK,MAAMiC,KAAUjC,EAAKuS,MACtBtQ,EAAOF,aAGf9X,KAAKolB,MAAMiH,WAAa,MAErB,CAAE9mB,MAAOsZ,EAAGqO,YAG3B,WAAW9tB,GAEP,OADA,IAAY,IAAgBA,IAAI,IAAM,sDAC/B,IAAIkoB,KAGP,IAAIN,EAFJ,IAAYM,EAAOvf,OAAMmY,GAAKA,aAAa,OAAS,IAAM,qEAG1D,MAAMiN,EAAW,GACjB7F,EAAOjkB,SAAQ,CAAC+pB,EAAOhlB,KACnB+kB,EAAS/kB,GAAKglB,KAyBlB,OAAOptB,KAAK4nB,cAAc,CACtBwB,YAxBgB,CAACjhB,EAAGklB,KACpBrG,EAAM5nB,KAASkoB,EAAQ+F,GACvB,IAAYrG,EAAIzhB,iBAAiB,KAAQ,IAAM,+FAE/C,IAAY,IAAgByhB,EAAIgF,WAAW,IAAM,qGAE1ChF,EAAIzhB,OAmBXgkB,cAjBkB,CAAC9B,EAAIa,KACvB,MAAMgF,EAAUtG,EAAIgF,SAASvE,EAAIa,GAC3B4E,EAAQxoB,MAAMC,QAAQ2oB,GAAWA,EAAU,CAACA,GAClD,IAAYJ,EAAMntB,SAAWunB,EAAOvnB,QAAQ,IAAM,wKAGlD,IAAYmtB,EAAMnlB,OAAMmY,GAAKA,aAAa,OAAS,IAAM,yIAGzD,MAAMqN,EAAU,GAIhB,OAHAL,EAAM7pB,SAAQ,CAACmqB,EAAMplB,KACjBmlB,EAAQnlB,GAAK,IAAMolB,KAEhBD,GAKPjG,OAAQ6F,KAIpB,SAAS1W,GAGL,OADazW,KAAKolB,MAAMZ,WAAW5N,IAAIH,GAC3BJ,QAAQmQ,SAAS/P,GAEjC,KAAKA,GAGD,OADazW,KAAKolB,MAAMZ,WAAW5N,IAAIH,GAC3BJ,QAAQoX,KAAKhX,GAE7B,WAAWiV,GACP,MAAM3E,EAAQ,gBACR2G,QAAmB1tB,KAAKqW,QAAQsX,KAAKjC,GAE3C,OADAgC,EAAWE,OAAS,gBAAQ7G,EACrB2G,EAQX,MAAM3qB,GAKF,OAJ8B,MAA1B/C,KAAKolB,MAAMoC,cACXzkB,EAAO4pB,QAAU3sB,KAAKolB,MAAMoC,YAAYuE,GACxC/rB,KAAKolB,MAAMoC,YAAY0D,MAAM1nB,KAAKT,IAE/BA,EAEX,0BACI,OAAO/C,KAAKolB,MAAMrB,oBAMtB,QAEI/jB,KAAKmlB,uBACLnlB,KAAKolB,MAAMtN,UACX9X,KAAK0V,IAAImY,QACT7tB,KAAKolB,MAAQ,IAAItB,EACjB,IAAK,MAAM3L,KAAenY,KAAKilB,SAC3BjlB,KAAKsmB,yBAAyBnO,GAC9BnY,KAAKilB,SAAS9M,GAAaL,iBACpB9X,KAAKilB,SAAS9M,GAEzBnY,KAAKmY,YAAc,KACnBnY,KAAKslB,gBAAkB,KACvBtlB,KAAKqlB,mBAAqB,MAS3B,SAASyI,IACZ,MAAMC,EAAK,cACX,GAAoB,MAAhBA,EAAGC,UAAmB,CACtB,MAAMC,EAAc,IAAI,IAAYF,GACpCA,EAAGC,UAAY,IAAIhJ,EAAOiJ,GAM9B,OAJA,YAAqBF,EAAGC,UAAUtY,KAGlC,aAAiB,IAAMqY,EAAGC,YACnBD,EAAGC,UAhBdhJ,EAAOkC,aAAe,EACtBlC,EAAOmC,eAAiB,EAiBjB,MAAMC,EAAS0G,IAOf,SAAS/O,EAAI9M,EAAGC,GAEnB,MAAMoV,EAAS,CAAErV,IAAGC,KACpB,OAAOkV,EAAOC,UAAU,IAAKC,K,gCCx+BjC,0KAgBO,MAAM4G,EACT,cACIluB,KAAKmuB,YAAc,GACnBnuB,KAAKouB,YAAc,GAEvB,qBAII,OAHiC,MAA7BF,EAAiBG,WACjBH,EAAiBG,SAAW,IAAIH,GAE7BA,EAAiBG,SAQ5B,0BAA0BC,GACtBJ,EAAiBK,cAAcJ,YAAY3qB,KAAK8qB,GAQpD,0BAA0BE,GACtBN,EAAiBK,cAAcH,YAAY5qB,KAAKgrB,GAUpD,uBAAuB/pB,GACnB,OAAOypB,EAAiBO,YAAYhqB,EAAK,QAU7C,uBAAuBA,EAAKmB,GACxB,OAAOsoB,EAAiBO,YAAYhqB,EAAK,OAAQmB,GAErD,mBAAmBnB,EAAKiqB,EAAa9oB,GACjC,MAAM+oB,EAAgB,GAUtB,OATgC,SAAhBD,EACZR,EAAiBK,cAAcH,YAC/BF,EAAiBK,cAAcJ,aAC3B9qB,SAAQurB,IACZ,MAAMC,EAAUD,EAAOnqB,EAAKmB,GACZ,OAAZipB,GACAF,EAAcnrB,KAAKqrB,MAGpBF,GAGR,MAAMnqB,EAAsBsqB,GAAeZ,EAAiB1pB,mBAAmBsqB,GACzE5iB,EAAsB4iB,GAAeZ,EAAiBhiB,mBAAmB4iB,GACzEC,EAAmBtqB,GAAQypB,EAAiBa,gBAAgBtqB,GAC5DuqB,EAAkB,CAACvqB,EAAKmB,IAAgBsoB,EAAiBc,gBAAgBvqB,EAAKmB,I,gCCpF3F,yJAkBA,MAAMqpB,EAAiB,YAAU,kBAAkB,IAAM,IAAIC,MACvDC,EAAe,YAAU,gBAAgB,IAAM,IAAID,MAOlD,SAASE,EAAUhY,EAAYe,GAClC,MAAM8C,EAAMoU,EAAQjY,EAAYe,GAChC,OAAO8W,EAAerY,IAAIqE,GAMvB,SAASqU,EAAYlY,GACxB,OAAO+X,EAAavY,IAAIQ,GAErB,SAASmY,EAAqBpX,GACjC,MAAMqX,EAAKP,EAAeQ,UACpB1sB,EAAS,GACf,OAAa,CACT,MAAM,KAAE2sB,EAAI,MAAEnqB,GAAUiqB,EAAGG,OAC3B,GAAID,EACA,MAEJ,MAAOzU,EAAK2U,GAAUrqB,GACf8Q,GAAY4E,EAAIpM,MAAM,KACzBwH,IAAY8B,GACZpV,EAAOS,KAAKosB,GAGpB,OAAO7sB,EAaJ,SAAS8sB,EAAeD,GAC3B,MAAM,WAAExY,EAAU,YAAEe,GAAgByX,EAC9B3U,EAAMoU,EAAQjY,EAAYe,GAC5B8W,EAAevY,IAAIuE,IACnBxO,QAAQC,KAAK,eAAe0K,mBACpBe,4BAEZ8W,EAAe1lB,IAAI0R,EAAK2U,GAwD5B,SAASP,EAAQjY,EAAYe,GACzB,MAAO,GAAGA,KAAef,M,+BChI7B,qkKAAO,MAAM0Y,EAAM,MACNC,EAAO,OACPC,EAAQ,QACRC,EAAM,MACNC,EAAO,OACPC,EAAM,MACNC,EAAM,MACNC,EAAS,SACTC,EAAS,SACTC,EAAO,OACPC,EAAQ,QACRC,EAAO,OACPC,EAAQ,QACRC,EAAQ,QACRC,EAAU,UAEVC,EAAY,YAEZC,EAAc,cACdC,EAAiB,iBACjBC,EAAW,WAEXC,EAAO,OACPC,EAAO,OACPC,EAAc,cACdC,EAAU,UACVC,EAAa,aACbC,EAAS,SACTC,EAAS,SACTC,EAAuB,uBACvBC,EAAsB,sBACtBC,EAAS,SAGTC,EAAM,MACNC,EAAO,OACPC,EAAS,SACTC,EAAgB,gBAChBC,EAAgB,gBAChBC,EAAe,eACfC,EAAwB,wBACxBC,EAAsC,sCACtCC,EAAqC,qCAErCC,EAAa,aAGbC,EAAU,UACVC,EAAS,SACTC,EAAM,MAENC,EAAM,MACNC,EAAQ,QACRC,EAAM,MACNC,EAAa,aACbC,EAAQ,QACRC,EAAM,MACNC,EAAO,OACPC,EAAgB,gBAChBC,EAAQ,QACRC,GAAW,WACXC,GAAiB,iBACjBC,GAAW,WACXC,GAAW,WACXC,GAAU,UACVC,GAAe,eACfC,GAAW,WACXC,GAAO,OACPC,GAAO,OAGPC,GAAQ,QACRC,GAAY,YACZC,GAAO,OACPC,GAAY,YACZC,GAAW,WACXC,GAAM,MACNC,GAAQ,QACRC,GAAa,aACbC,GAAa,aACbC,GAAY,YAEZC,GAAM,MAENC,GAAM,MACNC,GAAU,UACVC,GAAU,UAEVC,GAAY,YAEZC,GAAoB,oBACpBC,GAAO,OACPC,GAAM,MACNC,GAAU,UACVC,GAAY,YACZC,GAAM,MACNC,GAAc,cACdC,GAAW,WACXC,GAAM,MACNC,GAAW,WACXC,GAAsB,sBACtBC,GAAsB,sBACtBC,GAAsB,sBACtBC,GAAW,WACXC,GAAS,SACTC,GAAO,OACPC,GAAQ,QAERC,GAAM,MACNC,GAAQ,QACRC,GAAO,OACPC,GAAQ,QACRC,GAAO,OACPC,GAAa,aACbC,GAAO,OACPC,GAAU,UACVC,GAAwB,wBAExBC,GAAiB,iBAEjBC,GAAQ,QACRC,GAAU,UACVC,GAAQ,QACRC,GAAQ,QACRC,GAAY,YACZC,GAAS,SACTC,GAAO,OACPC,GAAQ,QACRC,GAAM,MACNC,GAAO,OACPC,GAAO,OACPC,GAAU,UACVC,GAAW,WACXC,GAAO,OACPC,GAAM,MACNC,GAAiB,iBACjBC,GAAS,SACTC,GAAU,UACVC,GAAsB,sBACtBC,GAAgB,gBAChBC,GAAoB,oBACpBC,GAAmB,mBACnBC,GAAgB,gBAChBC,GAAoB,oBACpBC,GAAS,SACTC,GAAe,eACfC,GAAe,eACfC,GAAc,cACdC,GAAyB,yBACzBC,GAAM,MACNC,GAAM,MACNC,GAAO,OACPC,GAAO,OACPC,GAAO,OACPC,GAAY,YACZC,GAAY,YACZC,GAAS,SACTC,GAAS,SAETC,GAAY,YAIZC,GAAO,OACPC,GAAa,aACbC,GAAmB,mBACnBC,GAAe,eACfC,GAAc,cACdC,GAAuB,wB,gCCxKpC,6LA4BA,MAAMC,EAAoB,MACnB,MAAMC,EACT,cACIl5B,KAAKm5B,SAAW,GAEpB,qBAII,OAH0C,MAAtCD,EAA0B7K,WAC1B6K,EAA0B7K,SAAW,IAAI6K,GAEtCA,EAA0B7K,SAQrC,uBAAuB+K,EAAQC,GAC3B,YAAiB,MAAVD,GAAgB,IAAM,0CACzBA,EAAOxwB,SAASqwB,KAChBG,EAASA,EAAOt5B,MAAM,EAAGs5B,EAAOz1B,QAAQs1B,KAE5C,YAAOG,EAAOr5B,OAAS,GAAG,IAAM,wCAChC,MAAMklB,EAAWiU,EAA0B3K,cAC3C,YAAoC,MAA7BtJ,EAASkU,SAASC,IAAiB,IAAM,2DAA2DA,QAC3GnU,EAASkU,SAASC,GAAUC,EAEhC,kBAAkBD,GACd,MAAMC,EAAUr5B,KAAKuuB,cAAc4K,SAASC,GAC5C,GAAe,MAAXC,EACA,MAAM,IAAI15B,MAAM,yCAAyCy5B,MAE7D,OAAOC,EAEX,oBACI,OAAOtvB,OAAOsS,KAAKrc,KAAKuuB,cAAc4K,WAW9C,SAASG,EAAS70B,GACd,IAAwC,IAApCA,EAAId,QAAQs1B,GACZ,MAAM,IAAIt5B,MAEN,6EAAGu5B,EAA0BK,aAAalxB,KAAK,QAEvD,MAAO,CACH+wB,OAAQ30B,EAAIoK,MAAMoqB,GAAmB,GACrC11B,KAAMkB,EAAIoK,MAAMoqB,GAAmB,IAG3CxzB,eAAe+zB,EAAmBC,EAAWC,EAASC,GAAe,GACjE,YAAOF,IAAcC,GAAS,IAAM,wCAAwCD,OAC5E,MAAMG,EAAe,IAAiB5K,gBAAgByK,GACtD,YAAOG,EAAa75B,OAAS,GAAG,IAAM,kEAAkE05B,OACxG,YAAOG,EAAa75B,OAAS,GAAG,IAAM,yCAAyC65B,EAAa75B,wCACxD05B,OACpC,MAAMI,EAAcD,EAAa,GAC3BE,EAAe,IAAiB/K,gBAAgB2K,GACtD,YAAOI,EAAa/5B,OAAS,GAAG,IAC5B,uEAAO25B,OACX,YAAOI,EAAa/5B,OAAS,GAAG,IAAM,yCAAyC65B,EAAa75B,6CACnD25B,OACzC,MAAMrtB,EAAcytB,EAAa,GAC3BC,EAAeT,EAASG,GAAWL,OACnCY,EAAaV,EAASG,GAAWl2B,KACjC02B,EAAaF,IAAiBT,EAASG,GAAWL,OAClDj5B,QAAuB05B,EAAYK,OAIrCP,GAAgBM,SACVf,EAA0BiB,WAAWJ,GACtCK,YAAYJ,GAErB,MAAMK,QAAmBhuB,EAAYghB,KAAKltB,GAQ1C,OAJIw5B,IAAiBM,SACXf,EAA0BiB,WAAWJ,GACtCK,YAAYJ,GAEdK,EAAWl4B,mBAqCtBsD,eAAe60B,IACX,MAAMC,EAAUrB,EAA0BK,aACpCxe,EAAM,GACZ,IAAK,MAAMqe,KAAUmB,EAAS,CAC1B,MAAMC,QAAkBtB,EAA0BiB,WAAWf,GAAQkB,aACrE,IAAK,MAAM/2B,KAAQi3B,EAAW,CAE1Bzf,EADYqe,EAASH,EAAoB11B,GAC9Bi3B,EAAUj3B,IAG7B,OAAOwX,EAmCXtV,eAAe20B,EAAY31B,GACvB,MAAMg2B,EAAgBnB,EAAS70B,GAE/B,OADgBy0B,EAA0BiB,WAAWM,EAAcrB,QACpDgB,YAAYK,EAAcl3B,MAiD7CkC,eAAei1B,EAAUjB,EAAWC,GAEhC,OAAOF,EAAmBC,EAAWC,GADhB,GAiDzBj0B,eAAek1B,EAAUlB,EAAWC,GAEhC,OAAOF,EAAmBC,EAAWC,GADhB,K,iCC9SzB,cAoBA,IAAIkB,EAEG,SAASC,IACZ,GAAuB,MAAnBD,EAAyB,CAEzB,IAAI7M,EACJ,GAAwB,oBAAb,OACPA,EAAK1tB,YAEJ,GAAwB,oBAAb,EACZ0tB,EAAK+M,OAEJ,GAAyB,oBAAd,EACZ/M,EAAKlY,MAEJ,IAAsB,oBAAX,KAIZ,MAAM,IAAIlW,MAAM,kCAHhBouB,EAAKlV,KAKT+hB,EAAkB7M,EAEtB,OAAO6M,EAiBJ,SAASG,EAAU9f,EAAKnR,GAC3B,MAAMkxB,EAfV,WACI,MAAMjN,EAAK8M,IAIX,OAHqB,MAAjB9M,EAAGkN,aACHlN,EAAGkN,WAAa,IAAI/L,KAEjBnB,EAAGkN,WAUQC,GAClB,GAAIF,EAAUtkB,IAAIuE,GACd,OAAO+f,EAAUpkB,IAAIqE,GAEpB,CACD,MAAMkgB,EAAYrxB,IAElB,OADAkxB,EAAUzxB,IAAI0R,EAAKkgB,GACZH,EAAUpkB,IAAIqE,IApE7B,sE,yDCAA,iHAkBA,MAAMmgB,EAA4B,YAQ3B,MAAMC,EAET,YAAYP,GACR96B,KAAK86B,OAASA,EACd96B,KAAKs7B,MAAQ,GACbt7B,KAAKu7B,aAAe,GACpBv7B,KAAKw7B,SAAW,GAEhBx7B,KAAKy7B,eAAiBA,EACtBz7B,KAAK07B,mBAET,YAAYC,EAAc71B,GACD,MAAjB9F,KAAK8F,UACL2G,QAAQC,KAAK,YAAY1M,KAAK27B,oEACO71B,MAEzC9F,KAAK27B,aAAeA,EACpB37B,KAAK8F,SAAWA,EAEpB,aAAa81B,EAAUC,EAAcC,GAIjC,GAHA97B,KAAKu7B,aAAaK,GAAY,CAAEC,eAAcC,WAGf,MAA3B97B,KAAKw7B,SAASI,GAAmB,CACjC,MAAMG,EAAY/7B,KAAKw7B,SAASI,GAChCnvB,QAAQC,KAAK,qCAAqCkvB,MAAaG,MAC/D/7B,KAAKuJ,IAAIqyB,EAAUG,IAG3B,eAAeH,GACX,OAAIA,KAAY57B,KAAKs7B,QAGrBt7B,KAAKs7B,MAAMM,SAAkB57B,KAAKg8B,aAAaJ,IAFpC57B,KAAKs7B,MAAMM,GAK1B,IAAIA,GACA,GAAIA,KAAY57B,KAAKs7B,MACjB,OAAOt7B,KAAKs7B,MAAMM,GAEtB,MAAMG,EAAY/7B,KAAKg8B,aAAaJ,GACpC,GAAI,YAAUG,GACV,MAAM,IAAIp8B,MAAM,QAAQi8B,uEAI5B,OADA57B,KAAKs7B,MAAMM,GAAYG,EAChB/7B,KAAKs7B,MAAMM,GAEtB,UAAUA,GACN,OAAO57B,KAAK4W,IAAIglB,GAEpB,QAAQA,GACJ,OAAO57B,KAAK4W,IAAIglB,GAEpB,WACI,OAAO57B,KAAKs7B,MAGhB,eACI,OAAOt7B,KAAKs7B,MAEhB,IAAIM,EAAUr2B,GACV,GAAmC,MAA/BvF,KAAKu7B,aAAaK,GAClB,MAAM,IAAIj8B,MAAM,mBAAmBi8B,oCAEvC57B,KAAKs7B,MAAMM,GAAYr2B,EACoB,MAAvCvF,KAAKu7B,aAAaK,GAAUE,SAC5B97B,KAAKu7B,aAAaK,GAAUE,QAAQv2B,GAG5C,aAAaq2B,GACT,GAAmC,MAA/B57B,KAAKu7B,aAAaK,GAClB,MAAM,IAAIj8B,MAAM,yBAAyBi8B,qCAE7C,OAAO57B,KAAKu7B,aAAaK,GAAUC,eAEvC,SAASP,GACLt7B,KAAKs7B,MAAQvxB,OAAOC,OAAO,GAAIsxB,GAEnC,QACIt7B,KAAKs7B,MAAQ,GACbt7B,KAAKw7B,SAAW,GAChBx7B,KAAK07B,mBAET,mBACI,GAA2B,oBAAhB17B,KAAK86B,QACoB,oBAAzB96B,KAAK86B,OAAOmB,UACoB,oBAAhCj8B,KAAK86B,OAAOmB,SAASC,OAC5B,OAEJ,MAAMC,EAAYn8B,KAAKy7B,eAAez7B,KAAK86B,OAAOmB,SAASC,QAC3D,GAAId,KAA6Be,EAAW,CACtBA,EAAmC,UAAEttB,MAAM,KACnDxL,SAAQ+4B,IACd,MAAOnhB,EAAK1V,GAAS62B,EAASvtB,MAAM,KACpC7O,KAAKw7B,SAASvgB,GAgB9B,SAAoB2gB,EAAUr2B,GAE1B,GAAc,UADdA,EAAQA,EAAM82B,gBACoB,UAAV92B,EACpB,MAAiB,SAAVA,EAEN,GAAI,KAAIA,IAAYA,EACrB,OAAQA,EAEZ,MAAM,IAAI5F,MAAM,oCAAoC4F,cAAkBq2B,MAxBrCU,CAAWrhB,EAAK1V,QAK9C,SAASk2B,EAAec,GAC3B,MAAMC,EAAS,GAKf,OAJAD,EAAY7tB,QAAQ,+BAA+B,CAACyC,KAAM+O,KAM9D,SAAqBsc,EAAQx5B,EAAMuC,GAC/Bi3B,EAAOC,mBAAmBz5B,IAASy5B,mBAAmBl3B,GAAS,IAN3Dm3B,CAAYF,EAAQtc,EAAE,GAAIA,EAAE,IACrBA,EAAE7X,KAAK,QAEXm0B,EAuBJ,SAASG,IACZ,OAAOjnB,EAEJ,IAAIA,EAAM,KACV,SAASknB,EAAqB3O,GACjCvY,EAAMuY","file":"js/bundle~bundle~fb9c722d.502ca0e9.js","sourcesContent":["/**\n * @license\n * Copyright 2020 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n// Required side effectful code for tfjs-core\n// Set up Engine and ENV\nimport { getOrMakeEngine } from './engine';\ngetOrMakeEngine();\n// Register backend-agnostic flags.\nimport './flags';\n// Register platforms\nimport './platforms/platform_browser';\nimport './platforms/platform_node';\n// Set up OpHandler\nimport { buffer } from './ops/buffer';\nimport { cast } from './ops/cast';\nimport { clone } from './ops/clone';\nimport { print } from './ops/print';\nimport { setOpHandler } from './tensor';\nconst opHandler = {\n    buffer,\n    cast,\n    clone,\n    print\n};\nsetOpHandler(opHandler);\n//# sourceMappingURL=base_side_effects.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n/**\n * IOHandlers related to files, such as browser-triggered file downloads,\n * user-selected files in browser.\n */\nimport '../flags';\nimport { env } from '../environment';\nimport { basename, concatenateArrayBuffers, getModelArtifactsInfoForJSON } from './io_utils';\nimport { IORouterRegistry } from './router_registry';\nconst DEFAULT_FILE_NAME_PREFIX = 'model';\nconst DEFAULT_JSON_EXTENSION_NAME = '.json';\nconst DEFAULT_WEIGHT_DATA_EXTENSION_NAME = '.weights.bin';\nfunction defer(f) {\n    return new Promise(resolve => setTimeout(resolve)).then(f);\n}\nexport class BrowserDownloads {\n    constructor(fileNamePrefix) {\n        if (!env().getBool('IS_BROWSER')) {\n            // TODO(cais): Provide info on what IOHandlers are available under the\n            //   current environment.\n            throw new Error('browserDownloads() cannot proceed because the current environment ' +\n                'is not a browser.');\n        }\n        if (fileNamePrefix.startsWith(BrowserDownloads.URL_SCHEME)) {\n            fileNamePrefix = fileNamePrefix.slice(BrowserDownloads.URL_SCHEME.length);\n        }\n        if (fileNamePrefix == null || fileNamePrefix.length === 0) {\n            fileNamePrefix = DEFAULT_FILE_NAME_PREFIX;\n        }\n        this.modelTopologyFileName = fileNamePrefix + DEFAULT_JSON_EXTENSION_NAME;\n        this.weightDataFileName =\n            fileNamePrefix + DEFAULT_WEIGHT_DATA_EXTENSION_NAME;\n    }\n    async save(modelArtifacts) {\n        if (typeof (document) === 'undefined') {\n            throw new Error('Browser downloads are not supported in ' +\n                'this environment since `document` is not present');\n        }\n        const weightsURL = window.URL.createObjectURL(new Blob([modelArtifacts.weightData], { type: 'application/octet-stream' }));\n        if (modelArtifacts.modelTopology instanceof ArrayBuffer) {\n            throw new Error('BrowserDownloads.save() does not support saving model topology ' +\n                'in binary formats yet.');\n        }\n        else {\n            const weightsManifest = [{\n                    paths: ['./' + this.weightDataFileName],\n                    weights: modelArtifacts.weightSpecs\n                }];\n            const modelTopologyAndWeightManifest = {\n                modelTopology: modelArtifacts.modelTopology,\n                format: modelArtifacts.format,\n                generatedBy: modelArtifacts.generatedBy,\n                convertedBy: modelArtifacts.convertedBy,\n                weightsManifest\n            };\n            if (modelArtifacts.signature != null) {\n                modelTopologyAndWeightManifest.signature = modelArtifacts.signature;\n            }\n            if (modelArtifacts.userDefinedMetadata != null) {\n                modelTopologyAndWeightManifest.userDefinedMetadata =\n                    modelArtifacts.userDefinedMetadata;\n            }\n            if (modelArtifacts.modelInitializer != null) {\n                modelTopologyAndWeightManifest.modelInitializer =\n                    modelArtifacts.modelInitializer;\n            }\n            const modelTopologyAndWeightManifestURL = window.URL.createObjectURL(new Blob([JSON.stringify(modelTopologyAndWeightManifest)], { type: 'application/json' }));\n            // If anchor elements are not provided, create them without attaching them\n            // to parents, so that the downloaded file names can be controlled.\n            const jsonAnchor = this.jsonAnchor == null ? document.createElement('a') :\n                this.jsonAnchor;\n            jsonAnchor.download = this.modelTopologyFileName;\n            jsonAnchor.href = modelTopologyAndWeightManifestURL;\n            // Trigger downloads by evoking a click event on the download anchors.\n            // When multiple downloads are started synchronously, Firefox will only\n            // save the last one.\n            await defer(() => jsonAnchor.dispatchEvent(new MouseEvent('click')));\n            if (modelArtifacts.weightData != null) {\n                const weightDataAnchor = this.weightDataAnchor == null ?\n                    document.createElement('a') :\n                    this.weightDataAnchor;\n                weightDataAnchor.download = this.weightDataFileName;\n                weightDataAnchor.href = weightsURL;\n                await defer(() => weightDataAnchor.dispatchEvent(new MouseEvent('click')));\n            }\n            return { modelArtifactsInfo: getModelArtifactsInfoForJSON(modelArtifacts) };\n        }\n    }\n}\nBrowserDownloads.URL_SCHEME = 'downloads://';\nclass BrowserFiles {\n    constructor(files) {\n        if (files == null || files.length < 1) {\n            throw new Error(`When calling browserFiles, at least 1 file is required, ` +\n                `but received ${files}`);\n        }\n        this.files = files;\n    }\n    async load() {\n        const jsonFile = this.files[0];\n        const weightFiles = this.files.slice(1);\n        return new Promise((resolve, reject) => {\n            const jsonReader = new FileReader();\n            jsonReader.onload = (event) => {\n                // tslint:disable-next-line:no-any\n                const modelJSON = JSON.parse(event.target.result);\n                const modelTopology = modelJSON.modelTopology;\n                if (modelTopology == null) {\n                    reject(new Error(`modelTopology field is missing from file ${jsonFile.name}`));\n                    return;\n                }\n                if (weightFiles.length === 0) {\n                    resolve({ modelTopology });\n                }\n                const weightsManifest = modelJSON.weightsManifest;\n                if (weightsManifest == null) {\n                    reject(new Error(`weightManifest field is missing from file ${jsonFile.name}`));\n                    return;\n                }\n                let pathToFile;\n                try {\n                    pathToFile =\n                        this.checkManifestAndWeightFiles(weightsManifest, weightFiles);\n                }\n                catch (err) {\n                    reject(err);\n                    return;\n                }\n                const weightSpecs = [];\n                const paths = [];\n                const perFileBuffers = [];\n                weightsManifest.forEach(weightsGroup => {\n                    weightsGroup.paths.forEach(path => {\n                        paths.push(path);\n                        perFileBuffers.push(null);\n                    });\n                    weightSpecs.push(...weightsGroup.weights);\n                });\n                weightsManifest.forEach(weightsGroup => {\n                    weightsGroup.paths.forEach(path => {\n                        const weightFileReader = new FileReader();\n                        weightFileReader.onload = (event) => {\n                            // tslint:disable-next-line:no-any\n                            const weightData = event.target.result;\n                            const index = paths.indexOf(path);\n                            perFileBuffers[index] = weightData;\n                            if (perFileBuffers.indexOf(null) === -1) {\n                                const result = {\n                                    modelTopology,\n                                    weightSpecs,\n                                    weightData: concatenateArrayBuffers(perFileBuffers),\n                                    format: modelJSON.format,\n                                    generatedBy: modelJSON.generatedBy,\n                                    convertedBy: modelJSON.convertedBy\n                                };\n                                if (modelJSON.signature != null) {\n                                    result.signature = modelJSON.signature;\n                                }\n                                if (modelJSON.userDefinedMetadata != null) {\n                                    result.userDefinedMetadata = modelJSON.userDefinedMetadata;\n                                }\n                                if (modelJSON.modelInitializer != null) {\n                                    result.modelInitializer = modelJSON.modelInitializer;\n                                }\n                                resolve(result);\n                            }\n                        };\n                        weightFileReader.onerror = error => reject(`Failed to weights data from file of path '${path}'.`);\n                        weightFileReader.readAsArrayBuffer(pathToFile[path]);\n                    });\n                });\n            };\n            jsonReader.onerror = error => reject(`Failed to read model topology and weights manifest JSON ` +\n                `from file '${jsonFile.name}'. BrowserFiles supports loading ` +\n                `Keras-style tf.Model artifacts only.`);\n            jsonReader.readAsText(jsonFile);\n        });\n    }\n    /**\n     * Check the compatibility between weights manifest and weight files.\n     */\n    checkManifestAndWeightFiles(manifest, files) {\n        const basenames = [];\n        const fileNames = files.map(file => basename(file.name));\n        const pathToFile = {};\n        for (const group of manifest) {\n            group.paths.forEach(path => {\n                const pathBasename = basename(path);\n                if (basenames.indexOf(pathBasename) !== -1) {\n                    throw new Error(`Duplicate file basename found in weights manifest: ` +\n                        `'${pathBasename}'`);\n                }\n                basenames.push(pathBasename);\n                if (fileNames.indexOf(pathBasename) === -1) {\n                    throw new Error(`Weight file with basename '${pathBasename}' is not provided.`);\n                }\n                else {\n                    pathToFile[path] = files[fileNames.indexOf(pathBasename)];\n                }\n            });\n        }\n        if (basenames.length !== files.length) {\n            throw new Error(`Mismatch in the number of files in weights manifest ` +\n                `(${basenames.length}) and the number of weight files provided ` +\n                `(${files.length}).`);\n        }\n        return pathToFile;\n    }\n}\nexport const browserDownloadsRouter = (url) => {\n    if (!env().getBool('IS_BROWSER')) {\n        return null;\n    }\n    else {\n        if (!Array.isArray(url) && url.startsWith(BrowserDownloads.URL_SCHEME)) {\n            return browserDownloads(url.slice(BrowserDownloads.URL_SCHEME.length));\n        }\n        else {\n            return null;\n        }\n    }\n};\nIORouterRegistry.registerSaveRouter(browserDownloadsRouter);\n/**\n * Creates an IOHandler that triggers file downloads from the browser.\n *\n * The returned `IOHandler` instance can be used as model exporting methods such\n * as `tf.Model.save` and supports only saving.\n *\n * ```js\n * const model = tf.sequential();\n * model.add(tf.layers.dense(\n *     {units: 1, inputShape: [10], activation: 'sigmoid'}));\n * const saveResult = await model.save('downloads://mymodel');\n * // This will trigger downloading of two files:\n * //   'mymodel.json' and 'mymodel.weights.bin'.\n * console.log(saveResult);\n * ```\n *\n * @param fileNamePrefix Prefix name of the files to be downloaded. For use with\n *   `tf.Model`, `fileNamePrefix` should follow either of the following two\n *   formats:\n *   1. `null` or `undefined`, in which case the default file\n *      names will be used:\n *      - 'model.json' for the JSON file containing the model topology and\n *        weights manifest.\n *      - 'model.weights.bin' for the binary file containing the binary weight\n *        values.\n *   2. A single string or an Array of a single string, as the file name prefix.\n *      For example, if `'foo'` is provided, the downloaded JSON\n *      file and binary weights file will be named 'foo.json' and\n *      'foo.weights.bin', respectively.\n * @param config Additional configuration for triggering downloads.\n * @returns An instance of `BrowserDownloads` `IOHandler`.\n *\n * @doc {\n *   heading: 'Models',\n *   subheading: 'Loading',\n *   namespace: 'io',\n *   ignoreCI: true\n * }\n */\nexport function browserDownloads(fileNamePrefix = 'model') {\n    return new BrowserDownloads(fileNamePrefix);\n}\n/**\n * Creates an IOHandler that loads model artifacts from user-selected files.\n *\n * This method can be used for loading from files such as user-selected files\n * in the browser.\n * When used in conjunction with `tf.loadLayersModel`, an instance of\n * `tf.LayersModel` (Keras-style) can be constructed from the loaded artifacts.\n *\n * ```js\n * // Note: This code snippet won't run properly without the actual file input\n * //   elements in the HTML DOM.\n *\n * // Suppose there are two HTML file input (`<input type=\"file\" ...>`)\n * // elements.\n * const uploadJSONInput = document.getElementById('upload-json');\n * const uploadWeightsInput = document.getElementById('upload-weights');\n * const model = await tf.loadLayersModel(tf.io.browserFiles(\n *     [uploadJSONInput.files[0], uploadWeightsInput.files[0]]));\n * ```\n *\n * @param files `File`s to load from. Currently, this function supports only\n *   loading from files that contain Keras-style models (i.e., `tf.Model`s), for\n *   which an `Array` of `File`s is expected (in that order):\n *   - A JSON file containing the model topology and weight manifest.\n *   - Optionally, One or more binary files containing the binary weights.\n *     These files must have names that match the paths in the `weightsManifest`\n *     contained by the aforementioned JSON file, or errors will be thrown\n *     during loading. These weights files have the same format as the ones\n *     generated by `tensorflowjs_converter` that comes with the `tensorflowjs`\n *     Python PIP package. If no weights files are provided, only the model\n *     topology will be loaded from the JSON file above.\n * @returns An instance of `Files` `IOHandler`.\n *\n * @doc {\n *   heading: 'Models',\n *   subheading: 'Loading',\n *   namespace: 'io',\n *   ignoreCI: true\n * }\n */\nexport function browserFiles(files) {\n    return new BrowserFiles(files);\n}\n//# sourceMappingURL=browser_files.js.map","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { assert } from '../util';\n/**\n * Monitor Promise.all progress, fire onProgress callback function.\n *\n * @param promises Promise list going to be monitored\n * @param onProgress Callback function. Fired when a promise resolved.\n * @param startFraction Optional fraction start. Default to 0.\n * @param endFraction Optional fraction end. Default to 1.\n */\nexport function monitorPromisesProgress(promises, onProgress, startFraction, endFraction) {\n    checkPromises(promises);\n    startFraction = startFraction == null ? 0 : startFraction;\n    endFraction = endFraction == null ? 1 : endFraction;\n    checkFraction(startFraction, endFraction);\n    let resolvedPromise = 0;\n    const registerMonitor = (promise) => {\n        promise.then(value => {\n            const fraction = startFraction +\n                ++resolvedPromise / promises.length * (endFraction - startFraction);\n            // pass fraction as parameter to callback function.\n            onProgress(fraction);\n            return value;\n        });\n        return promise;\n    };\n    function checkPromises(promises) {\n        assert(promises != null && Array.isArray(promises) && promises.length > 0, () => 'promises must be a none empty array');\n    }\n    function checkFraction(startFraction, endFraction) {\n        assert(startFraction >= 0 && startFraction <= 1, () => `Progress fraction must be in range [0, 1], but ` +\n            `got startFraction ${startFraction}`);\n        assert(endFraction >= 0 && endFraction <= 1, () => `Progress fraction must be in range [0, 1], but ` +\n            `got endFraction ${endFraction}`);\n        assert(endFraction >= startFraction, () => `startFraction must be no more than endFraction, but ` +\n            `got startFraction ${startFraction} and endFraction ` +\n            `${endFraction}`);\n    }\n    return Promise.all(promises.map(registerMonitor));\n}\n//# sourceMappingURL=progress.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { env } from '../environment';\nimport * as util from '../util';\nimport { decodeWeights } from './io_utils';\nimport { monitorPromisesProgress } from './progress';\nimport { DTYPE_VALUE_SIZE_MAP } from './types';\n/**\n * Reads binary weights data from a number of URLs.\n *\n * @param fetchURLs URLs to send the HTTP requests at, using `fetch` calls.\n * @param requestOptions RequestInit (options) for the HTTP requests.\n * @param fetchFunc Optional overriding value for the `window.fetch` function.\n * @param onProgress Optional, progress callback function, fired periodically\n *   before the load is completed.\n * @returns A `Promise` of an Array of `ArrayBuffer`. The Array has the same\n *   length as `fetchURLs`.\n */\nexport async function loadWeightsAsArrayBuffer(fetchURLs, loadOptions) {\n    if (loadOptions == null) {\n        loadOptions = {};\n    }\n    const fetchFunc = loadOptions.fetchFunc == null ? env().platform.fetch :\n        loadOptions.fetchFunc;\n    // Create the requests for all of the weights in parallel.\n    const requests = fetchURLs.map(fetchURL => fetchFunc(fetchURL, loadOptions.requestInit, { isBinary: true }));\n    const fetchStartFraction = 0;\n    const fetchEndFraction = 0.5;\n    const responses = loadOptions.onProgress == null ?\n        await Promise.all(requests) :\n        await monitorPromisesProgress(requests, loadOptions.onProgress, fetchStartFraction, fetchEndFraction);\n    const bufferPromises = responses.map(response => response.arrayBuffer());\n    const bufferStartFraction = 0.5;\n    const bufferEndFraction = 1;\n    const buffers = loadOptions.onProgress == null ?\n        await Promise.all(bufferPromises) :\n        await monitorPromisesProgress(bufferPromises, loadOptions.onProgress, bufferStartFraction, bufferEndFraction);\n    return buffers;\n}\n/**\n * Reads a weights manifest JSON configuration, fetches the weights and\n * returns them as `Tensor`s.\n *\n * @param manifest The weights manifest JSON.\n * @param filePathPrefix The path prefix for filenames given in the manifest.\n *     Defaults to the empty string.\n * @param weightNames The names of the weights to be fetched.\n */\nexport async function loadWeights(manifest, filePathPrefix = '', weightNames, requestInit) {\n    // TODO(nsthorat): Groups are currently fetched atomically. If you need a\n    // single weight from a group, the whole group will be fetched. At a future\n    // date, we should support fetching only the individual shards within a\n    // group that are needed to reconstruct the requested weight.\n    // TODO(cais): Use `decodeWeights` for implementation.\n    const fetchWeights = (fetchUrls) => loadWeightsAsArrayBuffer(fetchUrls, { requestInit });\n    const loadWeights = weightsLoaderFactory(fetchWeights);\n    return loadWeights(manifest, filePathPrefix, weightNames);\n}\n/**\n * Creates a function, which reads a weights manifest JSON configuration,\n * fetches the weight files using the specified function and returns them as\n * `Tensor`s.\n *\n * ```js\n * // example for creating a nodejs weight loader, which reads the weight files\n * // from disk using fs.readFileSync\n *\n * import * as fs from 'fs'\n *\n * const fetchWeightsFromDisk = (filePaths: string[]) =>\n *   filePaths.map(filePath => fs.readFileSync(filePath).buffer)\n *\n * const loadWeights = tf.io.weightsLoaderFactory(fetchWeightsFromDisk)\n *\n * const manifest = JSON.parse(\n *   fs.readFileSync('./my_model-weights_manifest').toString()\n * )\n * const weightMap = await loadWeights(manifest, './')\n * ```\n * @param fetchWeightsFunction The function used for fetching the weight files.\n * @returns Weight loading function.\n */\nexport function weightsLoaderFactory(fetchWeightsFunction) {\n    return async (manifest, filePathPrefix = '', weightNames) => {\n        // Collect all the groups, weights, and their relative offsets to be\n        // fetched.\n        const groupIndicesToFetchMap = manifest.map(() => false);\n        const groupWeightsToFetch = {};\n        const weightsFound = weightNames != null ? weightNames.map(() => false) : [];\n        const allManifestWeightNames = [];\n        manifest.forEach((manifestGroupConfig, groupIndex) => {\n            let groupOffset = 0;\n            manifestGroupConfig.weights.forEach(weightsEntry => {\n                const rawDtype = ('quantization' in weightsEntry) ?\n                    weightsEntry.quantization.dtype :\n                    weightsEntry.dtype;\n                const weightsBytes = DTYPE_VALUE_SIZE_MAP[rawDtype] *\n                    util.sizeFromShape(weightsEntry.shape);\n                const enqueueWeightsForFetchingFn = () => {\n                    groupIndicesToFetchMap[groupIndex] = true;\n                    if (groupWeightsToFetch[groupIndex] == null) {\n                        groupWeightsToFetch[groupIndex] = [];\n                    }\n                    groupWeightsToFetch[groupIndex].push({\n                        manifestEntry: weightsEntry,\n                        groupOffset,\n                        sizeBytes: weightsBytes\n                    });\n                };\n                if (weightNames != null) {\n                    weightNames.forEach((weightName, weightIndex) => {\n                        if (weightName === weightsEntry.name) {\n                            enqueueWeightsForFetchingFn();\n                            weightsFound[weightIndex] = true;\n                        }\n                    });\n                }\n                else {\n                    enqueueWeightsForFetchingFn();\n                }\n                allManifestWeightNames.push(weightsEntry.name);\n                groupOffset += weightsBytes;\n            });\n        });\n        if (!weightsFound.every(found => found)) {\n            const weightsNotFound = weightNames.filter((_, i) => !weightsFound[i]);\n            throw new Error(`Could not find weights in manifest with names: ` +\n                `${weightsNotFound.join(', ')}. \\n` +\n                `Manifest JSON has weights with names: ` +\n                `${allManifestWeightNames.join(', ')}.`);\n        }\n        // Convert the one-hot boolean groupId => shouldFetch map to a list of group\n        // IDs.\n        const groupIndicesToFetch = groupIndicesToFetchMap.reduce((accumulator, shouldFetch, i) => {\n            if (shouldFetch) {\n                accumulator.push(i);\n            }\n            return accumulator;\n        }, []);\n        const fetchUrls = [];\n        groupIndicesToFetch.forEach(i => {\n            manifest[i].paths.forEach(filepath => {\n                const fetchUrl = filePathPrefix +\n                    (!filePathPrefix.endsWith('/') ? '/' : '') + filepath;\n                fetchUrls.push(fetchUrl);\n            });\n        });\n        const buffers = await fetchWeightsFunction(fetchUrls);\n        const weightsTensorMap = {};\n        let bufferIndexOffset = 0;\n        groupIndicesToFetch.forEach(i => {\n            const numBuffers = manifest[i].paths.length;\n            let groupBytes = 0;\n            for (let i = 0; i < numBuffers; i++) {\n                groupBytes += buffers[bufferIndexOffset + i].byteLength;\n            }\n            // Create a buffer for the whole group.\n            const groupBuffer = new ArrayBuffer(groupBytes);\n            const groupByteBuffer = new Uint8Array(groupBuffer);\n            let groupBufferOffset = 0;\n            for (let i = 0; i < numBuffers; i++) {\n                const buffer = new Uint8Array(buffers[bufferIndexOffset + i]);\n                groupByteBuffer.set(buffer, groupBufferOffset);\n                groupBufferOffset += buffer.byteLength;\n            }\n            const weightsEntries = groupWeightsToFetch[i];\n            weightsEntries.forEach(weightsEntry => {\n                const byteBuffer = groupBuffer.slice(weightsEntry.groupOffset, weightsEntry.groupOffset + weightsEntry.sizeBytes);\n                const nameToTensorMap = decodeWeights(byteBuffer, [weightsEntry.manifestEntry]);\n                for (const name in nameToTensorMap) {\n                    weightsTensorMap[name] = nameToTensorMap[name];\n                }\n            });\n            bufferIndexOffset += numBuffers;\n        });\n        return weightsTensorMap;\n    };\n}\n//# sourceMappingURL=weights_loader.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n/**\n * IOHandler implementations based on HTTP requests in the web browser.\n *\n * Uses [`fetch`](https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API).\n */\nimport { env } from '../environment';\nimport { assert } from '../util';\nimport { concatenateArrayBuffers, getModelArtifactsInfoForJSON } from './io_utils';\nimport { IORouterRegistry } from './router_registry';\nimport { loadWeightsAsArrayBuffer } from './weights_loader';\nconst OCTET_STREAM_MIME_TYPE = 'application/octet-stream';\nconst JSON_TYPE = 'application/json';\nexport class HTTPRequest {\n    constructor(path, loadOptions) {\n        this.DEFAULT_METHOD = 'POST';\n        if (loadOptions == null) {\n            loadOptions = {};\n        }\n        this.weightPathPrefix = loadOptions.weightPathPrefix;\n        this.onProgress = loadOptions.onProgress;\n        this.weightUrlConverter = loadOptions.weightUrlConverter;\n        if (loadOptions.fetchFunc != null) {\n            assert(typeof loadOptions.fetchFunc === 'function', () => 'Must pass a function that matches the signature of ' +\n                '`fetch` (see ' +\n                'https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API)');\n            this.fetch = loadOptions.fetchFunc;\n        }\n        else {\n            this.fetch = env().platform.fetch;\n        }\n        assert(path != null && path.length > 0, () => 'URL path for http must not be null, undefined or ' +\n            'empty.');\n        if (Array.isArray(path)) {\n            assert(path.length === 2, () => 'URL paths for http must have a length of 2, ' +\n                `(actual length is ${path.length}).`);\n        }\n        this.path = path;\n        if (loadOptions.requestInit != null &&\n            loadOptions.requestInit.body != null) {\n            throw new Error('requestInit is expected to have no pre-existing body, but has one.');\n        }\n        this.requestInit = loadOptions.requestInit || {};\n    }\n    async save(modelArtifacts) {\n        if (modelArtifacts.modelTopology instanceof ArrayBuffer) {\n            throw new Error('BrowserHTTPRequest.save() does not support saving model topology ' +\n                'in binary formats yet.');\n        }\n        const init = Object.assign({ method: this.DEFAULT_METHOD }, this.requestInit);\n        init.body = new FormData();\n        const weightsManifest = [{\n                paths: ['./model.weights.bin'],\n                weights: modelArtifacts.weightSpecs,\n            }];\n        const modelTopologyAndWeightManifest = {\n            modelTopology: modelArtifacts.modelTopology,\n            format: modelArtifacts.format,\n            generatedBy: modelArtifacts.generatedBy,\n            convertedBy: modelArtifacts.convertedBy,\n            weightsManifest\n        };\n        if (modelArtifacts.signature != null) {\n            modelTopologyAndWeightManifest.signature = modelArtifacts.signature;\n        }\n        if (modelArtifacts.userDefinedMetadata != null) {\n            modelTopologyAndWeightManifest.userDefinedMetadata =\n                modelArtifacts.userDefinedMetadata;\n        }\n        if (modelArtifacts.modelInitializer != null) {\n            modelTopologyAndWeightManifest.modelInitializer =\n                modelArtifacts.modelInitializer;\n        }\n        init.body.append('model.json', new Blob([JSON.stringify(modelTopologyAndWeightManifest)], { type: JSON_TYPE }), 'model.json');\n        if (modelArtifacts.weightData != null) {\n            init.body.append('model.weights.bin', new Blob([modelArtifacts.weightData], { type: OCTET_STREAM_MIME_TYPE }), 'model.weights.bin');\n        }\n        const response = await this.fetch(this.path, init);\n        if (response.ok) {\n            return {\n                modelArtifactsInfo: getModelArtifactsInfoForJSON(modelArtifacts),\n                responses: [response],\n            };\n        }\n        else {\n            throw new Error(`BrowserHTTPRequest.save() failed due to HTTP response status ` +\n                `${response.status}.`);\n        }\n    }\n    /**\n     * Load model artifacts via HTTP request(s).\n     *\n     * See the documentation to `tf.io.http` for details on the saved\n     * artifacts.\n     *\n     * @returns The loaded model artifacts (if loading succeeds).\n     */\n    async load() {\n        const modelConfigRequest = await this.fetch(this.path, this.requestInit);\n        if (!modelConfigRequest.ok) {\n            throw new Error(`Request to ${this.path} failed with status code ` +\n                `${modelConfigRequest.status}. Please verify this URL points to ` +\n                `the model JSON of the model to load.`);\n        }\n        let modelConfig;\n        try {\n            modelConfig = await modelConfigRequest.json();\n        }\n        catch (e) {\n            let message = `Failed to parse model JSON of response from ${this.path}.`;\n            // TODO(nsthorat): Remove this after some time when we're comfortable that\n            // .pb files are mostly gone.\n            if (this.path.endsWith('.pb')) {\n                message += ' Your path contains a .pb file extension. ' +\n                    'Support for .pb models have been removed in TensorFlow.js 1.0 ' +\n                    'in favor of .json models. You can re-convert your Python ' +\n                    'TensorFlow model using the TensorFlow.js 1.0 conversion scripts ' +\n                    'or you can convert your.pb models with the \\'pb2json\\'' +\n                    'NPM script in the tensorflow/tfjs-converter repository.';\n            }\n            else {\n                message += ' Please make sure the server is serving valid ' +\n                    'JSON for this request.';\n            }\n            throw new Error(message);\n        }\n        const modelTopology = modelConfig.modelTopology;\n        const weightsManifest = modelConfig.weightsManifest;\n        const generatedBy = modelConfig.generatedBy;\n        const convertedBy = modelConfig.convertedBy;\n        const format = modelConfig.format;\n        const signature = modelConfig.signature;\n        const userDefinedMetadata = modelConfig.userDefinedMetadata;\n        // We do not allow both modelTopology and weightsManifest to be missing.\n        if (modelTopology == null && weightsManifest == null) {\n            throw new Error(`The JSON from HTTP path ${this.path} contains neither model ` +\n                `topology or manifest for weights.`);\n        }\n        let weightSpecs;\n        let weightData;\n        if (weightsManifest != null) {\n            const results = await this.loadWeights(weightsManifest);\n            [weightSpecs, weightData] = results;\n        }\n        const artifacts = {\n            modelTopology,\n            weightSpecs,\n            weightData,\n            generatedBy,\n            convertedBy,\n            format\n        };\n        if (signature != null) {\n            artifacts.signature = signature;\n        }\n        if (userDefinedMetadata != null) {\n            artifacts.userDefinedMetadata = userDefinedMetadata;\n        }\n        const initializer = modelConfig.modelInitializer;\n        if (initializer) {\n            artifacts.modelInitializer = initializer;\n        }\n        return artifacts;\n    }\n    async loadWeights(weightsManifest) {\n        const weightPath = Array.isArray(this.path) ? this.path[1] : this.path;\n        const [prefix, suffix] = parseUrl(weightPath);\n        const pathPrefix = this.weightPathPrefix || prefix;\n        const weightSpecs = [];\n        for (const entry of weightsManifest) {\n            weightSpecs.push(...entry.weights);\n        }\n        const fetchURLs = [];\n        const urlPromises = [];\n        for (const weightsGroup of weightsManifest) {\n            for (const path of weightsGroup.paths) {\n                if (this.weightUrlConverter != null) {\n                    urlPromises.push(this.weightUrlConverter(path));\n                }\n                else {\n                    fetchURLs.push(pathPrefix + path + suffix);\n                }\n            }\n        }\n        if (this.weightUrlConverter) {\n            fetchURLs.push(...await Promise.all(urlPromises));\n        }\n        const buffers = await loadWeightsAsArrayBuffer(fetchURLs, {\n            requestInit: this.requestInit,\n            fetchFunc: this.fetch,\n            onProgress: this.onProgress\n        });\n        return [weightSpecs, concatenateArrayBuffers(buffers)];\n    }\n}\nHTTPRequest.URL_SCHEME_REGEX = /^https?:\\/\\//;\n/**\n * Extract the prefix and suffix of the url, where the prefix is the path before\n * the last file, and suffix is the search params after the last file.\n * ```\n * const url = 'http://tfhub.dev/model/1/tensorflowjs_model.pb?tfjs-format=file'\n * [prefix, suffix] = parseUrl(url)\n * // prefix = 'http://tfhub.dev/model/1/'\n * // suffix = '?tfjs-format=file'\n * ```\n * @param url the model url to be parsed.\n */\nexport function parseUrl(url) {\n    const lastSlash = url.lastIndexOf('/');\n    const lastSearchParam = url.lastIndexOf('?');\n    const prefix = url.substring(0, lastSlash);\n    const suffix = lastSearchParam > lastSlash ? url.substring(lastSearchParam) : '';\n    return [prefix + '/', suffix];\n}\nexport function isHTTPScheme(url) {\n    return url.match(HTTPRequest.URL_SCHEME_REGEX) != null;\n}\nexport const httpRouter = (url, loadOptions) => {\n    if (typeof fetch === 'undefined' &&\n        (loadOptions == null || loadOptions.fetchFunc == null)) {\n        // `http` uses `fetch` or `node-fetch`, if one wants to use it in\n        // an environment that is not the browser or node they have to setup a\n        // global fetch polyfill.\n        return null;\n    }\n    else {\n        let isHTTP = true;\n        if (Array.isArray(url)) {\n            isHTTP = url.every(urlItem => isHTTPScheme(urlItem));\n        }\n        else {\n            isHTTP = isHTTPScheme(url);\n        }\n        if (isHTTP) {\n            return http(url, loadOptions);\n        }\n    }\n    return null;\n};\nIORouterRegistry.registerSaveRouter(httpRouter);\nIORouterRegistry.registerLoadRouter(httpRouter);\n/**\n * Creates an IOHandler subtype that sends model artifacts to HTTP server.\n *\n * An HTTP request of the `multipart/form-data` mime type will be sent to the\n * `path` URL. The form data includes artifacts that represent the topology\n * and/or weights of the model. In the case of Keras-style `tf.Model`, two\n * blobs (files) exist in form-data:\n *   - A JSON file consisting of `modelTopology` and `weightsManifest`.\n *   - A binary weights file consisting of the concatenated weight values.\n * These files are in the same format as the one generated by\n * [tfjs_converter](https://js.tensorflow.org/tutorials/import-keras.html).\n *\n * The following code snippet exemplifies the client-side code that uses this\n * function:\n *\n * ```js\n * const model = tf.sequential();\n * model.add(\n *     tf.layers.dense({units: 1, inputShape: [100], activation: 'sigmoid'}));\n *\n * const saveResult = await model.save(tf.io.http(\n *     'http://model-server:5000/upload', {requestInit: {method: 'PUT'}}));\n * console.log(saveResult);\n * ```\n *\n * If the default `POST` method is to be used, without any custom parameters\n * such as headers, you can simply pass an HTTP or HTTPS URL to `model.save`:\n *\n * ```js\n * const saveResult = await model.save('http://model-server:5000/upload');\n * ```\n *\n * The following GitHub Gist\n * https://gist.github.com/dsmilkov/1b6046fd6132d7408d5257b0976f7864\n * implements a server based on [flask](https://github.com/pallets/flask) that\n * can receive the request. Upon receiving the model artifacts via the requst,\n * this particular server reconsistutes instances of [Keras\n * Models](https://keras.io/models/model/) in memory.\n *\n *\n * @param path A URL path to the model.\n *   Can be an absolute HTTP path (e.g.,\n *   'http://localhost:8000/model-upload)') or a relative path (e.g.,\n *   './model-upload').\n * @param requestInit Request configurations to be used when sending\n *    HTTP request to server using `fetch`. It can contain fields such as\n *    `method`, `credentials`, `headers`, `mode`, etc. See\n *    https://developer.mozilla.org/en-US/docs/Web/API/Request/Request\n *    for more information. `requestInit` must not have a body, because the\n * body will be set by TensorFlow.js. File blobs representing the model\n * topology (filename: 'model.json') and the weights of the model (filename:\n * 'model.weights.bin') will be appended to the body. If `requestInit` has a\n * `body`, an Error will be thrown.\n * @param loadOptions Optional configuration for the loading. It includes the\n *   following fields:\n *   - weightPathPrefix Optional, this specifies the path prefix for weight\n *     files, by default this is calculated from the path param.\n *   - fetchFunc Optional, custom `fetch` function. E.g., in Node.js,\n *     the `fetch` from node-fetch can be used here.\n *   - onProgress Optional, progress callback function, fired periodically\n *     before the load is completed.\n * @returns An instance of `IOHandler`.\n *\n * @doc {\n *   heading: 'Models',\n *   subheading: 'Loading',\n *   namespace: 'io',\n *   ignoreCI: true\n * }\n */\nexport function http(path, loadOptions) {\n    return new HTTPRequest(path, loadOptions);\n}\n/**\n * Deprecated. Use `tf.io.http`.\n * @param path\n * @param loadOptions\n */\nexport function browserHTTPRequest(path, loadOptions) {\n    return http(path, loadOptions);\n}\n//# sourceMappingURL=http.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nclass PassthroughLoader {\n    constructor(modelArtifacts) {\n        this.modelArtifacts = modelArtifacts;\n    }\n    async load() {\n        return this.modelArtifacts;\n    }\n}\nclass PassthroughSaver {\n    constructor(saveHandler) {\n        this.saveHandler = saveHandler;\n    }\n    async save(modelArtifacts) {\n        return this.saveHandler(modelArtifacts);\n    }\n}\n/**\n * Creates an IOHandler that loads model artifacts from memory.\n *\n * When used in conjunction with `tf.loadLayersModel`, an instance of\n * `tf.LayersModel` (Keras-style) can be constructed from the loaded artifacts.\n *\n * ```js\n * const model = await tf.loadLayersModel(tf.io.fromMemory(\n *     modelTopology, weightSpecs, weightData));\n * ```\n *\n * @param modelArtifacts a object containing model topology (i.e., parsed from\n *   the JSON format).\n * @param weightSpecs An array of `WeightsManifestEntry` objects describing the\n *   names, shapes, types, and quantization of the weight data.\n * @param weightData A single `ArrayBuffer` containing the weight data,\n *   concatenated in the order described by the weightSpecs.\n * @param trainingConfig Model training configuration. Optional.\n *\n * @returns A passthrough `IOHandler` that simply loads the provided data.\n */\nexport function fromMemory(modelArtifacts, weightSpecs, weightData, trainingConfig) {\n    if (arguments.length === 1) {\n        const isModelArtifacts = modelArtifacts.modelTopology != null ||\n            modelArtifacts.weightSpecs != null;\n        if (isModelArtifacts) {\n            return new PassthroughLoader(modelArtifacts);\n        }\n        else {\n            // Legacy support: with only modelTopology.\n            // TODO(cais): Remove this deprecated API.\n            console.warn('Please call tf.io.fromMemory() with only one argument. ' +\n                'The argument should be of type ModelArtifacts. ' +\n                'The multi-argument signature of tf.io.fromMemory() has been ' +\n                'deprecated and will be removed in a future release.');\n            return new PassthroughLoader({ modelTopology: modelArtifacts });\n        }\n    }\n    else {\n        // Legacy support.\n        // TODO(cais): Remove this deprecated API.\n        console.warn('Please call tf.io.fromMemory() with only one argument. ' +\n            'The argument should be of type ModelArtifacts. ' +\n            'The multi-argument signature of tf.io.fromMemory() has been ' +\n            'deprecated and will be removed in a future release.');\n        return new PassthroughLoader({\n            modelTopology: modelArtifacts,\n            weightSpecs,\n            weightData,\n            trainingConfig\n        });\n    }\n}\n/**\n * Creates an IOHandler that passes saved model artifacts to a callback.\n *\n * ```js\n * function handleSave(artifacts) {\n *   // ... do something with the artifacts ...\n *   return {modelArtifactsInfo: {...}, ...};\n * }\n *\n * const saveResult = model.save(tf.io.withSaveHandler(handleSave));\n * ```\n *\n * @param saveHandler A function that accepts a `ModelArtifacts` and returns a\n *     `SaveResult`.\n */\nexport function withSaveHandler(saveHandler) {\n    return new PassthroughSaver(saveHandler);\n}\n//# sourceMappingURL=passthrough.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n/**\n * Merges real and imaginary Float32Arrays into a single complex Float32Array.\n *\n * The memory layout is interleaved as follows:\n * real: [r0, r1, r2]\n * imag: [i0, i1, i2]\n * complex: [r0, i0, r1, i1, r2, i2]\n *\n * This is the inverse of splitRealAndImagArrays.\n *\n * @param real The real values of the complex tensor values.\n * @param imag The imag values of the complex tensor values.\n * @returns A complex tensor as a Float32Array with merged values.\n */\nexport function mergeRealAndImagArrays(real, imag) {\n    if (real.length !== imag.length) {\n        throw new Error(`Cannot merge real and imag arrays of different lengths. real:` +\n            `${real.length}, imag: ${imag.length}.`);\n    }\n    const result = new Float32Array(real.length * 2);\n    for (let i = 0; i < result.length; i += 2) {\n        result[i] = real[i / 2];\n        result[i + 1] = imag[i / 2];\n    }\n    return result;\n}\n/**\n * Splits a complex Float32Array into real and imag parts.\n *\n * The memory layout is interleaved as follows:\n * complex: [r0, i0, r1, i1, r2, i2]\n * real: [r0, r1, r2]\n * imag: [i0, i1, i2]\n *\n * This is the inverse of mergeRealAndImagArrays.\n *\n * @param complex The complex tensor values.\n * @returns An object with real and imag Float32Array components of the complex\n *     tensor.\n */\nexport function splitRealAndImagArrays(complex) {\n    const real = new Float32Array(complex.length / 2);\n    const imag = new Float32Array(complex.length / 2);\n    for (let i = 0; i < complex.length; i += 2) {\n        real[i / 2] = complex[i];\n        imag[i / 2] = complex[i + 1];\n    }\n    return { real, imag };\n}\n/**\n * Extracts even indexed complex values in the given array.\n * @param complex The complex tensor values\n */\nexport function complexWithEvenIndex(complex) {\n    const len = Math.ceil(complex.length / 4);\n    const real = new Float32Array(len);\n    const imag = new Float32Array(len);\n    for (let i = 0; i < complex.length; i += 4) {\n        real[Math.floor(i / 4)] = complex[i];\n        imag[Math.floor(i / 4)] = complex[i + 1];\n    }\n    return { real, imag };\n}\n/**\n * Extracts odd indexed comple values in the given array.\n * @param complex The complex tensor values\n */\nexport function complexWithOddIndex(complex) {\n    const len = Math.floor(complex.length / 4);\n    const real = new Float32Array(len);\n    const imag = new Float32Array(len);\n    for (let i = 2; i < complex.length; i += 4) {\n        real[Math.floor(i / 4)] = complex[i];\n        imag[Math.floor(i / 4)] = complex[i + 1];\n    }\n    return { real, imag };\n}\n/**\n * Get the map representing a complex value in the given array.\n * @param complex The complex tensor values.\n * @param index An index of the target complex value.\n */\nexport function getComplexWithIndex(complex, index) {\n    const real = complex[index * 2];\n    const imag = complex[index * 2 + 1];\n    return { real, imag };\n}\n/**\n * Insert a given complex value into the TypedArray.\n * @param data The array in which the complex value is inserted.\n * @param c The complex value to be inserted.\n * @param index An index of the target complex value.\n */\nexport function assignToTypedArray(data, real, imag, index) {\n    data[index * 2] = real;\n    data[index * 2 + 1] = imag;\n}\n/**\n * Make the list of exponent terms used by FFT.\n */\nexport function exponents(n, inverse) {\n    const real = new Float32Array(n / 2);\n    const imag = new Float32Array(n / 2);\n    for (let i = 0; i < Math.ceil(n / 2); i++) {\n        const x = (inverse ? 2 : -2) * Math.PI * (i / n);\n        real[i] = Math.cos(x);\n        imag[i] = Math.sin(x);\n    }\n    return { real, imag };\n}\n/**\n * Make the exponent term used by FFT.\n */\nexport function exponent(k, n, inverse) {\n    const x = (inverse ? 2 : -2) * Math.PI * (k / n);\n    const real = Math.cos(x);\n    const imag = Math.sin(x);\n    return { real, imag };\n}\n//# sourceMappingURL=complex_util.js.map","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { assert } from '../util_base';\nconst ARROW = '->';\nconst ARROW_REGEX = /->/g;\nconst COMMA = ',';\nconst ELLIPSIS = '...';\n/**\n * Parse an equation for einsum.\n *\n * @param equation The einsum equation (e.g., \"ij,jk->ik\").\n * @param numTensors Number of tensors provided along with `equation`. Used to\n *   check matching number of input tensors.\n * @returns An object consisting of the following fields:\n *   - allDims: all dimension names as strings.\n *   - summedDims: a list of all dimensions being summed over, as indices to\n *     the elements of `allDims`.\n *   - idDims: indices of the dimensions in each input tensor, as indices to\n *     the elements of `allDims.\n */\nexport function decodeEinsumEquation(equation, numTensors) {\n    equation = equation.replace(/\\s/g, ''); // Remove witespace in equation.\n    const numArrows = (equation.length - equation.replace(ARROW_REGEX, '').length) /\n        ARROW.length;\n    if (numArrows < 1) {\n        throw new Error('Equations without an arrow are not supported.');\n    }\n    else if (numArrows > 1) {\n        throw new Error(`Equation must contain exactly one arrow (\"${ARROW}\").`);\n    }\n    const [inputString, outputString] = equation.split(ARROW);\n    assert(inputString.indexOf(ELLIPSIS) === -1, () => `The ellipsis notation (\"${ELLIPSIS}\") is not supported yet.`);\n    const inputTerms = inputString.split(COMMA);\n    const numInputs = inputTerms.length;\n    if (numTensors !== numInputs) {\n        throw new Error(`Expected ${numInputs} input tensors, received ${numTensors}`);\n    }\n    if (numInputs > 2) {\n        throw new Error('Support for more than 2 input tensors is not implemented yet.');\n    }\n    const allDims = [];\n    for (let i = 0; i < outputString.length; ++i) {\n        const dimName = outputString[i];\n        if (!inputTerms.some(inputTerm => inputTerm.indexOf(dimName) !== -1)) {\n            throw new Error(`Output subscripts contain the label ${dimName} ` +\n                `not present in the input subscripts.`);\n        }\n        if (allDims.indexOf(dimName) === -1) {\n            allDims.push(dimName);\n        }\n    }\n    for (let i = 0; i < inputString.length; ++i) {\n        const dimName = inputString[i];\n        if (allDims.indexOf(dimName) === -1 && dimName !== COMMA) {\n            allDims.push(dimName);\n        }\n    }\n    const idDims = new Array(inputTerms.length);\n    for (let i = 0; i < numInputs; ++i) {\n        if (new Set(inputTerms[i].split('')).size !== inputTerms[i].length) {\n            throw new Error(`Found duplicate axes in input component ${inputTerms[i]}. ` +\n                `Support for duplicate axes in input is not implemented yet.`);\n        }\n        idDims[i] = [];\n        for (let j = 0; j < inputTerms[i].length; ++j) {\n            idDims[i].push(allDims.indexOf(inputTerms[i][j]));\n        }\n    }\n    const numDims = allDims.length; // Number of unique dimensions.\n    const numOutDims = outputString.length; // Number of output dimensions.\n    const summedDims = []; // Dimensions being summed over.\n    for (let i = numOutDims; i < numDims; ++i) {\n        summedDims.push(i);\n    }\n    return { allDims, summedDims, idDims };\n}\n/**\n * Get the permutation for a given input tensor.\n *\n * @param nDims Total number of dimension of all tensors involved in the einsum\n *   operation.\n * @param idDims Dimension indices involve in the tensor in question.\n * @returns An object consisting of the following fields:\n *   - permutationIndices: Indices to permute the axes of the tensor with.\n *   - expandDims: Indices to the dimension that need to be expanded from the\n *     tensor after permutation.\n */\nexport function getEinsumPermutation(nDims, idDims) {\n    let permutationIndices = new Array(nDims);\n    permutationIndices.fill(-1);\n    for (let i = 0; i < idDims.length; ++i) {\n        permutationIndices[idDims[i]] = i;\n    }\n    const expandDims = [];\n    for (let i = 0; i < nDims; ++i) {\n        if (permutationIndices[i] === -1) {\n            expandDims.push(i);\n        }\n    }\n    permutationIndices = permutationIndices.filter(d => d !== -1);\n    return { permutationIndices, expandDims };\n}\n/**\n * Checks that the dimension sizes from different input tensors match the\n * equation.\n */\nexport function checkEinsumDimSizes(nDims, idDims, tensors) {\n    const dimSizes = new Array(nDims);\n    for (let i = 0; i < tensors.length; ++i) {\n        const shape = tensors[i].shape;\n        for (let j = 0; j < idDims[i].length; ++j) {\n            if (dimSizes[idDims[i][j]] === undefined) {\n                dimSizes[idDims[i][j]] = shape[j];\n            }\n            else {\n                assert(dimSizes[idDims[i][j]] === shape[j], () => `Expected dimension ${dimSizes[idDims[i][j]]} at axis ${j} ` +\n                    `of input shaped ${JSON.stringify(shape)}, ` +\n                    `but got dimension ${shape[j]}`);\n            }\n        }\n    }\n}\n/**\n * Gets path of computation for einsum.\n *\n * @param summedDims indices to the dimensions being summed over.\n * @param idDims A look up table for the dimensions present in each input\n *     tensor. Each consituent array contains indices for the dimensions in the\n *     corresponding input tensor.\n *\n * @return A map with two fields:\n *   - path: The path of computation, with each element indicating the dimension\n *     being summed over after the element-wise multiplication in that step.\n *   - steps: With the same length as `path`. Each element contains the indices\n *     to the input tensors being used for element-wise multiplication in the\n *     corresponding step.\n */\nexport function getEinsumComputePath(summedDims, idDims) {\n    const path = summedDims;\n    const steps = [];\n    let nSteps = 0;\n    if (summedDims.length === 0) {\n        // Einsum that involes no summing: e.g., transpose and outer product.\n        path.push(-1);\n    }\n    nSteps = summedDims.length + 1;\n    for (let i = 0; i < nSteps; ++i) {\n        steps.push([]);\n    }\n    const computedTermIndices = [];\n    for (let i = 0; i < path.length; ++i) {\n        const summedDim = path[i];\n        const termIndices = findTermsWithDim(idDims, summedDim);\n        for (const termIndex of termIndices) {\n            if (computedTermIndices.indexOf(termIndex) === -1) {\n                steps[i].push(termIndex);\n                computedTermIndices.push(termIndex);\n            }\n        }\n    }\n    return { path, steps };\n}\n/** Determines if an axes permutation is the identity permutation. */\nexport function isIdentityPermutation(perm) {\n    return perm.every((dim, index) => dim === index);\n}\nfunction findTermsWithDim(idDims, dim) {\n    const termIndices = [];\n    for (let i = 0; i < idDims.length; ++i) {\n        if (idDims[i].length === 0 || idDims[i].indexOf(dim) !== -1 || dim === -1) {\n            termIndices.push(i);\n        }\n    }\n    return termIndices;\n}\n//# sourceMappingURL=einsum_util.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { decodeString, encodeString } from '../util';\n// Utilities needed by backend consumers of tf-core.\nexport * from '../ops/axis_util';\nexport * from '../ops/broadcast_util';\nexport * from '../ops/concat_util';\nexport * from '../ops/conv_util';\nexport * from '../ops/fused_util';\nexport * from '../ops/reduce_util';\nimport * as slice_util from '../ops/slice_util';\nexport { slice_util };\nexport { upcastType } from '../types';\nexport * from '../ops/rotate_util';\nexport * from '../ops/array_ops_util';\nexport * from '../ops/gather_nd_util';\nexport * from '../ops/scatter_nd_util';\nexport * from '../ops/selu_util';\nexport * from '../ops/fused_util';\nexport * from '../ops/erf_util';\nexport * from '../log';\nexport * from '../backends/complex_util';\nexport * from '../backends/einsum_util';\nexport * from '../ops/split_util';\nimport * as segment_util from '../ops/segment_util';\nexport { segment_util };\nexport function fromUint8ToStringArray(vals) {\n    try {\n        // Decode the bytes into string.\n        return vals.map(val => decodeString(val));\n    }\n    catch (err) {\n        throw new Error(`Failed to decode encoded string bytes into utf-8, error: ${err}`);\n    }\n}\nexport function fromStringArrayToUint8(strings) {\n    return strings.map(s => encodeString(s));\n}\n//# sourceMappingURL=backend_util.js.map","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n/**\n * Inserts a value into a sorted array. This method allows duplicate, meaning it\n * allows inserting duplicate value, in which case, the element will be inserted\n * at the lowest index of the value.\n * @param arr The array to modify.\n * @param element The element to insert.\n * @param comparator Optional. If no comparator is specified, elements are\n * compared using array_util.defaultComparator, which is suitable for Strings\n * and Numbers in ascending arrays. If the array contains multiple instances of\n * the target value, the left-most instance will be returned. To provide a\n * comparator, it should take 2 arguments to compare and return a negative,\n * zero, or a positive number.\n */\nexport function binaryInsert(arr, element, comparator) {\n    const index = binarySearch(arr, element, comparator);\n    const insertionPoint = index < 0 ? -(index + 1) : index;\n    arr.splice(insertionPoint, 0, element);\n}\n/**\n * Searches the array for the target using binary search, returns the index\n * of the found element, or position to insert if element not found. If no\n * comparator is specified, elements are compared using array_\n * util.defaultComparator, which is suitable for Strings and Numbers in\n * ascending arrays. If the array contains multiple instances of the target\n * value, the left-most instance will be returned.\n * @param arr The array to be searched in.\n * @param target The target to be searched for.\n * @param comparator Should take 2 arguments to compare and return a negative,\n *    zero, or a positive number.\n * @return Lowest index of the target value if found, otherwise the insertion\n *    point where the target should be inserted, in the form of\n *    (-insertionPoint - 1).\n */\nexport function binarySearch(arr, target, comparator) {\n    return binarySearch_(arr, target, comparator || defaultComparator);\n}\n/**\n * Compares its two arguments for order.\n * @param a The first element to be compared.\n * @param b The second element to be compared.\n * @return A negative number, zero, or a positive number as the first\n *     argument is less than, equal to, or greater than the second.\n */\nfunction defaultComparator(a, b) {\n    return a > b ? 1 : a < b ? -1 : 0;\n}\nfunction binarySearch_(arr, target, comparator) {\n    let left = 0;\n    let right = arr.length;\n    let middle = 0;\n    let found = false;\n    while (left < right) {\n        middle = left + ((right - left) >>> 1);\n        const compareResult = comparator(target, arr[middle]);\n        if (compareResult > 0) {\n            left = middle + 1;\n        }\n        else {\n            right = middle;\n            // If compareResult is 0, the value is found. We record it is found,\n            // and then keep looking because there may be duplicate.\n            found = !compareResult;\n        }\n    }\n    return found ? left : -left - 1;\n}\n//# sourceMappingURL=non_max_suppression_util.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { binaryInsert } from './non_max_suppression_util';\nexport function nonMaxSuppressionV3Impl(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold) {\n    return nonMaxSuppressionImpl_(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, 0 /* softNmsSigma */);\n}\nexport function nonMaxSuppressionV4Impl(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, padToMaxOutputSize) {\n    return nonMaxSuppressionImpl_(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, 0 /* softNmsSigma */, false /* returnScoresTensor */, padToMaxOutputSize /* padToMaxOutputSize */, true\n    /* returnValidOutputs */ );\n}\nexport function nonMaxSuppressionV5Impl(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma) {\n    return nonMaxSuppressionImpl_(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma, true /* returnScoresTensor */);\n}\nfunction nonMaxSuppressionImpl_(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma, returnScoresTensor = false, padToMaxOutputSize = false, returnValidOutputs = false) {\n    // The list is sorted in ascending order, so that we can always pop the\n    // candidate with the largest score in O(1) time.\n    const candidates = [];\n    for (let i = 0; i < scores.length; i++) {\n        if (scores[i] > scoreThreshold) {\n            candidates.push({ score: scores[i], boxIndex: i, suppressBeginIndex: 0 });\n        }\n    }\n    candidates.sort(ascendingComparator);\n    // If softNmsSigma is 0, the outcome of this algorithm is exactly same as\n    // before.\n    const scale = softNmsSigma > 0 ? (-0.5 / softNmsSigma) : 0.0;\n    const selectedIndices = [];\n    const selectedScores = [];\n    while (selectedIndices.length < maxOutputSize && candidates.length > 0) {\n        const candidate = candidates.pop();\n        const { score: originalScore, boxIndex, suppressBeginIndex } = candidate;\n        if (originalScore < scoreThreshold) {\n            break;\n        }\n        // Overlapping boxes are likely to have similar scores, therefore we\n        // iterate through the previously selected boxes backwards in order to\n        // see if candidate's score should be suppressed. We use\n        // suppressBeginIndex to track and ensure a candidate can be suppressed\n        // by a selected box no more than once. Also, if the overlap exceeds\n        // iouThreshold, we simply ignore the candidate.\n        let ignoreCandidate = false;\n        for (let j = selectedIndices.length - 1; j >= suppressBeginIndex; --j) {\n            const iou = intersectionOverUnion(boxes, boxIndex, selectedIndices[j]);\n            if (iou >= iouThreshold) {\n                ignoreCandidate = true;\n                break;\n            }\n            candidate.score =\n                candidate.score * suppressWeight(iouThreshold, scale, iou);\n            if (candidate.score <= scoreThreshold) {\n                break;\n            }\n        }\n        // At this point, if `candidate.score` has not dropped below\n        // `scoreThreshold`, then we know that we went through all of the\n        // previous selections and can safely update `suppressBeginIndex` to the\n        // end of the selected array. Then we can re-insert the candidate with\n        // the updated score and suppressBeginIndex back in the candidate list.\n        // If on the other hand, `candidate.score` has dropped below the score\n        // threshold, we will not add it back to the candidates list.\n        candidate.suppressBeginIndex = selectedIndices.length;\n        if (!ignoreCandidate) {\n            // Candidate has passed all the tests, and is not suppressed, so\n            // select the candidate.\n            if (candidate.score === originalScore) {\n                selectedIndices.push(boxIndex);\n                selectedScores.push(candidate.score);\n            }\n            else if (candidate.score > scoreThreshold) {\n                // Candidate's score is suppressed but is still high enough to be\n                // considered, so add back to the candidates list.\n                binaryInsert(candidates, candidate, ascendingComparator);\n            }\n        }\n    }\n    // NonMaxSuppressionV4 feature: padding output to maxOutputSize.\n    const validOutputs = selectedIndices.length;\n    const elemsToPad = maxOutputSize - validOutputs;\n    if (padToMaxOutputSize && elemsToPad > 0) {\n        selectedIndices.push(...new Array(elemsToPad).fill(0));\n        selectedScores.push(...new Array(elemsToPad).fill(0.0));\n    }\n    const result = { selectedIndices };\n    if (returnScoresTensor) {\n        result['selectedScores'] = selectedScores;\n    }\n    if (returnValidOutputs) {\n        result['validOutputs'] = validOutputs;\n    }\n    return result;\n}\nfunction intersectionOverUnion(boxes, i, j) {\n    const iCoord = boxes.subarray(i * 4, i * 4 + 4);\n    const jCoord = boxes.subarray(j * 4, j * 4 + 4);\n    const yminI = Math.min(iCoord[0], iCoord[2]);\n    const xminI = Math.min(iCoord[1], iCoord[3]);\n    const ymaxI = Math.max(iCoord[0], iCoord[2]);\n    const xmaxI = Math.max(iCoord[1], iCoord[3]);\n    const yminJ = Math.min(jCoord[0], jCoord[2]);\n    const xminJ = Math.min(jCoord[1], jCoord[3]);\n    const ymaxJ = Math.max(jCoord[0], jCoord[2]);\n    const xmaxJ = Math.max(jCoord[1], jCoord[3]);\n    const areaI = (ymaxI - yminI) * (xmaxI - xminI);\n    const areaJ = (ymaxJ - yminJ) * (xmaxJ - xminJ);\n    if (areaI <= 0 || areaJ <= 0) {\n        return 0.0;\n    }\n    const intersectionYmin = Math.max(yminI, yminJ);\n    const intersectionXmin = Math.max(xminI, xminJ);\n    const intersectionYmax = Math.min(ymaxI, ymaxJ);\n    const intersectionXmax = Math.min(xmaxI, xmaxJ);\n    const intersectionArea = Math.max(intersectionYmax - intersectionYmin, 0.0) *\n        Math.max(intersectionXmax - intersectionXmin, 0.0);\n    return intersectionArea / (areaI + areaJ - intersectionArea);\n}\n// A Gaussian penalty function, this method always returns values in [0, 1].\n// The weight is a function of similarity, the more overlap two boxes are, the\n// smaller the weight is, meaning highly overlapping boxe will be significantly\n// penalized. On the other hand, a non-overlapping box will not be penalized.\nfunction suppressWeight(iouThreshold, scale, iou) {\n    const weight = Math.exp(scale * iou * iou);\n    return iou <= iouThreshold ? weight : 0.0;\n}\nfunction ascendingComparator(c1, c2) {\n    // For objects with same scores, we make the object with the larger index go\n    // first. In an array that pops from the end, this means that the object with\n    // the smaller index will be popped first. This ensures the same output as\n    // the TensorFlow python version.\n    return (c1.score - c2.score) ||\n        ((c1.score === c2.score) && (c2.boxIndex - c1.boxIndex));\n}\n//# sourceMappingURL=non_max_suppression_impl.js.map","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport './engine';\nimport * as device_util from './device_util';\nimport { env } from './environment';\nconst ENV = env();\n/**\n * This file contains environment-related flag registrations.\n */\n/** Whether to enable debug mode. */\nENV.registerFlag('DEBUG', () => false, debugValue => {\n    if (debugValue) {\n        console.warn('Debugging mode is ON. The output of every math call will ' +\n            'be downloaded to CPU and checked for NaNs. ' +\n            'This significantly impacts performance.');\n    }\n});\n/** Whether we are in a browser (as versus, say, node.js) environment. */\nENV.registerFlag('IS_BROWSER', () => device_util.isBrowser());\n/** Whether we are in a browser (as versus, say, node.js) environment. */\nENV.registerFlag('IS_NODE', () => (typeof process !== 'undefined') &&\n    (typeof process.versions !== 'undefined') &&\n    (typeof process.versions.node !== 'undefined'));\n/** Whether this browser is Chrome. */\nENV.registerFlag('IS_CHROME', () => typeof navigator !== 'undefined' && navigator != null &&\n    navigator.userAgent != null && /Chrome/.test(navigator.userAgent) &&\n    /Google Inc/.test(navigator.vendor));\n/**\n * True when the environment is \"production\" where we disable safety checks\n * to gain performance.\n */\nENV.registerFlag('PROD', () => false);\n/**\n * Whether to do sanity checks when inferring a shape from user-provided\n * values, used when creating a new tensor.\n */\nENV.registerFlag('TENSORLIKE_CHECK_SHAPE_CONSISTENCY', () => ENV.getBool('DEBUG'));\n/** Whether deprecation warnings are enabled. */\nENV.registerFlag('DEPRECATION_WARNINGS_ENABLED', () => true);\n/** True if running unit tests. */\nENV.registerFlag('IS_TEST', () => false);\n/** Whether to check computation result for errors. */\nENV.registerFlag('CHECK_COMPUTATION_FOR_ERRORS', () => true);\n/** Whether the backend needs to wrap input to imageBitmap. */\nENV.registerFlag('WRAP_TO_IMAGEBITMAP', () => false);\n//# sourceMappingURL=flags.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nexport const EPSILON_FLOAT32 = 1e-7;\nexport const EPSILON_FLOAT16 = 1e-4;\n/** Convenient class for storing tensor-related data. */\nexport class DataStorage {\n    constructor(backend, dataMover) {\n        this.backend = backend;\n        this.dataMover = dataMover;\n        this.data = new WeakMap();\n        this.dataIdsCount = 0;\n    }\n    get(dataId) {\n        if (!this.data.has(dataId)) {\n            this.dataMover.moveData(this.backend, dataId);\n        }\n        return this.data.get(dataId);\n    }\n    set(dataId, value) {\n        this.dataIdsCount++;\n        this.data.set(dataId, value);\n    }\n    has(dataId) {\n        return this.data.has(dataId);\n    }\n    delete(dataId) {\n        this.dataIdsCount--;\n        return this.data.delete(dataId);\n    }\n    numDataIds() {\n        return this.dataIdsCount;\n    }\n}\n/**\n * The interface that defines the kernels that should be implemented when\n * adding a new backend. New backends don't need to implement every one of the\n * methods, this can be done gradually (throw an error for unimplemented\n * methods).\n */\nexport class KernelBackend {\n    refCount(dataId) {\n        return notYetImplemented('refCount');\n    }\n    incRef(dataId) {\n        return notYetImplemented('incRef');\n    }\n    timerAvailable() {\n        return true;\n    }\n    time(f) {\n        return notYetImplemented('time');\n    }\n    read(dataId) {\n        return notYetImplemented('read');\n    }\n    readSync(dataId) {\n        return notYetImplemented('readSync');\n    }\n    numDataIds() {\n        return notYetImplemented('numDataIds');\n    }\n    disposeData(dataId, force) {\n        return notYetImplemented('disposeData');\n    }\n    write(values, shape, dtype) {\n        return notYetImplemented('write');\n    }\n    move(dataId, values, shape, dtype, refCount) {\n        return notYetImplemented('move');\n    }\n    memory() {\n        return notYetImplemented('memory');\n    }\n    /** Returns the highest precision for floats in bits (e.g. 16 or 32) */\n    floatPrecision() {\n        return notYetImplemented('floatPrecision');\n    }\n    /** Returns the smallest representable number.  */\n    epsilon() {\n        return this.floatPrecision() === 32 ? EPSILON_FLOAT32 : EPSILON_FLOAT16;\n    }\n    dispose() {\n        return notYetImplemented('dispose');\n    }\n}\nfunction notYetImplemented(kernelName) {\n    throw new Error(`'${kernelName}' not yet implemented or not found in the registry. ` +\n        `This kernel may not be supported by the tfjs backend you have chosen`);\n}\n//# sourceMappingURL=backend.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n/* Type definitions for exporting and importing of models. */\n/**\n * A map from Tensor dtype to number of bytes per element of the Tensor.\n */\nexport const DTYPE_VALUE_SIZE_MAP = {\n    'float32': 4,\n    'float16': 2,\n    'int32': 4,\n    'uint16': 2,\n    'uint8': 1,\n    'bool': 1,\n    'complex64': 8\n};\n//# sourceMappingURL=types.js.map","/**\n * @license\n * Copyright 2017 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n// tslint:disable-next-line:no-any\nfunction _isNavigatorDefined() {\n    return typeof navigator !== 'undefined' && navigator != null;\n}\nexport function isMobile(nav) {\n    if (nav || _isNavigatorDefined()) {\n        if (!nav) {\n            nav = navigator;\n        }\n        if (nav.product === 'ReactNative') {\n            return true;\n        }\n        // tslint:disable-next-line:no-any\n        const a = nav.userAgent || nav.vendor || window.opera;\n        // tslint:disable-next-line:max-line-length\n        return /(android|bb\\d+|meego).+mobile|avantgo|bada\\/|blackberry|blazer|compal|elaine|fennec|hiptop|iemobile|ip(hone|od)|iris|kindle|lge |maemo|midp|mmp|mobile.+firefox|netfront|opera m(ob|in)i|palm( os)?|phone|p(ixi|re)\\/|plucker|pocket|psp|series(4|6)0|symbian|treo|up\\.(browser|link)|vodafone|wap|windows ce|xda|xiino/i\n            .test(a) ||\n            // tslint:disable-next-line:max-line-length\n            /1207|6310|6590|3gso|4thp|50[1-6]i|770s|802s|a wa|abac|ac(er|oo|s\\-)|ai(ko|rn)|al(av|ca|co)|amoi|an(ex|ny|yw)|aptu|ar(ch|go)|as(te|us)|attw|au(di|\\-m|r |s )|avan|be(ck|ll|nq)|bi(lb|rd)|bl(ac|az)|br(e|v)w|bumb|bw\\-(n|u)|c55\\/|capi|ccwa|cdm\\-|cell|chtm|cldc|cmd\\-|co(mp|nd)|craw|da(it|ll|ng)|dbte|dc\\-s|devi|dica|dmob|do(c|p)o|ds(12|\\-d)|el(49|ai)|em(l2|ul)|er(ic|k0)|esl8|ez([4-7]0|os|wa|ze)|fetc|fly(\\-|_)|g1 u|g560|gene|gf\\-5|g\\-mo|go(\\.w|od)|gr(ad|un)|haie|hcit|hd\\-(m|p|t)|hei\\-|hi(pt|ta)|hp( i|ip)|hs\\-c|ht(c(\\-| |_|a|g|p|s|t)|tp)|hu(aw|tc)|i\\-(20|go|ma)|i230|iac( |\\-|\\/)|ibro|idea|ig01|ikom|im1k|inno|ipaq|iris|ja(t|v)a|jbro|jemu|jigs|kddi|keji|kgt( |\\/)|klon|kpt |kwc\\-|kyo(c|k)|le(no|xi)|lg( g|\\/(k|l|u)|50|54|\\-[a-w])|libw|lynx|m1\\-w|m3ga|m50\\/|ma(te|ui|xo)|mc(01|21|ca)|m\\-cr|me(rc|ri)|mi(o8|oa|ts)|mmef|mo(01|02|bi|de|do|t(\\-| |o|v)|zz)|mt(50|p1|v )|mwbp|mywa|n10[0-2]|n20[2-3]|n30(0|2)|n50(0|2|5)|n7(0(0|1)|10)|ne((c|m)\\-|on|tf|wf|wg|wt)|nok(6|i)|nzph|o2im|op(ti|wv)|oran|owg1|p800|pan(a|d|t)|pdxg|pg(13|\\-([1-8]|c))|phil|pire|pl(ay|uc)|pn\\-2|po(ck|rt|se)|prox|psio|pt\\-g|qa\\-a|qc(07|12|21|32|60|\\-[2-7]|i\\-)|qtek|r380|r600|raks|rim9|ro(ve|zo)|s55\\/|sa(ge|ma|mm|ms|ny|va)|sc(01|h\\-|oo|p\\-)|sdk\\/|se(c(\\-|0|1)|47|mc|nd|ri)|sgh\\-|shar|sie(\\-|m)|sk\\-0|sl(45|id)|sm(al|ar|b3|it|t5)|so(ft|ny)|sp(01|h\\-|v\\-|v )|sy(01|mb)|t2(18|50)|t6(00|10|18)|ta(gt|lk)|tcl\\-|tdg\\-|tel(i|m)|tim\\-|t\\-mo|to(pl|sh)|ts(70|m\\-|m3|m5)|tx\\-9|up(\\.b|g1|si)|utst|v400|v750|veri|vi(rg|te)|vk(40|5[0-3]|\\-v)|vm40|voda|vulc|vx(52|53|60|61|70|80|81|83|85|98)|w3c(\\-| )|webc|whit|wi(g |nc|nw)|wmlb|wonu|x700|yas\\-|your|zeto|zte\\-/i\n                .test(a.substr(0, 4));\n    }\n    return false;\n}\nexport function isBrowser() {\n    return (typeof window !== 'undefined' && window.document != null) ||\n        //@ts-ignore\n        (typeof WorkerGlobalScope !== 'undefined');\n}\n//# sourceMappingURL=device_util.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from './engine';\nimport { env } from './environment';\nimport { setDeprecationWarningFn } from './tensor';\nimport { getTensorsInContainer } from './tensor_util';\n/**\n * Enables production mode which disables correctness checks in favor of\n * performance.\n *\n * @doc {heading: 'Environment'}\n */\nexport function enableProdMode() {\n    env().set('PROD', true);\n}\n/**\n * Enables debug mode which will log information about all executed kernels:\n * the elapsed time of the kernel execution, as well as the rank, shape, and\n * size of the output tensor.\n *\n * Debug mode will significantly slow down your application as it will\n * download the result of every operation to the CPU. This should not be used in\n * production. Debug mode does not affect the timing information of the kernel\n * execution as we do not measure download time in the kernel execution time.\n *\n * See also: `tf.profile`, `tf.memory`.\n *\n * @doc {heading: 'Environment'}\n */\nexport function enableDebugMode() {\n    env().set('DEBUG', true);\n}\n/** Globally disables deprecation warnings */\nexport function disableDeprecationWarnings() {\n    env().set('DEPRECATION_WARNINGS_ENABLED', false);\n    console.warn(`TensorFlow.js deprecation warnings have been disabled.`);\n}\n/** Warn users about deprecated functionality. */\nexport function deprecationWarn(msg) {\n    if (env().getBool('DEPRECATION_WARNINGS_ENABLED')) {\n        console.warn(msg + ' You can disable deprecation warnings with ' +\n            'tf.disableDeprecationWarnings().');\n    }\n}\nsetDeprecationWarningFn(deprecationWarn);\n/**\n * Dispose all variables kept in backend engine.\n *\n * @doc {heading: 'Environment'}\n */\nexport function disposeVariables() {\n    ENGINE.disposeVariables();\n}\n/**\n * It returns the global engine that keeps track of all tensors and backends.\n *\n * @doc {heading: 'Environment'}\n */\nexport function engine() {\n    return ENGINE;\n}\n/**\n * Returns memory info at the current time in the program. The result is an\n * object with the following properties:\n *\n * - `numBytes`: Number of bytes allocated (undisposed) at this time.\n * - `numTensors`: Number of unique tensors allocated.\n * - `numDataBuffers`: Number of unique data buffers allocated\n *   (undisposed) at this time, which is  the number of tensors\n *   (e.g. `a.reshape(newShape)` makes a new Tensor that shares the same\n *   data buffer with `a`).\n * - `unreliable`: True if the memory usage is unreliable. See `reasons` when\n *    `unreliable` is true.\n * - `reasons`: `string[]`, reasons why the memory is unreliable, present if\n *    `unreliable` is true.\n *\n * WebGL Properties:\n * - `numBytesInGPU`: Number of bytes allocated (undisposed) in the GPU only at\n *     this time.\n *\n * @doc {heading: 'Performance', subheading: 'Memory'}\n */\nexport function memory() {\n    return ENGINE.memory();\n}\n/**\n * Executes the provided function `f()` and returns a promise that resolves\n * with information about the function's memory use:\n * - `newBytes`: the number of new bytes allocated\n * - `newTensors`: the number of new tensors created\n * - `peakBytes`: the peak number of bytes allocated\n * - `kernels`: an array of objects for each kernel involved that reports\n * their input and output shapes, number of bytes used, and number of new\n * tensors created.\n * - `kernelNames`: an array of unique strings with just the names of the\n * kernels in the `kernels` array.\n *\n * ```js\n * const profile = await tf.profile(() => {\n *   const x = tf.tensor1d([1, 2, 3]);\n *   let x2 = x.square();\n *   x2.dispose();\n *   x2 = x.square();\n *   x2.dispose();\n *   return x;\n * });\n *\n * console.log(`newBytes: ${profile.newBytes}`);\n * console.log(`newTensors: ${profile.newTensors}`);\n * console.log(`byte usage over all kernels: ${profile.kernels.map(k =>\n * k.totalBytesSnapshot)}`);\n * ```\n *\n *\n * @doc {heading: 'Performance', subheading: 'Profile'}\n */\nexport function profile(f) {\n    return ENGINE.profile(f);\n}\n/**\n * Executes the provided function `fn` and after it is executed, cleans up all\n * intermediate tensors allocated by `fn` except those returned by `fn`.\n * `fn` must not return a Promise (async functions not allowed). The returned\n * result can be a complex object.\n *\n * Using this method helps avoid memory leaks. In general, wrap calls to\n * operations in `tf.tidy` for automatic memory cleanup.\n *\n * NOTE: Variables do *not* get cleaned up when inside a tidy(). If you want to\n * dispose variables, please use `tf.disposeVariables` or call dispose()\n * directly on variables.\n *\n * ```js\n * // y = 2 ^ 2 + 1\n * const y = tf.tidy(() => {\n *   // a, b, and one will be cleaned up when the tidy ends.\n *   const one = tf.scalar(1);\n *   const a = tf.scalar(2);\n *   const b = a.square();\n *\n *   console.log('numTensors (in tidy): ' + tf.memory().numTensors);\n *\n *   // The value returned inside the tidy function will return\n *   // through the tidy, in this case to the variable y.\n *   return b.add(one);\n * });\n *\n * console.log('numTensors (outside tidy): ' + tf.memory().numTensors);\n * y.print();\n * ```\n *\n * @param nameOrFn The name of the closure, or the function to execute.\n *     If a name is provided, the 2nd argument should be the function.\n *     If debug mode is on, the timing and the memory usage of the function\n *     will be tracked and displayed on the console using the provided name.\n * @param fn The function to execute.\n *\n * @doc {heading: 'Performance', subheading: 'Memory'}\n */\nexport function tidy(nameOrFn, fn) {\n    return ENGINE.tidy(nameOrFn, fn);\n}\n/**\n * Disposes any `tf.Tensor`s found within the provided object.\n *\n * @param container an object that may be a `tf.Tensor` or may directly\n *     contain `tf.Tensor`s, such as a `Tensor[]` or `{key: Tensor, ...}`. If\n *     the object is not a `tf.Tensor` or does not contain `Tensors`, nothing\n *     happens. In general it is safe to pass any object here, except that\n *     `Promise`s are not supported.\n *\n * @doc {heading: 'Performance', subheading: 'Memory'}\n */\nexport function dispose(container) {\n    const tensors = getTensorsInContainer(container);\n    tensors.forEach(tensor => tensor.dispose());\n}\n/**\n * Keeps a `tf.Tensor` generated inside a `tf.tidy` from being disposed\n * automatically.\n *\n * ```js\n * let b;\n * const y = tf.tidy(() => {\n *   const one = tf.scalar(1);\n *   const a = tf.scalar(2);\n *\n *   // b will not be cleaned up by the tidy. a and one will be cleaned up\n *   // when the tidy ends.\n *   b = tf.keep(a.square());\n *\n *   console.log('numTensors (in tidy): ' + tf.memory().numTensors);\n *\n *   // The value returned inside the tidy function will return\n *   // through the tidy, in this case to the variable y.\n *   return b.add(one);\n * });\n *\n * console.log('numTensors (outside tidy): ' + tf.memory().numTensors);\n * console.log('y:');\n * y.print();\n * console.log('b:');\n * b.print();\n * ```\n *\n * @param result The tensor to keep from being disposed.\n *\n * @doc {heading: 'Performance', subheading: 'Memory'}\n */\nexport function keep(result) {\n    return ENGINE.keep(result);\n}\n/**\n * Executes `f()` and returns a promise that resolves with timing\n * information.\n *\n * The result is an object with the following properties:\n *\n * - `wallMs`: Wall execution time.\n * - `kernelMs`: Kernel execution time, ignoring data transfer. If using the\n * WebGL backend and the query timer extension is not available, this will\n * return an error object.\n * - On `WebGL` The following additional properties exist:\n *   - `uploadWaitMs`: CPU blocking time on texture uploads.\n *   - `downloadWaitMs`: CPU blocking time on texture downloads (readPixels).\n *\n * ```js\n * const x = tf.randomNormal([20, 20]);\n * const time = await tf.time(() => x.matMul(x));\n *\n * console.log(`kernelMs: ${time.kernelMs}, wallTimeMs: ${time.wallMs}`);\n * ```\n *\n * @param f The function to execute and time.\n *\n * @doc {heading: 'Performance', subheading: 'Timing'}\n */\nexport function time(f) {\n    return ENGINE.time(f);\n}\n/**\n * Sets the backend (cpu, webgl, wasm, etc) responsible for creating tensors and\n * executing operations on those tensors. Returns a promise that resolves\n * to a boolean if the backend initialization was successful.\n *\n * Note this disposes the current backend, if any, as well as any tensors\n * associated with it. A new backend is initialized, even if it is of the\n * same type as the previous one.\n *\n * @param backendName The name of the backend. Currently supports\n *     `'webgl'|'cpu'` in the browser, `'tensorflow'` under node.js\n *     (requires tfjs-node), and `'wasm'` (requires tfjs-backend-wasm).\n *\n * @doc {heading: 'Backends'}\n */\nexport function setBackend(backendName) {\n    return ENGINE.setBackend(backendName);\n}\n/**\n * Returns a promise that resolves when the currently selected backend (or the\n * highest priority one) has initialized. Await this promise when you are using\n * a backend that has async initialization.\n *\n * @doc {heading: 'Backends'}\n */\nexport function ready() {\n    return ENGINE.ready();\n}\n/**\n * Returns the current backend name (cpu, webgl, etc). The backend is\n * responsible for creating tensors and executing operations on those tensors.\n *\n * @doc {heading: 'Backends'}\n */\nexport function getBackend() {\n    return ENGINE.backendName;\n}\n/**\n * Removes a backend and the registered factory.\n *\n * @doc {heading: 'Backends'}\n */\nexport function removeBackend(name) {\n    ENGINE.removeBackend(name);\n}\n/**\n * Finds the backend registered under the provided name. Returns null if the\n * name is not in the registry, or the registration hasn't finished yet.\n */\nexport function findBackend(name) {\n    return ENGINE.findBackend(name);\n}\n/**\n * Finds the backend factory registered under the provided name. Returns a\n * function that produces a new backend when called. Returns null if the name\n * is not in the registry.\n */\nexport function findBackendFactory(name) {\n    return ENGINE.findBackendFactory(name);\n}\n/**\n * Registers a global backend. The registration should happen when importing\n * a module file (e.g. when importing `backend_webgl.ts`), and is used for\n * modular builds (e.g. custom tfjs bundle with only webgl support).\n *\n * @param factory The backend factory function. When called, it should\n * return a backend instance, or a promise of an instance.\n * @param priority The priority of the backend (higher = more important).\n *     In case multiple backends are registered, the priority is used to find\n *     the best backend. Defaults to 1.\n * @return False if there is already a registered backend under this name, true\n *     if not.\n *\n * @doc {heading: 'Backends'}\n */\nexport function registerBackend(name, factory, priority = 1) {\n    return ENGINE.registerBackend(name, factory, priority);\n}\n/**\n * Gets the current backend. If no backends have been initialized, this will\n * attempt to initialize the best backend. Will throw an error if the highest\n * priority backend has async initialization, in which case, you should call\n * 'await tf.ready()' before running other code.\n *\n * @doc {heading: 'Backends'}\n */\nexport function backend() {\n    return ENGINE.backend;\n}\n/**\n * Sets the global platform.\n *\n * @param platformName The name of this platform.\n * @param platform A platform implementation.\n */\nexport function setPlatform(platformName, platform) {\n    env().setPlatform(platformName, platform);\n}\n//# sourceMappingURL=globals.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport '../flags';\nimport { env } from '../environment';\nimport { getModelArtifactsInfoForJSON } from './io_utils';\nimport { IORouterRegistry } from './router_registry';\nconst DATABASE_NAME = 'tensorflowjs';\nconst DATABASE_VERSION = 1;\n// Model data and ModelArtifactsInfo (metadata) are stored in two separate\n// stores for efficient access of the list of stored models and their metadata.\n// 1. The object store for model data: topology, weights and weight manifests.\nconst MODEL_STORE_NAME = 'models_store';\n// 2. The object store for ModelArtifactsInfo, including meta-information such\n//    as the type of topology (JSON vs binary), byte size of the topology, byte\n//    size of the weights, etc.\nconst INFO_STORE_NAME = 'model_info_store';\n/**\n * Delete the entire database for tensorflow.js, including the models store.\n */\nexport async function deleteDatabase() {\n    const idbFactory = getIndexedDBFactory();\n    return new Promise((resolve, reject) => {\n        const deleteRequest = idbFactory.deleteDatabase(DATABASE_NAME);\n        deleteRequest.onsuccess = () => resolve();\n        deleteRequest.onerror = error => reject(error);\n    });\n}\nfunction getIndexedDBFactory() {\n    if (!env().getBool('IS_BROWSER')) {\n        // TODO(cais): Add more info about what IOHandler subtypes are available.\n        //   Maybe point to a doc page on the web and/or automatically determine\n        //   the available IOHandlers and print them in the error message.\n        throw new Error('Failed to obtain IndexedDB factory because the current environment' +\n            'is not a web browser.');\n    }\n    // tslint:disable-next-line:no-any\n    const theWindow = typeof window === 'undefined' ? self : window;\n    const factory = theWindow.indexedDB || theWindow.mozIndexedDB ||\n        theWindow.webkitIndexedDB || theWindow.msIndexedDB ||\n        theWindow.shimIndexedDB;\n    if (factory == null) {\n        throw new Error('The current browser does not appear to support IndexedDB.');\n    }\n    return factory;\n}\nfunction setUpDatabase(openRequest) {\n    const db = openRequest.result;\n    db.createObjectStore(MODEL_STORE_NAME, { keyPath: 'modelPath' });\n    db.createObjectStore(INFO_STORE_NAME, { keyPath: 'modelPath' });\n}\n/**\n * IOHandler subclass: Browser IndexedDB.\n *\n * See the doc string of `browserIndexedDB` for more details.\n */\nexport class BrowserIndexedDB {\n    constructor(modelPath) {\n        this.indexedDB = getIndexedDBFactory();\n        if (modelPath == null || !modelPath) {\n            throw new Error('For IndexedDB, modelPath must not be null, undefined or empty.');\n        }\n        this.modelPath = modelPath;\n    }\n    async save(modelArtifacts) {\n        // TODO(cais): Support saving GraphDef models.\n        if (modelArtifacts.modelTopology instanceof ArrayBuffer) {\n            throw new Error('BrowserLocalStorage.save() does not support saving model topology ' +\n                'in binary formats yet.');\n        }\n        return this.databaseAction(this.modelPath, modelArtifacts);\n    }\n    async load() {\n        return this.databaseAction(this.modelPath);\n    }\n    /**\n     * Perform database action to put model artifacts into or read model artifacts\n     * from IndexedDB object store.\n     *\n     * Whether the action is put or get depends on whether `modelArtifacts` is\n     * specified. If it is specified, the action will be put; otherwise the action\n     * will be get.\n     *\n     * @param modelPath A unique string path for the model.\n     * @param modelArtifacts If specified, it will be the model artifacts to be\n     *   stored in IndexedDB.\n     * @returns A `Promise` of `SaveResult`, if the action is put, or a `Promise`\n     *   of `ModelArtifacts`, if the action is get.\n     */\n    databaseAction(modelPath, modelArtifacts) {\n        return new Promise((resolve, reject) => {\n            const openRequest = this.indexedDB.open(DATABASE_NAME, DATABASE_VERSION);\n            openRequest.onupgradeneeded = () => setUpDatabase(openRequest);\n            openRequest.onsuccess = () => {\n                const db = openRequest.result;\n                if (modelArtifacts == null) {\n                    // Read model out from object store.\n                    const modelTx = db.transaction(MODEL_STORE_NAME, 'readonly');\n                    const modelStore = modelTx.objectStore(MODEL_STORE_NAME);\n                    const getRequest = modelStore.get(this.modelPath);\n                    getRequest.onsuccess = () => {\n                        if (getRequest.result == null) {\n                            db.close();\n                            return reject(new Error(`Cannot find model with path '${this.modelPath}' ` +\n                                `in IndexedDB.`));\n                        }\n                        else {\n                            resolve(getRequest.result.modelArtifacts);\n                        }\n                    };\n                    getRequest.onerror = error => {\n                        db.close();\n                        return reject(getRequest.error);\n                    };\n                    modelTx.oncomplete = () => db.close();\n                }\n                else {\n                    // Put model into object store.\n                    const modelArtifactsInfo = getModelArtifactsInfoForJSON(modelArtifacts);\n                    // First, put ModelArtifactsInfo into info store.\n                    const infoTx = db.transaction(INFO_STORE_NAME, 'readwrite');\n                    let infoStore = infoTx.objectStore(INFO_STORE_NAME);\n                    const putInfoRequest = infoStore.put({ modelPath: this.modelPath, modelArtifactsInfo });\n                    let modelTx;\n                    putInfoRequest.onsuccess = () => {\n                        // Second, put model data into model store.\n                        modelTx = db.transaction(MODEL_STORE_NAME, 'readwrite');\n                        const modelStore = modelTx.objectStore(MODEL_STORE_NAME);\n                        const putModelRequest = modelStore.put({\n                            modelPath: this.modelPath,\n                            modelArtifacts,\n                            modelArtifactsInfo\n                        });\n                        putModelRequest.onsuccess = () => resolve({ modelArtifactsInfo });\n                        putModelRequest.onerror = error => {\n                            // If the put-model request fails, roll back the info entry as\n                            // well.\n                            infoStore = infoTx.objectStore(INFO_STORE_NAME);\n                            const deleteInfoRequest = infoStore.delete(this.modelPath);\n                            deleteInfoRequest.onsuccess = () => {\n                                db.close();\n                                return reject(putModelRequest.error);\n                            };\n                            deleteInfoRequest.onerror = error => {\n                                db.close();\n                                return reject(putModelRequest.error);\n                            };\n                        };\n                    };\n                    putInfoRequest.onerror = error => {\n                        db.close();\n                        return reject(putInfoRequest.error);\n                    };\n                    infoTx.oncomplete = () => {\n                        if (modelTx == null) {\n                            db.close();\n                        }\n                        else {\n                            modelTx.oncomplete = () => db.close();\n                        }\n                    };\n                }\n            };\n            openRequest.onerror = error => reject(openRequest.error);\n        });\n    }\n}\nBrowserIndexedDB.URL_SCHEME = 'indexeddb://';\nexport const indexedDBRouter = (url) => {\n    if (!env().getBool('IS_BROWSER')) {\n        return null;\n    }\n    else {\n        if (!Array.isArray(url) && url.startsWith(BrowserIndexedDB.URL_SCHEME)) {\n            return browserIndexedDB(url.slice(BrowserIndexedDB.URL_SCHEME.length));\n        }\n        else {\n            return null;\n        }\n    }\n};\nIORouterRegistry.registerSaveRouter(indexedDBRouter);\nIORouterRegistry.registerLoadRouter(indexedDBRouter);\n/**\n * Creates a browser IndexedDB IOHandler for saving and loading models.\n *\n * ```js\n * const model = tf.sequential();\n * model.add(\n *     tf.layers.dense({units: 1, inputShape: [100], activation: 'sigmoid'}));\n *\n * const saveResult = await model.save('indexeddb://MyModel'));\n * console.log(saveResult);\n * ```\n *\n * @param modelPath A unique identifier for the model to be saved. Must be a\n *   non-empty string.\n * @returns An instance of `BrowserIndexedDB` (sublcass of `IOHandler`),\n *   which can be used with, e.g., `tf.Model.save`.\n */\nexport function browserIndexedDB(modelPath) {\n    return new BrowserIndexedDB(modelPath);\n}\nfunction maybeStripScheme(key) {\n    return key.startsWith(BrowserIndexedDB.URL_SCHEME) ?\n        key.slice(BrowserIndexedDB.URL_SCHEME.length) :\n        key;\n}\nexport class BrowserIndexedDBManager {\n    constructor() {\n        this.indexedDB = getIndexedDBFactory();\n    }\n    async listModels() {\n        return new Promise((resolve, reject) => {\n            const openRequest = this.indexedDB.open(DATABASE_NAME, DATABASE_VERSION);\n            openRequest.onupgradeneeded = () => setUpDatabase(openRequest);\n            openRequest.onsuccess = () => {\n                const db = openRequest.result;\n                const tx = db.transaction(INFO_STORE_NAME, 'readonly');\n                const store = tx.objectStore(INFO_STORE_NAME);\n                // tslint:disable:max-line-length\n                // Need to cast `store` as `any` here because TypeScript's DOM\n                // library does not have the `getAll()` method even though the\n                // method is supported in the latest version of most mainstream\n                // browsers:\n                // https://developer.mozilla.org/en-US/docs/Web/API/IDBObjectStore/getAll\n                // tslint:enable:max-line-length\n                // tslint:disable-next-line:no-any\n                const getAllInfoRequest = store.getAll();\n                getAllInfoRequest.onsuccess = () => {\n                    const out = {};\n                    for (const item of getAllInfoRequest.result) {\n                        out[item.modelPath] = item.modelArtifactsInfo;\n                    }\n                    resolve(out);\n                };\n                getAllInfoRequest.onerror = error => {\n                    db.close();\n                    return reject(getAllInfoRequest.error);\n                };\n                tx.oncomplete = () => db.close();\n            };\n            openRequest.onerror = error => reject(openRequest.error);\n        });\n    }\n    async removeModel(path) {\n        path = maybeStripScheme(path);\n        return new Promise((resolve, reject) => {\n            const openRequest = this.indexedDB.open(DATABASE_NAME, DATABASE_VERSION);\n            openRequest.onupgradeneeded = () => setUpDatabase(openRequest);\n            openRequest.onsuccess = () => {\n                const db = openRequest.result;\n                const infoTx = db.transaction(INFO_STORE_NAME, 'readwrite');\n                const infoStore = infoTx.objectStore(INFO_STORE_NAME);\n                const getInfoRequest = infoStore.get(path);\n                let modelTx;\n                getInfoRequest.onsuccess = () => {\n                    if (getInfoRequest.result == null) {\n                        db.close();\n                        return reject(new Error(`Cannot find model with path '${path}' ` +\n                            `in IndexedDB.`));\n                    }\n                    else {\n                        // First, delete the entry in the info store.\n                        const deleteInfoRequest = infoStore.delete(path);\n                        const deleteModelData = () => {\n                            // Second, delete the entry in the model store.\n                            modelTx = db.transaction(MODEL_STORE_NAME, 'readwrite');\n                            const modelStore = modelTx.objectStore(MODEL_STORE_NAME);\n                            const deleteModelRequest = modelStore.delete(path);\n                            deleteModelRequest.onsuccess = () => resolve(getInfoRequest.result.modelArtifactsInfo);\n                            deleteModelRequest.onerror = error => reject(getInfoRequest.error);\n                        };\n                        // Proceed with deleting model data regardless of whether deletion\n                        // of info data succeeds or not.\n                        deleteInfoRequest.onsuccess = deleteModelData;\n                        deleteInfoRequest.onerror = error => {\n                            deleteModelData();\n                            db.close();\n                            return reject(getInfoRequest.error);\n                        };\n                    }\n                };\n                getInfoRequest.onerror = error => {\n                    db.close();\n                    return reject(getInfoRequest.error);\n                };\n                infoTx.oncomplete = () => {\n                    if (modelTx == null) {\n                        db.close();\n                    }\n                    else {\n                        modelTx.oncomplete = () => db.close();\n                    }\n                };\n            };\n            openRequest.onerror = error => reject(openRequest.error);\n        });\n    }\n}\n//# sourceMappingURL=indexed_db.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport '../flags';\nimport { env } from '../environment';\nimport { assert } from '../util';\nimport { arrayBufferToBase64String, base64StringToArrayBuffer, getModelArtifactsInfoForJSON } from './io_utils';\nimport { IORouterRegistry } from './router_registry';\nconst PATH_SEPARATOR = '/';\nconst PATH_PREFIX = 'tensorflowjs_models';\nconst INFO_SUFFIX = 'info';\nconst MODEL_TOPOLOGY_SUFFIX = 'model_topology';\nconst WEIGHT_SPECS_SUFFIX = 'weight_specs';\nconst WEIGHT_DATA_SUFFIX = 'weight_data';\nconst MODEL_METADATA_SUFFIX = 'model_metadata';\n/**\n * Purge all tensorflow.js-saved model artifacts from local storage.\n *\n * @returns Paths of the models purged.\n */\nexport function purgeLocalStorageArtifacts() {\n    if (!env().getBool('IS_BROWSER') || typeof window === 'undefined' ||\n        typeof window.localStorage === 'undefined') {\n        throw new Error('purgeLocalStorageModels() cannot proceed because local storage is ' +\n            'unavailable in the current environment.');\n    }\n    const LS = window.localStorage;\n    const purgedModelPaths = [];\n    for (let i = 0; i < LS.length; ++i) {\n        const key = LS.key(i);\n        const prefix = PATH_PREFIX + PATH_SEPARATOR;\n        if (key.startsWith(prefix) && key.length > prefix.length) {\n            LS.removeItem(key);\n            const modelName = getModelPathFromKey(key);\n            if (purgedModelPaths.indexOf(modelName) === -1) {\n                purgedModelPaths.push(modelName);\n            }\n        }\n    }\n    return purgedModelPaths;\n}\nfunction getModelKeys(path) {\n    return {\n        info: [PATH_PREFIX, path, INFO_SUFFIX].join(PATH_SEPARATOR),\n        topology: [PATH_PREFIX, path, MODEL_TOPOLOGY_SUFFIX].join(PATH_SEPARATOR),\n        weightSpecs: [PATH_PREFIX, path, WEIGHT_SPECS_SUFFIX].join(PATH_SEPARATOR),\n        weightData: [PATH_PREFIX, path, WEIGHT_DATA_SUFFIX].join(PATH_SEPARATOR),\n        modelMetadata: [PATH_PREFIX, path, MODEL_METADATA_SUFFIX].join(PATH_SEPARATOR)\n    };\n}\n/**\n * Get model path from a local-storage key.\n *\n * E.g., 'tensorflowjs_models/my/model/1/info' --> 'my/model/1'\n *\n * @param key\n */\nfunction getModelPathFromKey(key) {\n    const items = key.split(PATH_SEPARATOR);\n    if (items.length < 3) {\n        throw new Error(`Invalid key format: ${key}`);\n    }\n    return items.slice(1, items.length - 1).join(PATH_SEPARATOR);\n}\nfunction maybeStripScheme(key) {\n    return key.startsWith(BrowserLocalStorage.URL_SCHEME) ?\n        key.slice(BrowserLocalStorage.URL_SCHEME.length) :\n        key;\n}\n/**\n * IOHandler subclass: Browser Local Storage.\n *\n * See the doc string to `browserLocalStorage` for more details.\n */\nexport class BrowserLocalStorage {\n    constructor(modelPath) {\n        if (!env().getBool('IS_BROWSER') || typeof window === 'undefined' ||\n            typeof window.localStorage === 'undefined') {\n            // TODO(cais): Add more info about what IOHandler subtypes are\n            // available.\n            //   Maybe point to a doc page on the web and/or automatically determine\n            //   the available IOHandlers and print them in the error message.\n            throw new Error('The current environment does not support local storage.');\n        }\n        this.LS = window.localStorage;\n        if (modelPath == null || !modelPath) {\n            throw new Error('For local storage, modelPath must not be null, undefined or empty.');\n        }\n        this.modelPath = modelPath;\n        this.keys = getModelKeys(this.modelPath);\n    }\n    /**\n     * Save model artifacts to browser local storage.\n     *\n     * See the documentation to `browserLocalStorage` for details on the saved\n     * artifacts.\n     *\n     * @param modelArtifacts The model artifacts to be stored.\n     * @returns An instance of SaveResult.\n     */\n    async save(modelArtifacts) {\n        if (modelArtifacts.modelTopology instanceof ArrayBuffer) {\n            throw new Error('BrowserLocalStorage.save() does not support saving model topology ' +\n                'in binary formats yet.');\n        }\n        else {\n            const topology = JSON.stringify(modelArtifacts.modelTopology);\n            const weightSpecs = JSON.stringify(modelArtifacts.weightSpecs);\n            const modelArtifactsInfo = getModelArtifactsInfoForJSON(modelArtifacts);\n            try {\n                this.LS.setItem(this.keys.info, JSON.stringify(modelArtifactsInfo));\n                this.LS.setItem(this.keys.topology, topology);\n                this.LS.setItem(this.keys.weightSpecs, weightSpecs);\n                this.LS.setItem(this.keys.weightData, arrayBufferToBase64String(modelArtifacts.weightData));\n                const result = {\n                    format: modelArtifacts.format,\n                    generatedBy: modelArtifacts.generatedBy,\n                    convertedBy: modelArtifacts.convertedBy\n                };\n                if (modelArtifacts.signature != null) {\n                    result.signature = modelArtifacts.signature;\n                }\n                if (modelArtifacts.userDefinedMetadata != null) {\n                    result.userDefinedMetadata = modelArtifacts.userDefinedMetadata;\n                }\n                if (modelArtifacts.modelInitializer != null) {\n                    result.modelInitializer = modelArtifacts.modelInitializer;\n                }\n                this.LS.setItem(this.keys.modelMetadata, JSON.stringify(result));\n                return { modelArtifactsInfo };\n            }\n            catch (err) {\n                // If saving failed, clean up all items saved so far.\n                this.LS.removeItem(this.keys.info);\n                this.LS.removeItem(this.keys.topology);\n                this.LS.removeItem(this.keys.weightSpecs);\n                this.LS.removeItem(this.keys.weightData);\n                this.LS.removeItem(this.keys.modelMetadata);\n                throw new Error(`Failed to save model '${this.modelPath}' to local storage: ` +\n                    `size quota being exceeded is a possible cause of this failure: ` +\n                    `modelTopologyBytes=${modelArtifactsInfo.modelTopologyBytes}, ` +\n                    `weightSpecsBytes=${modelArtifactsInfo.weightSpecsBytes}, ` +\n                    `weightDataBytes=${modelArtifactsInfo.weightDataBytes}.`);\n            }\n        }\n    }\n    /**\n     * Load a model from local storage.\n     *\n     * See the documentation to `browserLocalStorage` for details on the saved\n     * artifacts.\n     *\n     * @returns The loaded model (if loading succeeds).\n     */\n    async load() {\n        const info = JSON.parse(this.LS.getItem(this.keys.info));\n        if (info == null) {\n            throw new Error(`In local storage, there is no model with name '${this.modelPath}'`);\n        }\n        if (info.modelTopologyType !== 'JSON') {\n            throw new Error('BrowserLocalStorage does not support loading non-JSON model ' +\n                'topology yet.');\n        }\n        const out = {};\n        // Load topology.\n        const topology = JSON.parse(this.LS.getItem(this.keys.topology));\n        if (topology == null) {\n            throw new Error(`In local storage, the topology of model '${this.modelPath}' ` +\n                `is missing.`);\n        }\n        out.modelTopology = topology;\n        // Load weight specs.\n        const weightSpecs = JSON.parse(this.LS.getItem(this.keys.weightSpecs));\n        if (weightSpecs == null) {\n            throw new Error(`In local storage, the weight specs of model '${this.modelPath}' ` +\n                `are missing.`);\n        }\n        out.weightSpecs = weightSpecs;\n        // Load meta-data fields.\n        const metadataString = this.LS.getItem(this.keys.modelMetadata);\n        if (metadataString != null) {\n            const metadata = JSON.parse(metadataString);\n            out.format = metadata['format'];\n            out.generatedBy = metadata['generatedBy'];\n            out.convertedBy = metadata['convertedBy'];\n            if (metadata['signature'] != null) {\n                out.signature = metadata['signature'];\n            }\n            if (metadata['userDefinedMetadata'] != null) {\n                out.userDefinedMetadata = metadata['userDefinedMetadata'];\n            }\n            if (metadata['modelInitializer'] != null) {\n                out.modelInitializer = metadata['modelInitializer'];\n            }\n        }\n        // Load weight data.\n        const weightDataBase64 = this.LS.getItem(this.keys.weightData);\n        if (weightDataBase64 == null) {\n            throw new Error(`In local storage, the binary weight values of model ` +\n                `'${this.modelPath}' are missing.`);\n        }\n        out.weightData = base64StringToArrayBuffer(weightDataBase64);\n        return out;\n    }\n}\nBrowserLocalStorage.URL_SCHEME = 'localstorage://';\nexport const localStorageRouter = (url) => {\n    if (!env().getBool('IS_BROWSER')) {\n        return null;\n    }\n    else {\n        if (!Array.isArray(url) && url.startsWith(BrowserLocalStorage.URL_SCHEME)) {\n            return browserLocalStorage(url.slice(BrowserLocalStorage.URL_SCHEME.length));\n        }\n        else {\n            return null;\n        }\n    }\n};\nIORouterRegistry.registerSaveRouter(localStorageRouter);\nIORouterRegistry.registerLoadRouter(localStorageRouter);\n/**\n * Factory function for local storage IOHandler.\n *\n * This `IOHandler` supports both `save` and `load`.\n *\n * For each model's saved artifacts, four items are saved to local storage.\n *   - `${PATH_SEPARATOR}/${modelPath}/info`: Contains meta-info about the\n *     model, such as date saved, type of the topology, size in bytes, etc.\n *   - `${PATH_SEPARATOR}/${modelPath}/topology`: Model topology. For Keras-\n *     style models, this is a stringized JSON.\n *   - `${PATH_SEPARATOR}/${modelPath}/weight_specs`: Weight specs of the\n *     model, can be used to decode the saved binary weight values (see\n *     item below).\n *   - `${PATH_SEPARATOR}/${modelPath}/weight_data`: Concatenated binary\n *     weight values, stored as a base64-encoded string.\n *\n * Saving may throw an `Error` if the total size of the artifacts exceed the\n * browser-specific quota.\n *\n * @param modelPath A unique identifier for the model to be saved. Must be a\n *   non-empty string.\n * @returns An instance of `IOHandler`, which can be used with, e.g.,\n *   `tf.Model.save`.\n */\nexport function browserLocalStorage(modelPath) {\n    return new BrowserLocalStorage(modelPath);\n}\nexport class BrowserLocalStorageManager {\n    constructor() {\n        assert(env().getBool('IS_BROWSER'), () => 'Current environment is not a web browser');\n        assert(typeof window === 'undefined' ||\n            typeof window.localStorage !== 'undefined', () => 'Current browser does not appear to support localStorage');\n        this.LS = window.localStorage;\n    }\n    async listModels() {\n        const out = {};\n        const prefix = PATH_PREFIX + PATH_SEPARATOR;\n        const suffix = PATH_SEPARATOR + INFO_SUFFIX;\n        for (let i = 0; i < this.LS.length; ++i) {\n            const key = this.LS.key(i);\n            if (key.startsWith(prefix) && key.endsWith(suffix)) {\n                const modelPath = getModelPathFromKey(key);\n                out[modelPath] = JSON.parse(this.LS.getItem(key));\n            }\n        }\n        return out;\n    }\n    async removeModel(path) {\n        path = maybeStripScheme(path);\n        const keys = getModelKeys(path);\n        if (this.LS.getItem(keys.info) == null) {\n            throw new Error(`Cannot find model at path '${path}'`);\n        }\n        const info = JSON.parse(this.LS.getItem(keys.info));\n        this.LS.removeItem(keys.info);\n        this.LS.removeItem(keys.topology);\n        this.LS.removeItem(keys.weightSpecs);\n        this.LS.removeItem(keys.weightData);\n        return info;\n    }\n}\n//# sourceMappingURL=local_storage.js.map","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n// Workaround for allowing cjs module to be included in bundle created by\n// rollup.\nimport * as LongExports from 'long';\n// tslint:disable-next-line\nconst Long = \n// tslint:disable-next-line\nLongExports.default || LongExports;\nexport function hexToLong(hex) {\n    return Long.fromString(hex, true, 16);\n}\n// Some primes between 2^63 and 2^64 for various uses.\n// Hex 0xc3a5c85c97cb3127\nconst k0 = hexToLong('c3a5c85c97cb3127');\n// Hex 0xb492b66fbe98f273\nconst k1 = hexToLong('b492b66fbe98f273');\n// Hex 0x9ae16a3b2f90404f\nconst k2 = hexToLong('9ae16a3b2f90404f');\nfunction shiftMix(val) {\n    return val.xor(val.shru(47));\n}\nfunction fetch(s, offset, numBytes) {\n    const bytes = s.slice(offset, offset + numBytes);\n    return Long.fromBytes(Array.from(bytes), true, true);\n}\nfunction fetch64(s, offset) {\n    return fetch(s, offset, 8);\n}\nfunction fetch32(s, offset) {\n    return fetch(s, offset, 4);\n}\nfunction rotate64(val, shift) {\n    // Avoid shifting by 64: doing so yields an undefined result.\n    return shift === 0 ? val : val.shru(shift).or(val.shl(64 - shift));\n}\nfunction hashLen16(u, v, mul = hexToLong('9ddfea08eb382d69')) {\n    // Murmur-inspired hashing.\n    let a = u.xor(v).mul(mul);\n    a = a.xor(a.shru(47));\n    let b = v.xor(a).mul(mul);\n    b = b.xor(b.shru(47));\n    b = b.mul(mul);\n    return b;\n}\n// Return a 16-byte hash for 48 bytes.  Quick and dirty.\n// Callers do best to use \"random-looking\" values for a and b.\nfunction weakHashLen32WithSeeds(w, x, y, z, a, b) {\n    a = a.add(w);\n    b = rotate64(b.add(a).add(z), 21);\n    const c = a;\n    a = a.add(x);\n    a = a.add(y);\n    b = b.add(rotate64(a, 44));\n    return [a.add(z), b.add(c)];\n}\nfunction weakHashLen32WithSeedsStr(s, offset, a, b) {\n    return weakHashLen32WithSeeds(fetch64(s, offset), fetch64(s, offset + 8), fetch64(s, offset + 16), fetch64(s, offset + 24), a, b);\n}\nfunction hashLen0to16(s, len = s.length) {\n    if (len >= 8) {\n        const mul = k2.add(len * 2);\n        const a = fetch64(s, 0).add(k2);\n        const b = fetch64(s, len - 8);\n        const c = rotate64(b, 37).mul(mul).add(a);\n        const d = rotate64(a, 25).add(b).mul(mul);\n        return hashLen16(c, d, mul);\n    }\n    if (len >= 4) {\n        const mul = k2.add(len * 2);\n        const a = fetch32(s, 0);\n        return hashLen16(a.shl(3).add(len), fetch32(s, len - 4), mul);\n    }\n    if (len > 0) {\n        const a = s[0];\n        const b = s[len >> 1];\n        const c = s[len - 1];\n        const y = a + (b << 8);\n        const z = len + (c << 2);\n        return shiftMix(k2.mul(y).xor(k0.mul(z))).mul(k2);\n    }\n    return k2;\n}\nfunction hashLen17to32(s, len = s.length) {\n    const mul = k2.add(len * 2);\n    const a = fetch64(s, 0).mul(k1);\n    const b = fetch64(s, 8);\n    const c = fetch64(s, len - 8).mul(mul);\n    const d = fetch64(s, len - 16).mul(k2);\n    return hashLen16(rotate64(a.add(b), 43).add(rotate64(c, 30)).add(d), a.add(rotate64(b.add(k2), 18)).add(c), mul);\n}\nfunction hashLen33to64(s, len = s.length) {\n    const mul = k2.add(len * 2);\n    const a = fetch64(s, 0).mul(k2);\n    const b = fetch64(s, 8);\n    const c = fetch64(s, len - 8).mul(mul);\n    const d = fetch64(s, len - 16).mul(k2);\n    const y = rotate64(a.add(b), 43).add(rotate64(c, 30)).add(d);\n    const z = hashLen16(y, a.add(rotate64(b.add(k2), 18)).add(c), mul);\n    const e = fetch64(s, 16).mul(mul);\n    const f = fetch64(s, 24);\n    const g = y.add(fetch64(s, len - 32)).mul(mul);\n    const h = z.add(fetch64(s, len - 24)).mul(mul);\n    return hashLen16(rotate64(e.add(f), 43).add(rotate64(g, 30)).add(h), e.add(rotate64(f.add(a), 18)).add(g), mul);\n}\nexport function fingerPrint64(s, len = s.length) {\n    const seed = Long.fromNumber(81, true);\n    if (len <= 32) {\n        if (len <= 16) {\n            return hashLen0to16(s, len);\n        }\n        else {\n            return hashLen17to32(s, len);\n        }\n    }\n    else if (len <= 64) {\n        return hashLen33to64(s, len);\n    }\n    // For strings over 64 bytes we loop.  Internal state consists of\n    // 56 bytes: v, w, x, y, and z.\n    let x = seed;\n    let y = seed.mul(k1).add(113);\n    let z = shiftMix(y.mul(k2).add(113)).mul(k2);\n    let v = [Long.UZERO, Long.UZERO];\n    let w = [Long.UZERO, Long.UZERO];\n    x = x.mul(k2).add(fetch64(s, 0));\n    let offset = 0;\n    // Set end so that after the loop we have 1 to 64 bytes left to process.\n    const end = ((len - 1) >> 6) * 64;\n    const last64 = end + ((len - 1) & 63) - 63;\n    do {\n        x = rotate64(x.add(y).add(v[0]).add(fetch64(s, offset + 8)), 37).mul(k1);\n        y = rotate64(y.add(v[1]).add(fetch64(s, offset + 48)), 42).mul(k1);\n        x = x.xor(w[1]);\n        y = y.add(v[0]).add(fetch64(s, offset + 40));\n        z = rotate64(z.add(w[0]), 33).mul(k1);\n        v = weakHashLen32WithSeedsStr(s, offset, v[1].mul(k1), x.add(w[0]));\n        w = weakHashLen32WithSeedsStr(s, offset + 32, z.add(w[1]), y.add(fetch64(s, offset + 16)));\n        [z, x] = [x, z];\n        offset += 64;\n    } while (offset !== end);\n    const mul = k1.add(z.and(0xff).shl(1));\n    // Point to the last 64 bytes of input.\n    offset = last64;\n    w[0] = w[0].add((len - 1) & 63);\n    v[0] = v[0].add(w[0]);\n    w[0] = w[0].add(v[0]);\n    x = rotate64(x.add(y).add(v[0]).add(fetch64(s, offset + 8)), 37).mul(mul);\n    y = rotate64(y.add(v[1]).add(fetch64(s, offset + 48)), 42).mul(mul);\n    x = x.xor(w[1].mul(9));\n    y = y.add(v[0].mul(9).add(fetch64(s, offset + 40)));\n    z = rotate64(z.add(w[0]), 33).mul(mul);\n    v = weakHashLen32WithSeedsStr(s, offset, v[1].mul(mul), x.add(w[0]));\n    w = weakHashLen32WithSeedsStr(s, offset + 32, z.add(w[1]), y.add(fetch64(s, offset + 16)));\n    [z, x] = [x, z];\n    return hashLen16(hashLen16(v[0], w[0], mul).add(shiftMix(y).mul(k0)).add(z), hashLen16(v[1], w[1], mul).add(x), mul);\n}\n//# sourceMappingURL=hash_util.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { complex } from '../ops/complex';\nimport { tensor } from '../ops/tensor';\nimport { sizeFromShape } from '../util';\nimport { DTYPE_VALUE_SIZE_MAP } from './types';\n/** Number of bytes reserved for the length of the string. (32bit integer). */\nconst NUM_BYTES_STRING_LENGTH = 4;\n/**\n * Encode a map from names to weight values as an ArrayBuffer, along with an\n * `Array` of `WeightsManifestEntry` as specification of the encoded weights.\n *\n * This function does not perform sharding.\n *\n * This function is the reverse of `decodeWeights`.\n *\n * @param tensors A map (\"dict\") from names to tensors.\n * @param group Group to which the weights belong (optional).\n * @returns A `Promise` of\n *   - A flat `ArrayBuffer` with all the binary values of the `Tensor`s\n *     concatenated.\n *   - An `Array` of `WeightManifestEntry`s, carrying information including\n *     tensor names, `dtype`s and shapes.\n * @throws Error: on unsupported tensor `dtype`.\n */\nexport async function encodeWeights(tensors, group) {\n    // TODO(adarob, cais): Support quantization.\n    const specs = [];\n    const dataPromises = [];\n    const names = Array.isArray(tensors) ?\n        tensors.map(tensor => tensor.name) :\n        Object.keys(tensors);\n    for (let i = 0; i < names.length; ++i) {\n        const name = names[i];\n        const t = Array.isArray(tensors) ? tensors[i].tensor : tensors[name];\n        if (t.dtype !== 'float32' && t.dtype !== 'int32' && t.dtype !== 'bool' &&\n            t.dtype !== 'string' && t.dtype !== 'complex64') {\n            throw new Error(`Unsupported dtype in weight '${name}': ${t.dtype}`);\n        }\n        const spec = { name, shape: t.shape, dtype: t.dtype };\n        if (t.dtype === 'string') {\n            const utf8bytes = new Promise(async (resolve) => {\n                const vals = await t.bytes();\n                const totalNumBytes = vals.reduce((p, c) => p + c.length, 0) +\n                    NUM_BYTES_STRING_LENGTH * vals.length;\n                const bytes = new Uint8Array(totalNumBytes);\n                let offset = 0;\n                for (let i = 0; i < vals.length; i++) {\n                    const val = vals[i];\n                    const bytesOfLength = new Uint8Array(new Uint32Array([val.length]).buffer);\n                    bytes.set(bytesOfLength, offset);\n                    offset += NUM_BYTES_STRING_LENGTH;\n                    bytes.set(val, offset);\n                    offset += val.length;\n                }\n                resolve(bytes);\n            });\n            dataPromises.push(utf8bytes);\n        }\n        else {\n            dataPromises.push(t.data());\n        }\n        if (group != null) {\n            spec.group = group;\n        }\n        specs.push(spec);\n    }\n    const tensorValues = await Promise.all(dataPromises);\n    return { data: concatenateTypedArrays(tensorValues), specs };\n}\n/**\n * Decode flat ArrayBuffer as weights.\n *\n * This function does not handle sharding.\n *\n * This function is the reverse of `encodeWeights`.\n *\n * @param buffer A flat ArrayBuffer carrying the binary values of the tensors\n *   concatenated in the order specified in `specs`.\n * @param specs Specifications of the names, dtypes and shapes of the tensors\n *   whose value are encoded by `buffer`.\n * @return A map from tensor name to tensor value, with the names corresponding\n *   to names in `specs`.\n * @throws Error, if any of the tensors has unsupported dtype.\n */\nexport function decodeWeights(buffer, specs) {\n    // TODO(adarob, cais): Support quantization.\n    const out = {};\n    let float16Decode;\n    let offset = 0;\n    for (const spec of specs) {\n        const name = spec.name;\n        const dtype = spec.dtype;\n        const shape = spec.shape;\n        const size = sizeFromShape(shape);\n        let values;\n        if ('quantization' in spec) {\n            const quantization = spec.quantization;\n            if (quantization.dtype === 'uint8' || quantization.dtype === 'uint16') {\n                if (!('min' in quantization && 'scale' in quantization)) {\n                    throw new Error(`Weight ${spec.name} with quantization ${quantization.dtype} ` +\n                        `doesn't have corresponding metadata min and scale.`);\n                }\n            }\n            else if (quantization.dtype === 'float16') {\n                if (dtype !== 'float32') {\n                    throw new Error(`Weight ${spec.name} is quantized with ${quantization.dtype} ` +\n                        `which only supports weights of type float32 not ${dtype}.`);\n                }\n            }\n            else {\n                throw new Error(`Weight ${spec.name} has unknown ` +\n                    `quantization dtype ${quantization.dtype}. ` +\n                    `Supported quantization dtypes are: ` +\n                    `'uint8', 'uint16', and 'float16'.`);\n            }\n            const quantizationSizeFactor = DTYPE_VALUE_SIZE_MAP[quantization.dtype];\n            const byteBuffer = buffer.slice(offset, offset + size * quantizationSizeFactor);\n            const quantizedArray = (quantization.dtype === 'uint8') ?\n                new Uint8Array(byteBuffer) :\n                new Uint16Array(byteBuffer);\n            if (dtype === 'float32') {\n                if (quantization.dtype === 'uint8' || quantization.dtype === 'uint16') {\n                    values = new Float32Array(quantizedArray.length);\n                    for (let i = 0; i < quantizedArray.length; i++) {\n                        const v = quantizedArray[i];\n                        values[i] = v * quantization.scale + quantization.min;\n                    }\n                }\n                else if (quantization.dtype === 'float16') {\n                    if (float16Decode === undefined) {\n                        float16Decode = getFloat16Decoder();\n                    }\n                    values = float16Decode(quantizedArray);\n                }\n                else {\n                    throw new Error(`Unsupported quantization type ${quantization.dtype} ` +\n                        `for weight type float32.`);\n                }\n            }\n            else if (dtype === 'int32') {\n                if (quantization.dtype !== 'uint8' && quantization.dtype !== 'uint16') {\n                    throw new Error(`Unsupported quantization type ${quantization.dtype} ` +\n                        `for weight type int32.`);\n                }\n                values = new Int32Array(quantizedArray.length);\n                for (let i = 0; i < quantizedArray.length; i++) {\n                    const v = quantizedArray[i];\n                    values[i] = Math.round(v * quantization.scale + quantization.min);\n                }\n            }\n            else {\n                throw new Error(`Unsupported dtype in weight '${name}': ${dtype}`);\n            }\n            offset += size * quantizationSizeFactor;\n        }\n        else if (dtype === 'string') {\n            const size = sizeFromShape(spec.shape);\n            values = [];\n            for (let i = 0; i < size; i++) {\n                const byteLength = new Uint32Array(buffer.slice(offset, offset + NUM_BYTES_STRING_LENGTH))[0];\n                offset += NUM_BYTES_STRING_LENGTH;\n                const bytes = new Uint8Array(buffer.slice(offset, offset + byteLength));\n                values.push(bytes);\n                offset += byteLength;\n            }\n        }\n        else {\n            const dtypeFactor = DTYPE_VALUE_SIZE_MAP[dtype];\n            const byteBuffer = buffer.slice(offset, offset + size * dtypeFactor);\n            if (dtype === 'float32') {\n                values = new Float32Array(byteBuffer);\n            }\n            else if (dtype === 'int32') {\n                values = new Int32Array(byteBuffer);\n            }\n            else if (dtype === 'bool') {\n                values = new Uint8Array(byteBuffer);\n            }\n            else if (dtype === 'complex64') {\n                values = new Float32Array(byteBuffer);\n                const real = new Float32Array(values.length / 2);\n                const image = new Float32Array(values.length / 2);\n                for (let i = 0; i < real.length; i++) {\n                    real[i] = values[i * 2];\n                    image[i] = values[i * 2 + 1];\n                }\n                const realTensor = tensor(real, shape, 'float32');\n                const imageTensor = tensor(image, shape, 'float32');\n                out[name] = complex(realTensor, imageTensor);\n                realTensor.dispose();\n                imageTensor.dispose();\n            }\n            else {\n                throw new Error(`Unsupported dtype in weight '${name}': ${dtype}`);\n            }\n            offset += size * dtypeFactor;\n        }\n        if (dtype !== 'complex64') {\n            out[name] = tensor(values, shape, dtype);\n        }\n    }\n    return out;\n}\n/**\n * Concatenate TypedArrays into an ArrayBuffer.\n */\nexport function concatenateTypedArrays(xs) {\n    // TODO(adarob, cais): Support quantization.\n    if (xs === null) {\n        throw new Error(`Invalid input value: ${JSON.stringify(xs)}`);\n    }\n    let totalByteLength = 0;\n    // `normalizedXs` is here for this reason: a `TypedArray`'s `buffer'\n    // can have a different byte length from that of the `TypedArray` itself,\n    // for example, when the `TypedArray` is created from an offset in an\n    // `ArrayBuffer`. `normliazedXs` holds `TypedArray`s whose `buffer`s match\n    // the `TypedArray` in byte length. If an element of `xs` does not show\n    // this property, a new `TypedArray` that satisfy this property will be\n    // constructed and pushed into `normalizedXs`.\n    const normalizedXs = [];\n    xs.forEach((x) => {\n        totalByteLength += x.byteLength;\n        // tslint:disable:no-any\n        normalizedXs.push(x.byteLength === x.buffer.byteLength ? x :\n            new x.constructor(x));\n        if (!(x instanceof Float32Array || x instanceof Int32Array ||\n            x instanceof Uint8Array)) {\n            throw new Error(`Unsupported TypedArray subtype: ${x.constructor.name}`);\n        }\n        // tslint:enable:no-any\n    });\n    const y = new Uint8Array(totalByteLength);\n    let offset = 0;\n    normalizedXs.forEach((x) => {\n        y.set(new Uint8Array(x.buffer), offset);\n        offset += x.byteLength;\n    });\n    return y.buffer;\n}\n// Use Buffer on Node.js instead of Blob/atob/btoa\nconst useNodeBuffer = typeof Buffer !== 'undefined' &&\n    (typeof Blob === 'undefined' || typeof atob === 'undefined' ||\n        typeof btoa === 'undefined');\n/**\n * Calculate the byte length of a JavaScript string.\n *\n * Note that a JavaScript string can contain wide characters, therefore the\n * length of the string is not necessarily equal to the byte length.\n *\n * @param str Input string.\n * @returns Byte length.\n */\nexport function stringByteLength(str) {\n    if (useNodeBuffer) {\n        return Buffer.byteLength(str);\n    }\n    return new Blob([str]).size;\n}\n/**\n * Encode an ArrayBuffer as a base64 encoded string.\n *\n * @param buffer `ArrayBuffer` to be converted.\n * @returns A string that base64-encodes `buffer`.\n */\nexport function arrayBufferToBase64String(buffer) {\n    if (useNodeBuffer) {\n        return Buffer.from(buffer).toString('base64');\n    }\n    const buf = new Uint8Array(buffer);\n    let s = '';\n    for (let i = 0, l = buf.length; i < l; i++) {\n        s += String.fromCharCode(buf[i]);\n    }\n    return btoa(s);\n}\n/**\n * Decode a base64 string as an ArrayBuffer.\n *\n * @param str Base64 string.\n * @returns Decoded `ArrayBuffer`.\n */\nexport function base64StringToArrayBuffer(str) {\n    if (useNodeBuffer) {\n        const buf = Buffer.from(str, 'base64');\n        return buf.buffer.slice(buf.byteOffset, buf.byteOffset + buf.byteLength);\n    }\n    const s = atob(str);\n    const buffer = new Uint8Array(s.length);\n    for (let i = 0; i < s.length; ++i) {\n        buffer.set([s.charCodeAt(i)], i);\n    }\n    return buffer.buffer;\n}\n/**\n * Concatenate a number of ArrayBuffers into one.\n *\n * @param buffers A number of array buffers to concatenate.\n * @returns Result of concatenating `buffers` in order.\n */\nexport function concatenateArrayBuffers(buffers) {\n    if (buffers.length === 1) {\n        return buffers[0];\n    }\n    let totalByteLength = 0;\n    buffers.forEach((buffer) => {\n        totalByteLength += buffer.byteLength;\n    });\n    const temp = new Uint8Array(totalByteLength);\n    let offset = 0;\n    buffers.forEach((buffer) => {\n        temp.set(new Uint8Array(buffer), offset);\n        offset += buffer.byteLength;\n    });\n    return temp.buffer;\n}\n/**\n * Get the basename of a path.\n *\n * Behaves in a way analogous to Linux's basename command.\n *\n * @param path\n */\nexport function basename(path) {\n    const SEPARATOR = '/';\n    path = path.trim();\n    while (path.endsWith(SEPARATOR)) {\n        path = path.slice(0, path.length - 1);\n    }\n    const items = path.split(SEPARATOR);\n    return items[items.length - 1];\n}\n/**\n * Populate ModelArtifactsInfo fields for a model with JSON topology.\n * @param modelArtifacts\n * @returns A ModelArtifactsInfo object.\n */\nexport function getModelArtifactsInfoForJSON(modelArtifacts) {\n    if (modelArtifacts.modelTopology instanceof ArrayBuffer) {\n        throw new Error('Expected JSON model topology, received ArrayBuffer.');\n    }\n    return {\n        dateSaved: new Date(),\n        modelTopologyType: 'JSON',\n        modelTopologyBytes: modelArtifacts.modelTopology == null ?\n            0 :\n            stringByteLength(JSON.stringify(modelArtifacts.modelTopology)),\n        weightSpecsBytes: modelArtifacts.weightSpecs == null ?\n            0 :\n            stringByteLength(JSON.stringify(modelArtifacts.weightSpecs)),\n        weightDataBytes: modelArtifacts.weightData == null ?\n            0 :\n            modelArtifacts.weightData.byteLength,\n    };\n}\n/**\n * Computes mantisa table for casting Float16 to Float32\n * See http://www.fox-toolkit.org/ftp/fasthalffloatconversion.pdf\n *\n * @returns Uint32Array, 2048 mantissa lookup values.\n */\nfunction computeFloat16MantisaTable() {\n    const convertMantissa = (i) => {\n        let m = i << 13;\n        let e = 0;\n        while ((m & 0x00800000) === 0) {\n            e -= 0x00800000;\n            m <<= 1;\n        }\n        m &= ~0x00800000;\n        e += 0x38800000;\n        return m | e;\n    };\n    const mantisaTable = new Uint32Array(2048);\n    mantisaTable[0] = 0;\n    for (let i = 1; i < 1024; i++) {\n        mantisaTable[i] = convertMantissa(i);\n    }\n    for (let i = 1024; i < 2048; i++) {\n        mantisaTable[i] = 0x38000000 + ((i - 1024) << 13);\n    }\n    return mantisaTable;\n}\n/**\n * Computes exponent table for casting Float16 to Float32\n * See http://www.fox-toolkit.org/ftp/fasthalffloatconversion.pdf\n *\n * @returns Uint32Array, 64 exponent lookup values.\n */\nfunction computeFloat16ExponentTable() {\n    const exponentTable = new Uint32Array(64);\n    exponentTable[0] = 0;\n    exponentTable[31] = 0x47800000;\n    exponentTable[32] = 0x80000000;\n    exponentTable[63] = 0xc7800000;\n    for (let i = 1; i < 31; i++) {\n        exponentTable[i] = i << 23;\n    }\n    for (let i = 33; i < 63; i++) {\n        exponentTable[i] = 0x80000000 + ((i - 32) << 23);\n    }\n    return exponentTable;\n}\n/**\n * Computes offset table for casting Float16 to Float32\n * See http://www.fox-toolkit.org/ftp/fasthalffloatconversion.pdf\n *\n * @returns Uint32Array, 6d offset values.\n */\nfunction computeFloat16OffsetTable() {\n    const offsetTable = new Uint32Array(64);\n    for (let i = 0; i < 64; i++) {\n        offsetTable[i] = 1024;\n    }\n    offsetTable[0] = offsetTable[32] = 0;\n    return offsetTable;\n}\n/**\n * Retrieve a Float16 decoder which will decode a ByteArray of Float16 values\n * to a Float32Array.\n *\n * @returns Function (buffer: Uint16Array) => Float32Array which decodes\n *          the Uint16Array of Float16 bytes to a Float32Array.\n */\nexport function getFloat16Decoder() {\n    // Algorithm is based off of\n    // http://www.fox-toolkit.org/ftp/fasthalffloatconversion.pdf\n    // Cache lookup tables\n    const mantisaTable = computeFloat16MantisaTable();\n    const exponentTable = computeFloat16ExponentTable();\n    const offsetTable = computeFloat16OffsetTable();\n    return (quantizedArray) => {\n        const buffer = new ArrayBuffer(4 * quantizedArray.length);\n        const bufferUint32View = new Uint32Array(buffer);\n        for (let index = 0; index < quantizedArray.length; index++) {\n            const float16Bits = quantizedArray[index];\n            const float32Bits = mantisaTable[offsetTable[float16Bits >> 10] + (float16Bits & 0x3ff)] +\n                exponentTable[float16Bits >> 10];\n            bufferUint32View[index] = float32Bits;\n        }\n        return new Float32Array(buffer);\n    };\n}\n//# sourceMappingURL=io_utils.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from './engine';\nimport { Tensor, Variable } from './tensor';\nimport { convertToTensor, convertToTensorArray } from './tensor_util_env';\nimport * as util from './util';\n/**\n * Provided `f(x)`, returns another function `g(x, dy?)`, which gives the\n * gradient of `f(x)` with respect to `x`.\n *\n * If `dy` is provided, the gradient of `f(x).mul(dy).sum()` with respect to\n * `x` is computed instead. `f(x)` must take a single tensor `x` and return a\n * single tensor `y`. If `f()` takes multiple inputs, use `tf.grads` instead.\n *\n * ```js\n * // f(x) = x ^ 2\n * const f = x => x.square();\n * // f'(x) = 2x\n * const g = tf.grad(f);\n *\n * const x = tf.tensor1d([2, 3]);\n * g(x).print();\n * ```\n *\n * ```js\n * // f(x) = x ^ 3\n * const f = x => x.pow(tf.scalar(3, 'int32'));\n * // f'(x) = 3x ^ 2\n * const g = tf.grad(f);\n * // f''(x) = 6x\n * const gg = tf.grad(g);\n *\n * const x = tf.tensor1d([2, 3]);\n * gg(x).print();\n * ```\n *\n * @param f The function f(x), to compute gradient for.\n *\n * @doc {heading: 'Training', subheading: 'Gradients'}\n */\nfunction grad(f) {\n    util.assert(util.isFunction(f), () => 'The f passed in grad(f) must be a function');\n    return (x, dy) => {\n        // x can be of any dtype, thus null as the last argument.\n        const $x = convertToTensor(x, 'x', 'tf.grad', 'string_or_numeric');\n        const $dy = (dy != null) ? convertToTensor(dy, 'dy', 'tf.grad') : null;\n        return ENGINE.tidy(() => {\n            const { value, grads } = ENGINE.gradients(() => f($x), [$x], $dy);\n            if ($dy != null) {\n                util.assertShapesMatch(value.shape, $dy.shape, 'The shape of dy passed in grad(f)(x, dy) must match the shape ' +\n                    'returned by f(x)');\n            }\n            checkGrads(grads);\n            return grads[0];\n        });\n    };\n}\n/**\n * Provided `f(x1, x2,...)`, returns another function `g([x1, x2,...], dy?)`,\n * which gives an array of gradients of `f()` with respect to each input\n * [`x1`,`x2`,...].\n *\n * If `dy` is passed when calling `g()`, the gradient of\n * `f(x1,...).mul(dy).sum()` with respect to each input is computed instead.\n * The provided `f` must take one or more tensors and return a single tensor\n * `y`. If `f()` takes a single input, we recommend using `tf.grad` instead.\n *\n * ```js\n * // f(a, b) = a * b\n * const f = (a, b) => a.mul(b);\n * // df / da = b, df / db = a\n * const g = tf.grads(f);\n *\n * const a = tf.tensor1d([2, 3]);\n * const b = tf.tensor1d([-2, -3]);\n * const [da, db] = g([a, b]);\n * console.log('da');\n * da.print();\n * console.log('db');\n * db.print();\n * ```\n *\n * @param f The function `f(x1, x2,...)` to compute gradients for.\n *\n * @doc {heading: 'Training', subheading: 'Gradients'}\n */\nfunction grads(f) {\n    util.assert(util.isFunction(f), () => 'The f passed in grads(f) must be a function');\n    return (args, dy) => {\n        util.assert(Array.isArray(args), () => 'The args passed in grads(f)(args) must be an array ' +\n            'of `Tensor`s or `TensorLike`s');\n        // args can be of any dtype, thus null as the last argument.\n        const $args = convertToTensorArray(args, 'args', 'tf.grads', 'string_or_numeric');\n        const $dy = (dy != null) ? convertToTensor(dy, 'dy', 'tf.grads') : null;\n        return ENGINE.tidy(() => {\n            const { value, grads } = ENGINE.gradients(() => f(...$args), $args, $dy);\n            if ($dy != null) {\n                util.assertShapesMatch(value.shape, $dy.shape, 'The shape of dy passed in grads(f)([x1,...], dy) must ' +\n                    'match the shape returned by f([x1,...])');\n            }\n            checkGrads(grads);\n            return grads;\n        });\n    };\n}\n/**\n * Like `tf.grad`, but also returns the value of `f()`. Useful when `f()`\n * returns a metric you want to show.\n *\n * The result is a rich object with the following properties:\n * - grad: The gradient of `f(x)` w.r.t `x` (result of `tf.grad`).\n * - value: The value returned by `f(x)`.\n *\n * ```js\n * // f(x) = x ^ 2\n * const f = x => x.square();\n * // f'(x) = 2x\n * const g = tf.valueAndGrad(f);\n *\n * const x = tf.tensor1d([2, 3]);\n * const {value, grad} = g(x);\n *\n * console.log('value');\n * value.print();\n * console.log('grad');\n * grad.print();\n * ```\n *\n * @doc {heading: 'Training', subheading: 'Gradients'}\n */\nfunction valueAndGrad(f) {\n    util.assert(util.isFunction(f), () => 'The f passed in valueAndGrad(f) must be a function');\n    return (x, dy) => {\n        util.assert(x instanceof Tensor, () => 'The x passed in valueAndGrad(f)(x) must be a tensor');\n        util.assert(dy == null || dy instanceof Tensor, () => 'The dy passed in valueAndGrad(f)(x, dy) must be a tensor');\n        const { grads, value } = ENGINE.gradients(() => f(x), [x], dy);\n        checkGrads(grads);\n        return { grad: grads[0], value };\n    };\n}\n/**\n * Like `tf.grads`, but returns also the value of `f()`. Useful when `f()`\n * returns a metric you want to show.\n *\n * The result is a rich object with the following properties:\n * - grads: The gradients of `f()` w.r.t each input (result of `tf.grads`).\n * - value: The value returned by `f(x)`.\n *\n * ```js\n * // f(a, b) = a * b\n * const f = (a, b) => a.mul(b);\n * // df/da = b, df/db = a\n * const g = tf.valueAndGrads(f);\n *\n * const a = tf.tensor1d([2, 3]);\n * const b = tf.tensor1d([-2, -3]);\n * const {value, grads} = g([a, b]);\n *\n * const [da, db] = grads;\n *\n * console.log('value');\n * value.print();\n *\n * console.log('da');\n * da.print();\n * console.log('db');\n * db.print();\n * ```\n *\n * @doc {heading: 'Training', subheading: 'Gradients'}\n */\nfunction valueAndGrads(f) {\n    util.assert(util.isFunction(f), () => 'The f passed in valueAndGrads(f) must be a function');\n    return (args, dy) => {\n        util.assert(Array.isArray(args) && args.every(arg => arg instanceof Tensor), () => 'The args passed in valueAndGrads(f)(args) must be array of ' +\n            'tensors');\n        util.assert(dy == null || dy instanceof Tensor, () => 'The dy passed in valueAndGrads(f)(args, dy) must be a tensor');\n        const res = ENGINE.gradients(() => f(...args), args, dy);\n        if (dy != null) {\n            util.assertShapesMatch(res.value.shape, dy.shape, 'The shape of dy passed in valueAndGrads(f)([x1,...], dy) must ' +\n                'match the shape returned by f([x1,...])');\n        }\n        checkGrads(res.grads);\n        return res;\n    };\n}\n/**\n * Computes and returns the gradient of f(x) with respect to the list of\n * trainable variables provided by `varList`. If no list is provided, it\n * defaults to all trainable variables.\n *\n * ```js\n * const a = tf.variable(tf.tensor1d([3, 4]));\n * const b = tf.variable(tf.tensor1d([5, 6]));\n * const x = tf.tensor1d([1, 2]);\n *\n * // f(a, b) = a * x ^ 2 + b * x\n * const f = () => a.mul(x.square()).add(b.mul(x)).sum();\n * // df/da = x ^ 2, df/db = x\n * const {value, grads} = tf.variableGrads(f);\n *\n * Object.keys(grads).forEach(varName => grads[varName].print());\n * ```\n *\n * @param f The function to execute. f() should return a scalar.\n * @param varList The list of variables to compute the gradients with respect\n *     to. Defaults to all trainable variables.\n * @returns An object with the following keys and values:\n *   - `value`: The value of the function `f`.\n *   - `grads`: A map from the names of the variables to the gradients.\n *     If the `varList` argument is provided explicitly and contains a subset of\n *     non-trainable variables, this map in the return value will contain keys\n *     that map the names of the non-trainable variables to `null`.\n *\n * @doc {heading: 'Training', subheading: 'Gradients'}\n */\nfunction variableGrads(f, varList) {\n    util.assert(util.isFunction(f), () => 'The f passed in variableGrads(f) must be a function');\n    util.assert(varList == null ||\n        Array.isArray(varList) && varList.every(v => v instanceof Variable), () => 'The varList passed in variableGrads(f, varList) must be an array ' +\n        'of variables');\n    const specifiedVarList = varList != null;\n    if (!specifiedVarList) {\n        // Get all of the trainable variables.\n        varList = [];\n        for (const varName in ENGINE.registeredVariables) {\n            varList.push(ENGINE.registeredVariables[varName]);\n        }\n    }\n    const specifiedNonTrainable = specifiedVarList ? varList.filter(variable => !variable.trainable) : null;\n    // Prune non-trainable variables.\n    const originalVarCount = varList.length;\n    varList = varList.filter(variable => variable.trainable);\n    util.assert(varList.length > 0, () => `variableGrads() expects at least one of the input variables to ` +\n        `be trainable, but none of the ${originalVarCount} variables is ` +\n        `trainable.`);\n    const allowNoGradients = true;\n    const { value, grads } = ENGINE.gradients(f, varList, null, allowNoGradients);\n    util.assert(grads.some(g => g != null), () => 'Cannot find a connection between any variable and the result of ' +\n        'the loss function y=f(x). Please make sure the operations that ' +\n        'use variables are inside the function f passed to minimize().');\n    util.assert(value.rank === 0, () => `The f passed in variableGrads(f) must return a scalar, but it ` +\n        `returned a rank-${value.rank} tensor`);\n    const namedGrads = {};\n    varList.forEach((v, i) => {\n        if (grads[i] != null) {\n            namedGrads[v.name] = grads[i];\n        }\n    });\n    if (specifiedNonTrainable != null) {\n        // If varList is explicitly provided and contains non-trainable values,\n        // add them to the returned gradients with `null` values.\n        specifiedNonTrainable.forEach(v => namedGrads[v.name] = null);\n    }\n    return { value, grads: namedGrads };\n}\n/**\n * Overrides the gradient computation of a function `f`.\n *\n * Takes a function\n * `f(...inputs, save) => {value: Tensor, gradFunc: (dy, saved) => Tensor[]}`\n * and returns another function `g(...inputs)` which takes the same inputs as\n * `f`. When called, `g` returns `f().value`. In backward mode, custom gradients\n * with respect to each input of `f` are computed using `f().gradFunc`.\n *\n * The `save` function passsed to `f` should be used for saving tensors needed\n * in the gradient. And the `saved` passed to the `gradFunc` is a\n * `NamedTensorMap`, which contains those saved tensor.\n *\n * ```js\n * const customOp = tf.customGrad((x, save) => {\n *   // Save x to make sure it's available later for the gradient.\n *   save([x]);\n *   // Override gradient of our custom x ^ 2 op to be dy * abs(x);\n *   return {\n *     value: x.square(),\n *     // Note `saved.x` which points to the `x` we saved earlier.\n *     gradFunc: (dy, saved) => [dy.mul(saved[0].abs())]\n *   };\n * });\n *\n * const x = tf.tensor1d([-1, -2, 3]);\n * const dx = tf.grad(x => customOp(x));\n *\n * console.log(`f(x):`);\n * customOp(x).print();\n * console.log(`f'(x):`);\n * dx(x).print();\n * ```\n *\n * @param f The function to evaluate in forward mode, which should return\n *     `{value: Tensor, gradFunc: (dy, saved) => Tensor[]}`, where `gradFunc`\n *     returns the custom gradients of `f` with respect to its inputs.\n *\n * @doc {heading: 'Training', subheading: 'Gradients'}\n */\nfunction customGrad(f) {\n    return ENGINE.customGrad(f);\n}\nfunction checkGrads(grads) {\n    const numNullGradients = grads.filter(g => g == null).length;\n    if (numNullGradients > 0) {\n        throw new Error(`Cannot compute gradient of y=f(x) with respect to x. Make sure that\n    the f you passed encloses all operations that lead from x to y.`);\n    }\n}\nexport { customGrad, variableGrads, valueAndGrad, valueAndGrads, grad, grads, };\n//# sourceMappingURL=gradients.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { KernelBackend } from './backends/backend';\nimport { Environment, setEnvironmentGlobal } from './environment';\nimport { getGlobalNamespace } from './global_util';\nimport { Add, Cast, Identity } from './kernel_names';\nimport { getGradient, getKernel, getKernelsForBackend } from './kernel_registry';\nimport { Profiler } from './profiler';\nimport { backpropagateGradients, getFilteredNodesXToY } from './tape';\nimport { setTensorTracker, Tensor, Variable } from './tensor';\nimport { getTensorsInContainer } from './tensor_util';\nimport * as util from './util';\nimport { bytesFromStringArray, makeOnesTypedArray, now, sizeFromShape } from './util';\nfunction isRegisteredKernelInvocation(kernelInvocation) {\n    return kernelInvocation.kernelName != null;\n}\nclass EngineState {\n    constructor() {\n        // Public since optimizers will use it.\n        this.registeredVariables = {};\n        this.nextTapeNodeId = 0;\n        this.numBytes = 0;\n        this.numTensors = 0;\n        this.numStringTensors = 0;\n        this.numDataBuffers = 0;\n        // Number of nested tf.grad() statements when computing higher-order\n        // gradients. E.g. `1` for first-order gradients and `2` for second-order\n        // gradients. Used to track if the tape should be removed after a backprop.\n        this.gradientDepth = 0;\n        // Number of nested kernel calls. When kernel depth is greater than 1, we turn\n        // off the tape.\n        this.kernelDepth = 0;\n        this.scopeStack = [];\n        /**\n         * Keeps track of the number of data moves during a kernel execution. We\n         * maintain a stack since kernels can call other kernels, recursively.\n         */\n        this.numDataMovesStack = [];\n        this.nextScopeId = 0;\n        this.tensorInfo = new WeakMap();\n        this.profiling = false;\n        this.activeProfile = {\n            newBytes: 0,\n            newTensors: 0,\n            peakBytes: 0,\n            kernels: [],\n            result: null,\n            get kernelNames() {\n                return Array.from(new Set(this.kernels.map(k => k.name)));\n            }\n        };\n    }\n    dispose() {\n        for (const variableName in this.registeredVariables) {\n            this.registeredVariables[variableName].dispose();\n        }\n    }\n}\nexport class Engine {\n    constructor(ENV) {\n        this.ENV = ENV;\n        this.registry = {};\n        this.registryFactory = {};\n        this.pendingBackendInitId = 0;\n        this.state = new EngineState();\n    }\n    async ready() {\n        if (this.pendingBackendInit != null) {\n            return this.pendingBackendInit.then(() => { });\n        }\n        if (this.backendInstance != null) {\n            return;\n        }\n        const sortedBackends = this.getSortedBackends();\n        for (let i = 0; i < sortedBackends.length; i++) {\n            const backendName = sortedBackends[i];\n            const success = await this.initializeBackend(backendName).success;\n            if (success) {\n                await this.setBackend(backendName);\n                return;\n            }\n        }\n        throw new Error(`Could not initialize any backends, all backend initializations ` +\n            `failed.`);\n    }\n    get backend() {\n        if (this.pendingBackendInit != null) {\n            throw new Error(`Backend '${this.backendName}' has not yet been initialized. Make ` +\n                `sure to await tf.ready() or await tf.setBackend() before calling ` +\n                `other methods`);\n        }\n        if (this.backendInstance == null) {\n            const { name, asyncInit } = this.initializeBackendsAndReturnBest();\n            if (asyncInit) {\n                throw new Error(`The highest priority backend '${name}' has not yet been ` +\n                    `initialized. Make sure to await tf.ready() or ` +\n                    `await tf.setBackend() before calling other methods`);\n            }\n            this.setBackend(name);\n        }\n        return this.backendInstance;\n    }\n    backendNames() {\n        return Object.keys(this.registryFactory);\n    }\n    findBackend(backendName) {\n        if (!(backendName in this.registry)) {\n            // If the backend hasn't been initialized but we have a registry entry for\n            // it, initialize it and return it.\n            if (backendName in this.registryFactory) {\n                const { asyncInit } = this.initializeBackend(backendName);\n                if (asyncInit) {\n                    // Backend is not ready yet.\n                    return null;\n                }\n            }\n            else {\n                return null;\n            }\n        }\n        return this.registry[backendName];\n    }\n    findBackendFactory(backendName) {\n        if (!(backendName in this.registryFactory)) {\n            return null;\n        }\n        return this.registryFactory[backendName].factory;\n    }\n    registerBackend(backendName, factory, priority = 1) {\n        if (backendName in this.registryFactory) {\n            console.warn(`${backendName} backend was already registered. ` +\n                `Reusing existing backend factory.`);\n            return false;\n        }\n        this.registryFactory[backendName] = { factory, priority };\n        return true;\n    }\n    async setBackend(backendName) {\n        if (this.registryFactory[backendName] == null) {\n            throw new Error(`Backend name '${backendName}' not found in registry`);\n        }\n        this.backendName = backendName;\n        if (this.registry[backendName] == null) {\n            this.backendInstance = null;\n            const { success, asyncInit } = this.initializeBackend(backendName);\n            const result = asyncInit ? await success : success;\n            if (!result) {\n                return false;\n            }\n        }\n        this.backendInstance = this.registry[backendName];\n        this.setupRegisteredKernels();\n        // Reset the profiler.\n        this.profiler = new Profiler(this.backendInstance);\n        return true;\n    }\n    setupRegisteredKernels() {\n        const kernels = getKernelsForBackend(this.backendName);\n        kernels.forEach(kernel => {\n            if (kernel.setupFunc != null) {\n                kernel.setupFunc(this.backendInstance);\n            }\n        });\n    }\n    disposeRegisteredKernels(backendName) {\n        const kernels = getKernelsForBackend(backendName);\n        kernels.forEach(kernel => {\n            if (kernel.disposeFunc != null) {\n                kernel.disposeFunc(this.registry[backendName]);\n            }\n        });\n    }\n    /**\n     * Initializes a backend by looking up the backend name in the factory\n     * registry and calling the factory method. Returns a boolean representing\n     * whether the initialization of the backend suceeded. Throws an error if\n     * there is no backend in the factory registry.\n     */\n    initializeBackend(backendName) {\n        const registryFactoryEntry = this.registryFactory[backendName];\n        if (registryFactoryEntry == null) {\n            throw new Error(`Cannot initialize backend ${backendName}, no registration found.`);\n        }\n        try {\n            const backend = registryFactoryEntry.factory();\n            /* Test if the factory returns a promise.\n            Done in a more liberal way than\n            previous 'Promise.resolve(backend)===backend'\n            as we needed to account for custom Promise\n            implementations (e.g. Angular) */\n            if (backend && !(backend instanceof KernelBackend) &&\n                typeof backend.then === 'function') {\n                const promiseId = ++this.pendingBackendInitId;\n                const success = backend\n                    .then(backendInstance => {\n                    // Outdated promise. Another backend was set in the meantime.\n                    if (promiseId < this.pendingBackendInitId) {\n                        return false;\n                    }\n                    this.registry[backendName] = backendInstance;\n                    this.pendingBackendInit = null;\n                    return true;\n                })\n                    .catch(err => {\n                    // Outdated promise. Another backend was set in the meantime.\n                    if (promiseId < this.pendingBackendInitId) {\n                        return false;\n                    }\n                    this.pendingBackendInit = null;\n                    console.warn(`Initialization of backend ${backendName} failed`);\n                    console.warn(err.stack || err.message);\n                    return false;\n                });\n                this.pendingBackendInit = success;\n                return { success, asyncInit: true };\n            }\n            else {\n                this.registry[backendName] = backend;\n                return { success: true, asyncInit: false };\n            }\n        }\n        catch (err) {\n            console.warn(`Initialization of backend ${backendName} failed`);\n            console.warn(err.stack || err.message);\n            return { success: false, asyncInit: false };\n        }\n    }\n    removeBackend(backendName) {\n        if (!(backendName in this.registryFactory)) {\n            throw new Error(`${backendName} backend not found in registry`);\n        }\n        if (this.backendName === backendName && this.pendingBackendInit != null) {\n            // There is a pending promise of the backend we want to remove. Make it\n            // obsolete.\n            this.pendingBackendInitId++;\n        }\n        if (backendName in this.registry) {\n            this.disposeRegisteredKernels(backendName);\n            this.registry[backendName].dispose();\n            delete this.registry[backendName];\n        }\n        delete this.registryFactory[backendName];\n        // Unset the backend if it is active.\n        if (this.backendName === backendName) {\n            this.pendingBackendInit = null;\n            this.backendName = null;\n            this.backendInstance = null;\n        }\n    }\n    getSortedBackends() {\n        if (Object.keys(this.registryFactory).length === 0) {\n            throw new Error('No backend found in registry.');\n        }\n        return Object.keys(this.registryFactory).sort((a, b) => {\n            // Highest priority comes first.\n            return this.registryFactory[b].priority -\n                this.registryFactory[a].priority;\n        });\n    }\n    initializeBackendsAndReturnBest() {\n        const sortedBackends = this.getSortedBackends();\n        for (let i = 0; i < sortedBackends.length; i++) {\n            const backendName = sortedBackends[i];\n            const { success, asyncInit } = this.initializeBackend(backendName);\n            if (asyncInit || success) {\n                return { name: backendName, asyncInit };\n            }\n        }\n        throw new Error(`Could not initialize any backends, all backend initializations ` +\n            `failed.`);\n    }\n    moveData(backend, dataId) {\n        const info = this.state.tensorInfo.get(dataId);\n        const srcBackend = info.backend;\n        const values = this.readSync(dataId);\n        const refCount = srcBackend.refCount(dataId);\n        // Delete the tensor from the old backend and move it to the new\n        // backend.\n        srcBackend.disposeData(dataId, true);\n        info.backend = backend;\n        backend.move(dataId, values, info.shape, info.dtype, refCount);\n        if (this.shouldCheckForMemLeaks()) {\n            // Track the number of moves during a kernel execution to correctly\n            // detect memory leaks.\n            this.state.numDataMovesStack[this.state.numDataMovesStack.length - 1]++;\n        }\n    }\n    tidy(nameOrFn, fn) {\n        let name = null;\n        if (fn == null) {\n            // Called with only 1 argument.\n            if (typeof nameOrFn !== 'function') {\n                throw new Error('Please provide a function to tidy()');\n            }\n            fn = nameOrFn;\n        }\n        else {\n            // Called with 2 arguments.\n            if (typeof nameOrFn !== 'string' && !(nameOrFn instanceof String)) {\n                throw new Error('When calling with two arguments, the first argument ' +\n                    'to tidy() must be a string');\n            }\n            if (typeof fn !== 'function') {\n                throw new Error('When calling with two arguments, the 2nd argument ' +\n                    'to tidy() must be a function');\n            }\n            name = nameOrFn;\n            // TODO(nsthorat,smilkov): Do operation logging and performance\n            // profiling.\n        }\n        let result;\n        return this.scopedRun(() => this.startScope(name), () => this.endScope(result), () => {\n            result = fn();\n            if (result instanceof Promise) {\n                console.error('Cannot return a Promise inside of tidy.');\n            }\n            return result;\n        });\n    }\n    scopedRun(start, end, f) {\n        start();\n        try {\n            const res = f();\n            end();\n            return res;\n        }\n        catch (ex) {\n            end();\n            throw ex;\n        }\n    }\n    nextTensorId() {\n        return Engine.nextTensorId++;\n    }\n    nextVariableId() {\n        return Engine.nextVariableId++;\n    }\n    /**\n     * This method is called instead of the public-facing tensor.clone() when\n     * saving a tensor for backwards pass. It makes sure to add the clone\n     * operation to the tape regardless of being called inside a kernel\n     * execution.\n     */\n    clone(x) {\n        const y = ENGINE.runKernel(Identity, { x });\n        const inputs = { x };\n        const grad = (dy) => ({\n            x: () => {\n                const dtype = 'float32';\n                const gradInputs = { x: dy };\n                const attrs = { dtype };\n                return ENGINE.runKernel(Cast, gradInputs, \n                // tslint:disable-next-line: no-unnecessary-type-assertion\n                attrs);\n            }\n        });\n        const saved = [];\n        this.addTapeNode(this.state.activeScope.name, inputs, [y], grad, saved, {});\n        return y;\n    }\n    /**\n     * Execute a kernel with the given name and return the output tensor.\n     *\n     * @param kernelName The name of the kernel to execute.\n     * @param inputs A map of input names to tensors.\n     * @param attrs A map of attribute names to their values. An attribute is a\n     *     primitive (non-tensor) input to the kernel.\n     * @param inputsToSave A list of tensors, inputs to save for the backprop\n     *     computation.\n     * @param outputsToSave A list of booleans, specifying which output to save\n     *     for the backprop computation. These are booleans since the output\n     * tensors are not visible to the user.\n     */\n    runKernel(kernelName, inputs, attrs) {\n        const hasKernel = getKernel(kernelName, this.backendName) != null;\n        if (!hasKernel) {\n            throw new Error(`Kernel '${kernelName}' not registered for backend '${this.backendName}'`);\n        }\n        return this.runKernelFunc({ kernelName, inputs, attrs });\n    }\n    shouldCheckForMemLeaks() {\n        return this.ENV.getBool('IS_TEST');\n    }\n    checkKernelForMemLeak(kernelName, numDataIdsBefore, outInfos) {\n        const numDataIdsAfter = this.backend.numDataIds();\n        // Count the number of data ids associated with the result of the kernel.\n        let numOutputDataIds = 0;\n        outInfos.forEach(info => {\n            // Complex numbers allocate 3 data ids, one for 'real', one for\n            // 'imaginary', and one for the container that holds the former two.\n            numOutputDataIds += (info.dtype === 'complex64' ? 3 : 1);\n        });\n        // Account for the number of moves during kernel execution. A \"data move\"\n        // can happen in the middle of a kernel execution, placing a new (key,value)\n        // pair in the data storage. Since data moves have net zero effect (we\n        // always remove the data from the old backend), we have to cancel them out\n        // when detecting memory leaks.\n        const numMoves = this.state.numDataMovesStack[this.state.numDataMovesStack.length - 1];\n        const dataIdsLeaked = numDataIdsAfter - numDataIdsBefore - numOutputDataIds - numMoves;\n        if (dataIdsLeaked > 0) {\n            throw new Error(`Backend '${this.backendName}' has an internal memory leak ` +\n                `(${dataIdsLeaked} data ids) after running '${kernelName}'`);\n        }\n    }\n    /**\n     * Internal helper method to execute a kernel Func\n     *\n     * Use `runKernel` to execute kernels from outside of engine.\n     */\n    runKernelFunc(kernelParams) {\n        let outputs;\n        let saved = [];\n        const isTapeOn = this.isTapeOn();\n        const startingBytecount = this.state.numBytes;\n        const startingNumTensors = this.state.numTensors;\n        if (this.shouldCheckForMemLeaks()) {\n            this.state.numDataMovesStack.push(0);\n        }\n        let kernelFunc;\n        if (this.backendName == null) {\n            // backend has not been initialized yet (backend initialization is lazy\n            // can be deferred until an op/ kernel is run).\n            // The below getter has side effects that will try to initialize the\n            // backend and set properties like this.backendName\n            // tslint:disable-next-line: no-unused-expression\n            this.backend;\n        }\n        let out;\n        const kernelOrScopeName = isRegisteredKernelInvocation(kernelParams) ?\n            kernelParams.kernelName :\n            this.state.activeScope != null ? this.state.activeScope.name : '';\n        // Create the kernelFunc from either a registered kernel OR passed in\n        // forward/backward functions (used by custom grad). In this context a\n        // kernelFunc wraps a kernel implementation with some bookkeeping.\n        if (isRegisteredKernelInvocation(kernelParams)) {\n            const { kernelName, inputs, attrs } = kernelParams;\n            if (this.backendName == null) {\n                // backend has not been initialized yet (backend initialization is lazy\n                // can be deferred until an op/ kernel is run).\n                // The below getter has side effects that will try to initialize the\n                // backend and set properties like this.backendName\n                // tslint:disable-next-line: no-unused-expression\n                this.backend;\n            }\n            const kernel = getKernel(kernelName, this.backendName);\n            util.assert(kernel != null, () => `Cannot find registered kernel '${kernelName}' for backend '${this.backendName}'`);\n            kernelFunc = () => {\n                const numDataIdsBefore = this.backend.numDataIds();\n                out = kernel.kernelFunc({ inputs, attrs, backend: this.backend });\n                const outInfos = Array.isArray(out) ? out : [out];\n                if (this.shouldCheckForMemLeaks()) {\n                    this.checkKernelForMemLeak(kernelName, numDataIdsBefore, outInfos);\n                }\n                const outTensors = outInfos.map((outInfo) => {\n                    // todo (yassogba) remove this option (Tensor) when node backend\n                    // methods have been modularized and they all return tensorInfo.\n                    // TensorInfos do not have a rank attribute.\n                    if (outInfo.rank != null) {\n                        return outInfo;\n                    }\n                    const { dataId, shape, dtype } = outInfo;\n                    return this.makeTensorFromDataId(dataId, shape, dtype);\n                });\n                // Save any required inputs and outputs.\n                // Do not save unless we are recording to the tape. Otherwise it would\n                // cause a mem leak since there would be no backprop for these tensors\n                // (which would otherwise dispose them).\n                if (isTapeOn) {\n                    const tensorsToSave = this.getTensorsForGradient(kernelName, inputs, outTensors);\n                    saved = this.saveTensorsForBackwardMode(tensorsToSave);\n                }\n                return outTensors;\n            };\n        }\n        else {\n            const { forwardFunc } = kernelParams;\n            // Running a customGrad op.\n            const saveFunc = (tensors) => {\n                // Do not save unless we are recording to the tape. Otherwise it would\n                // cause a mem leak since we would never run backprop, which disposes\n                // the kept tensors.\n                if (!isTapeOn) {\n                    return;\n                }\n                saved = tensors.map(tensor => this.keep(this.clone(tensor)));\n            };\n            kernelFunc = () => {\n                const numDataIdsBefore = this.backend.numDataIds();\n                out = this.tidy(() => forwardFunc(this.backend, saveFunc));\n                const outs = (Array.isArray(out) ? out : [out]);\n                if (this.shouldCheckForMemLeaks()) {\n                    // Scope name is used to print a more helpful error message if needed.\n                    this.checkKernelForMemLeak(kernelOrScopeName, numDataIdsBefore, outs);\n                }\n                return outs;\n            };\n        }\n        //\n        // Run the kernelFunc. Optionally profiling it.\n        //\n        const { inputs, attrs } = kernelParams;\n        const backwardsFunc = isRegisteredKernelInvocation(kernelParams) ?\n            null :\n            kernelParams.backwardsFunc;\n        let kernelProfile;\n        this.scopedRun(\n        // Stop recording to a tape when running a kernel.\n        () => this.state.kernelDepth++, () => this.state.kernelDepth--, () => {\n            if (!this.ENV.getBool('DEBUG') && !this.state.profiling) {\n                outputs = kernelFunc();\n            }\n            else {\n                kernelProfile = this.profiler.profileKernel(kernelOrScopeName, inputs, () => kernelFunc());\n                if (this.ENV.getBool('DEBUG')) {\n                    this.profiler.logKernelProfile(kernelProfile);\n                }\n                outputs = kernelProfile.outputs;\n            }\n        });\n        if (isTapeOn) {\n            this.addTapeNode(kernelOrScopeName, inputs, outputs, backwardsFunc, saved, attrs);\n        }\n        if (this.state.profiling) {\n            this.state.activeProfile.kernels.push({\n                name: kernelOrScopeName,\n                bytesAdded: this.state.numBytes - startingBytecount,\n                totalBytesSnapshot: this.state.numBytes,\n                tensorsAdded: this.state.numTensors - startingNumTensors,\n                totalTensorsSnapshot: this.state.numTensors,\n                inputShapes: Object.keys(inputs).map(key => inputs[key] != null ? inputs[key].shape : null),\n                outputShapes: outputs.map(item => item.shape),\n                kernelTimeMs: kernelProfile.timeMs,\n                extraInfo: kernelProfile.extraInfo\n            });\n        }\n        return (Array.isArray(out) ? outputs : outputs[0]);\n    }\n    /**\n     * Saves tensors used in forward mode for use in backward mode.\n     *\n     * @param tensors the list of tensors to save.\n     */\n    saveTensorsForBackwardMode(tensors) {\n        const saved = tensors.map(tensor => this.keep(this.clone(tensor)));\n        return saved;\n    }\n    /**\n     * Returns a list of tensors to save for a given gradient calculation.\n     *\n     * @param kernelName name of kernel to look up gradient for.\n     * @param inputs a map of input tensors.\n     * @param outputs an array of output tensors from forward mode of kernel.\n     */\n    getTensorsForGradient(kernelName, inputs, outputs) {\n        const gradConfig = getGradient(kernelName);\n        if (gradConfig != null) {\n            const inputsToSave = gradConfig.inputsToSave || [];\n            const outputsToSave = gradConfig.outputsToSave || [];\n            // If saveAllInputs is true, all inputs will be saved. Otherwise, inputs\n            // specified in inputsToSave will be saved.\n            let inputTensorsToSave;\n            if (gradConfig.saveAllInputs) {\n                util.assert(Array.isArray(inputs), () => 'saveAllInputs is true, expected inputs to be an array.');\n                inputTensorsToSave = Object.keys(inputs).map((key) => inputs[key]);\n            }\n            else {\n                inputTensorsToSave = inputsToSave.map((inputName) => inputs[inputName]);\n            }\n            const outputTensorsToSave = outputs.filter((_, i) => outputsToSave[i]);\n            return inputTensorsToSave.concat(outputTensorsToSave);\n        }\n        // We return an empty list rather than throw an error because the kernel we\n        // are looking up may not actually be relevant to backproping through the\n        // overall function\n        //\n        // See 'does not error if irrelevant (pruned) ops are missing grads' test\n        // in gradients_test.ts for an example.\n        return [];\n    }\n    /**\n     * Internal method used by public APIs for tensor creation. Makes a new\n     * tensor with the provided shape, dtype and values. It always\n     * creates a new data id and writes the values to the underlying backend.\n     */\n    makeTensor(values, shape, dtype, backend) {\n        if (values == null) {\n            throw new Error('Values passed to engine.makeTensor() are null');\n        }\n        dtype = dtype || 'float32';\n        backend = backend || this.backend;\n        let backendVals = values;\n        if (dtype === 'string' && util.isString(values[0])) {\n            backendVals = values.map(d => util.encodeString(d));\n        }\n        const dataId = backend.write(backendVals, shape, dtype);\n        const t = new Tensor(shape, dtype, dataId, this.nextTensorId());\n        this.trackTensor(t, backend);\n        // Count bytes for string tensors.\n        if (dtype === 'string') {\n            const info = this.state.tensorInfo.get(dataId);\n            const newBytes = bytesFromStringArray(backendVals);\n            this.state.numBytes += newBytes - info.bytes;\n            info.bytes = newBytes;\n        }\n        return t;\n    }\n    /**\n     * Internal method used by backends. Makes a new tensor\n     * that is a wrapper around an existing data id. It doesn't create\n     * a new data id, only increments the ref count used in memory tracking.\n     */\n    makeTensorFromDataId(dataId, shape, dtype, backend) {\n        dtype = dtype || 'float32';\n        const t = new Tensor(shape, dtype, dataId, this.nextTensorId());\n        this.trackTensor(t, backend);\n        return t;\n    }\n    makeVariable(initialValue, trainable = true, name, dtype) {\n        name = name || this.nextVariableId().toString();\n        if (dtype != null && dtype !== initialValue.dtype) {\n            initialValue = initialValue.cast(dtype);\n        }\n        const v = new Variable(initialValue, trainable, name, this.nextTensorId());\n        if (this.state.registeredVariables[v.name] != null) {\n            throw new Error(`Variable with name ${v.name} was already registered`);\n        }\n        this.state.registeredVariables[v.name] = v;\n        this.incRef(v, this.backend);\n        return v;\n    }\n    trackTensor(a, backend) {\n        this.state.numTensors++;\n        if (a.dtype === 'string') {\n            this.state.numStringTensors++;\n        }\n        // Bytes for complex numbers are counted by their components. Bytes for\n        // string tensors are counted when writing values.\n        let bytes = 0;\n        if (a.dtype !== 'complex64' && a.dtype !== 'string') {\n            bytes = a.size * util.bytesPerElement(a.dtype);\n        }\n        this.state.numBytes += bytes;\n        if (!this.state.tensorInfo.has(a.dataId)) {\n            this.state.numDataBuffers++;\n            this.state.tensorInfo.set(a.dataId, {\n                backend: backend || this.backend,\n                dtype: a.dtype,\n                shape: a.shape,\n                bytes\n            });\n        }\n        if (!(a instanceof Variable)) {\n            this.track(a);\n        }\n    }\n    // Track the tensor by dataId and increase the refCount for the dataId in the\n    // backend.\n    // TODO(pyu10055): This is currently used by makeVariable method, to increase\n    // refCount on the backend for the dataId. It can potentially be replaced with\n    // Identity op indead of calling backend directly.\n    incRef(a, backend) {\n        this.trackTensor(a, backend);\n        this.backend.incRef(a.dataId);\n    }\n    removeDataId(dataId, backend) {\n        if (this.state.tensorInfo.has(dataId) &&\n            this.state.tensorInfo.get(dataId).backend === backend) {\n            this.state.tensorInfo.delete(dataId);\n            this.state.numDataBuffers--;\n        }\n    }\n    disposeTensor(a) {\n        if (!this.state.tensorInfo.has(a.dataId)) {\n            return;\n        }\n        const info = this.state.tensorInfo.get(a.dataId);\n        this.state.numTensors--;\n        if (a.dtype === 'string') {\n            this.state.numStringTensors--;\n            this.state.numBytes -= info.bytes;\n        }\n        // Don't count bytes for complex numbers as they are counted by their\n        // components.\n        if (a.dtype !== 'complex64' && a.dtype !== 'string') {\n            const bytes = a.size * util.bytesPerElement(a.dtype);\n            this.state.numBytes -= bytes;\n        }\n        // Remove the reference to dataId if backend dispose the data successfully\n        if (info.backend.disposeData(a.dataId)) {\n            this.removeDataId(a.dataId, info.backend);\n        }\n        // TODO(nsthorat): Construct an error and save the stack trace for\n        // debugging when in debug mode. Creating a stack trace is too expensive\n        // to do unconditionally.\n    }\n    disposeVariables() {\n        for (const varName in this.state.registeredVariables) {\n            const v = this.state.registeredVariables[varName];\n            this.disposeVariable(v);\n        }\n    }\n    disposeVariable(v) {\n        this.disposeTensor(v);\n        if (this.state.registeredVariables[v.name] != null) {\n            delete this.state.registeredVariables[v.name];\n        }\n    }\n    memory() {\n        const info = this.backend.memory();\n        info.numTensors = this.state.numTensors;\n        info.numDataBuffers = this.state.numDataBuffers;\n        info.numBytes = this.state.numBytes;\n        if (this.state.numStringTensors > 0) {\n            info.unreliable = true;\n            if (info.reasons == null) {\n                info.reasons = [];\n            }\n            info.reasons.push('Memory usage by string tensors is approximate ' +\n                '(2 bytes per character)');\n        }\n        return info;\n    }\n    async profile(query) {\n        this.state.profiling = true;\n        const startBytes = this.state.numBytes;\n        const startNumTensors = this.state.numTensors;\n        this.state.activeProfile.kernels = [];\n        this.state.activeProfile.result = await query();\n        this.state.profiling = false;\n        this.state.activeProfile.peakBytes = Math.max(...this.state.activeProfile.kernels.map(d => d.totalBytesSnapshot));\n        this.state.activeProfile.newBytes = this.state.numBytes - startBytes;\n        this.state.activeProfile.newTensors =\n            this.state.numTensors - startNumTensors;\n        for (const kernel of this.state.activeProfile.kernels) {\n            kernel.kernelTimeMs = await kernel.kernelTimeMs;\n            kernel.extraInfo = await kernel.extraInfo;\n        }\n        return this.state.activeProfile;\n    }\n    isTapeOn() {\n        return this.state.gradientDepth > 0 && this.state.kernelDepth === 0;\n    }\n    addTapeNode(kernelName, inputs, outputs, gradientsFunc, saved, attrs) {\n        const tapeNode = { id: this.state.nextTapeNodeId++, kernelName, inputs, outputs, saved };\n        const gradConfig = getGradient(kernelName);\n        if (gradConfig != null) {\n            gradientsFunc = gradConfig.gradFunc;\n        }\n        if (gradientsFunc != null) {\n            tapeNode.gradient = (dys) => {\n                // TODO(smilkov): To optimize back-prop, pass dys that are not used in\n                // the backprop graph to the user as null instead of zeros\n                dys = dys.map((dy, i) => {\n                    if (dy == null) {\n                        const output = outputs[i];\n                        const vals = util.makeZerosTypedArray(output.size, output.dtype);\n                        return this.makeTensor(vals, output.shape, output.dtype);\n                    }\n                    return dy;\n                });\n                // Grad functions of ops with single outputs expect a dy, while ops\n                // with multiple outputs expect dys (array of dy).\n                return gradientsFunc(dys.length > 1 ? dys : dys[0], saved, attrs);\n            };\n        }\n        this.state.activeTape.push(tapeNode);\n    }\n    keep(result) {\n        result.kept = true;\n        return result;\n    }\n    startTape() {\n        if (this.state.gradientDepth === 0) {\n            this.state.activeTape = [];\n        }\n        this.state.gradientDepth++;\n    }\n    endTape() {\n        this.state.gradientDepth--;\n    }\n    /**\n     * Start a scope. Use this with endScope() to achieve the same functionality\n     * as scope() without the need for a function closure.\n     */\n    startScope(name) {\n        const scopeInfo = {\n            track: [],\n            name: 'unnamed scope',\n            id: this.state.nextScopeId++\n        };\n        if (name) {\n            scopeInfo.name = name;\n        }\n        this.state.scopeStack.push(scopeInfo);\n        this.state.activeScope = scopeInfo;\n    }\n    /**\n     * End a scope. Use this with startScope() to achieve the same functionality\n     * as scope() without the need for a function closure.\n     */\n    endScope(result) {\n        const tensorsToTrackInParent = getTensorsInContainer(result);\n        const tensorsToTrackInParentSet = new Set(tensorsToTrackInParent.map(t => t.id));\n        // Dispose the arrays tracked in this scope.\n        for (let i = 0; i < this.state.activeScope.track.length; i++) {\n            const tensor = this.state.activeScope.track[i];\n            if (!tensor.kept && !tensorsToTrackInParentSet.has(tensor.id)) {\n                tensor.dispose();\n            }\n        }\n        const oldScope = this.state.scopeStack.pop();\n        this.state.activeScope = this.state.scopeStack.length === 0 ?\n            null :\n            this.state.scopeStack[this.state.scopeStack.length - 1];\n        // Track the current result in the parent scope.\n        tensorsToTrackInParent.forEach(tensor => {\n            // Only track the tensor if was allocated in the inner scope and is not\n            // globally kept.\n            if (!tensor.kept && tensor.scopeId === oldScope.id) {\n                this.track(tensor);\n            }\n        });\n    }\n    /**\n     * Returns gradients of `f` with respect to each of the `xs`. The gradients\n     * returned are of the same length as `xs`, but some might be null if `f`\n     * was not a function of that `x`. It also takes optional dy to multiply the\n     * gradient, which defaults to `1`.\n     */\n    gradients(f, xs, dy, allowNoGradients = false) {\n        util.assert(xs.length > 0, () => 'gradients() received an empty list of xs.');\n        if (dy != null && dy.dtype !== 'float32') {\n            throw new Error(`dy must have 'float32' dtype, but has '${dy.dtype}'`);\n        }\n        const y = this.scopedRun(() => this.startTape(), () => this.endTape(), () => this.tidy('forward', f));\n        util.assert(y instanceof Tensor, () => 'The result y returned by f() must be a tensor.');\n        // Filter out the nodes that don't connect x => y.\n        const filteredTape = getFilteredNodesXToY(this.state.activeTape, xs, y);\n        if (!allowNoGradients && filteredTape.length === 0 && xs.length > 0) {\n            throw new Error('Cannot compute gradient of y=f(x) with respect to x. Make sure ' +\n                'that the f you passed encloses all operations that lead from x ' +\n                'to y.');\n        }\n        return this.tidy('backward', () => {\n            const accumulatedGradientMap = {};\n            accumulatedGradientMap[y.id] = (dy == null) ? ones(y.shape) : dy;\n            // Backprop gradients through the filtered nodes.\n            backpropagateGradients(accumulatedGradientMap, filteredTape, \n            // Pass the tidy function to avoid circular dep with `tape.ts`.\n            f => this.tidy(f), \n            // Pass an add function to avoide a circular dep with `tape.ts`.\n            add);\n            const grads = xs.map(x => accumulatedGradientMap[x.id]);\n            if (this.state.gradientDepth === 0) {\n                // This means that we are not computing higher-order gradients\n                // and can clean up the tape.\n                this.state.activeTape.forEach(node => {\n                    for (const tensor of node.saved) {\n                        tensor.dispose();\n                    }\n                });\n                this.state.activeTape = null;\n            }\n            return { value: y, grads };\n        });\n    }\n    customGrad(f) {\n        util.assert(util.isFunction(f), () => 'The f passed in customGrad(f) must be a function.');\n        return (...inputs) => {\n            util.assert(inputs.every(t => t instanceof Tensor), () => 'The args passed in customGrad(f)(x1, x2,...) must all be ' +\n                'tensors');\n            let res;\n            const inputMap = {};\n            inputs.forEach((input, i) => {\n                inputMap[i] = input;\n            });\n            const forwardFunc = (_, save) => {\n                res = f(...[...inputs, save]);\n                util.assert(res.value instanceof Tensor, () => 'The function f passed in customGrad(f) must return an ' +\n                    'object where `obj.value` is a tensor');\n                util.assert(util.isFunction(res.gradFunc), () => 'The function f passed in customGrad(f) must return an ' +\n                    'object where `obj.gradFunc` is a function.');\n                return res.value;\n            };\n            const backwardsFunc = (dy, saved) => {\n                const gradRes = res.gradFunc(dy, saved);\n                const grads = Array.isArray(gradRes) ? gradRes : [gradRes];\n                util.assert(grads.length === inputs.length, () => 'The function f passed in customGrad(f) must return an ' +\n                    'object where `obj.gradFunc` is a function that returns ' +\n                    'the same number of tensors as inputs passed to f(...).');\n                util.assert(grads.every(t => t instanceof Tensor), () => 'The function f passed in customGrad(f) must return an ' +\n                    'object where `obj.gradFunc` is a function that returns ' +\n                    'a list of only tensors.');\n                const gradMap = {};\n                grads.forEach((grad, i) => {\n                    gradMap[i] = () => grad;\n                });\n                return gradMap;\n            };\n            return this.runKernelFunc({\n                forwardFunc,\n                backwardsFunc,\n                inputs: inputMap,\n            });\n        };\n    }\n    readSync(dataId) {\n        // Route the read to the correct backend.\n        const info = this.state.tensorInfo.get(dataId);\n        return info.backend.readSync(dataId);\n    }\n    read(dataId) {\n        // Route the read to the correct backend.\n        const info = this.state.tensorInfo.get(dataId);\n        return info.backend.read(dataId);\n    }\n    async time(query) {\n        const start = now();\n        const timingInfo = await this.backend.time(query);\n        timingInfo.wallMs = now() - start;\n        return timingInfo;\n    }\n    /**\n     * Tracks a Tensor in the current scope to be automatically cleaned up\n     * when the current scope ends, and returns the value.\n     *\n     * @param result The Tensor to track in the current scope.\n     */\n    track(result) {\n        if (this.state.activeScope != null) {\n            result.scopeId = this.state.activeScope.id;\n            this.state.activeScope.track.push(result);\n        }\n        return result;\n    }\n    get registeredVariables() {\n        return this.state.registeredVariables;\n    }\n    /**\n     * Resets the engine state. Removes all backends but does not remove\n     * registered backend factories.\n     */\n    reset() {\n        // Make any pending promise obsolete.\n        this.pendingBackendInitId++;\n        this.state.dispose();\n        this.ENV.reset();\n        this.state = new EngineState();\n        for (const backendName in this.registry) {\n            this.disposeRegisteredKernels(backendName);\n            this.registry[backendName].dispose();\n            delete this.registry[backendName];\n        }\n        this.backendName = null;\n        this.backendInstance = null;\n        this.pendingBackendInit = null;\n    }\n}\nEngine.nextTensorId = 0;\nEngine.nextVariableId = 0;\nfunction ones(shape) {\n    const values = makeOnesTypedArray(sizeFromShape(shape), 'float32');\n    return ENGINE.makeTensor(values, shape, 'float32');\n}\nexport function getOrMakeEngine() {\n    const ns = getGlobalNamespace();\n    if (ns._tfengine == null) {\n        const environment = new Environment(ns);\n        ns._tfengine = new Engine(environment);\n    }\n    setEnvironmentGlobal(ns._tfengine.ENV);\n    // Tell the current tensor interface that the global engine is responsible\n    // for tracking.\n    setTensorTracker(() => ns._tfengine);\n    return ns._tfengine;\n}\nexport const ENGINE = getOrMakeEngine();\n/**\n * A implementation of the add op for use within engine and tape.\n *\n * This allows us to avoid a circular dependency between add.ts and engine.\n * It is exported to be available in tape tests.\n */\nexport function add(a, b) {\n    // We duplicate Add here to avoid a circular dependency with add.ts.\n    const inputs = { a, b };\n    return ENGINE.runKernel(Add, inputs);\n}\n//# sourceMappingURL=engine.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nexport class IORouterRegistry {\n    constructor() {\n        this.saveRouters = [];\n        this.loadRouters = [];\n    }\n    static getInstance() {\n        if (IORouterRegistry.instance == null) {\n            IORouterRegistry.instance = new IORouterRegistry();\n        }\n        return IORouterRegistry.instance;\n    }\n    /**\n     * Register a save-handler router.\n     *\n     * @param saveRouter A function that maps a URL-like string onto an instance\n     * of `IOHandler` with the `save` method defined or `null`.\n     */\n    static registerSaveRouter(saveRouter) {\n        IORouterRegistry.getInstance().saveRouters.push(saveRouter);\n    }\n    /**\n     * Register a load-handler router.\n     *\n     * @param loadRouter A function that maps a URL-like string onto an instance\n     * of `IOHandler` with the `load` method defined or `null`.\n     */\n    static registerLoadRouter(loadRouter) {\n        IORouterRegistry.getInstance().loadRouters.push(loadRouter);\n    }\n    /**\n     * Look up IOHandler for saving, given a URL-like string.\n     *\n     * @param url\n     * @returns If only one match is found, an instance of IOHandler with the\n     * `save` method defined. If no match is found, `null`.\n     * @throws Error, if more than one match is found.\n     */\n    static getSaveHandlers(url) {\n        return IORouterRegistry.getHandlers(url, 'save');\n    }\n    /**\n     * Look up IOHandler for loading, given a URL-like string.\n     *\n     * @param url\n     * @param loadOptions Optional, custom load options.\n     * @returns All valid handlers for `url`, given the currently registered\n     *   handler routers.\n     */\n    static getLoadHandlers(url, loadOptions) {\n        return IORouterRegistry.getHandlers(url, 'load', loadOptions);\n    }\n    static getHandlers(url, handlerType, loadOptions) {\n        const validHandlers = [];\n        const routers = handlerType === 'load' ?\n            IORouterRegistry.getInstance().loadRouters :\n            IORouterRegistry.getInstance().saveRouters;\n        routers.forEach(router => {\n            const handler = router(url, loadOptions);\n            if (handler !== null) {\n                validHandlers.push(handler);\n            }\n        });\n        return validHandlers;\n    }\n}\nexport const registerSaveRouter = (loudRouter) => IORouterRegistry.registerSaveRouter(loudRouter);\nexport const registerLoadRouter = (loudRouter) => IORouterRegistry.registerLoadRouter(loudRouter);\nexport const getSaveHandlers = (url) => IORouterRegistry.getSaveHandlers(url);\nexport const getLoadHandlers = (url, loadOptions) => IORouterRegistry.getLoadHandlers(url, loadOptions);\n//# sourceMappingURL=router_registry.js.map","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { env } from './environment';\nimport { getGlobal } from './global_util';\nconst kernelRegistry = getGlobal('kernelRegistry', () => new Map());\nconst gradRegistry = getGlobal('gradRegistry', () => new Map());\n/**\n * Returns the kernel function (code) associated with the provided names.\n *\n * @param kernelName The official name of the kernel.\n * @param backendName The official name of the backend.\n */\nexport function getKernel(kernelName, backendName) {\n    const key = makeKey(kernelName, backendName);\n    return kernelRegistry.get(key);\n}\n/**\n * Returns the registered gradient info associated with the provided kernel.\n * @param kernelName The official TF kernel name.\n */\nexport function getGradient(kernelName) {\n    return gradRegistry.get(kernelName);\n}\nexport function getKernelsForBackend(backendName) {\n    const it = kernelRegistry.entries();\n    const result = [];\n    while (true) {\n        const { done, value } = it.next();\n        if (done) {\n            break;\n        }\n        const [key, config] = value;\n        const [backend,] = key.split('_');\n        if (backend === backendName) {\n            result.push(config);\n        }\n    }\n    return result;\n}\n/**\n * Registers the function (forward pass) for the kernel in a global registry.\n *\n * @param config A config object with the following properties:\n * - `kernelName` The official name of the kernel.\n * - `backendName` The official name of the backend.\n * - `kernelFunc` The function to run during the forward pass of the kernel.\n * - `setupFunc` Optional. Gets called once, after the backend initializes.\n * - `disposeFunc` Optional. Gets called once, right before the backend is\n * disposed.\n */\nexport function registerKernel(config) {\n    const { kernelName, backendName } = config;\n    const key = makeKey(kernelName, backendName);\n    if (kernelRegistry.has(key)) {\n        console.warn(`The kernel '${kernelName}' for backend ` +\n            `'${backendName}' is already registered`);\n    }\n    kernelRegistry.set(key, config);\n}\n/**\n * Registers a gradient function for a given kernel in the global registry,\n * to be used during the back-propagation of that kernel.\n *\n * @param config An object with the following properties:\n * - `kernelName` The name of the kernel that the gradient function is for.\n * - `gradFunc` The function to run during back-propagation.\n */\nexport function registerGradient(config) {\n    const { kernelName } = config;\n    if (gradRegistry.has(kernelName)) {\n        // TODO (yassogba) after 3.0 assess whether we need to keep this gated\n        // to debug mode.\n        if (env().getBool('DEBUG')) {\n            console.warn(`Overriding the gradient for '${kernelName}'`);\n        }\n    }\n    gradRegistry.set(kernelName, config);\n}\n/**\n * Removes the kernel function from the registry.\n *\n * @param kernelName The official name of the kernel.\n * @param backendName The official name of the backend.\n *\n */\nexport function unregisterKernel(kernelName, backendName) {\n    const key = makeKey(kernelName, backendName);\n    if (!kernelRegistry.has(key)) {\n        throw new Error(`The kernel '${kernelName}' for backend ` +\n            `'${backendName}' is not registered`);\n    }\n    kernelRegistry.delete(key);\n}\n/** Removes the registered gradient from the global registry. */\nexport function unregisterGradient(kernelName) {\n    if (!gradRegistry.has(kernelName)) {\n        throw new Error(`The gradient '${kernelName}' for backend is not registered`);\n    }\n    gradRegistry.delete(kernelName);\n}\n/**\n * Finds kernels that have already been registered to a backend and re-registers\n * them for a new backend. Useful for registering custom backends.\n * @param registeredBackendName Already registered backend.\n * @param newBackendName New backend.\n */\nexport function copyRegisteredKernels(registeredBackendName, newBackendName) {\n    const kernels = getKernelsForBackend(registeredBackendName);\n    kernels.forEach(kernelConfig => {\n        const newKernelConfig = Object.assign({}, kernelConfig, { backendName: newBackendName });\n        registerKernel(newKernelConfig);\n    });\n}\nfunction makeKey(kernelName, backendName) {\n    return `${backendName}_${kernelName}`;\n}\n//# sourceMappingURL=kernel_registry.js.map","export const Abs = 'Abs';\nexport const Acos = 'Acos';\nexport const Acosh = 'Acosh';\nexport const Add = 'Add';\nexport const AddN = 'AddN';\nexport const All = 'All';\nexport const Any = 'Any';\nexport const ArgMax = 'ArgMax';\nexport const ArgMin = 'ArgMin';\nexport const Asin = 'Asin';\nexport const Asinh = 'Asinh';\nexport const Atan = 'Atan';\nexport const Atanh = 'Atanh';\nexport const Atan2 = 'Atan2';\nexport const AvgPool = 'AvgPool';\nexport const AvgPoolGrad = 'AvgPoolGrad';\nexport const AvgPool3D = 'AvgPool3D';\nexport const AvgPool3DGrad = 'AvgPool3DGrad';\nexport const BatchMatMul = 'BatchMatMul';\nexport const BatchToSpaceND = 'BatchToSpaceND';\nexport const Bincount = 'Bincount';\nexport const BroadcastTo = 'BroadcastTo';\nexport const Cast = 'Cast';\nexport const Ceil = 'Ceil';\nexport const ClipByValue = 'ClipByValue';\nexport const Complex = 'Complex';\nexport const ComplexAbs = 'ComplexAbs';\nexport const Concat = 'Concat';\nexport const Conv2D = 'Conv2D';\nexport const Conv2DBackpropFilter = 'Conv2DBackpropFilter';\nexport const Conv2DBackpropInput = 'Conv2DBackpropInput';\nexport const Conv3D = 'Conv3D';\nexport const Conv3DBackpropFilterV2 = 'Conv3DBackpropFilterV2';\nexport const Conv3DBackpropInputV2 = 'Conv3DBackpropInputV2';\nexport const Cos = 'Cos';\nexport const Cosh = 'Cosh';\nexport const Cumsum = 'Cumsum';\nexport const CropAndResize = 'CropAndResize';\nexport const DenseBincount = 'DenseBincount';\nexport const DepthToSpace = 'DepthToSpace';\nexport const DepthwiseConv2dNative = 'DepthwiseConv2dNative';\nexport const DepthwiseConv2dNativeBackpropFilter = 'DepthwiseConv2dNativeBackpropFilter';\nexport const DepthwiseConv2dNativeBackpropInput = 'DepthwiseConv2dNativeBackpropInput';\nexport const Diag = 'Diag';\nexport const Dilation2D = 'Dilation2D';\nexport const Dilation2DBackpropInput = 'Dilation2DBackpropInput';\nexport const Dilation2DBackpropFilter = 'Dilation2DBackpropFilter';\nexport const RealDiv = 'RealDiv';\nexport const Einsum = 'Einsum';\nexport const Elu = 'Elu';\nexport const EluGrad = 'EluGrad';\nexport const Erf = 'Erf';\nexport const Equal = 'Equal';\nexport const Exp = 'Exp';\nexport const ExpandDims = 'ExpandDims';\nexport const Expm1 = 'Expm1';\nexport const FFT = 'FFT';\nexport const Fill = 'Fill';\nexport const FlipLeftRight = 'FlipLeftRight';\nexport const Floor = 'Floor';\nexport const FloorDiv = 'FloorDiv';\nexport const FusedBatchNorm = 'FusedBatchNorm';\nexport const GatherV2 = 'GatherV2';\nexport const GatherNd = 'GatherNd';\nexport const Greater = 'Greater';\nexport const GreaterEqual = 'GreaterEqual';\nexport const Identity = 'Identity';\nexport const IFFT = 'IFFT';\nexport const Imag = 'Imag';\nexport const IsFinite = 'IsFinite';\nexport const IsInf = 'IsInf';\nexport const IsNan = 'IsNan';\nexport const LeakyRelu = 'LeakyRelu';\nexport const Less = 'Less';\nexport const LessEqual = 'LessEqual';\nexport const LinSpace = 'LinSpace';\nexport const Log = 'Log';\nexport const Log1p = 'Log1p';\nexport const LogicalAnd = 'LogicalAnd';\nexport const LogicalNot = 'LogicalNot';\nexport const LogicalOr = 'LogicalOr';\nexport const LogSoftmax = 'LogSoftmax';\nexport const LRN = 'LRN';\nexport const LRNGrad = 'LRNGrad';\nexport const Max = 'Max';\nexport const Maximum = 'Maximum';\nexport const MaxPool = 'MaxPool';\nexport const MaxPoolGrad = 'MaxPoolGrad';\nexport const MaxPool3D = 'MaxPool3D';\nexport const MaxPool3DGrad = 'MaxPool3DGrad';\nexport const MaxPoolWithArgmax = 'MaxPoolWithArgmax';\nexport const Mean = 'Mean';\nexport const Min = 'Min';\nexport const Minimum = 'Minimum';\nexport const MirrorPad = 'MirrorPad';\nexport const Mod = 'Mod';\nexport const Multinomial = 'Multinomial';\nexport const Multiply = 'Multiply';\nexport const Neg = 'Neg';\nexport const NotEqual = 'NotEqual';\nexport const NonMaxSuppressionV3 = 'NonMaxSuppressionV3';\nexport const NonMaxSuppressionV4 = 'NonMaxSuppressionV4';\nexport const NonMaxSuppressionV5 = 'NonMaxSuppressionV5';\nexport const OnesLike = 'OnesLike';\nexport const OneHot = 'OneHot';\nexport const Pack = 'Pack';\nexport const PadV2 = 'PadV2';\nexport const Pool = 'Pool';\nexport const Pow = 'Pow';\nexport const Prelu = 'Prelu';\nexport const Prod = 'Prod';\nexport const Range = 'Range';\nexport const Real = 'Real';\nexport const Reciprocal = 'Reciprocal';\nexport const Relu = 'Relu';\nexport const Reshape = 'Reshape';\nexport const ResizeNearestNeighbor = 'ResizeNearestNeighbor';\nexport const ResizeNearestNeighborGrad = 'ResizeNearestNeighborGrad';\nexport const ResizeBilinear = 'ResizeBilinear';\nexport const ResizeBilinearGrad = 'ResizeBilinearGrad';\nexport const Relu6 = 'Relu6';\nexport const Reverse = 'Reverse';\nexport const Round = 'Round';\nexport const Rsqrt = 'Rsqrt';\nexport const ScatterNd = 'ScatterNd';\nexport const Select = 'Select';\nexport const Selu = 'Selu';\nexport const Slice = 'Slice';\nexport const Sin = 'Sin';\nexport const Sinh = 'Sinh';\nexport const Sign = 'Sign';\nexport const Sigmoid = 'Sigmoid';\nexport const Softplus = 'Softplus';\nexport const Sqrt = 'Sqrt';\nexport const Sum = 'Sum';\nexport const SpaceToBatchND = 'SpaceToBatchND';\nexport const SplitV = 'SplitV';\nexport const Softmax = 'Softmax';\nexport const SparseFillEmptyRows = 'SparseFillEmptyRows';\nexport const SparseReshape = 'SparseReshape';\nexport const SparseSegmentMean = 'SparseSegmentMean';\nexport const SparseSegmentSum = 'SparseSegmentSum';\nexport const SparseToDense = 'SparseToDense';\nexport const SquaredDifference = 'SquaredDifference';\nexport const Square = 'Square';\nexport const StridedSlice = 'StridedSlice';\nexport const StringNGrams = 'StringNGrams';\nexport const StringSplit = 'StringSplit';\nexport const StringToHashBucketFast = 'StringToHashBucketFast';\nexport const Sub = 'Sub';\nexport const Tan = 'Tan';\nexport const Tanh = 'Tanh';\nexport const Tile = 'Tile';\nexport const TopK = 'TopK';\nexport const Transform = 'Transform';\nexport const Transpose = 'Transpose';\nexport const Unique = 'Unique';\nexport const Unpack = 'Unpack';\nexport const UnsortedSegmentSum = 'UnsortedSegmentSum';\nexport const ZerosLike = 'ZerosLike';\n/**\n * TensorFlow.js-only kernels\n */\nexport const Step = 'Step';\nexport const FromPixels = 'FromPixels';\nexport const RotateWithOffset = 'RotateWithOffset';\nexport const _FusedMatMul = '_FusedMatMul';\nexport const FusedConv2D = 'FusedConv2D';\nexport const FusedDepthwiseConv2D = 'FusedDepthwiseConv2D';\n//# sourceMappingURL=kernel_names.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n/**\n * Classes and functions for model management across multiple storage mediums.\n *\n * Supported client actions:\n * - Listing models on all registered storage mediums.\n * - Remove model by URL from any registered storage mediums, by using URL\n *   string.\n * - Moving or copying model from one path to another in the same medium or from\n *   one medium to another, by using URL strings.\n */\nimport { assert } from '../util';\nimport { IORouterRegistry } from './router_registry';\nconst URL_SCHEME_SUFFIX = '://';\nexport class ModelStoreManagerRegistry {\n    constructor() {\n        this.managers = {};\n    }\n    static getInstance() {\n        if (ModelStoreManagerRegistry.instance == null) {\n            ModelStoreManagerRegistry.instance = new ModelStoreManagerRegistry();\n        }\n        return ModelStoreManagerRegistry.instance;\n    }\n    /**\n     * Register a save-handler router.\n     *\n     * @param saveRouter A function that maps a URL-like string onto an instance\n     * of `IOHandler` with the `save` method defined or `null`.\n     */\n    static registerManager(scheme, manager) {\n        assert(scheme != null, () => 'scheme must not be undefined or null.');\n        if (scheme.endsWith(URL_SCHEME_SUFFIX)) {\n            scheme = scheme.slice(0, scheme.indexOf(URL_SCHEME_SUFFIX));\n        }\n        assert(scheme.length > 0, () => 'scheme must not be an empty string.');\n        const registry = ModelStoreManagerRegistry.getInstance();\n        assert(registry.managers[scheme] == null, () => `A model store manager is already registered for scheme '${scheme}'.`);\n        registry.managers[scheme] = manager;\n    }\n    static getManager(scheme) {\n        const manager = this.getInstance().managers[scheme];\n        if (manager == null) {\n            throw new Error(`Cannot find model manager for scheme '${scheme}'`);\n        }\n        return manager;\n    }\n    static getSchemes() {\n        return Object.keys(this.getInstance().managers);\n    }\n}\n/**\n * Helper method for parsing a URL string into a scheme and a path.\n *\n * @param url E.g., 'localstorage://my-model'\n * @returns A dictionary with two fields: scheme and path.\n *   Scheme: e.g., 'localstorage' in the example above.\n *   Path: e.g., 'my-model' in the example above.\n */\nfunction parseURL(url) {\n    if (url.indexOf(URL_SCHEME_SUFFIX) === -1) {\n        throw new Error(`The url string provided does not contain a scheme. ` +\n            `Supported schemes are: ` +\n            `${ModelStoreManagerRegistry.getSchemes().join(',')}`);\n    }\n    return {\n        scheme: url.split(URL_SCHEME_SUFFIX)[0],\n        path: url.split(URL_SCHEME_SUFFIX)[1],\n    };\n}\nasync function cloneModelInternal(sourceURL, destURL, deleteSource = false) {\n    assert(sourceURL !== destURL, () => `Old path and new path are the same: '${sourceURL}'`);\n    const loadHandlers = IORouterRegistry.getLoadHandlers(sourceURL);\n    assert(loadHandlers.length > 0, () => `Copying failed because no load handler is found for source URL ${sourceURL}.`);\n    assert(loadHandlers.length < 2, () => `Copying failed because more than one (${loadHandlers.length}) ` +\n        `load handlers for source URL ${sourceURL}.`);\n    const loadHandler = loadHandlers[0];\n    const saveHandlers = IORouterRegistry.getSaveHandlers(destURL);\n    assert(saveHandlers.length > 0, () => `Copying failed because no save handler is found for destination ` +\n        `URL ${destURL}.`);\n    assert(saveHandlers.length < 2, () => `Copying failed because more than one (${loadHandlers.length}) ` +\n        `save handlers for destination URL ${destURL}.`);\n    const saveHandler = saveHandlers[0];\n    const sourceScheme = parseURL(sourceURL).scheme;\n    const sourcePath = parseURL(sourceURL).path;\n    const sameMedium = sourceScheme === parseURL(sourceURL).scheme;\n    const modelArtifacts = await loadHandler.load();\n    // If moving within the same storage medium, remove the old model as soon as\n    // the loading is done. Without doing this, it is possible that the combined\n    // size of the two models will cause the cloning to fail.\n    if (deleteSource && sameMedium) {\n        await ModelStoreManagerRegistry.getManager(sourceScheme)\n            .removeModel(sourcePath);\n    }\n    const saveResult = await saveHandler.save(modelArtifacts);\n    // If moving between mediums, the deletion is done after the save succeeds.\n    // This guards against the case in which saving to the destination medium\n    // fails.\n    if (deleteSource && !sameMedium) {\n        await ModelStoreManagerRegistry.getManager(sourceScheme)\n            .removeModel(sourcePath);\n    }\n    return saveResult.modelArtifactsInfo;\n}\n/**\n * List all models stored in registered storage mediums.\n *\n * For a web browser environment, the registered mediums are Local Storage and\n * IndexedDB.\n *\n * ```js\n * // First create and save a model.\n * const model = tf.sequential();\n * model.add(tf.layers.dense(\n *     {units: 1, inputShape: [10], activation: 'sigmoid'}));\n * await model.save('localstorage://demo/management/model1');\n *\n * // Then list existing models.\n * console.log(JSON.stringify(await tf.io.listModels()));\n *\n * // Delete the model.\n * await tf.io.removeModel('localstorage://demo/management/model1');\n *\n * // List models again.\n * console.log(JSON.stringify(await tf.io.listModels()));\n * ```\n *\n * @returns A `Promise` of a dictionary mapping URLs of existing models to\n * their model artifacts info. URLs include medium-specific schemes, e.g.,\n *   'indexeddb://my/model/1'. Model artifacts info include type of the\n * model's topology, byte sizes of the topology, weights, etc.\n *\n * @doc {\n *   heading: 'Models',\n *   subheading: 'Management',\n *   namespace: 'io',\n *   ignoreCI: true\n * }\n */\nasync function listModels() {\n    const schemes = ModelStoreManagerRegistry.getSchemes();\n    const out = {};\n    for (const scheme of schemes) {\n        const schemeOut = await ModelStoreManagerRegistry.getManager(scheme).listModels();\n        for (const path in schemeOut) {\n            const url = scheme + URL_SCHEME_SUFFIX + path;\n            out[url] = schemeOut[path];\n        }\n    }\n    return out;\n}\n/**\n * Remove a model specified by URL from a reigstered storage medium.\n *\n * ```js\n * // First create and save a model.\n * const model = tf.sequential();\n * model.add(tf.layers.dense(\n *     {units: 1, inputShape: [10], activation: 'sigmoid'}));\n * await model.save('localstorage://demo/management/model1');\n *\n * // Then list existing models.\n * console.log(JSON.stringify(await tf.io.listModels()));\n *\n * // Delete the model.\n * await tf.io.removeModel('localstorage://demo/management/model1');\n *\n * // List models again.\n * console.log(JSON.stringify(await tf.io.listModels()));\n * ```\n *\n * @param url A URL to a stored model, with a scheme prefix, e.g.,\n *   'localstorage://my-model-1', 'indexeddb://my/model/2'.\n * @returns ModelArtifactsInfo of the deleted model (if and only if deletion\n *   is successful).\n * @throws Error if deletion fails, e.g., if no model exists at `path`.\n *\n * @doc {\n *   heading: 'Models',\n *   subheading: 'Management',\n *   namespace: 'io',\n *   ignoreCI: true\n * }\n */\nasync function removeModel(url) {\n    const schemeAndPath = parseURL(url);\n    const manager = ModelStoreManagerRegistry.getManager(schemeAndPath.scheme);\n    return manager.removeModel(schemeAndPath.path);\n}\n/**\n * Copy a model from one URL to another.\n *\n * This function supports:\n *\n * 1. Copying within a storage medium, e.g.,\n *    `tf.io.copyModel('localstorage://model-1', 'localstorage://model-2')`\n * 2. Copying between two storage mediums, e.g.,\n *    `tf.io.copyModel('localstorage://model-1', 'indexeddb://model-1')`\n *\n * ```js\n * // First create and save a model.\n * const model = tf.sequential();\n * model.add(tf.layers.dense(\n *     {units: 1, inputShape: [10], activation: 'sigmoid'}));\n * await model.save('localstorage://demo/management/model1');\n *\n * // Then list existing models.\n * console.log(JSON.stringify(await tf.io.listModels()));\n *\n * // Copy the model, from Local Storage to IndexedDB.\n * await tf.io.copyModel(\n *     'localstorage://demo/management/model1',\n *     'indexeddb://demo/management/model1');\n *\n * // List models again.\n * console.log(JSON.stringify(await tf.io.listModels()));\n *\n * // Remove both models.\n * await tf.io.removeModel('localstorage://demo/management/model1');\n * await tf.io.removeModel('indexeddb://demo/management/model1');\n * ```\n *\n * @param sourceURL Source URL of copying.\n * @param destURL Destination URL of copying.\n * @returns ModelArtifactsInfo of the copied model (if and only if copying\n *   is successful).\n * @throws Error if copying fails, e.g., if no model exists at `sourceURL`, or\n *   if `oldPath` and `newPath` are identical.\n *\n * @doc {\n *   heading: 'Models',\n *   subheading: 'Management',\n *   namespace: 'io',\n *   ignoreCI: true\n * }\n */\nasync function copyModel(sourceURL, destURL) {\n    const deleteSource = false;\n    return cloneModelInternal(sourceURL, destURL, deleteSource);\n}\n/**\n * Move a model from one URL to another.\n *\n * This function supports:\n *\n * 1. Moving within a storage medium, e.g.,\n *    `tf.io.moveModel('localstorage://model-1', 'localstorage://model-2')`\n * 2. Moving between two storage mediums, e.g.,\n *    `tf.io.moveModel('localstorage://model-1', 'indexeddb://model-1')`\n *\n * ```js\n * // First create and save a model.\n * const model = tf.sequential();\n * model.add(tf.layers.dense(\n *     {units: 1, inputShape: [10], activation: 'sigmoid'}));\n * await model.save('localstorage://demo/management/model1');\n *\n * // Then list existing models.\n * console.log(JSON.stringify(await tf.io.listModels()));\n *\n * // Move the model, from Local Storage to IndexedDB.\n * await tf.io.moveModel(\n *     'localstorage://demo/management/model1',\n *     'indexeddb://demo/management/model1');\n *\n * // List models again.\n * console.log(JSON.stringify(await tf.io.listModels()));\n *\n * // Remove the moved model.\n * await tf.io.removeModel('indexeddb://demo/management/model1');\n * ```\n *\n * @param sourceURL Source URL of moving.\n * @param destURL Destination URL of moving.\n * @returns ModelArtifactsInfo of the copied model (if and only if copying\n *   is successful).\n * @throws Error if moving fails, e.g., if no model exists at `sourceURL`, or\n *   if `oldPath` and `newPath` are identical.\n *\n * @doc {\n *   heading: 'Models',\n *   subheading: 'Management',\n *   namespace: 'io',\n *   ignoreCI: true\n * }\n */\nasync function moveModel(sourceURL, destURL) {\n    const deleteSource = true;\n    return cloneModelInternal(sourceURL, destURL, deleteSource);\n}\nexport { moveModel, copyModel, removeModel, listModels };\n//# sourceMappingURL=model_management.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n// Note that the identifier globalNameSpace is scoped to this module, but will\n// always resolve to the same global object regardless of how the module is\n// resolved.\n// tslint:disable-next-line:no-any\nlet globalNameSpace;\n// tslint:disable-next-line:no-any\nexport function getGlobalNamespace() {\n    if (globalNameSpace == null) {\n        // tslint:disable-next-line:no-any\n        let ns;\n        if (typeof (window) !== 'undefined') {\n            ns = window;\n        }\n        else if (typeof (global) !== 'undefined') {\n            ns = global;\n        }\n        else if (typeof (process) !== 'undefined') {\n            ns = process;\n        }\n        else if (typeof (self) !== 'undefined') {\n            ns = self;\n        }\n        else {\n            throw new Error('Could not find a global object');\n        }\n        globalNameSpace = ns;\n    }\n    return globalNameSpace;\n}\n// tslint:disable-next-line:no-any\nfunction getGlobalMap() {\n    const ns = getGlobalNamespace();\n    if (ns._tfGlobals == null) {\n        ns._tfGlobals = new Map();\n    }\n    return ns._tfGlobals;\n}\n/**\n * Returns a globally accessible 'singleton' object.\n *\n * @param key the name of the object\n * @param init a function to initialize to initialize this object\n *             the first time it is fetched.\n */\nexport function getGlobal(key, init) {\n    const globalMap = getGlobalMap();\n    if (globalMap.has(key)) {\n        return globalMap.get(key);\n    }\n    else {\n        const singleton = init();\n        globalMap.set(key, singleton);\n        return globalMap.get(key);\n    }\n}\n//# sourceMappingURL=global_util.js.map","/**\n * @license\n * Copyright 2017 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { isPromise } from './util_base';\n// Expects flags from URL in the format ?tfjsflags=FLAG1:1,FLAG2:true.\nconst TENSORFLOWJS_FLAGS_PREFIX = 'tfjsflags';\n/**\n * The environment contains evaluated flags as well as the registered platform.\n * This is always used as a global singleton and can be retrieved with\n * `tf.env()`.\n *\n * @doc {heading: 'Environment'}\n */\nexport class Environment {\n    // tslint:disable-next-line: no-any\n    constructor(global) {\n        this.global = global;\n        this.flags = {};\n        this.flagRegistry = {};\n        this.urlFlags = {};\n        // Jasmine spies on this in 'environment_test.ts'\n        this.getQueryParams = getQueryParams;\n        this.populateURLFlags();\n    }\n    setPlatform(platformName, platform) {\n        if (this.platform != null) {\n            console.warn(`Platform ${this.platformName} has already been set. ` +\n                `Overwriting the platform with ${platform}.`);\n        }\n        this.platformName = platformName;\n        this.platform = platform;\n    }\n    registerFlag(flagName, evaluationFn, setHook) {\n        this.flagRegistry[flagName] = { evaluationFn, setHook };\n        // Override the flag value from the URL. This has to happen here because the\n        // environment is initialized before flags get registered.\n        if (this.urlFlags[flagName] != null) {\n            const flagValue = this.urlFlags[flagName];\n            console.warn(`Setting feature override from URL ${flagName}: ${flagValue}.`);\n            this.set(flagName, flagValue);\n        }\n    }\n    async getAsync(flagName) {\n        if (flagName in this.flags) {\n            return this.flags[flagName];\n        }\n        this.flags[flagName] = await this.evaluateFlag(flagName);\n        return this.flags[flagName];\n    }\n    get(flagName) {\n        if (flagName in this.flags) {\n            return this.flags[flagName];\n        }\n        const flagValue = this.evaluateFlag(flagName);\n        if (isPromise(flagValue)) {\n            throw new Error(`Flag ${flagName} cannot be synchronously evaluated. ` +\n                `Please use getAsync() instead.`);\n        }\n        this.flags[flagName] = flagValue;\n        return this.flags[flagName];\n    }\n    getNumber(flagName) {\n        return this.get(flagName);\n    }\n    getBool(flagName) {\n        return this.get(flagName);\n    }\n    getFlags() {\n        return this.flags;\n    }\n    // For backwards compatibility.\n    get features() {\n        return this.flags;\n    }\n    set(flagName, value) {\n        if (this.flagRegistry[flagName] == null) {\n            throw new Error(`Cannot set flag ${flagName} as it has not been registered.`);\n        }\n        this.flags[flagName] = value;\n        if (this.flagRegistry[flagName].setHook != null) {\n            this.flagRegistry[flagName].setHook(value);\n        }\n    }\n    evaluateFlag(flagName) {\n        if (this.flagRegistry[flagName] == null) {\n            throw new Error(`Cannot evaluate flag '${flagName}': no evaluation function found.`);\n        }\n        return this.flagRegistry[flagName].evaluationFn();\n    }\n    setFlags(flags) {\n        this.flags = Object.assign({}, flags);\n    }\n    reset() {\n        this.flags = {};\n        this.urlFlags = {};\n        this.populateURLFlags();\n    }\n    populateURLFlags() {\n        if (typeof this.global === 'undefined' ||\n            typeof this.global.location === 'undefined' ||\n            typeof this.global.location.search === 'undefined') {\n            return;\n        }\n        const urlParams = this.getQueryParams(this.global.location.search);\n        if (TENSORFLOWJS_FLAGS_PREFIX in urlParams) {\n            const keyValues = urlParams[TENSORFLOWJS_FLAGS_PREFIX].split(',');\n            keyValues.forEach(keyValue => {\n                const [key, value] = keyValue.split(':');\n                this.urlFlags[key] = parseValue(key, value);\n            });\n        }\n    }\n}\nexport function getQueryParams(queryString) {\n    const params = {};\n    queryString.replace(/[?&]([^=?&]+)(?:=([^&]*))?/g, (s, ...t) => {\n        decodeParam(params, t[0], t[1]);\n        return t.join('=');\n    });\n    return params;\n}\nfunction decodeParam(params, name, value) {\n    params[decodeURIComponent(name)] = decodeURIComponent(value || '');\n}\nfunction parseValue(flagName, value) {\n    value = value.toLowerCase();\n    if (value === 'true' || value === 'false') {\n        return value === 'true';\n    }\n    else if (`${+value}` === value) {\n        return +value;\n    }\n    throw new Error(`Could not parse value flag value ${value} for flag ${flagName}.`);\n}\n/**\n * Returns the current environment (a global singleton).\n *\n * The environment object contains the evaluated feature values as well as the\n * active platform.\n *\n * @doc {heading: 'Environment'}\n */\nexport function env() {\n    return ENV;\n}\nexport let ENV = null;\nexport function setEnvironmentGlobal(environment) {\n    ENV = environment;\n}\n//# sourceMappingURL=environment.js.map"],"sourceRoot":""}