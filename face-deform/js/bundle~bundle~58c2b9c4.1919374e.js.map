{"version":3,"sources":["webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/reverse.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/sqrt.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/transpose.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/sub.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/slice_util.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/print.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/sigmoid.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/sum.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/squeeze.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/spectral/irfft.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/round.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/pow.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/scalar.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/ones.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/not_equal.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/squared_difference.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/step.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/relu6.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/prelu.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/tensor3d.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/reduce_util.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/slice.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/rotate_util.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/selu_util.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/split_util.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/segment_util.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/signal_ops_util.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/signal/hamming_window.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/signal/hann_window.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/signal/frame.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/signal/stft.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/sparse/sparse_fill_empty_rows.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/sparse/sparse_reshape.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/sparse/sparse_segment_mean.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/sparse/sparse_segment_sum.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/string/string_n_grams.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/string/string_split.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/string/string_to_hash_bucket_fast.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/ops.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/profiler.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/tensor1d.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/operation.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/nonmax_util.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/platforms/platform_browser.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/platforms/platform_node.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/where.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/tensor_ops_util.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/stack.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/split.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/zeros.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/relu.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/tensor.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/tensor2d.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/range.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/spectral/ifft.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/real.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/reshape.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/unstack.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/spectral/fft.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/spectral/rfft.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/norm.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/square.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/tile.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/scatter_nd_util.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/zeros_like.js"],"names":["reverse","reverse_","x","axis","inputs","attrs","dims","runKernel","sqrt","sqrt_","transpose","transpose_","perm","$x","shape","map","s","i","rank","length","forEach","clone","sub","sub_","a","b","$a","$b","assertParamsValid","input","begin","size","inputRank","maskToAxes","mask","axes","push","computeOutShape","end","strides","Math","ceil","stridesWithElidedDims","ellipsisInsertionIndex","numElidedAxes","inputShape","newStrides","splice","pop","unnormalizeAxis","normalizedAxis","getElidedAxes","elidedAxes","getNormalizedAxes","ellipsisAxes","numInterpolatedAxes","beginMask","endMask","ellipsisMask","normalizedBegin","Array","normalizedEnd","normalizedStrides","fullIndex","startIndicesWithElidedDims","stopIndicesWithElidedDims","startForAxis","stopForAxis","stridesForAxis","originalBegin","newIndices","indexOf","originalAxis","originalValue","originalEnd","Number","MAX_SAFE_INTEGER","axisSize","stride","startIndices","start","MIN_SAFE_INTEGER","stopIndices","stop","isSliceContinous","firstNonOneAxis","computeFlatOffset","flatOffset","parseSliceParams","begin_","xRank","size_","fill","concat","slice","d","sliceInfo","xShape","newAxisMask","shrinkAxisMask","$begin","$end","$strides","Error","expandAxes","newShape","shrinkAxes","outShape","filter","_","nonStrided","every","v","print","verbose","console","log","toString","sigmoid","sigmoid_","sum","sum_","keepDims","dtype","squeeze","squeeze_","irfft","irfft_","innerDimensionSize","batch","ret","complexInput","outputShape","realInput","imagInput","realConjugate","imagConjugate","r","temp","dispose","round","round_","pow","pow_","base","exp","$base","$exp","scalar","value","isArray","Uint8Array","ones","real","imag","values","makeTensor","notEqual","notEqual_","squaredDifference","squaredDifference_","step","step_","alpha","relu6","relu6_","prelu","prelu_","tensor3d","inferredShape","PARALLELIZE_THRESHOLD","computeOptimalWindowSize","inSize","floor","slice_","getImageCenter","center","imageHeight","imageWidth","SELU_SCALEALPHA","SELU_SCALE","prepareSplitSize","numOrSizeSplits","splitSizes","numOfNegs","reduce","count","negIndex","total","segOpComputeOptimalWindowSize","numSegments","res","done","aShape","dim","collectGatherOpShapeInfo","indices","batchDims","indicesRank","dimSize","batchSize","outerSize","sliceSize","cosineWindow","windowLength","even","newValues","Float32Array","cosArg","PI","cos","tensor1d","hammingWindow_","hannWindow","hannWindow_","frame_","signal","frameLength","frameStep","padEnd","padValue","output","padLen","pad","tensor2d","reshape","stft_","fftLength","windowFn","framedSignal","windowedSignal","mul","rfft","sparseFillEmptyRows","sparseFillEmptyRows_","denseShape","defaultValue","$indices","$values","$denseShape","$defaultValue","result","outputIndices","outputValues","emptyRowIndicator","reverseIndexMap","sparseReshape","sparseReshape_","inputIndices","$inputIndices","$inputShape","$newShape","sparseSegmentMean","sparseSegmentMean_","data","segmentIds","$data","$segmentIds","sparseSegmentSum","sparseSegmentSum_","stringNGrams","stringNGrams_","dataSplits","separator","nGramWidths","leftPad","rightPad","padWidth","preserveShortSequences","$dataSplits","nGrams","nGramsSplits","stringSplit","stringSplit_","delimiter","skipEmpty","$input","$delimiter","stringToHashBucketFast","stringToHashBucketFast_","numBuckets","fft","ifft","flipLeftRight","resizeNearestNeighbor","resizeBilinear","rotateWithOffset","cropAndResize","nonMaxSuppression","nonMaxSuppressionAsync","nonMaxSuppressionWithScore","nonMaxSuppressionWithScoreAsync","nonMaxSuppressionPadded","nonMaxSuppressionPaddedAsync","threshold","transform","sparse","qr","string","Profiler","backendTimer","logger","this","Logger","kernelName","f","outputs","holdResultWrapperFn","timer","timerAvailable","time","dataSync","Promise","resolve","kernelMs","getBool","then","tensorVals","checkComputationForErrors","timeMs","timing","extraInfo","getExtraProfileInfo","kernelProfile","all","valueContainer","logKernelProfile","vals","num","isNaN","isFinite","warn","name","paddedName","inputShapesDescription","op","keys","Object","opName","fn","endsWith","substring","f2","args","startScope","error","endScope","ex","defineProperty","configurable","nonMaxSuppSanityCheck","boxes","scores","maxOutputSize","iouThreshold","scoreThreshold","softNmsSigma","NEGATIVE_INFINITY","numBoxes","min","PlatformBrowser","path","init","fetch","performance","now","text","encoding","textEncoder","TextEncoder","encode","bytes","TextDecoder","decode","get","setPlatform","registerManager","URL_SCHEME","err","getNodeFetch","systemFetch","PlatformNode","util","requestInits","global","process","hrtime","where","where_","condition","$condition","broadcastShape","t","e","providedSize","inferredSize","inferred","flatDimsDontMatch","stack","stack_","tensors","$tensors","split","split_","attr","zeros","relu","relu_","tensor","range","ifft_","real_","reshape_","unstack","unstack_","fft_","rfft_","adjustedInput","zerosShape","zerosInput","half","realValues","imagValues","realComplexConjugate","imagComplexConjugate","normImpl","p","Infinity","norm","norm_","ord","keepDimsShape","square","square_","tile","tile_","reps","validateUpdateShape","updates","sliceDim","batchDim","shapeError","validateInput","calculateShapes","sliceRank","totalNd","safeSliceDim","numUpdates","outputSize","zerosLike","zerosLike_"],"mappings":";sJAAA,kEAyDO,MAAMA,EAAU,YAAG,CAAEC,SAN5B,SAAkBC,EAAGC,GACjB,MACMC,EAAS,CAAEF,EADN,YAAgBA,EAAG,IAAK,YAE7BG,EAAQ,CAAEC,KAAMH,GACtB,OAAO,IAAOI,UAAU,KAASH,EAAQC,O,iCCvD7C,kEAqCO,MAAMG,EAAO,YAAG,CAAEC,MALzB,SAAeP,GACX,MACME,EAAS,CAAEF,EADN,YAAgBA,EAAG,IAAK,SAEnC,OAAO,IAAOK,UAAU,KAAMH,O,iCCnClC,yEA0DO,MAAMM,EAAY,YAAG,CAAEC,WAlB9B,SAAoBT,EAAGU,GACnB,MAAMC,EAAK,YAAgBX,EAAG,IAAK,aAUnC,GATY,MAARU,IACAA,EAAOC,EAAGC,MAAMC,KAAI,CAACC,EAAGC,IAAMA,IAAGjB,WAErC,IAAYa,EAAGK,OAASN,EAAKO,QAAQ,IAAM,qCAAqCN,EAAGK,kCAClDN,OACjCA,EAAKQ,SAAQjB,IACT,IAAYA,GAAQ,GAAKA,EAAOU,EAAGK,MAAM,IAAM,gDAA+CL,EAAGK,KAAO,GACpG,YAAYN,SAEhBC,EAAGK,MAAQ,EACX,OAAOL,EAAGQ,QAEd,MAAMjB,EAAS,CAAEF,EAAGW,GACdR,EAAQ,CAAEO,QAChB,OAAO,IAAOL,UAAU,KAAWH,EAAQC,O,gCCxD/C,0EAmDO,MAAMiB,EAAM,YAAG,CAAEC,KAPxB,SAAcC,EAAGC,GACb,IAAIC,EAAK,YAAgBF,EAAG,IAAK,OAC7BG,EAAK,YAAgBF,EAAG,IAAK,QAChCC,EAAIC,GAAM,YAAeD,EAAIC,GAC9B,MAAMvB,EAAS,CAAEoB,EAAGE,EAAID,EAAGE,GAC3B,OAAO,IAAOpB,UAAU,KAAKH,O,iCCjDjC,ksBAiBO,SAASwB,EAAkBC,EAAOC,EAAOC,GAC5C,MAAMC,EAAYH,EAAMf,MAAMK,OAC9B,IAAYa,IAAcF,EAAMX,QAAQ,IAAM,iBAAiBa,uBAA+BF,uCAC1DE,QACpC,IAAYA,IAAcD,EAAKZ,QAAQ,IAAM,iBAAiBa,sBAA8BD,uCACxDC,QACpC,IAAK,IAAIf,EAAI,EAAGA,EAAIe,IAAaf,EAC7B,IAAYa,EAAMb,GAAKc,EAAKd,IAAMY,EAAMf,MAAMG,IAAI,IAAM,iBAAiBe,aAAqBf,aAAaA,OACnGa,EAAMb,GAAKc,EAAKd,kCAAkCA,OAAOY,EAAMf,MAAMG,QAI9E,SAASgB,EAAWC,GACvB,MAAMC,EAAO,GACb,IAAIhC,EAAO,EACX,KAAO+B,EAAO,GACC,EAAPA,GACAC,EAAKC,KAAKjC,GAEd+B,GAAQ,EACR/B,IAEJ,OAAOgC,EAGJ,SAASE,EAAgBP,EAAOQ,EAAKC,GACxC,MAAMR,EAAO,GACb,IAAK,IAAI5B,EAAO,EAAGA,EAAO2B,EAAMX,OAAQhB,IACpC4B,EAAK5B,GAAQqC,KAAKC,MAAMH,EAAInC,GAAQ2B,EAAM3B,IAASoC,EAAQpC,IAE/D,OAAO4B,EAIJ,SAASW,EAAsBH,EAASI,EAAwBC,EAAeC,GAClF,MAAMC,EAAa,IAAIP,GACvB,IAAK,IAAItB,EAAI6B,EAAW3B,OAAQF,EAAI4B,EAAW1B,OAAQF,IACnD6B,EAAWV,KAAK,GAEpB,IAAK,IAAInB,EAAI,EAAGA,EAAI2B,EAAe3B,IACrB,IAANA,EACA6B,EAAWH,GAA0B,GAGrCG,EAAWC,OAAOJ,EAAwB,EAAgC,GAC1EG,EAAWE,OAGnB,OAAOF,EAEX,SAASG,EAAgBN,EAAwBC,EAAeM,GAC5D,OAAIA,GAAkBP,EACXO,EAEJA,GAAkBN,EAAgB,GAE7C,SAASO,EAAcP,EAAeD,GAClC,MAAMS,EAAa,GACnB,IAAK,IAAInC,EAAI,EAAGA,EAAI2B,EAAe3B,IAC/BmC,EAAWhB,KAAKO,EAAyB1B,GAE7C,OAAOmC,EAGJ,SAASC,EAAkBR,EAAYS,EAAcC,EAAqBzB,EAAOQ,EAAKC,EAASiB,EAAWC,EAASC,GACtH,MAAM1B,EAAYa,EAAW1B,OAC7B,IAAIwC,EAAkB,IAAIC,MAAM5B,GAAY6B,EAAgB,IAAID,MAAM5B,GAAY8B,EAAoB,IAAIF,MAAM5B,GAChH,GAAIsB,EAAanC,QAAUoC,EAAsB,EAAG,CAChD,MAAMQ,EAAYT,EAAa,GAGzBV,EAAgBW,EAAsB,EAC5CI,EAAkBK,EAA2BR,EAAWO,EAAWnB,EAAed,EAAOe,GACzFgB,EAAgBI,EAA0BR,EAASM,EAAWnB,EAAeN,EAAKO,GAClFiB,EACIpB,EAAsBH,EAASwB,EAAWnB,EAAeC,QAG7D,IAAK,IAAI1C,EAAO,EAAGA,EAAO6B,EAAW7B,IACjCwD,EAAgBxD,GAAQ+D,EAAaV,EAAW1B,EAAOS,EAASM,EAAY1C,EAAMuD,GAClFG,EAAc1D,GACVgE,EAAYV,EAASnB,EAAKC,EAASM,EAAY1C,EAAMuD,GACzDI,EAAkB3D,GAAQiE,EAAe7B,EAASpC,EAAMuD,GAGhE,MAAO,CACH5B,MAAO6B,EACPrB,IAAKuB,EACLtB,QAASuB,GAKV,SAASE,EAA2BR,EAAWb,EAAwBC,EAAeyB,EAAexB,GACxG,MAAMyB,EAAa,IAAIzB,GACjBO,EAAaD,EAAcP,EAAeD,GAChD,IAAK,IAAIxC,EAAO,EAAGA,EAAOmE,EAAWnD,OAAQhB,IACzC,GAAIiD,EAAWmB,QAAQpE,IAAS,EAC5BmE,EAAWnE,GAAQ,MAElB,CACD,MAAMqE,EAAevB,EAAgBN,EAAwBC,EAAezC,GAC5E,IAAIsE,EAAgBJ,EAAcG,GAC9BhB,EAAY,GAAKgB,IACjBC,EAAgB,GAEpBH,EAAWnE,GAAQsE,EAG3B,OAAOH,EAIJ,SAASL,EAA0BR,EAASd,EAAwBC,EAAe8B,EAAa7B,GACnG,MAAMyB,EAAa,IAAIzB,GACjBO,EAAaD,EAAcP,EAAeD,GAChD,IAAK,IAAIxC,EAAO,EAAGA,EAAOmE,EAAWnD,OAAQhB,IACzC,GAAIiD,EAAWmB,QAAQpE,IAAS,EAC5BmE,EAAWnE,GAAQwE,OAAOC,qBAEzB,CACD,MAAMJ,EAAevB,EAAgBN,EAAwBC,EAAezC,GAC5E,IAAIsE,EAAgBC,EAAYF,GAC5Bf,EAAU,GAAKe,IACfC,EAAgBE,OAAOC,kBAE3BN,EAAWnE,GAAQsE,EAG3B,IAAK,IAAIxD,EAAI,EAAGA,EAAIqD,EAAWnD,OAAQF,IAAK,CAExC,MAAM4D,EAAWhC,EAAW5B,GACxBqD,EAAWrD,GAAK,IAChBqD,EAAWrD,IAAM4D,GAErBP,EAAWrD,GAAK,IAAW,EAAGqD,EAAWrD,GAAI4B,EAAW5B,IAE5D,OAAOqD,EAEJ,SAASF,EAAe7B,EAASpC,EAAMuD,GAC1C,IAAIoB,EAASvC,EAAQpC,GAIrB,OAHIuD,EAAgB,GAAKvD,GAAmB,MAAV2E,KAC9BA,EAAS,GAENA,EAEJ,SAASZ,EAAaV,EAAWuB,EAAcxC,EAASM,EAAY1C,EAAMuD,GAE7E,IAAIsB,EAAQD,EAAa5E,GACzB,MAAM2E,EAASvC,EAAQpC,IAAS,GAG5BqD,EAAY,GAAKrD,GAAQuD,EAAe,GAAKvD,GAAiB,MAAT6E,KAKjDA,EAJAF,EAAS,EAIDH,OAAOM,iBAIPN,OAAOC,kBAIvB,MAAMC,EAAWhC,EAAW1C,GAM5B,OALI6E,EAAQ,IACRA,GAASH,GAGbG,EAAQ,IAAW,EAAGA,EAAOH,EAAW,GACjCG,EAEJ,SAASb,EAAYV,EAASyB,EAAa3C,EAASM,EAAY1C,EAAMuD,GAEzE,IAAIyB,EAAOD,EAAY/E,GACvB,MAAM2E,EAASvC,EAAQpC,IAAS,GAG5BsD,EAAW,GAAKtD,GAASuD,EAAgB,GAAKvD,GAAiB,MAARgF,KAInDA,EAHAL,EAAS,EAGFH,OAAOC,iBAIPD,OAAOM,kBAItB,MAAMJ,EAAWhC,EAAW1C,GAe5B,OAdIgF,EAAO,IACPA,GAAQN,GAORM,EAFAL,EAAS,EAEF,IAAW,EAAGK,EAAMN,GAIpB,KAAY,EAAGM,EAAMN,EAAW,GAEpCM,EAMJ,SAASC,EAAiBtE,EAAOgB,EAAOC,GAE3C,IAAIsD,EAAkBtD,EAAKZ,OAC3B,IAAK,IAAIF,EAAI,EAAGA,EAAIc,EAAKZ,OAAQF,IAC7B,GAAIc,EAAKd,GAAK,EAAG,CACboE,EAAkBpE,EAClB,MAGR,IAAK,IAAIA,EAAIoE,EAAkB,EAAGpE,EAAIc,EAAKZ,OAAQF,IAC/C,GAAIa,EAAMb,GAAK,GAAKc,EAAKd,KAAOH,EAAMG,GAClC,OAAO,EAGf,OAAO,EAEJ,SAASqE,EAAkBxD,EAAOS,GACrC,IAAIgD,EAAazD,EAAMX,OAAS,EAAIW,EAAMA,EAAMX,OAAS,GAAK,EAC9D,IAAK,IAAIF,EAAI,EAAGA,EAAIa,EAAMX,OAAS,EAAGF,IAClCsE,GAAczD,EAAMb,GAAKsB,EAAQtB,GAErC,OAAOsE,EAEJ,SAASC,EAAiBtF,EAAG4B,EAAOC,GAEvC,IAAI0D,EACJ,MAAMC,EAAQxF,EAAEY,MAAMK,OAatB,IAAIwE,EAuBJ,OAlCIF,EADiB,iBAAV3D,EACE,CAACA,KAAU,IAAI8B,MAAM8B,EAAQ,GAAGE,KAAK,IAEzC9D,EAAMX,OAASuE,EACX5D,EAAM+D,OAAO,IAAIjC,MAAM8B,EAAQ5D,EAAMX,QAAQyE,KAAK,IAGlD9D,EAAMgE,QAEnBL,EAAOrE,SAAQ2E,IACX,KAAmB,IAAPA,GAAU,IAAM,yDAI5BJ,EADQ,MAAR5D,EACQ,IAAI6B,MAAM8B,GAAOE,MAAM,GAEV,iBAAT7D,EACJ,CAACA,KAAS,IAAI6B,MAAM8B,EAAQ,GAAGE,MAAM,IAExC7D,EAAKZ,OAASuE,EACX3D,EAAK8D,OAAO,IAAIjC,MAAM8B,EAAQ3D,EAAKZ,QAAQyE,MAAM,IAGjD7D,EAEZ4D,EAAQA,EAAM5E,KAAI,CAACgF,EAAG9E,IACd8E,GAAK,EACEA,GAGP,KAAmB,IAAPA,GAAU,IAClB,qDAAGA,mCAAmC9E,OACnCf,EAAEY,MAAMG,GAAKwE,EAAOxE,MAG5B,CAACwE,EAAQE,GAEb,SAASK,EAAUC,EAAQnE,EAAOQ,EAAKC,EAASiB,EAAWC,EAASC,EAAcwC,EAAaC,GAElG,IAAIC,EAAStE,EAAMgE,QACfO,EAAO/D,EAAIwD,QACXQ,EAAW/D,EACA,MAAXA,IACA+D,EAAW,IAAI1C,MAAMwC,EAAOjF,SAEhC,MAAMmC,EAAerB,EAAWyB,GAChC,GAAIJ,EAAanC,OAAS,EACtB,MAAM,IAAIoF,MAAM,8CAEpB,GAAqB,IAAjB7C,GAAsC,IAAhBwC,EACtB,MAAM,IAAIK,MAAM,iEAEpB,GAAqB,IAAjB7C,GAAyC,IAAnByC,EACtB,MAAM,IAAII,MAAM,oEAEpB,MAAMhD,EAAsB0C,EAAO9E,OAASiF,EAAOjF,OAE7CqF,EAAavE,EAAWiE,GACxBO,EAAWR,EAAOH,QACxBU,EAAWpF,SAAQjB,IACfiG,EAAOjG,GAAQ,EACfkG,EAAKlG,GAAQ,EACbsG,EAAS1D,OAAO5C,EAAM,EAAG,MAE7B,MAAQ2B,MAAO6B,EAAiBrB,IAAKuB,EAAetB,QAASuB,GAAsBT,EAAkBoD,EAAUnD,EAAcC,EAAqB6C,EAAQC,EAAMC,EAAU9C,EAAWC,EAASC,GAC9L0C,EAASzC,EACT0C,EAAOxC,EACPyC,EAAWxC,EACX,MAAM4C,EAAazE,EAAWkE,GAE9BO,EAAWtF,SAAQjB,IACfkG,EAAKlG,GAAQiG,EAAOjG,GAAQ,EAC5BmG,EAASnG,GAAQ,KAGrB,MAAM4B,EAAOM,EAAgB+D,EAAQC,EAAMC,GAErCK,EAAW5E,EAAK6E,QAAO,CAACC,EAAG1G,KAAuC,IAA9BuG,EAAWnC,QAAQpE,KAE7D,MAAO,CAAE2G,WADUR,EAASS,OAAMC,GAAW,IAANA,IAClBZ,SAAQC,OAAMC,WAAUvE,OAAM0E,WAAUE,c,iCClT1D,SAASM,EAAM/G,EAAGgH,GAAU,GAC/BC,QAAQC,IAAIlH,EAAEmH,SAASH,IA9B3B,mC,iCCAA,kEAqCO,MAAMI,EAAU,YAAG,CAAEC,SAL5B,SAAkBrH,GACd,MACME,EAAS,CAAEF,EADN,YAAgBA,EAAG,IAAK,YAEnC,OAAO,IAAOK,UAAU,KAASH,O,gCCnCrC,0EA4DO,MAAMoH,EAAM,YAAG,CAAEC,KATxB,SAAcvH,EAAGC,EAAO,KAAMuH,GAAW,GACrC,IAAI7G,EAAK,YAAgBX,EAAG,IAAK,OAChB,SAAbW,EAAG8G,QACH9G,EAAK,YAAKA,EAAI,UAElB,MAAMT,EAAS,CAAEF,EAAGW,GACdR,EAAQ,CAAEF,OAAMuH,YACtB,OAAO,IAAOnH,UAAU,KAAKH,EAAQC,O,iCC1DzC,kEAuCO,MAAMuH,EAAU,YAAG,CAAEC,SAJ5B,SAAkB3H,EAAGC,GACjB,MAAMU,EAAK,YAAgBX,EAAG,IAAK,WACnC,OAAO,YAAQW,EAAI,YAAaA,EAAGC,MAAOX,GAAMsG,c,iCCrCpD,6HA2EO,MAAMqB,EAAQ,YAAG,CAAEC,OA/B1B,SAAgBlG,GACZ,MAAMmG,EAAqBnG,EAAMf,MAAMe,EAAMf,MAAMK,OAAS,GACtD8G,EAAQpG,EAAME,KAAOiG,EAC3B,IAAIE,EACJ,GAAIF,GAAsB,EAAG,CACzB,MAAMG,EAAe,YAAQtG,EAAO,CAACoG,EAAOD,IAC5CE,EAAM,YAAKC,OAEV,CAGD,MAAMC,EAAc,CAACH,EAAO,GAAKD,EAAqB,IAChDK,EAAY,YAAQ,YAAKxG,GAAQ,CAACoG,EAAOD,IACzCM,EAAY,YAAQ,YAAKzG,GAAQ,CAACoG,EAAOD,IACzCO,EAAgB,YAAQ,YAAMF,EAAW,CAAC,EAAG,GAAI,CAACJ,EAAOD,EAAqB,IAAK,GACnFQ,EAAgB,YAAI,YAAQ,YAAMF,EAAW,CAAC,EAAG,GAAI,CAACL,EAAOD,EAAqB,IAAK,GAAI,aAAQ,IACnGS,EAAI,YAAO,CAACJ,EAAWE,GAAgB,GACvCtH,EAAI,YAAO,CAACqH,EAAWE,GAAgB,GACvCL,EAAe,YAAQ,YAAQM,EAAGxH,GAAI,CAACmH,EAAY,GAAIA,EAAY,KACzEF,EAAM,YAAKC,GAIf,GAFAD,EAAM,YAAKA,GAEQ,IAAfrG,EAAMX,MAAiC,IAAnBW,EAAMf,MAAM,GAAU,CAC1C,MAAM4H,EAAOR,EACPD,EAAQpG,EAAMf,MAAM,GAC1BoH,EAAM,YAAQA,EAAK,CAACD,EAAOC,EAAIpH,MAAM,GAAKmH,EAAOC,EAAIpH,MAAM,KAC3D4H,EAAKC,UAET,OAAOT,M,iCCzEX,kEAsCO,MAAMU,EAAQ,YAAG,CAAEC,OAL1B,SAAgB3I,GACZ,MACME,EAAS,CAAEF,EADN,YAAgBA,EAAG,IAAK,UAEnC,OAAO,IAAOK,UAAU,KAAOH,O,iCCpCnC,0EAwDO,MAAM0I,EAAM,YAAG,CAAEC,KAPxB,SAAcC,EAAMC,GAChB,IAAIC,EAAQ,YAAgBF,EAAM,OAAQ,OACtCG,EAAO,YAAgBF,EAAK,MAAO,QACtCC,EAAOC,GAAQ,YAAeD,EAAOC,GACtC,MAAM/I,EAAS,CAAEoB,EAAG0H,EAAOzH,EAAG0H,GAC9B,OAAO,IAAO5I,UAAU,KAAKH,O,gCCtDjC,qDAiCO,SAASgJ,EAAOC,EAAO1B,GAC1B,IAAM,YAAa0B,IAAoB,WAAV1B,GAAuB/D,MAAM0F,QAAQD,KACpD,cAAV1B,EACA,MAAM,IAAIpB,MAAM,kFAGpB,GAAc,WAAVoB,GAAsB,YAAa0B,MACjCA,aAAiBE,YACnB,MAAM,IAAIhD,MAAM,6EAKpB,OAAO,YAAW8C,EAFJ,GACQ,GACyB1B,K,iCC9CnD,oEAiCO,SAAS6B,EAAK1I,EAAO6G,EAAQ,WAChC,GAAc,cAAVA,EAAuB,CACvB,MAAM8B,EAAOD,EAAK1I,EAAO,WACnB4I,EAAO,YAAM5I,EAAO,WAC1B,OAAO,YAAQ2I,EAAMC,GAEzB,MAAMC,EAAS,YAAmB,YAAc7I,GAAQ6G,GACxD,OAAO,IAAOiC,WAAWD,EAAQ7I,EAAO6G,K,iCCxC5C,kFA4CO,MAAMkC,EAAW,YAAG,CAAEC,UAR7B,SAAmBtI,EAAGC,GAClB,IAAIC,EAAK,YAAgBF,EAAG,IAAK,WAAY,qBACzCG,EAAK,YAAgBF,EAAG,IAAK,WAAY,sBAC5CC,EAAIC,GAAM,YAAeD,EAAIC,GAC9B,YAA2BD,EAAGZ,MAAOa,EAAGb,OACxC,MAAMV,EAAS,CAAEoB,EAAGE,EAAID,EAAGE,GAC3B,OAAO,IAAOpB,UAAU,KAAUH,O,iCC1CtC,kFAuDO,MAAM2J,EAAoB,YAAG,CAAEC,mBATtC,SAA4BxI,EAAGC,GAC3B,IAAIC,EAAK,YAAgBF,EAAG,IAAK,qBAC7BG,EAAK,YAAgBF,EAAG,IAAK,sBAChCC,EAAIC,GAAM,YAAeD,EAAIC,GAC9B,YAA2BD,EAAGZ,MAAOa,EAAGb,OACxC,MAAMV,EAAS,CAAEoB,EAAGE,EAAID,EAAGE,GAE3B,OAAO,IAAOpB,UAAU,KAAmBH,EAD7B,Q,iCCpDlB,kEAuCO,MAAM6J,EAAO,YAAG,CAAEC,MANzB,SAAehK,EAAGiK,EAAQ,GACtB,MACM/J,EAAS,CAAEF,EADN,YAAgBA,EAAG,IAAK,SAE7BG,EAAQ,CAAE8J,SAChB,OAAO,IAAO5J,UAAU,KAAMH,EAAQC,O,iCCrC1C,kEAsCO,MAAM+J,EAAQ,YAAG,CAAEC,OAL1B,SAAgBnK,GACZ,MACME,EAAS,CAAEF,EADN,YAAgBA,EAAG,IAAK,UAEnC,OAAO,IAAOK,UAAU,KAAOH,O,iCCpCnC,kEA0CO,MAAMkK,EAAQ,YAAG,CAAEC,OAN1B,SAAgBrK,EAAGiK,GACf,MAEM/J,EAAS,CAAEF,EAFN,YAAgBA,EAAG,IAAK,SAEXiK,MADT,YAAgBA,EAAO,QAAS,UAE/C,OAAO,IAAO5J,UAAU,KAAOH,O,iCCxCnC,4DA0CO,SAASoK,EAASb,EAAQ7I,EAAO6G,GAEpC,GADA,YAAcgC,GACD,MAAT7I,GAAkC,IAAjBA,EAAMK,OACvB,MAAM,IAAIoF,MAAM,mDAEpB,MAAMkE,EAAgB,YAAWd,EAAQhC,GACzC,GAA6B,IAAzB8C,EAActJ,QAAyC,IAAzBsJ,EAActJ,OAC5C,MAAM,IAAIoF,MAAM,oEAEpB,GAA6B,IAAzBkE,EAActJ,QAAyB,MAATL,EAC9B,MAAM,IAAIyF,MAAM,2EAGpB,OAAO,YAAWoD,EAAQ7I,EAAO2J,EAAe9C,K,iCCvDpD,+EAqBO,MAAM+C,EAAwB,GAC9B,SAASC,EAAyBC,GACrC,OAAIA,GAAUF,EACHE,EAEJ,YAAeA,EAAQpI,KAAKqI,MAAMrI,KAAKhC,KAAKoK,O,gCC1BvD,kEA+DO,MAAM9E,EAAQ,YAAG,CAAEgF,OAT1B,SAAgB5K,EAAG4B,EAAOC,GACtB,MAAMlB,EAAK,YAAgBX,EAAG,IAAK,QAAS,qBAC5C,GAAgB,IAAZW,EAAGK,KACH,MAAM,IAAIqF,MAAM,kCAEpB,MAAMnG,EAAS,CAAEF,EAAGW,GACdR,EAAQ,CAAEyB,QAAOC,QACvB,OAAO,IAAOxB,UAAU,KAAOH,EAAQC,O,iCC5CpC,SAAS0K,EAAeC,EAAQC,EAAaC,GAGhD,MAAO,CAFSA,GAAgC,iBAAXF,EAAsBA,EAASA,EAAO,IAC3DC,GAAiC,iBAAXD,EAAsBA,EAASA,EAAO,KAnBhF,mC,iCCAA,oEAgBO,MAAMG,EAAkB,mBAClBC,EAAa,oB,iCCjB1B,6CAMO,SAASC,EAAiBnL,EAAGoL,EAAiBnL,EAAO,GACxD,IAAIoL,EAAa,GACjB,GAAiC,iBAAtB,EACP,YAAOrL,EAAEY,MAAMX,GAAQmL,GAAoB,GAAG,IAAM,kDACpDC,EACI,IAAI3H,MAAM0H,GAAiB1F,KAAK1F,EAAEY,MAAMX,GAAQmL,OAEnD,CACD,MAAME,EAAYF,EAAgBG,QAAO,CAACC,EAAOrC,MAC9B,IAAXA,IACAqC,GAAS,GAENA,IACR,GACH,YAAOF,GAAa,GAAG,IAAM,4DAC7B,MAAMG,EAAWL,EAAgB/G,SAAS,GAG1C,IAAkB,IAAdoH,EAAiB,CACjB,MAAMC,EAAQN,EAAgBG,QAAO,CAACjK,EAAGC,IAAMA,EAAI,EAAID,EAAIC,EAAID,IAC/D8J,EAAgBK,GAAYzL,EAAEY,MAAMX,GAAQyL,EAEhD,YAAO1L,EAAEY,MAAMX,KAAUmL,EAAgBG,QAAO,CAACjK,EAAGC,IAAMD,EAAIC,KAAI,IAAM,gEACxE8J,EAAaD,EAEjB,OAAOC,I,iCC/BX,kMAkBO,SAASM,EAA8BjB,EAAQkB,GAClD,IACIC,EADAC,GAAO,EASX,IAPIpB,GAAU,KACVmB,EAAMnB,EACNoB,GAAO,GAGPD,EAAM,YAAenB,EAAQpI,KAAKqI,MAAMrI,KAAKhC,KAAKoK,MAE9CoB,GACAD,EAAMD,GAAeC,IAAQnB,EAC7BoB,GAAO,EAGPD,EAAM,YAAenB,EAAQmB,EAAM,GAG3C,OAAOA,EAEJ,SAAS1J,EAAgB4J,EAAQ9L,EAAM2L,GAC1C,MAAMnF,EAAW,GACXzF,EAAO+K,EAAO9K,OACpB,IAAK,IAAI+K,EAAM,EAAGA,EAAMhL,EAAMgL,IACtBA,IAAQ/L,EACRwG,EAASvE,KAAK6J,EAAOC,IAGrBvF,EAASvE,KAAK0J,GAGtB,OAAOnF,EAEJ,SAASwF,EAAyBjM,EAAGkM,EAASjM,EAAMkM,GACvD,MAAMC,EAAcF,EAAQtL,MAAMK,OAC5BuE,EAAQxF,EAAEY,MAAMK,OACtB,GAAkB,IAAdkL,IACIA,GAAaC,GAAeD,EAAYC,GACxC,MAAM,IAAI/F,MAAM,sCAAsC+F,MAAgBA,eAAyBD,KAMvG,GAHIA,EAAY,IACZA,GAAaC,GAEbD,EAAY3G,EACZ,MAAM,IAAIa,MAAM,cAAc8F,uCAChC3G,OAEF,GAAIvF,EAAOkM,EACP,MAAM,IAAI9F,MAAM,cAAc8F,0CAAkDlM,OAEpF,IAAK,IAAIc,EAAI,EAAGA,EAAIoL,IAAapL,EAC7B,GAAIf,EAAEY,MAAMG,KAAOmL,EAAQtL,MAAMG,GAC7B,MAAM,IAAIsF,MAAM,WAAWtF,OAAOf,EAAEY,MAAMG,uCAAuCA,OAAOmL,EAAQtL,MAAMG,OAG9G,MAAMsL,EAAUrM,EAAEY,MAAMX,GAClBiI,EAAc,GACpB,IAAIoE,EAAY,EACZC,EAAY,EACZC,EAAY,EAChB,IAAK,IAAIzL,EAAI,EAAGA,EAAIoL,IAAapL,EAC7BmH,EAAYhG,KAAKlC,EAAEY,MAAMG,IACzBuL,GAAatM,EAAEY,MAAMG,GAEzB,IAAK,IAAIA,EAAIoL,EAAWpL,EAAId,EAAMc,IAC9BmH,EAAYhG,KAAKlC,EAAEY,MAAMG,IACzBwL,GAAavM,EAAEY,MAAMG,GAEzB,IAAK,IAAIA,EAAIoL,EAAWpL,EAAIqL,EAAarL,IACrCmH,EAAYhG,KAAKgK,EAAQtL,MAAMG,IAEnC,IAAK,IAAIA,EAAId,EAAO,EAAGc,EAAIyE,EAAOzE,IAC9BmH,EAAYhG,KAAKlC,EAAEY,MAAMG,IACzByL,GAAaxM,EAAEY,MAAMG,GAEzB,MAAO,CAAEuL,YAAWE,YAAWD,YAAWF,UAASnE,iB,mlCCzEhD,SAASuE,EAAaC,EAAcpL,EAAGC,GAC1C,MAAMoL,EAAO,EAAID,EAAe,EAC1BE,EAAY,IAAIC,aAAaH,GACnC,IAAK,IAAI3L,EAAI,EAAGA,EAAI2L,IAAgB3L,EAAG,CACnC,MAAM+L,EAAU,EAAMxK,KAAKyK,GAAKhM,GAAM2L,EAAeC,EAAO,GAC5DC,EAAU7L,GAAKO,EAAIC,EAAIe,KAAK0K,IAAIF,GAEpC,OAAO,OAAAG,EAAA,GAASL,EAAW,WCKF,YAAG,CAAEM,eAHlC,SAAwBR,GACpB,OAAOD,EAAaC,EAAc,IAAM,QCErC,MAAMS,EAAa,YAAG,CAAEC,YAH/B,SAAqBV,GACjB,OAAOD,EAAaC,EAAc,GAAK,O,YC6BpC,MAAM,EAAQ,YAAG,CAAEW,OAtB1B,SAAgBC,EAAQC,EAAaC,EAAWC,GAAS,EAAOC,EAAW,GACvE,IAAI5I,EAAQ,EACZ,MAAM6I,EAAS,GACf,KAAO7I,EAAQyI,GAAeD,EAAOzL,MACjC8L,EAAOzL,KAAK,OAAA0D,EAAA,GAAM0H,EAAQxI,EAAOyI,IACjCzI,GAAS0I,EAEb,GAAIC,EACA,KAAO3I,EAAQwI,EAAOzL,MAAM,CACxB,MAAM+L,EAAU9I,EAAQyI,EAAeD,EAAOzL,KACxCgM,EAAM,OAAAlI,EAAA,GAAO,CACf,OAAAC,EAAA,GAAM0H,EAAQxI,EAAOyI,EAAcK,GAAS,OAAAlI,EAAA,GAAK,CAACkI,GAASF,KAE/DC,EAAOzL,KAAK2L,GACZ/I,GAAS0I,EAGjB,OAAsB,IAAlBG,EAAO1M,OACA,OAAA6M,EAAA,GAAS,GAAI,CAAC,EAAGP,IAErB,OAAAQ,EAAA,GAAQ,OAAApI,EAAA,GAAOgI,GAAS,CAACA,EAAO1M,OAAQsM,OCZ/B,YAAG,CAAES,MARzB,SAAeV,EAAQC,EAAaC,EAAWS,EAAWC,EAAWf,GJrB9D,IAA6BhE,EIsBf,MAAb8E,IJtB4B9E,EIuBIoE,EAAhCU,EJrBG3L,KAAKqI,MAAMrI,KAAKsG,IAAI,EAAGtG,KAAKC,KAAKD,KAAK4E,IAAIiC,GAAS7G,KAAK4E,IAAI,OIuBnE,MAAMiH,EAAe,EAAMb,EAAQC,EAAaC,GAC1CY,EAAiB,OAAAC,EAAA,GAAIF,EAAcD,EAASX,IAClD,OAAO,OAAAe,EAAA,GAAKF,EAAgBH,M,gQCgEzB,MAAMM,GAAsB,YAAG,CAAEC,qBAhCxC,SAA8BtC,EAASzC,EAAQgF,EAAYC,GACvD,MAAMC,EAAW,aAAgBzC,EAAS,UAAW,uBAC/C0C,EAAU,aAAgBnF,EAAQ,SAAU,uBAC5CoF,EAAc,aAAgBJ,EAAY,aAAc,uBACxDK,EAAgB,aAAgBJ,EAAc,eAAgB,sBAAuBE,EAAQnH,OACnG,GAAsB,IAAlBkH,EAAS3N,KACT,MAAM,IAAIqF,MAAM,0DACdsI,EAAS/N,SAEf,GAAqB,IAAjBgO,EAAQ5N,KACR,MAAM,IAAIqF,MAAM,gDAAgDuI,EAAQhO,SAE5E,GAAyB,IAArBiO,EAAY7N,KACZ,MAAM,IAAIqF,MAAM,qDAAqDwI,EAAYjO,SAErF,GAA2B,IAAvBkO,EAAc9N,KACd,MAAM,IAAIqF,MAAM,uDAAuDyI,EAAclO,SAEzF,MAAMV,EAAS,CACXgM,QAASyC,EACTlF,OAAQmF,EACRH,WAAYI,EACZH,aAAcI,GAEZC,EAAS,KAAO1O,UAAU,MAAqBH,GACrD,MAAO,CACH8O,cAAeD,EAAO,GACtBE,aAAcF,EAAO,GACrBG,kBAAmBH,EAAO,GAC1BI,gBAAiBJ,EAAO,OC7BzB,MAAMK,GAAgB,YAAG,CAAEC,eAtBlC,SAAwBC,EAAc3M,EAAY4D,GAC9C,MAAMgJ,EAAgB,aAAgBD,EAAc,eAAgB,iBAC9DE,EAAc,aAAgB7M,EAAY,aAAc,iBACxD8M,EAAY,aAAgBlJ,EAAU,WAAY,iBACxD,GAA2B,IAAvBgJ,EAAcvO,KACd,MAAM,IAAIqF,MAAM,gEACdkJ,EAAc3O,SAEpB,GAAyB,IAArB4O,EAAYxO,KACZ,MAAM,IAAIqF,MAAM,qDAAqDmJ,EAAY5O,SAErF,GAAuB,IAAnB6O,EAAUzO,KACV,MAAM,IAAIqF,MAAM,mDAAmDoJ,EAAU7O,SAEjF,MAAMV,EAAS,CACXoP,aAAcC,EACd5M,WAAY6M,EACZjJ,SAAUkJ,GAERV,EAAS,KAAO1O,UAAU,MAAeH,GAC/C,MAAO,CAAE8O,cAAeD,EAAO,GAAI7G,YAAa6G,EAAO,OCEpD,MAAMW,GAAoB,YAAG,CAAEC,mBAtBtC,SAA4BC,EAAM1D,EAAS2D,GACvC,MAAMC,EAAQ,aAAgBF,EAAM,OAAQ,qBACtCjB,EAAW,aAAgBzC,EAAS,UAAW,qBAC/C6D,EAAc,aAAgBF,EAAY,aAAc,qBAC9D,GAAIC,EAAM9O,KAAO,EACb,MAAM,IAAIqF,MAAM,6DAEpB,GAAsB,IAAlBsI,EAAS3N,KACT,MAAM,IAAIqF,MAAM,4DACZsI,EAAS/N,SAEjB,GAAyB,IAArBmP,EAAY/O,KACZ,MAAM,IAAIqF,MAAM,gEACZ0J,EAAYnP,SAEpB,MAAMV,EAAS,CACX0P,KAAME,EACN5D,QAASyC,EACTkB,WAAYE,GAEhB,OAAO,KAAO1P,UAAU,MAAmBH,MCExC,MAAM8P,GAAmB,YAAG,CAAEC,kBAtBrC,SAA2BL,EAAM1D,EAAS2D,GACtC,MAAMC,EAAQ,aAAgBF,EAAM,OAAQ,oBACtCjB,EAAW,aAAgBzC,EAAS,UAAW,oBAC/C6D,EAAc,aAAgBF,EAAY,aAAc,oBAC9D,GAAIC,EAAM9O,KAAO,EACb,MAAM,IAAIqF,MAAM,6DAEpB,GAAsB,IAAlBsI,EAAS3N,KACT,MAAM,IAAIqF,MAAM,2DACbsI,EAAS/N,SAEhB,GAAyB,IAArBmP,EAAY/O,KACZ,MAAM,IAAIqF,MAAM,+DACb0J,EAAYnP,SAEnB,MAAMV,EAAS,CACX0P,KAAME,EACN5D,QAASyC,EACTkB,WAAYE,GAEhB,OAAO,KAAO1P,UAAU,MAAkBH,MCWvC,MAAMgQ,GAAe,YAAG,CAAEC,cAxBjC,SAAuBP,EAAMQ,EAAYC,EAAWC,EAAaC,EAASC,EAAUC,EAAUC,GAC1F,MAAMZ,EAAQ,aAAgBF,EAAM,OAAQ,eAAgB,UAC5D,GAAoB,WAAhBE,EAAMrI,MACN,MAAM,IAAIpB,MAAM,mCAEpB,GAA2B,IAAvByJ,EAAMlP,MAAMK,OACZ,MAAM,IAAIoF,MAAM,+BAA+ByJ,EAAMlP,SAEzD,MAAM+P,EAAc,aAAgBP,EAAY,aAAc,gBAC9D,GAA0B,UAAtBO,EAAYlJ,MACZ,MAAM,IAAIpB,MAAM,yCAEpB,MAAMlG,EAAQ,CACVkQ,YACAC,cACAC,UACAC,WACAC,WACAC,0BAEExQ,EAAS,CAAE0P,KAAME,EAAOM,WAAYO,GACpC5B,EAAS,KAAO1O,UAAU,MAAcH,EAAQC,GACtD,MAAO,CAAEyQ,OAAQ7B,EAAO,GAAI8B,aAAc9B,EAAO,OCjB9C,MAAM+B,GAAc,YAAG,CAAEC,aAdhC,SAAsBpP,EAAOqP,EAAWC,GAAY,GAChD,MAAMC,EAAS,aAAgBvP,EAAO,QAAS,cAAe,UACxDwP,EAAa,aAAgBH,EAAW,YAAa,cAAe,UAC1E,GAAoB,IAAhBE,EAAOlQ,KACP,MAAM,IAAIqF,MAAM,+CAA+C6K,EAAOtQ,SAE1E,GAAwB,IAApBuQ,EAAWnQ,KACX,MAAM,IAAIqF,MAAM,mDAAmD8K,EAAWvQ,SAElF,MAAMT,EAAQ,CAAE8Q,aACV/Q,EAAS,CAAEyB,MAAOuP,EAAQF,UAAWG,GACrCpC,EAAS,KAAO1O,UAAU,MAAaH,EAAQC,GACrD,MAAO,CAAE+L,QAAS6C,EAAO,GAAItF,OAAQsF,EAAO,GAAInO,MAAOmO,EAAO,OCd3D,MAAMqC,GAAyB,YAAG,CAAEC,wBAT3C,SAAiC1P,EAAO2P,GACpC,MAAMJ,EAAS,aAAgBvP,EAAO,QAAS,yBAA0B,UACnExB,EAAQ,CAAEmR,cAChB,GAAIA,GAAc,EACd,MAAM,IAAIjL,MAAM,wCAEpB,MAAMnG,EAAS,CAAEyB,MAAOuP,GACxB,OAAO,KAAO7Q,UAAU,MAAwBH,EAAQC,MCqMtD,IA9BFoR,EAAA,EACAC,EAAA,EACAlD,EAAA,EACA1G,EAAA,EA2BU,CACV6J,cAAA,IACAC,sBAAA,IACAC,eAAA,IACAC,iBAAA,IACAC,cAAA,IACAC,kBAAA,IACAC,uBAAA,IACAC,2BAAA,IACAC,gCAAA,IACAC,wBAAA,IACAC,6BAAA,IACAC,YAAA,EACAC,YAAA,IAoCEC,IA7BF,IACA,IACAC,EAAA,EAaA,IACA,IACA,IACA,IACA,IACA,KACA,KACA,KACA,KAMW,CACXhE,uBACAa,iBACAM,qBACAM,sBAMEwC,GAAS,CACXtC,gBACAY,eACAM,4B,iCCnTJ,2DAkBO,MAAMqB,EACT,YAAYC,EAAcC,GACtBC,KAAKF,aAAeA,EACpBE,KAAKD,OAASA,EACA,MAAVA,IACAC,KAAKD,OAAS,IAAIE,GAG1B,cAAcC,EAAY5S,EAAQ6S,GAC9B,IAAIC,EACJ,MAAMC,EAAsB,KACxBD,EAAUD,KAEd,IAAIG,EACJ,MAAMpO,EAAQ,QACd,GAAI8N,KAAKF,aAAaS,iBAClBD,EAAQN,KAAKF,aAAaU,KAAKH,OAE9B,CACDA,IACA,IAAK,MAAMtF,KAAUqF,EACjBrF,EAAO0F,WAEXH,EAAQI,QAAQC,QAAQ,CAAEC,SAAU,QAAa1O,IAErD,GAAI,cAAM2O,QAAQ,gCACd,IAAK,IAAI1S,EAAI,EAAGA,EAAIiS,EAAQ/R,OAAQF,IAAK,CACrC,MAAM4M,EAASqF,EAAQjS,GAGvB4M,EAAOiC,OAAO8D,MAAKC,IACfC,EAA0BD,EAAYhG,EAAOlG,MAAOqL,MAahE,MATsB,CAClBA,aACAE,UACA9S,SACA2T,OAAQX,EAAMQ,MAAKI,GAAUA,EAAON,WACpCO,UAAWb,EAAMQ,MAAKI,GAAwC,MAA9BA,EAAOE,oBACnCF,EAAOE,sBACP,MAIZ,iBAAiBC,GACb,MAAM,WAAEnB,EAAU,QAAEE,EAAO,OAAEa,EAAM,OAAE3T,EAAM,UAAE6T,GAAcE,EAC3DjB,EAAQ9R,SAAQ6N,IACZuE,QAAQY,IAAI,CAACnF,EAAOa,OAAQiE,EAAQE,IAAYL,MAAKS,IACjDvB,KAAKD,OAAOyB,iBAAiBtB,EAAY/D,EAAQoF,EAAe,GAAIA,EAAe,GAAIjU,EAAQiU,EAAe,WAKvH,SAASP,EAA0BS,EAAM5M,EAAOqL,GACnD,GAAc,YAAVrL,EAEA,OAAO,EAEX,IAAK,IAAI1G,EAAI,EAAGA,EAAIsT,EAAKpT,OAAQF,IAAK,CAClC,MAAMuT,EAAMD,EAAKtT,GACjB,GAAIwT,MAAMD,KAASE,SAASF,GAGxB,OADArN,QAAQwN,KAAK,SAASH,uBAAyBxB,OACxC,EAGf,OAAO,EAEJ,MAAMD,EACT,iBAAiB6B,EAAM3F,EAAQsF,EAAMR,EAAQ3T,EAAQ6T,GACjD,MAAMX,EAAyB,iBAAXS,EAAsB,IAAc,GAAGA,MAAY,GACnEA,EAAc,MACZc,EAAa,IAAcD,EAAM,IACjC1T,EAAO+N,EAAO/N,KACda,EAAOkN,EAAOlN,KACdjB,EAAQ,IAAcmO,EAAOnO,MAAMuG,WAAY,IACrD,IAAIyN,EAAyB,GAC7B,IAAK,MAAMF,KAAQxU,EAAQ,CACvB,MAAMyB,EAAQzB,EAAOwU,GACrB,GAAa,MAAT/S,EAAe,CAGf,MAAMgB,EAAahB,EAAMf,OAASmO,EAAOnO,MACnCkB,EAAYa,EAAW1B,OAC7B2T,GACI,GAAGF,MAAS5S,MAAcA,EAAY,EAAIa,EAAa,OAGnEsE,QAAQC,IAAI,KAAKyN,QAAiBvB,QAAWpS,MAASJ,QAAYiB,QAAW+S,QAA6Bb,IAAa,mBAAoB,YAAa,aAAc,gBAAiB,eAAgB,uB,gCC5G/M,4DAmCO,SAAS9G,EAASxD,EAAQhC,GAC7B,YAAcgC,GACd,MAAMc,EAAgB,YAAWd,EAAQhC,GACzC,GAA6B,IAAzB8C,EAActJ,OACd,MAAM,IAAIoF,MAAM,sDAGpB,OAAO,YAAWoD,EADJ,KACmBc,EAAe9C,K,+BC1CpD,oDAwBO,SAASoN,EAAG9B,GACf,MAAM+B,EAAOC,OAAOD,KAAK/B,GACzB,GAAoB,IAAhB+B,EAAK7T,OACL,MAAM,IAAIoF,MAEN,yGAAGyO,EAAK7T,gBAEhB,IAAI+T,EAASF,EAAK,GAClB,MAAMG,EAAKlC,EAAEiC,GAETA,EAAOE,SAAS,OAChBF,EAASA,EAAOG,UAAU,EAAGH,EAAO/T,OAAS,IAGjD+T,GApB2B,OAsB3B,MAAMI,EAAK,IAAIC,KACX,IAAOC,WAAWN,GAClB,IACI,MAAMjG,EAASkG,KAAMI,GAKrB,OAJI,YAAUtG,IACV9H,QAAQsO,MAAM,2CAElB,IAAOC,SAASzG,GACTA,EAEX,MAAO0G,GAEH,MADA,IAAOD,SAAS,MACVC,IAKd,OAFAV,OAAOW,eAAeN,EAAI,OAAQ,CAAEjM,MAAO6L,EAAQW,cAAc,IAE1DP,I,gCCzDX,6CAiBA,SAASQ,EAAsBC,EAAOC,EAAQC,EAAeC,EAAcC,EAAgBC,GACnE,MAAhBF,IACAA,EAAe,IAEG,MAAlBC,IACAA,EAAiBxR,OAAO0R,mBAER,MAAhBD,IACAA,EAAe,GAEnB,MAAME,EAAWP,EAAMjV,MAAM,GAS7B,OARAmV,EAAgBzT,KAAK+T,IAAIN,EAAeK,GACxC,IAAY,GAAKJ,GAAgBA,GAAgB,GAAG,IAAM,4CAA4CA,OACtG,IAA2B,IAAfH,EAAM7U,MAAY,IAAM,+CAA+C6U,EAAM7U,UACzF,IAA+B,IAAnB6U,EAAMjV,MAAM,IAAU,IAAM,oDAAoDiV,EAAMjV,MAAM,OACxG,IAA4B,IAAhBkV,EAAO9U,MAAY,IAAM,+BACrC,IAAY8U,EAAOlV,MAAM,KAAOwV,GAAU,IAAM,sDAAsDA,cACvFN,EAAOlV,MAAM,OAC5B,IAAY,GAAKsV,GAAgBA,GAAgB,GAAG,IAAM,4CAA4CA,OAC/F,CAAEH,gBAAeC,eAAcC,iBAAgBC,kB,iCCpC1D,4CAqBO,MAAMI,EACT,MAAMC,EAAMC,GACR,OAAOC,MAAMF,EAAMC,GAEvB,MACI,OAAOE,YAAYC,MAEvB,OAAOC,EAAMC,GACT,GAAiB,UAAbA,GAAqC,SAAbA,EACxB,MAAM,IAAIxQ,MAAM,kDAAkDwQ,KAKtE,OAHwB,MAApBjE,KAAKkE,cACLlE,KAAKkE,YAAc,IAAIC,aAEpBnE,KAAKkE,YAAYE,OAAOJ,GAEnC,OAAOK,EAAOJ,GACV,OAAO,IAAIK,YAAYL,GAAUM,OAAOF,IAGhD,GAAI,cAAMG,IAAI,cAAe,CACzB,cAAMC,YAAY,UAAW,IAAIf,GAEjC,IACI,IAA0BgB,gBAAgB,IAAoBC,WAAY,IAAI,KAElF,MAAOC,IAGP,IACI,IAA0BF,gBAAgB,IAAiBC,WAAY,IAAI,KAE/E,MAAOC,O,kCCrDX,uBAkBO,MAAMC,EAEI,IAAM,EAAQ,KAE/B,IAAIC,EAYG,MAAMC,EACT,cAEI/E,KAAKgF,KAAO,EAAQ,KAGpBhF,KAAKkE,YAAc,IAAIlE,KAAKgF,KAAKb,YAErC,MAAMR,EAAMsB,GACR,OAA0B,MAAtB,cAAMC,OAAOrB,MACN,cAAMqB,OAAOrB,MAAMF,EAAMsB,IAEjB,MAAfH,IACAA,EAAcD,KAEXC,EAAYnB,EAAMsB,IAE7B,MACI,MAAMzE,EAAO2E,EAAQC,SACrB,OAAiB,IAAV5E,EAAK,GAAYA,EAAK,GAAK,IAEtC,OAAOwD,EAAMC,GACT,GAAiB,UAAbA,GAAqC,SAAbA,EACxB,MAAM,IAAIxQ,MAAM,sDAAsDwQ,KAE1E,OAAOjE,KAAKkE,YAAYE,OAAOJ,GAEnC,OAAOK,EAAOJ,GACV,OAAqB,IAAjBI,EAAMhW,OACC,GAEJ,IAAI2R,KAAKgF,KAAKV,YAAYL,GAAUM,OAAOF,IAGtD,cAAMG,IAAI,YACV,cAAMC,YAAY,OAAQ,IAAIM,K,kDCrElC,kFA+DO,MAAMM,EAAQ,YAAG,CAAEC,OAlB1B,SAAgBC,EAAW7W,EAAGC,GAC1B,MAAMC,EAAK,YAAgBF,EAAG,IAAK,SAC7BG,EAAK,YAAgBF,EAAG,IAAK,SAC7B6W,EAAa,YAAgBD,EAAW,YAAa,QAAS,QAI9DE,EAAiB,YAA2B,YAA2BD,EAAWxX,MAAOY,EAAGZ,OAAQa,EAAGb,OAIvGV,EAAS,CACXiY,UAJ0B,YAAYC,EAAYC,GAKlDC,EAJkB,YAAY9W,EAAI6W,GAKlCE,EAJkB,YAAY9W,EAAI4W,IAMtC,OAAO,IAAOhY,UAAU,KAAQH,O,gCC7DpC,2DAmBO,SAASwJ,EAAWD,EAAQ7I,EAAO2J,EAAe9C,GAIrD,GAHa,MAATA,IACAA,EAAQ,YAAWgC,IAET,cAAVhC,EACA,MAAM,IAAIpB,MAAM,oFAGpB,IAAK,YAAaoD,KAAY/F,MAAM0F,QAAQK,IACtB,iBAAXA,GAAyC,kBAAXA,GACnB,iBAAXA,EACP,MAAM,IAAIpD,MAAM,4HAGpB,GAAa,MAATzF,EAAe,CACf,YAAmCA,GACnC,MAAM4X,EAAe,YAAc5X,GAC7B6X,EAAe,YAAclO,GACnC,YAAOiO,IAAiBC,GAAc,IAAM,iCAAiC7X,8BACtE4X,oBAA+BC,MACtC,IAAK,IAAI1X,EAAI,EAAGA,EAAIwJ,EAActJ,SAAUF,EAAG,CAC3C,MAAM2X,EAAWnO,EAAcxJ,GACzB4X,EAAoB5X,IAAMwJ,EAActJ,OAAS,GACnDyX,IAAa,YAAc9X,EAAMgF,MAAM7E,IAE3C,YAAOwJ,EAAcxJ,KAAOH,EAAMG,KAAO4X,GAAmB,IACxD,gDAAIpO,yCACM3J,UAUtB,OAPK,YAAa6I,IAAY/F,MAAM0F,QAAQK,KACxCA,EAAS,CAACA,IAEd7I,EAAQA,GAAS2J,EACjBd,EAAmB,WAAVhC,EACL,uBAAagC,EAAQhC,GACrB,YAAQgC,EAAQ,IAAI,GACjB,IAAOC,WAAWD,EAAQ7I,EAAO6G,K,gCCxD5C,yEA8CO,MAAMmR,EAAQ,YAAG,CAAEC,OAV1B,SAAgBC,EAAS7Y,EAAO,GAC5B,MAAM8Y,EAAW,YAAqBD,EAAS,UAAW,QAAS,qBACnE,IAAYC,EAAS9X,QAAU,GAAG,IAAM,yCACpC8X,EAAS9X,OAAS,GAClB,IAAYhB,GAAQ8Y,EAAS,GAAG/X,MAAM,IAAM,uCAEhD,MAAMd,EAAS6Y,EACT5Y,EAAQ,CAAEF,QAChB,OAAO,IAAOI,UAAU,KAAMH,EAAQC,O,gCC5C1C,kEA6DO,MAAM6Y,EAAQ,YAAG,CAAEC,OAN1B,SAAgBjZ,EAAGoL,EAAiBnL,EAAO,GACvC,MACMC,EAAS,CAAEF,EADN,YAAgBA,EAAG,IAAK,UAE7BkZ,EAAO,CAAE9N,kBAAiBnL,QAChC,OAAO,IAAOI,UAAU,KAAQH,EAAQgZ,O,gCC3D5C,4DAgCO,SAASC,EAAMvY,EAAO6G,EAAQ,WACjC,GAAc,cAAVA,EAAuB,CACvB,MAAM8B,EAAO4P,EAAMvY,EAAO,WACpB4I,EAAO2P,EAAMvY,EAAO,WAC1B,OAAO,YAAQ2I,EAAMC,GAEzB,MAAMC,EAAS,YAAoB,YAAc7I,GAAQ6G,GACzD,OAAO,IAAOiC,WAAWD,EAAQ7I,EAAO6G,K,gCCvC5C,kEAsCO,MAAM2R,EAAO,YAAG,CAAEC,MALzB,SAAerZ,GACX,MACME,EAAS,CAAEF,EADN,YAAgBA,EAAG,IAAK,SAEnC,OAAO,IAAOK,UAAU,KAAMH,O,gCCpClC,qDA8CO,SAASoZ,EAAO7P,EAAQ7I,EAAO6G,GAClC,MAAM8C,EAAgB,YAAWd,EAAQhC,GACzC,OAAO,YAAWgC,EAAQ7I,EAAO2J,EAAe9C,K,gCChDpD,4DA0CO,SAASqG,EAASrE,EAAQ7I,EAAO6G,GAEpC,GADA,YAAcgC,GACD,MAAT7I,GAAkC,IAAjBA,EAAMK,OACvB,MAAM,IAAIoF,MAAM,iDAEpB,MAAMkE,EAAgB,YAAWd,EAAQhC,GACzC,GAA6B,IAAzB8C,EAActJ,QAAyC,IAAzBsJ,EAActJ,OAC5C,MAAM,IAAIoF,MAAM,kEAEpB,GAA6B,IAAzBkE,EAActJ,QAAyB,MAATL,EAC9B,MAAM,IAAIyF,MAAM,gFAGpB,OAAO,YAAWoD,EAAQ7I,EAAO2J,EAAe9C,K,gCCvDpD,oDAqCO,SAAS8R,EAAMzU,EAAOG,EAAM8E,EAAO,EAAGtC,EAAQ,WACjD,GAAa,IAATsC,EACA,MAAM,IAAI1D,MAAM,8BAEpB,MAAMlG,EAAQ,CAAE2E,QAAOG,OAAM8E,OAAMtC,SACnC,OAAO,IAAOpH,UAAU,KAAO,GAAiBF,K,gCC1CpD,kEA2CO,MAAMqR,EAAO,YAAG,CAAEgI,MANzB,SAAe7X,GACX,YAAuB,cAAhBA,EAAM8F,OAAuB,IAChC,8DAAW9F,EAAM8F,WACrB,MAAMvH,EAAS,CAAEyB,SACjB,OAAO,IAAOtB,UAAU,KAAMH,O,gCCzClC,kEAwCO,MAAMqJ,EAAO,YAAG,CAAEkQ,MALzB,SAAe9X,GACX,MACMzB,EAAS,CAAEyB,MADF,YAAgBA,EAAO,QAAS,SAE/C,OAAO,IAAOtB,UAAU,KAAMH,O,+BCtClC,kEAoDO,MAAM6N,EAAU,YAAG,CAAE2L,SAN5B,SAAkB1Z,EAAGY,GACjB,MACMV,EAAS,CAAEF,EADN,YAAgBA,EAAG,IAAK,UAAW,sBAExCG,EAAQ,CAAES,SAChB,OAAO,IAAOP,UAAU,KAASH,EAAQC,O,gCClD7C,yEA0CO,MAAMwZ,EAAU,YAAG,CAAEC,SAP5B,SAAkB5Z,EAAGC,EAAO,GACxB,MAAMU,EAAK,YAAgBX,EAAG,IAAK,UAAW,qBAC9C,IAAYC,IAASU,EAAGC,MAAMK,QAAUhB,EAAOU,EAAGC,MAAMK,QAAQ,IAAM,UAAUhB,iBAAoBU,EAAGC,MAAMK,WAAWN,EAAGC,MAAMK,YACjI,MAAMf,EAAS,CAAEiJ,MAAOxI,GAClBR,EAAQ,CAAEF,QAChB,OAAO,IAAOI,UAAU,KAAQH,EAAQC,O,gCCxC5C,kEA2CO,MAAMoR,EAAM,YAAG,CAAEsI,KANxB,SAAclY,GACV,YAAuB,cAAhBA,EAAM8F,OAAuB,IAChC,6DAAW9F,EAAM8F,WACrB,MAAMvH,EAAS,CAAEyB,SACjB,OAAO,IAAOtB,UAAU,IAAKH,O,gCCzCjC,mIAgFO,MAAMoO,EAAO,YAAG,CAAEwL,MArCzB,SAAenY,EAAOsM,GAClB,YAAuB,YAAhBtM,EAAM8F,OAAqB,IAAM,mDAAmD9F,EAAM8F,UACjG,IAAIK,EAAqBnG,EAAMf,MAAMe,EAAMf,MAAMK,OAAS,GAC1D,MAAM8G,EAAQpG,EAAME,KAAOiG,EAC3B,IAAIiS,EACJ,GAAiB,MAAb9L,GAAqBA,EAAYnG,EAAoB,CAErD,MAAMlG,EAAQD,EAAMf,MAAMC,KAAIiG,GAAK,IAC7BjF,EAAOF,EAAMf,MAAMC,KAAIiG,GAAKA,IAClCjF,EAAKF,EAAMf,MAAMK,OAAS,GAAKgN,EAC/B8L,EAAgB,YAAMpY,EAAOC,EAAOC,GACpCiG,EAAqBmG,OAEpB,GAAiB,MAAbA,GAAqBA,EAAYnG,EAAoB,CAE1D,MAAMkS,EAAarY,EAAMf,MAAMC,KAAIiG,GAAKA,IACxCkT,EAAWrY,EAAMf,MAAMK,OAAS,GAAKgN,EAAYnG,EACjDiS,EAAgB,YAAO,CAACpY,EAAO,YAAMqY,IAAcrY,EAAMf,MAAMK,OAAS,GACxE6G,EAAqBmG,OAGrB8L,EAAgBpY,EAGpB,MAAMsY,EAAa,YAAUF,GACvB9R,EAAe,YAAQ,YAAQ8R,EAAeE,GAAa,CAAClS,EAAOD,IACnEE,EAAM,YAAIC,GAEViS,EAAO5X,KAAKqI,MAAM7C,EAAqB,GAAK,EAC5CqS,EAAa,YAAKnS,GAClBoS,EAAa,YAAKpS,GAClBqS,EAAuB,YAAMF,EAAY,CAACD,EAAMpS,EAAqBoS,GAAOC,EAAWvZ,MAAMK,OAAS,GACtGqZ,EAAuB,YAAMF,EAAY,CAACF,EAAMpS,EAAqBoS,GAAOE,EAAWxZ,MAAMK,OAAS,GACtGiH,EAAc6R,EAAcnZ,MAAMgF,QAExC,OADAsC,EAAY6R,EAAcnZ,MAAMK,OAAS,GAAKiZ,EACvC,YAAQ,YAAQG,EAAqB,GAAIC,EAAqB,IAAKpS,O,gCC9E9E,6IA6EA,SAASqS,EAASva,EAAGwa,EAAGva,EAAO,MAC3B,GAAe,IAAXD,EAAEgB,KACF,OAAO,YAAIhB,GAGf,GAAe,IAAXA,EAAEgB,MAAuB,OAATf,EAChB,OAAOsa,EAAS,YAAQva,EAAG,EAAE,IAAKwa,EAAGva,GAGzC,GAAe,IAAXD,EAAEgB,MAA8B,iBAATf,GACvByD,MAAM0F,QAAQnJ,IAAyB,IAAhBA,EAAKgB,OAAc,CAC1C,GAAU,IAANuZ,EACA,OAAO,YAAI,YAAIxa,GAAIC,GAEvB,GAAIua,IAAMC,IACN,OAAO,YAAI,YAAIza,GAAIC,GAEvB,GAAIua,KAAOC,IACP,OAAO,YAAI,YAAIza,GAAIC,GAEvB,GAAU,cAANua,GAA2B,IAANA,EAErB,OAAO,YAAK,YAAI,YAAI,YAAIxa,GAAI,YAAO,EAAG,UAAWC,IAErD,MAAM,IAAIoG,MAAM,qCAAqCmU,KAGzD,GAAI9W,MAAM0F,QAAQnJ,IAAyB,IAAhBA,EAAKgB,OAAc,CAC1C,GAAU,IAANuZ,EACA,OAAO,YAAI,YAAI,YAAIxa,GAAIC,EAAK,IAAKA,EAAK,GAAK,GAE/C,GAAIua,IAAMC,IACN,OAAO,YAAI,YAAI,YAAIza,GAAIC,EAAK,IAAKA,EAAK,IAE1C,GAAIua,KAAOC,IACP,OAAO,YAAI,YAAI,YAAIza,GAAIC,EAAK,IAAKA,EAAK,IAE1C,GAAU,QAANua,GAAqB,cAANA,EAEf,OAAO,YAAK,YAAI,YAAOxa,GAAIC,IAE/B,MAAM,IAAIoG,MAAM,qCAAqCmU,KAEzD,MAAM,IAAInU,MAAM,gCAAgCpG,KAE7C,MAAMya,EAAO,YAAG,CAAEC,MAvDzB,SAAe3a,EAAG4a,EAAM,YAAa3a,EAAO,KAAMuH,GAAW,GAEzD,MAAMkT,EAAOH,EADbva,EAAI,YAAgBA,EAAG,IAAK,QACH4a,EAAK3a,GAC9B,IAAI4a,EAAgBH,EAAK9Z,MACzB,GAAI4G,EAAU,CACV,MAAMvF,EAAO,YAAehC,EAAMD,EAAEY,OACpCia,EAAgB,IAA+BH,EAAK9Z,MAAOqB,GAE/D,OAAO,YAAQyY,EAAMG,O,gCC3EzB,2DAoCO,MAAMC,EAAS,YAAG,CAAEC,QAL3B,SAAiB/a,GACb,MAAMW,EAAK,YAAgBX,EAAG,IAAK,UAEnC,OAAO,IAAOK,UAAU,SAAU,CAAEL,EAAGW,GADzB,Q,gCCjClB,yEAsDO,MAAMqa,EAAO,YAAG,CAAEC,MARzB,SAAejb,EAAGkb,GACd,MAAMva,EAAK,YAAgBX,EAAG,IAAK,OAAQ,qBAC3C,IAAYW,EAAGK,OAASka,EAAKja,QAAQ,IAAM,qCAAqCN,EAAGK,kCAClDka,OACjC,MAAMhb,EAAS,CAAEF,EAAGW,GACdR,EAAQ,CAAE+a,QAChB,OAAO,IAAO7a,UAAU,KAAMH,EAAQC,O,gCCpD1C,oKAOO,SAASgb,EAAoBva,EAAOsL,EAASkP,GAChD,MAAMC,EAAYnP,EAAQlL,KAAO,EAAKkL,EAAQtL,MAAMsL,EAAQlL,KAAO,GAAK,EAClEsa,EAAYpP,EAAQlL,KAAO,EAAKkL,EAAQlL,KAAO,EAAI,EACnDua,EACF,6FAAwCH,EAAQxa,yBAC5BsL,EAAQtL,iBAAiBA,gBAC9Bya,oBAA2BC,KAC9C,GAAIF,EAAQpa,KAAOsa,EACf,MAAM,IAAIjV,MAAMkV,EAAa,kBAAkBD,OAEnD,GAAI1a,EAAMK,OAASoa,GAAYD,EAAQpa,KAAOsa,GAC1C,MAAM,IAAIjV,MAAMkV,EACZ,0BAA0BF,GAAYD,EAAQpa,KAAOsa,MAE7D,GAAIF,EAAQpa,OAASsa,EAAW1a,EAAMK,OAASoa,EAC3C,MAAM,IAAIhV,MAAMkV,EAAa,oBAAmBD,EAAW1a,EAAMK,OAASoa,IAE9E,IAAK,IAAIxV,EAAI,EAAGA,EAAIyV,IAAYzV,EAC5B,GAAIuV,EAAQxa,MAAMiF,KAAOqG,EAAQtL,MAAMiF,GACnC,MAAM,IAAIQ,MAAMkV,EACZ,kBAAkB1V,OAAOuV,EAAQxa,MAAMiF,wBAAwBA,OAAOqG,EAAQtL,MAAMiF,QAGhG,IAAK,IAAIA,EAAI,EAAGA,EAAIuV,EAAQpa,KAAOsa,IAAYzV,EAC3C,GAAIuV,EAAQxa,MAAMiF,EAAIyV,KAAc1a,EAAMiF,EAAIwV,GAC1C,MAAM,IAAIhV,MAAMkV,EACZ,kBAAkB1V,EAAIyV,OAAcF,EAAQxa,MAAMiF,EAAIyV,gBAAuBzV,EAAIyV,OAAc1a,EAAMiF,EAAIyV,OAWlH,SAASE,EAAcJ,EAASlP,EAAStL,GAC5C,GAAIsL,EAAQlL,KAAO,EACf,MAAM,IAAIqF,MACN,+EAAqB6F,EAAQlL,SAErC,GAAIoa,EAAQpa,KAAO,EACf,MAAM,IAAIqF,MACN,+EAAqB+U,EAAQpa,SAErC,GAAsB,UAAlBkL,EAAQzE,MACR,MAAM,IAAIpB,MAAM,0DAA0D6F,EAAQzE,SAEtF,GAAI7G,EAAMK,OAAS,EACf,MAAM,IAAIoF,MAAM,6DAA6DzF,KAEjF,GAAqB,IAAjBA,EAAMK,OAAc,CACpB,GAAqB,IAAjBiL,EAAQrK,KACR,MAAM,IAAIwE,MAAM,sDAAsD6F,EAAQtL,SAElF,GAAqB,IAAjBwa,EAAQvZ,KACR,MAAM,IAAIwE,MAAM,sDAAsD+U,EAAQxa,SAGtFua,EAAoBva,EAAOsL,EAASkP,GAWjC,SAASK,EAAgBL,EAASlP,EAAStL,GAE9C,MAAMwL,EAAcF,EAAQtL,MAAMK,OAC5Bya,EAAatP,EAAc,EAAKF,EAAQtL,MAAMwL,EAAc,GAAK,EAIjEuP,EAAU/a,EAAMK,OACtB,IAAIuL,EAAY,EAChB,IAAK,IAAIzL,EAAI2a,EAAW3a,EAAI4a,IAAW5a,EACnCyL,GAAa5L,EAAMG,GAEvB,MAAM6a,EAAgBF,EAAY,EAAK,EAAIA,EAI3C,MAAO,CAAEA,YAAWG,WAHD,YAAc3P,EAAQtL,OAASgb,EAGlBpP,YAAWnK,QAF3B,IAAI,YAAezB,EAAMgF,MAAM,EAAG8V,IAAa,GAEXI,WADjC,YAAclb,M,gCC7FrC,kEAsCO,MAAMmb,EAAY,YAAG,CAAEC,WAL9B,SAAoBhc,GAChB,MACME,EAAS,CAAEF,EADN,YAAgBA,EAAG,IAAK,cAEnC,OAAO,IAAOK,UAAU,KAAWH","file":"js/bundle~bundle~58c2b9c4.1919374e.js","sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Reverse } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Reverses a `tf.Tensor` along a specified axis.\n *\n * Also available are stricter rank-specific methods that assert that `x` is\n * of the given rank:\n *   - `tf.reverse1d`\n *   - `tf.reverse2d`\n *   - `tf.reverse3d`\n *   - `tf.reverse4d`\n *\n * Except `tf.reverse1d` (which does not have axis param), all methods have\n * same signature as this method.\n *\n * ```js\n * const x = tf.tensor1d([1, 2, 3, 4]);\n *\n * x.reverse().print();\n * ```\n *\n * ```js\n * const x = tf.tensor2d([1, 2, 3, 4], [2, 2]);\n *\n * const axis = 1;\n * x.reverse(axis).print();\n * ```\n * @param x The input tensor to be reversed.\n * @param axis The set of dimensions to reverse. Must be in the\n *     range [-rank(x), rank(x)). Defaults to all axes.\n *\n * @doc {heading: 'Tensors', subheading: 'Slicing and Joining'}\n */\nfunction reverse_(x, axis) {\n    const $x = convertToTensor(x, 'x', 'reverse');\n    const inputs = { x: $x };\n    const attrs = { dims: axis };\n    return ENGINE.runKernel(Reverse, inputs, attrs);\n}\nexport const reverse = op({ reverse_ });\n//# sourceMappingURL=reverse.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Sqrt } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes square root of the input `tf.Tensor` element-wise: `y = sqrt(x)`\n *\n * ```js\n * const x = tf.tensor1d([1, 2, 4, -1]);\n *\n * x.sqrt().print();  // or tf.sqrt(x)\n * ```\n * @param x The input tensor.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction sqrt_(x) {\n    const $x = convertToTensor(x, 'x', 'sqrt');\n    const inputs = { x: $x };\n    return ENGINE.runKernel(Sqrt, inputs);\n}\nexport const sqrt = op({ sqrt_ });\n//# sourceMappingURL=sqrt.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Transpose } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport * as util from '../util';\nimport { op } from './operation';\n/**\n * Transposes the `tf.Tensor`. Permutes the dimensions according to `perm`.\n *\n * The returned `tf.Tensor`'s dimension `i` will correspond to the input\n * dimension `perm[i]`. If `perm` is not given, it is set to `[n-1...0]`,\n * where `n` is the rank of the input `tf.Tensor`. Hence by default, this\n * operation performs a regular matrix transpose on 2-D input `tf.Tensor`s.\n *\n * ```js\n * const a = tf.tensor2d([1, 2, 3, 4, 5, 6], [2, 3]);\n *\n * a.transpose().print();  // or tf.transpose(a)\n * ```\n *\n * @param x The tensor to transpose.\n * @param perm The permutation of the dimensions of a.\n *\n * @doc {heading: 'Operations', subheading: 'Matrices'}\n */\nfunction transpose_(x, perm) {\n    const $x = convertToTensor(x, 'x', 'transpose');\n    if (perm == null) {\n        perm = $x.shape.map((s, i) => i).reverse();\n    }\n    util.assert($x.rank === perm.length, () => `Error in transpose: rank of input ${$x.rank} ` +\n        `must match length of perm ${perm}.`);\n    perm.forEach(axis => {\n        util.assert(axis >= 0 && axis < $x.rank, () => `All entries in 'perm' must be between 0 and ${$x.rank - 1}` +\n            ` but got ${perm}`);\n    });\n    if ($x.rank <= 1) {\n        return $x.clone();\n    }\n    const inputs = { x: $x };\n    const attrs = { perm };\n    return ENGINE.runKernel(Transpose, inputs, attrs);\n}\nexport const transpose = op({ transpose_ });\n//# sourceMappingURL=transpose.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Sub } from '../kernel_names';\nimport { makeTypesMatch } from '../tensor_util';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Subtracts two `tf.Tensor`s element-wise, A - B. Supports broadcasting.\n *\n * ```js\n * const a = tf.tensor1d([10, 20, 30, 40]);\n * const b = tf.tensor1d([1, 2, 3, 4]);\n *\n * a.sub(b).print();  // or tf.sub(a, b)\n * ```\n *\n * ```js\n * // Broadcast subtract a with b.\n * const a = tf.tensor1d([10, 20, 30, 40]);\n * const b = tf.scalar(5);\n *\n * a.sub(b).print();  // or tf.sub(a, b)\n * ```\n * @param a The first `tf.Tensor` to subtract from.\n * @param b The second `tf.Tensor` to be subtracted. Must have the same dtype as\n * `a`.\n *\n * @doc {heading: 'Operations', subheading: 'Arithmetic'}\n */\nfunction sub_(a, b) {\n    let $a = convertToTensor(a, 'a', 'sub');\n    let $b = convertToTensor(b, 'b', 'sub');\n    [$a, $b] = makeTypesMatch($a, $b);\n    const inputs = { a: $a, b: $b };\n    return ENGINE.runKernel(Sub, inputs);\n}\nexport const sub = op({ sub_ });\n//# sourceMappingURL=sub.js.map","/**\n * @license\n * Copyright 2017 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport * as util from '../util';\nexport function assertParamsValid(input, begin, size) {\n    const inputRank = input.shape.length;\n    util.assert(inputRank === begin.length, () => `Error in slice${inputRank}D: Length of begin ${begin} must ` +\n        `match the rank of the array (${inputRank}).`);\n    util.assert(inputRank === size.length, () => `Error in slice${inputRank}D: Length of size ${size} must ` +\n        `match the rank of the array (${inputRank}).`);\n    for (let i = 0; i < inputRank; ++i) {\n        util.assert(begin[i] + size[i] <= input.shape[i], () => `Error in slice${inputRank}D: begin[${i}] + size[${i}] ` +\n            `(${begin[i] + size[i]}) would overflow input.shape[${i}] (${input.shape[i]})`);\n    }\n}\n/** Converts a binary mask to an array of axes. Used in stridedSlice(). */\nexport function maskToAxes(mask) {\n    const axes = [];\n    let axis = 0;\n    while (mask > 0) {\n        if (mask & 1) {\n            axes.push(axis);\n        }\n        mask /= 2;\n        axis++;\n    }\n    return axes;\n}\n/** Computes the output shape given the strided slice params. */\nexport function computeOutShape(begin, end, strides) {\n    const size = [];\n    for (let axis = 0; axis < begin.length; axis++) {\n        size[axis] = Math.ceil((end[axis] - begin[axis]) / strides[axis]);\n    }\n    return size;\n}\n// Creates full selection at the elided dimensions. If the dimension matches\n// the ellipsis mask, override the current stride value. Otherwise, insert.\nexport function stridesWithElidedDims(strides, ellipsisInsertionIndex, numElidedAxes, inputShape) {\n    const newStrides = [...strides];\n    for (let i = newStrides.length; i < inputShape.length; i++) {\n        newStrides.push(1);\n    }\n    for (let i = 0; i < numElidedAxes; i++) {\n        if (i === 0) {\n            newStrides[ellipsisInsertionIndex] = 1;\n        }\n        else {\n            newStrides.splice(ellipsisInsertionIndex, 0 /* num elements to delete */, 1 /* element to add */);\n            newStrides.pop();\n        }\n    }\n    return newStrides;\n}\nfunction unnormalizeAxis(ellipsisInsertionIndex, numElidedAxes, normalizedAxis) {\n    if (normalizedAxis <= ellipsisInsertionIndex) {\n        return normalizedAxis;\n    }\n    return normalizedAxis - (numElidedAxes - 1);\n}\nfunction getElidedAxes(numElidedAxes, ellipsisInsertionIndex) {\n    const elidedAxes = [];\n    for (let i = 0; i < numElidedAxes; i++) {\n        elidedAxes.push(ellipsisInsertionIndex + i);\n    }\n    return elidedAxes;\n}\n// Normalize the start, end and strides.\nexport function getNormalizedAxes(inputShape, ellipsisAxes, numInterpolatedAxes, begin, end, strides, beginMask, endMask, ellipsisMask) {\n    const inputRank = inputShape.length;\n    let normalizedBegin = new Array(inputRank), normalizedEnd = new Array(inputRank), normalizedStrides = new Array(inputRank);\n    if (ellipsisAxes.length && numInterpolatedAxes > 0) {\n        const fullIndex = ellipsisAxes[0];\n        // The ellipsis applies to the masked index as well as any dimensions\n        // that are interpolated.\n        const numElidedAxes = numInterpolatedAxes + 1;\n        normalizedBegin = startIndicesWithElidedDims(beginMask, fullIndex, numElidedAxes, begin, inputShape);\n        normalizedEnd = stopIndicesWithElidedDims(endMask, fullIndex, numElidedAxes, end, inputShape);\n        normalizedStrides =\n            stridesWithElidedDims(strides, fullIndex, numElidedAxes, inputShape);\n    }\n    else {\n        for (let axis = 0; axis < inputRank; axis++) {\n            normalizedBegin[axis] = startForAxis(beginMask, begin, strides, inputShape, axis, ellipsisMask);\n            normalizedEnd[axis] =\n                stopForAxis(endMask, end, strides, inputShape, axis, ellipsisMask);\n            normalizedStrides[axis] = stridesForAxis(strides, axis, ellipsisMask);\n        }\n    }\n    return {\n        begin: normalizedBegin,\n        end: normalizedEnd,\n        strides: normalizedStrides\n    };\n}\n// Creates full selection at the elided dimensions. If the dimension matches\n// the ellipsis mask, override the current start value. Otherwise, insert.\nexport function startIndicesWithElidedDims(beginMask, ellipsisInsertionIndex, numElidedAxes, originalBegin, inputShape) {\n    const newIndices = [...inputShape];\n    const elidedAxes = getElidedAxes(numElidedAxes, ellipsisInsertionIndex);\n    for (let axis = 0; axis < newIndices.length; axis++) {\n        if (elidedAxes.indexOf(axis) > -1) {\n            newIndices[axis] = 0;\n        }\n        else {\n            const originalAxis = unnormalizeAxis(ellipsisInsertionIndex, numElidedAxes, axis);\n            let originalValue = originalBegin[originalAxis];\n            if (beginMask & 1 << originalAxis) {\n                originalValue = 0;\n            }\n            newIndices[axis] = originalValue;\n        }\n    }\n    return newIndices;\n}\n// Creates full selection at the elided dimensions. If the dimension matches\n// the ellipsis mask, override the current stop value. Otherwise, insert.\nexport function stopIndicesWithElidedDims(endMask, ellipsisInsertionIndex, numElidedAxes, originalEnd, inputShape) {\n    const newIndices = [...inputShape];\n    const elidedAxes = getElidedAxes(numElidedAxes, ellipsisInsertionIndex);\n    for (let axis = 0; axis < newIndices.length; axis++) {\n        if (elidedAxes.indexOf(axis) > -1) {\n            newIndices[axis] = Number.MAX_SAFE_INTEGER;\n        }\n        else {\n            const originalAxis = unnormalizeAxis(ellipsisInsertionIndex, numElidedAxes, axis);\n            let originalValue = originalEnd[originalAxis];\n            if (endMask & 1 << originalAxis) {\n                originalValue = Number.MAX_SAFE_INTEGER;\n            }\n            newIndices[axis] = originalValue;\n        }\n    }\n    for (let i = 0; i < newIndices.length; i++) {\n        // Handle negative indices\n        const axisSize = inputShape[i];\n        if (newIndices[i] < 0) {\n            newIndices[i] += axisSize;\n        }\n        newIndices[i] = util.clamp(0, newIndices[i], inputShape[i]);\n    }\n    return newIndices;\n}\nexport function stridesForAxis(strides, axis, ellipsisMask) {\n    let stride = strides[axis];\n    if (ellipsisMask & (1 << axis) || stride == null) {\n        stride = 1;\n    }\n    return stride;\n}\nexport function startForAxis(beginMask, startIndices, strides, inputShape, axis, ellipsisMask) {\n    // Begin with the specified index\n    let start = startIndices[axis];\n    const stride = strides[axis] || 1;\n    // Check the axis bit from right of masked axes, or the begin index is not set\n    // for the axis.\n    if (beginMask & 1 << axis || ellipsisMask & 1 << axis || start == null) {\n        if (stride > 0) {\n            // Forward iteration - use the first element. These values will get\n            // clamped below (Note: We could have set them to 0 and axis_size-1, but\n            // use lowest() and max() to maintain symmetry with StopForAxis())\n            start = Number.MIN_SAFE_INTEGER;\n        }\n        else {\n            // Backward iteration - use the last element.\n            start = Number.MAX_SAFE_INTEGER;\n        }\n    }\n    // Handle negative indices\n    const axisSize = inputShape[axis];\n    if (start < 0) {\n        start += axisSize;\n    }\n    // Clamping\n    start = util.clamp(0, start, axisSize - 1);\n    return start;\n}\nexport function stopForAxis(endMask, stopIndices, strides, inputShape, axis, ellipsisMask) {\n    // Begin with the specified index\n    let stop = stopIndices[axis];\n    const stride = strides[axis] || 1;\n    // Check the axis bit from right of masked axes, or if the stop index is not\n    // set for this axis.\n    if (endMask & (1 << axis) || ellipsisMask & (1 << axis) || stop == null) {\n        if (stride > 0) {\n            // Forward iteration - use the last element. These values will get\n            // clamped below\n            stop = Number.MAX_SAFE_INTEGER;\n        }\n        else {\n            // Backward iteration - use the first element.\n            stop = Number.MIN_SAFE_INTEGER;\n        }\n    }\n    // Handle negative indices\n    const axisSize = inputShape[axis];\n    if (stop < 0) {\n        stop += axisSize;\n    }\n    // Clamping\n    // Because the end index points one past the last element, we need slightly\n    // different clamping ranges depending on the direction.\n    if (stride > 0) {\n        // Forward iteration\n        stop = util.clamp(0, stop, axisSize);\n    }\n    else {\n        // Backward iteration\n        stop = util.clamp(-1, stop, axisSize - 1);\n    }\n    return stop;\n}\n/**\n * Returns true if the slice occupies a continous set of elements in the\n * 'flat' space.\n */\nexport function isSliceContinous(shape, begin, size) {\n    // Index of the first axis that has size > 1.\n    let firstNonOneAxis = size.length;\n    for (let i = 0; i < size.length; i++) {\n        if (size[i] > 1) {\n            firstNonOneAxis = i;\n            break;\n        }\n    }\n    for (let i = firstNonOneAxis + 1; i < size.length; i++) {\n        if (begin[i] > 0 || size[i] !== shape[i]) {\n            return false;\n        }\n    }\n    return true;\n}\nexport function computeFlatOffset(begin, strides) {\n    let flatOffset = begin.length > 0 ? begin[begin.length - 1] : 1;\n    for (let i = 0; i < begin.length - 1; i++) {\n        flatOffset += begin[i] * strides[i];\n    }\n    return flatOffset;\n}\nexport function parseSliceParams(x, begin, size) {\n    // The following logic allows for more ergonomic calls.\n    let begin_;\n    const xRank = x.shape.length;\n    if (typeof begin === 'number') {\n        begin_ = [begin, ...new Array(xRank - 1).fill(0)];\n    }\n    else if (begin.length < xRank) {\n        begin_ = begin.concat(new Array(xRank - begin.length).fill(0));\n    }\n    else {\n        begin_ = begin.slice();\n    }\n    begin_.forEach(d => {\n        util.assert(d !== -1, () => 'slice() does not support negative begin indexing.');\n    });\n    let size_;\n    if (size == null) {\n        size_ = new Array(xRank).fill(-1);\n    }\n    else if (typeof size === 'number') {\n        size_ = [size, ...new Array(xRank - 1).fill(-1)];\n    }\n    else if (size.length < xRank) {\n        size_ = size.concat(new Array(xRank - size.length).fill(-1));\n    }\n    else {\n        size_ = size;\n    }\n    size_ = size_.map((d, i) => {\n        if (d >= 0) {\n            return d;\n        }\n        else {\n            util.assert(d === -1, () => `Negative size values should be exactly -1 but got ` +\n                `${d} for the slice() size at index ${i}.`);\n            return x.shape[i] - begin_[i];\n        }\n    });\n    return [begin_, size_];\n}\nexport function sliceInfo(xShape, begin, end, strides, beginMask, endMask, ellipsisMask, newAxisMask, shrinkAxisMask) {\n    // make a copy because it may be modified further down.\n    let $begin = begin.slice();\n    let $end = end.slice();\n    let $strides = strides;\n    if (strides == null) {\n        $strides = new Array($begin.length);\n    }\n    const ellipsisAxes = maskToAxes(ellipsisMask);\n    if (ellipsisAxes.length > 1) {\n        throw new Error('Multiple ellipses in slice is not allowed.');\n    }\n    if (ellipsisMask !== 0 && newAxisMask !== 0) {\n        throw new Error('Using both ellipsisMask and newAxisMask is not yet supported.');\n    }\n    if (ellipsisMask !== 0 && shrinkAxisMask !== 0) {\n        throw new Error('Using both ellipsisMask and shrinkAxisMask is not yet supported.');\n    }\n    const numInterpolatedAxes = xShape.length - $begin.length;\n    // Expand the dims of x based on the newAxisMask.\n    const expandAxes = maskToAxes(newAxisMask);\n    const newShape = xShape.slice();\n    expandAxes.forEach(axis => {\n        $begin[axis] = 0;\n        $end[axis] = 1;\n        newShape.splice(axis, 0, 1);\n    });\n    const { begin: normalizedBegin, end: normalizedEnd, strides: normalizedStrides } = getNormalizedAxes(newShape, ellipsisAxes, numInterpolatedAxes, $begin, $end, $strides, beginMask, endMask, ellipsisMask);\n    $begin = normalizedBegin;\n    $end = normalizedEnd;\n    $strides = normalizedStrides;\n    const shrinkAxes = maskToAxes(shrinkAxisMask);\n    // Adjust the ends based on the shrink mask.\n    shrinkAxes.forEach(axis => {\n        $end[axis] = $begin[axis] + 1;\n        $strides[axis] = 1;\n    });\n    // Figure out the output shape.\n    const size = computeOutShape($begin, $end, $strides);\n    // Remove the axes based on shrinkMask.\n    const outShape = size.filter((_, axis) => shrinkAxes.indexOf(axis) === -1);\n    const nonStrided = $strides.every(v => v === 1);\n    return { nonStrided, $begin, $end, $strides, size, newShape, outShape };\n}\n//# sourceMappingURL=slice_util.js.map","/**\n * @license\n * Copyright 2020 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n/**\n * Prints information about the `tf.Tensor` including its data.\n *\n * ```js\n * const verbose = true;\n * tf.tensor2d([1, 2, 3, 4], [2, 2]).print(verbose);\n * ```\n * @param x The tensor to be printed.\n * @param verbose Whether to print verbose information about the ` Tensor`,\n * including dtype and size.\n *\n * @doc {heading: 'Tensors', subheading: 'Creation'}\n */\nexport function print(x, verbose = false) {\n    console.log(x.toString(verbose));\n}\n//# sourceMappingURL=print.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Sigmoid } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes sigmoid element-wise, `1 / (1 + exp(-x))`\n *\n * ```js\n * const x = tf.tensor1d([0, -1, 2, -3]);\n *\n * x.sigmoid().print();  // or tf.sigmoid(x)\n * ```\n * @param x The input tensor.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction sigmoid_(x) {\n    const $x = convertToTensor(x, 'x', 'sigmoid');\n    const inputs = { x: $x };\n    return ENGINE.runKernel(Sigmoid, inputs);\n}\nexport const sigmoid = op({ sigmoid_ });\n//# sourceMappingURL=sigmoid.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Sum } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { cast } from './cast';\nimport { op } from './operation';\n/**\n * Computes the sum of elements across dimensions of a `tf.Tensor`.\n *\n * Reduces the input along the dimensions given in `axes`. Unless `keepDims`\n * is true, the rank of the `tf.Tensor` is reduced by 1 for each entry in\n * `axes`. If `keepDims` is true, the reduced dimensions are retained with\n * length 1. If axes has no entries, all dimensions are reduced, and a\n * `tf.Tensor` with a single element is returned.\n *\n * ```js\n * const x = tf.tensor1d([1, 2, 3]);\n *\n * x.sum().print();  // or tf.sum(x)\n * ```\n *\n * ```js\n * const x = tf.tensor2d([1, 2, 3, 4], [2, 2]);\n *\n * const axis = 1;\n * x.sum(axis).print();  // or tf.sum(x, axis)\n * ```\n *\n * @param x The input tensor to compute the sum over. If the dtype is `bool`\n *   it will be converted to `int32` and the output dtype will be `int32`.\n * @param axis The dimension(s) to reduce. By default it reduces\n *     all dimensions.\n * @param keepDims If true, retains reduced dimensions with size 1.\n *\n * @doc {heading: 'Operations', subheading: 'Reduction'}\n */\nfunction sum_(x, axis = null, keepDims = false) {\n    let $x = convertToTensor(x, 'x', 'sum');\n    if ($x.dtype === 'bool') {\n        $x = cast($x, 'int32');\n    }\n    const inputs = { x: $x };\n    const attrs = { axis, keepDims };\n    return ENGINE.runKernel(Sum, inputs, attrs);\n}\nexport const sum = op({ sum_ });\n//# sourceMappingURL=sum.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { convertToTensor } from '../tensor_util_env';\nimport { squeezeShape } from '../util';\nimport { op } from './operation';\nimport { reshape } from './reshape';\n/**\n * Removes dimensions of size 1 from the shape of a `tf.Tensor`.\n *\n * ```js\n * const x = tf.tensor([1, 2, 3, 4], [1, 1, 4]);\n * x.squeeze().print();\n * ```\n *\n * @param x The input tensor to be squeezed.\n * @param axis An optional list of numbers. If specified, only\n *     squeezes the dimensions listed. The dimension index starts at 0. It\n * is an error to squeeze a dimension that is not 1.\n *\n * @doc {heading: 'Tensors', subheading: 'Transformations'}\n */\nfunction squeeze_(x, axis) {\n    const $x = convertToTensor(x, 'x', 'squeeze');\n    return reshape($x, squeezeShape($x.shape, axis).newShape);\n}\nexport const squeeze = op({ squeeze_ });\n//# sourceMappingURL=squeeze.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { complex } from '../complex';\nimport { concat } from '../concat';\nimport { imag } from '../imag';\nimport { mul } from '../mul';\nimport { op } from '../operation';\nimport { real } from '../real';\nimport { reshape } from '../reshape';\nimport { reverse } from '../reverse';\nimport { scalar } from '../scalar';\nimport { slice } from '../slice';\nimport { ifft } from './ifft';\n/**\n * Inversed real value input fast Fourier transform.\n *\n * Computes the 1-dimensional inversed discrete Fourier transform over the\n * inner-most dimension of the real input.\n *\n * ```js\n * const real = tf.tensor1d([1, 2, 3]);\n * const imag = tf.tensor1d([0, 0, 0]);\n * const x = tf.complex(real, imag);\n *\n * x.irfft().print();\n * ```\n * @param input The real value input to compute an irfft over.\n *\n * @doc {heading: 'Operations', subheading: 'Spectral', namespace: 'spectral'}\n */\nfunction irfft_(input) {\n    const innerDimensionSize = input.shape[input.shape.length - 1];\n    const batch = input.size / innerDimensionSize;\n    let ret;\n    if (innerDimensionSize <= 2) {\n        const complexInput = reshape(input, [batch, innerDimensionSize]);\n        ret = ifft(complexInput);\n    }\n    else {\n        // The length of unique components of the DFT of a real-valued signal\n        // is 2 * (input_len - 1)\n        const outputShape = [batch, 2 * (innerDimensionSize - 1)];\n        const realInput = reshape(real(input), [batch, innerDimensionSize]);\n        const imagInput = reshape(imag(input), [batch, innerDimensionSize]);\n        const realConjugate = reverse(slice(realInput, [0, 1], [batch, innerDimensionSize - 2]), 1);\n        const imagConjugate = mul(reverse(slice(imagInput, [0, 1], [batch, innerDimensionSize - 2]), 1), scalar(-1));\n        const r = concat([realInput, realConjugate], 1);\n        const i = concat([imagInput, imagConjugate], 1);\n        const complexInput = reshape(complex(r, i), [outputShape[0], outputShape[1]]);\n        ret = ifft(complexInput);\n    }\n    ret = real(ret);\n    // reshape the result if the input is 3D tensor.\n    if (input.rank === 3 && input.shape[0] !== 0) {\n        const temp = ret;\n        const batch = input.shape[0];\n        ret = reshape(ret, [batch, ret.shape[0] / batch, ret.shape[1]]);\n        temp.dispose();\n    }\n    return ret;\n}\nexport const irfft = op({ irfft_ });\n//# sourceMappingURL=irfft.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Round } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes round of input `tf.Tensor` element-wise: `round(x)`.\n * It implements banker's rounding.\n *\n * ```js\n * const x = tf.tensor1d([.6, 1.1, -3.3]);\n *\n * x.round().print();  // or tf.round(x)\n * ```\n * @param x The input tensor.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction round_(x) {\n    const $x = convertToTensor(x, 'x', 'round');\n    const inputs = { x: $x };\n    return ENGINE.runKernel(Round, inputs);\n}\nexport const round = op({ round_ });\n//# sourceMappingURL=round.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Pow } from '../kernel_names';\nimport { makeTypesMatch } from '../tensor_util';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes the power of one `tf.Tensor` to another. Supports broadcasting.\n *\n * Given a `tf.Tensor` x and a `tf.Tensor` y, this operation computes x^y for\n * corresponding elements in x and y. The result's dtype will be the upcasted\n * type of the `base` and `exp` dtypes.\n *\n * ```js\n * const a = tf.tensor([[2, 3], [4, 5]])\n * const b = tf.tensor([[1, 2], [3, 0]]).toInt();\n *\n * a.pow(b).print();  // or tf.pow(a, b)\n * ```\n *\n * ```js\n * const a = tf.tensor([[1, 2], [3, 4]])\n * const b = tf.tensor(2).toInt();\n *\n * a.pow(b).print();  // or tf.pow(a, b)\n * ```\n * We also expose `powStrict` which has the same signature as this op and\n * asserts that `base` and `exp` are the same shape (does not broadcast).\n *\n * @param base The base `tf.Tensor` to pow element-wise.\n * @param exp The exponent `tf.Tensor` to pow element-wise.\n *\n * @doc {heading: 'Operations', subheading: 'Arithmetic'}\n */\nfunction pow_(base, exp) {\n    let $base = convertToTensor(base, 'base', 'pow');\n    let $exp = convertToTensor(exp, 'exp', 'pow');\n    [$base, $exp] = makeTypesMatch($base, $exp);\n    const inputs = { a: $base, b: $exp };\n    return ENGINE.runKernel(Pow, inputs);\n}\nexport const pow = op({ pow_ });\n//# sourceMappingURL=pow.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { isTypedArray } from '../util';\nimport { makeTensor } from './tensor_ops_util';\n/**\n * Creates rank-0 `tf.Tensor` (scalar) with the provided value and dtype.\n *\n * The same functionality can be achieved with `tf.tensor`, but in general\n * we recommend using `tf.scalar` as it makes the code more readable.\n *\n * ```js\n * tf.scalar(3.14).print();\n * ```\n *\n * @param value The value of the scalar.\n * @param dtype The data type.\n *\n * @doc {heading: 'Tensors', subheading: 'Creation'}\n */\nexport function scalar(value, dtype) {\n    if (((isTypedArray(value) && dtype !== 'string') || Array.isArray(value)) &&\n        dtype !== 'complex64') {\n        throw new Error('Error creating a new Scalar: value must be a primitive ' +\n            '(number|boolean|string)');\n    }\n    if (dtype === 'string' && isTypedArray(value) &&\n        !(value instanceof Uint8Array)) {\n        throw new Error('When making a scalar from encoded string, ' +\n            'the value must be `Uint8Array`.');\n    }\n    const shape = [];\n    const inferredShape = [];\n    return makeTensor(value, shape, inferredShape, dtype);\n}\n//# sourceMappingURL=scalar.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { makeOnesTypedArray, sizeFromShape } from '../util';\nimport { complex } from './complex';\nimport { zeros } from './zeros';\n/**\n * Creates a `tf.Tensor` with all elements set to 1.\n *\n * ```js\n * tf.ones([2, 2]).print();\n * ```\n *\n * @param shape An array of integers defining the output tensor shape.\n * @param dtype The type of an element in the resulting tensor. Defaults to\n *     'float'.\n *\n * @doc {heading: 'Tensors', subheading: 'Creation'}\n */\nexport function ones(shape, dtype = 'float32') {\n    if (dtype === 'complex64') {\n        const real = ones(shape, 'float32');\n        const imag = zeros(shape, 'float32');\n        return complex(real, imag);\n    }\n    const values = makeOnesTypedArray(sizeFromShape(shape), dtype);\n    return ENGINE.makeTensor(values, shape, dtype);\n}\n//# sourceMappingURL=ones.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { NotEqual } from '../kernel_names';\nimport { makeTypesMatch } from '../tensor_util';\nimport { convertToTensor } from '../tensor_util_env';\nimport { assertAndGetBroadcastShape } from './broadcast_util';\nimport { op } from './operation';\n/**\n * Returns the truth value of (a != b) element-wise. Supports broadcasting.\n *\n * ```js\n * const a = tf.tensor1d([1, 2, 3]);\n * const b = tf.tensor1d([0, 2, 3]);\n *\n * a.notEqual(b).print();\n * ```\n * @param a The first input tensor.\n * @param b The second input tensor. Must have the same dtype as `a`.\n *\n * @doc {heading: 'Operations', subheading: 'Logical'}\n */\nfunction notEqual_(a, b) {\n    let $a = convertToTensor(a, 'a', 'notEqual', 'string_or_numeric');\n    let $b = convertToTensor(b, 'b', 'notEqual', 'string_or_numeric');\n    [$a, $b] = makeTypesMatch($a, $b);\n    assertAndGetBroadcastShape($a.shape, $b.shape);\n    const inputs = { a: $a, b: $b };\n    return ENGINE.runKernel(NotEqual, inputs);\n}\nexport const notEqual = op({ notEqual_ });\n//# sourceMappingURL=not_equal.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { SquaredDifference } from '../kernel_names';\nimport { makeTypesMatch } from '../tensor_util';\nimport { convertToTensor } from '../tensor_util_env';\nimport { assertAndGetBroadcastShape } from './broadcast_util';\nimport { op } from './operation';\n/**\n * Returns (a - b) * (a - b) element-wise.\n * Supports broadcasting.\n *\n * ```js\n * const a = tf.tensor1d([1, 4, 3, 16]);\n * const b = tf.tensor1d([1, 2, 9, 4]);\n *\n * a.squaredDifference(b).print();  // or tf.squaredDifference(a, b)\n * ```\n *\n * ```js\n * // Broadcast squared difference  a with b.\n * const a = tf.tensor1d([2, 4, 6, 8]);\n * const b = tf.scalar(5);\n *\n * a.squaredDifference(b).print();  // or tf.squaredDifference(a, b)\n * ```\n *\n * @param a The first tensor.\n * @param b The second tensor. Must have the same type as `a`.\n *\n * @doc {heading: 'Operations', subheading: 'Arithmetic'}\n */\nfunction squaredDifference_(a, b) {\n    let $a = convertToTensor(a, 'a', 'squaredDifference');\n    let $b = convertToTensor(b, 'b', 'squaredDifference');\n    [$a, $b] = makeTypesMatch($a, $b);\n    assertAndGetBroadcastShape($a.shape, $b.shape);\n    const inputs = { a: $a, b: $b };\n    const attrs = {};\n    return ENGINE.runKernel(SquaredDifference, inputs, attrs);\n}\nexport const squaredDifference = op({ squaredDifference_ });\n//# sourceMappingURL=squared_difference.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Step } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes step of the input `tf.Tensor` element-wise: `x > 0 ? 1 : alpha * x`\n *\n * ```js\n * const x = tf.tensor1d([0, 2, -1, -3]);\n *\n * x.step(.5).print();  // or tf.step(x, .5)\n * ```\n * @param x The input tensor.\n * @param alpha The gradient when input is negative.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction step_(x, alpha = 0.0) {\n    const $x = convertToTensor(x, 'x', 'step');\n    const inputs = { x: $x };\n    const attrs = { alpha };\n    return ENGINE.runKernel(Step, inputs, attrs);\n}\nexport const step = op({ step_ });\n//# sourceMappingURL=step.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Relu6 } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes rectified linear 6 element-wise: `min(max(x, 0), 6)`.\n *\n * ```js\n * const x = tf.tensor1d([-1, 2, -3, 8]);\n *\n * x.relu6().print();  // or tf.relu6(x)\n * ```\n * @param x The input tensor. If the dtype is `bool`, the output dtype will be\n *     `int32'.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction relu6_(x) {\n    const $x = convertToTensor(x, 'x', 'relu6');\n    const inputs = { x: $x };\n    return ENGINE.runKernel(Relu6, inputs);\n}\nexport const relu6 = op({ relu6_ });\n//# sourceMappingURL=relu6.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Prelu } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes leaky rectified linear element-wise with parametric alphas.\n *\n * `x < 0 ? alpha * x : f(x) = x`\n *\n * ```js\n * const x = tf.tensor1d([-1, 2, -3, 4]);\n * const alpha = tf.scalar(0.1);\n *\n * x.prelu(alpha).print();  // or tf.prelu(x, alpha)\n * ```\n * @param x The input tensor.\n * @param alpha Scaling factor for negative values.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction prelu_(x, alpha) {\n    const $x = convertToTensor(x, 'x', 'prelu');\n    const $alpha = convertToTensor(alpha, 'alpha', 'prelu');\n    const inputs = { x: $x, alpha: $alpha };\n    return ENGINE.runKernel(Prelu, inputs);\n}\nexport const prelu = op({ prelu_ });\n//# sourceMappingURL=prelu.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { inferShape } from '../tensor_util_env';\nimport { assertNonNull } from '../util';\nimport { makeTensor } from './tensor_ops_util';\n/**\n * Creates rank-3 `tf.Tensor` with the provided values, shape and dtype.\n *\n * The same functionality can be achieved with `tf.tensor`, but in general\n * we recommend using `tf.tensor3d` as it makes the code more readable.\n *\n *  ```js\n * // Pass a nested array.\n * tf.tensor3d([[[1], [2]], [[3], [4]]]).print();\n * ```\n * ```js\n * // Pass a flat array and specify a shape.\n * tf.tensor3d([1, 2, 3, 4], [2, 2, 1]).print();\n * ```\n *\n * @param values The values of the tensor. Can be nested array of numbers,\n *     or a flat array, or a `TypedArray`.\n * @param shape The shape of the tensor. If not provided,  it is inferred from\n *     `values`.\n * @param dtype The data type.\n *\n * @doc {heading: 'Tensors', subheading: 'Creation'}\n */\nexport function tensor3d(values, shape, dtype) {\n    assertNonNull(values);\n    if (shape != null && shape.length !== 3) {\n        throw new Error('tensor3d() requires shape to have three numbers');\n    }\n    const inferredShape = inferShape(values, dtype);\n    if (inferredShape.length !== 3 && inferredShape.length !== 1) {\n        throw new Error('tensor3d() requires values to be number[][][] or flat/TypedArray');\n    }\n    if (inferredShape.length === 1 && shape == null) {\n        throw new Error('tensor3d() requires shape to be provided when `values` ' +\n            'are a flat array');\n    }\n    return makeTensor(values, shape, inferredShape, dtype);\n}\n//# sourceMappingURL=tensor3d.js.map","/**\n * @license\n * Copyright 2017 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n/**\n * Inputs of size above this threshold will be parallelized by calling multiple\n * shader programs.\n */\nimport { nearestDivisor } from '../util';\nexport const PARALLELIZE_THRESHOLD = 30;\nexport function computeOptimalWindowSize(inSize) {\n    if (inSize <= PARALLELIZE_THRESHOLD) {\n        return inSize;\n    }\n    return nearestDivisor(inSize, Math.floor(Math.sqrt(inSize)));\n}\n//# sourceMappingURL=reduce_util.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Slice } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Extracts a slice from a `tf.Tensor` starting at coordinates `begin`\n * and is of size `size`.\n *\n * Also available are stricter rank-specific methods with the same signature\n * as this method that assert that `x` is of the given rank:\n *   - `tf.slice1d`\n *   - `tf.slice2d`\n *   - `tf.slice3d`\n *   - `tf.slice4d`\n *\n * ```js\n * const x = tf.tensor1d([1, 2, 3, 4]);\n *\n * x.slice([1], [2]).print();\n * ```\n *\n * ```js\n * const x = tf.tensor2d([1, 2, 3, 4], [2, 2]);\n *\n * x.slice([1, 0], [1, 2]).print();\n * ```\n * @param x The input `tf.Tensor` to slice from.\n * @param begin The coordinates to start the slice from. The length can be\n *     less than the rank of x - the rest of the axes will have implicit 0 as\n *     start. Can also be a single number, in which case it specifies the\n *     first axis.\n * @param size The size of the slice. The length can be less than the rank of\n *     x - the rest of the axes will have implicit -1. A value of -1 requests\n *     the rest of the dimensions in the axis. Can also be a single number,\n *     in which case it specifies the size of the first axis.\n *\n * @doc {heading: 'Tensors', subheading: 'Slicing and Joining'}\n */\nfunction slice_(x, begin, size) {\n    const $x = convertToTensor(x, 'x', 'slice', 'string_or_numeric');\n    if ($x.rank === 0) {\n        throw new Error('Slicing scalar is not possible');\n    }\n    const inputs = { x: $x };\n    const attrs = { begin, size };\n    return ENGINE.runKernel(Slice, inputs, attrs);\n}\nexport const slice = op({ slice_ });\n//# sourceMappingURL=slice.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n// Returns the image center in pixels.\nexport function getImageCenter(center, imageHeight, imageWidth) {\n    const centerX = imageWidth * (typeof center === 'number' ? center : center[0]);\n    const centerY = imageHeight * (typeof center === 'number' ? center : center[1]);\n    return [centerX, centerY];\n}\n//# sourceMappingURL=rotate_util.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nexport const SELU_SCALEALPHA = 1.7580993408473768599402175208123;\nexport const SELU_SCALE = 1.0507009873554804934193349852946;\n//# sourceMappingURL=selu_util.js.map","import { assert } from '../util';\n/**\n * Prepare the split size array. When the input is a number, the axis is evenly\n * divided among the split size. When the input contains the negative value, the\n * rest of the axis is allocated toward that.\n */\nexport function prepareSplitSize(x, numOrSizeSplits, axis = 0) {\n    let splitSizes = [];\n    if (typeof (numOrSizeSplits) === 'number') {\n        assert(x.shape[axis] % numOrSizeSplits === 0, () => 'Number of splits must evenly divide the axis.');\n        splitSizes =\n            new Array(numOrSizeSplits).fill(x.shape[axis] / numOrSizeSplits);\n    }\n    else {\n        const numOfNegs = numOrSizeSplits.reduce((count, value) => {\n            if (value === -1) {\n                count += 1;\n            }\n            return count;\n        }, 0);\n        assert(numOfNegs <= 1, () => 'There should be only one negative value in split array.');\n        const negIndex = numOrSizeSplits.indexOf(-1);\n        // Allow the number of split array to be -1, which indicates the rest\n        // of dimension is allocated to that split.\n        if (negIndex !== -1) {\n            const total = numOrSizeSplits.reduce((a, b) => b > 0 ? a + b : a);\n            numOrSizeSplits[negIndex] = x.shape[axis] - total;\n        }\n        assert(x.shape[axis] === numOrSizeSplits.reduce((a, b) => a + b), () => 'The sum of sizes must match the size of the axis dimension.');\n        splitSizes = numOrSizeSplits;\n    }\n    return splitSizes;\n}\n//# sourceMappingURL=split_util.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { nearestDivisor } from '../util';\nimport { PARALLELIZE_THRESHOLD } from './reduce_util';\nexport function segOpComputeOptimalWindowSize(inSize, numSegments) {\n    let done = false;\n    let res;\n    if (inSize <= PARALLELIZE_THRESHOLD) {\n        res = inSize;\n        done = true;\n    }\n    else {\n        res = nearestDivisor(inSize, Math.floor(Math.sqrt(inSize)));\n    }\n    while (!done) {\n        if (res > numSegments || res === inSize) {\n            done = true;\n        }\n        else {\n            res = nearestDivisor(inSize, res + 1);\n        }\n    }\n    return res;\n}\nexport function computeOutShape(aShape, axis, numSegments) {\n    const outShape = [];\n    const rank = aShape.length;\n    for (let dim = 0; dim < rank; dim++) {\n        if (dim !== axis) {\n            outShape.push(aShape[dim]);\n        }\n        else {\n            outShape.push(numSegments);\n        }\n    }\n    return outShape;\n}\nexport function collectGatherOpShapeInfo(x, indices, axis, batchDims) {\n    const indicesRank = indices.shape.length;\n    const xRank = x.shape.length;\n    if (batchDims !== 0) {\n        if (batchDims < -indicesRank || batchDims > indicesRank) {\n            throw new Error(`Expect batchDims in the range of [-${indicesRank}, ${indicesRank}], but got ${batchDims}`);\n        }\n    }\n    if (batchDims < 0) {\n        batchDims += indicesRank;\n    }\n    if (batchDims > xRank) {\n        throw new Error(`batchDims (${batchDims}) must be less than rank(x) (\n    ${xRank}).`);\n    }\n    if (axis < batchDims) {\n        throw new Error(`batchDims (${batchDims}) must be less than or equal to axis (${axis}).`);\n    }\n    for (let i = 0; i < batchDims; ++i) {\n        if (x.shape[i] !== indices.shape[i]) {\n            throw new Error(`x.shape[${i}]: ${x.shape[i]} should be equal to indices.shape[${i}]: ${indices.shape[i]}.`);\n        }\n    }\n    const dimSize = x.shape[axis];\n    const outputShape = [];\n    let batchSize = 1;\n    let outerSize = 1;\n    let sliceSize = 1;\n    for (let i = 0; i < batchDims; ++i) {\n        outputShape.push(x.shape[i]);\n        batchSize *= x.shape[i];\n    }\n    for (let i = batchDims; i < axis; i++) {\n        outputShape.push(x.shape[i]);\n        outerSize *= x.shape[i];\n    }\n    for (let i = batchDims; i < indicesRank; i++) {\n        outputShape.push(indices.shape[i]);\n    }\n    for (let i = axis + 1; i < xRank; i++) {\n        outputShape.push(x.shape[i]);\n        sliceSize *= x.shape[i];\n    }\n    return { batchSize, sliceSize, outerSize, dimSize, outputShape };\n}\n//# sourceMappingURL=segment_util.js.map","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { tensor1d } from './tensor1d';\nexport function enclosingPowerOfTwo(value) {\n    // Return 2**N for integer N such that 2**N >= value.\n    return Math.floor(Math.pow(2, Math.ceil(Math.log(value) / Math.log(2.0))));\n}\nexport function cosineWindow(windowLength, a, b) {\n    const even = 1 - windowLength % 2;\n    const newValues = new Float32Array(windowLength);\n    for (let i = 0; i < windowLength; ++i) {\n        const cosArg = (2.0 * Math.PI * i) / (windowLength + even - 1);\n        newValues[i] = a - b * Math.cos(cosArg);\n    }\n    return tensor1d(newValues, 'float32');\n}\n//# sourceMappingURL=signal_ops_util.js.map","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { op } from '../operation';\nimport { cosineWindow } from '../signal_ops_util';\n/**\n * Generate a hamming window.\n *\n * See: https://en.wikipedia.org/wiki/Window_function#Hann_and_Hamming_windows\n *\n * ```js\n * tf.signal.hammingWindow(10).print();\n * ```\n * @param The length of window\n *\n * @doc {heading: 'Operations', subheading: 'Signal', namespace: 'signal'}\n */\nfunction hammingWindow_(windowLength) {\n    return cosineWindow(windowLength, 0.54, 0.46);\n}\nexport const hammingWindow = op({ hammingWindow_ });\n//# sourceMappingURL=hamming_window.js.map","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { op } from '../operation';\nimport { cosineWindow } from '../signal_ops_util';\n/**\n * Generate a Hann window.\n *\n * See: https://en.wikipedia.org/wiki/Window_function#Hann_and_Hamming_windows\n *\n * ```js\n * tf.signal.hannWindow(10).print();\n * ```\n * @param The length of window\n *\n * @doc {heading: 'Operations', subheading: 'Signal', namespace: 'signal'}\n */\nfunction hannWindow_(windowLength) {\n    return cosineWindow(windowLength, 0.5, 0.5);\n}\nexport const hannWindow = op({ hannWindow_ });\n//# sourceMappingURL=hann_window.js.map","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { concat } from '../concat';\nimport { fill } from '../fill';\nimport { op } from '../operation';\nimport { reshape } from '../reshape';\nimport { slice } from '../slice';\nimport { tensor2d } from '../tensor2d';\n/**\n * Expands input into frames of frameLength.\n * Slides a window size with frameStep.\n *\n * ```js\n * tf.signal.frame([1, 2, 3], 2, 1).print();\n * ```\n * @param signal The input tensor to be expanded\n * @param frameLength Length of each frame\n * @param frameStep The frame hop size in samples.\n * @param padEnd Whether to pad the end of signal with padValue.\n * @param padValue An number to use where the input signal does\n *     not exist when padEnd is True.\n *\n * @doc {heading: 'Operations', subheading: 'Signal', namespace: 'signal'}\n */\nfunction frame_(signal, frameLength, frameStep, padEnd = false, padValue = 0) {\n    let start = 0;\n    const output = [];\n    while (start + frameLength <= signal.size) {\n        output.push(slice(signal, start, frameLength));\n        start += frameStep;\n    }\n    if (padEnd) {\n        while (start < signal.size) {\n            const padLen = (start + frameLength) - signal.size;\n            const pad = concat([\n                slice(signal, start, frameLength - padLen), fill([padLen], padValue)\n            ]);\n            output.push(pad);\n            start += frameStep;\n        }\n    }\n    if (output.length === 0) {\n        return tensor2d([], [0, frameLength]);\n    }\n    return reshape(concat(output), [output.length, frameLength]);\n}\nexport const frame = op({ frame_ });\n//# sourceMappingURL=frame.js.map","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { mul } from '../mul';\nimport { op } from '../operation';\nimport { enclosingPowerOfTwo } from '../signal_ops_util';\nimport { rfft } from '../spectral/rfft';\nimport { frame } from './frame';\nimport { hannWindow } from './hann_window';\n/**\n * Computes the Short-time Fourier Transform of signals\n * See: https://en.wikipedia.org/wiki/Short-time_Fourier_transform\n *\n * ```js\n * const input = tf.tensor1d([1, 1, 1, 1, 1])\n * tf.signal.stft(input, 3, 1).print();\n * ```\n * @param signal 1-dimensional real value tensor.\n * @param frameLength The window length of samples.\n * @param frameStep The number of samples to step.\n * @param fftLength The size of the FFT to apply.\n * @param windowFn A callable that takes a window length and returns 1-d tensor.\n *\n * @doc {heading: 'Operations', subheading: 'Signal', namespace: 'signal'}\n */\nfunction stft_(signal, frameLength, frameStep, fftLength, windowFn = hannWindow) {\n    if (fftLength == null) {\n        fftLength = enclosingPowerOfTwo(frameLength);\n    }\n    const framedSignal = frame(signal, frameLength, frameStep);\n    const windowedSignal = mul(framedSignal, windowFn(frameLength));\n    return rfft(windowedSignal, fftLength);\n}\nexport const stft = op({ stft_ });\n//# sourceMappingURL=stft.js.map","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../../engine';\nimport { SparseFillEmptyRows } from '../../kernel_names';\nimport { convertToTensor } from '../../tensor_util_env';\nimport { op } from '../operation';\n/**\n * The input SparseTensor is represented via the map of inputs {`indices`,\n * `values`, `denseShape`}. The output SparseTensor has the same `denseShape`\n * but with indices `outputIndices` and values `outputValues`. This op inserts a\n * single entry for every row that doesn't have any values. The index is created\n * as `[row, 0, ..., 0]` and the inserted value is `defaultValue`.\n *\n * For example, suppose `spInput` has shape [5, 6] and non-empty values:\n * [0, 1]: a\n * [0, 3]: b\n * [2, 0]: c\n * [3, 1]: d\n *\n * Rows 1 and 4 are empty, so the output will be of shape [5, 6] with values:\n * [0, 1]: a\n * [0, 3]: b\n * [1, 0]: `defaultValue`\n * [2, 0]: c\n * [3, 1]: d\n * [4, 0]: `defaultValue`\n *\n * The output SparseTensor will be in row-major order and will have the same\n * shape as the input.\n *\n * This op also returns an indicator vector shaped [dense_shape[0]] such that\n * emptyRowIndicator[i] = True iff row i was an empty row.\n *\n * And a reverse index map vector shaped [indices.shape[0]] that is used during\n * backpropagation, reverseIndexMap[i] = outi s.t. indices[i, j] ==\n * outputIndices[outi, j] for all j\n *\n * ```js\n * const result = tf.sparse.sparseFillEmptyRows(\n *   [[0, 0], [1, 0], [1, 3], [1, 4], [3, 2], [3, 3]],\n *   [0, 10, 13, 14, 32, 33], [5, 6], -1);\n * console.log(result);\n * result['outputIndices'].print(); // [[0, 0], [1, 0], [1, 3], [1, 4],\n *                                  //  [2, 0], [3, 2], [3, 3], [4, 0]]\n * result['outputValues'].print(); // [0, 10, 13, 14,-1, 32, 33, -1]\n * result['emptyRowIndicator'].print(); // [false, false, true, false, true]\n * result['reverseIndexMap'].print(); // [0, 1, 2, 3, 5, 6]\n * ```\n * @param indices: 2-D. the indices of the sparse tensor.\n * @param values: 1-D. the values of the sparse tensor.\n * @param denseShape: 1-D. the shape of the sparse tensor.\n * @param defaultValue: 0-D. default value to insert into location [row, 0, ...,\n *     0] for rows missing from the input sparse tensor.\n * @return A map with the following properties:\n *     - outputIndices\n *     - outputValues: 1-D. the values of the filled sparse tensor.\n *     - emptyRowIndicator: 1-D. whether the dense row was missing in the input\n * sparse tensor.\n *     - reverseIndexMap: 1-D. a map from the input indices to the output\n * indices.\n * @doc {heading: 'Operations', subheading: 'Sparse'}\n */\nfunction sparseFillEmptyRows_(indices, values, denseShape, defaultValue) {\n    const $indices = convertToTensor(indices, 'indices', 'sparseFillEmptyRows');\n    const $values = convertToTensor(values, 'values', 'sparseFillEmptyRows');\n    const $denseShape = convertToTensor(denseShape, 'denseShape', 'sparseFillEmptyRows');\n    const $defaultValue = convertToTensor(defaultValue, 'defaultValue', 'sparseFillEmptyRows', $values.dtype);\n    if ($indices.rank !== 2) {\n        throw new Error(`Indices should be Tensor2D but received shape\n        ${$indices.shape}`);\n    }\n    if ($values.rank !== 1) {\n        throw new Error(`Values should be Tensor1D but received shape ${$values.shape}`);\n    }\n    if ($denseShape.rank !== 1) {\n        throw new Error(`Dense shape should be Tensor1D but received shape ${$denseShape.shape}`);\n    }\n    if ($defaultValue.rank !== 0) {\n        throw new Error(`Default value should be a scalar but received shape ${$defaultValue.shape}`);\n    }\n    const inputs = {\n        indices: $indices,\n        values: $values,\n        denseShape: $denseShape,\n        defaultValue: $defaultValue\n    };\n    const result = ENGINE.runKernel(SparseFillEmptyRows, inputs);\n    return {\n        outputIndices: result[0],\n        outputValues: result[1],\n        emptyRowIndicator: result[2],\n        reverseIndexMap: result[3]\n    };\n}\nexport const sparseFillEmptyRows = op({ sparseFillEmptyRows_ });\n//# sourceMappingURL=sparse_fill_empty_rows.js.map","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../../engine';\nimport { SparseReshape } from '../../kernel_names';\nimport { convertToTensor } from '../../tensor_util_env';\nimport { op } from '../operation';\n/**\n * This operation has the same semantics as reshape on the represented dense\n * tensor. The `inputIndices` are recomputed based on the requested `newShape`.\n * If one component of `newShape` is the special value -1, the size of that\n * dimension is computed so that the total dense size remains constant. At most\n * one component of `newShape` can be -1. The number of dense elements implied\n * by `newShape` must be the same as the number of dense elements originally\n * implied by `inputShape`. Reshaping does not affect the order of values in the\n * SparseTensor. If the input tensor has rank R_in and N non-empty values, and\n * `newShape` has length R_out, then `inputIndices` has shape [N, R_in],\n * `inputShape` has length R_in, `outputIndices` has shape [N, R_out], and\n * `outputShape` has length R_out.\n *\n * ```js\n * const result = tf.sparse.sparseReshape(\n *   [[0, 0, 0], [0, 0, 1], [0, 1, 0], [1, 0, 0], [1, 2, 3]],\n *   [2, 3, 6], [9, -1]);\n * console.log(result);\n * result['outputIndices'].print(); //[[0, 0], [0, 1], [1, 2], [4, 2], [8, 1]]\n * result['outputShape'].print(); // [9, 4]\n * ```\n * @param inputIndices: 2-D. N x R_in matrix with the indices of non-empty\n * values in a SparseTensor.\n * @param inputShape: 1-D. R_in Tensor1D with the input SparseTensor's dense\n * shape.\n * @param newShape: 1-D. R_out Tensor1D with the requested new dense shape.\n * @return A map with the following properties:\n *     - outputIndices: 2-D. N x R_out matrix with the updated indices of\n *       non-empty values in the output SparseTensor.\n *     - outputShape: 1-D. R_out vector with the full dense shape of the output\n *       SparseTensor. This is the same as newShape but with any -1 dimensions\n *        filled in.\n * @doc {heading: 'Operations', subheading: 'Sparse'}\n */\nfunction sparseReshape_(inputIndices, inputShape, newShape) {\n    const $inputIndices = convertToTensor(inputIndices, 'inputIndices', 'sparseReshape');\n    const $inputShape = convertToTensor(inputShape, 'inputShape', 'sparseReshape');\n    const $newShape = convertToTensor(newShape, 'newShape', 'sparseReshape');\n    if ($inputIndices.rank !== 2) {\n        throw new Error(`Input indices should be Tensor2D but received shape\n        ${$inputIndices.shape}`);\n    }\n    if ($inputShape.rank !== 1) {\n        throw new Error(`Input shape should be Tensor1D but received shape ${$inputShape.shape}`);\n    }\n    if ($newShape.rank !== 1) {\n        throw new Error(`New shape should be Tensor1D but received shape ${$newShape.shape}`);\n    }\n    const inputs = {\n        inputIndices: $inputIndices,\n        inputShape: $inputShape,\n        newShape: $newShape\n    };\n    const result = ENGINE.runKernel(SparseReshape, inputs);\n    return { outputIndices: result[0], outputShape: result[1] };\n}\nexport const sparseReshape = op({ sparseReshape_ });\n//# sourceMappingURL=sparse_reshape.js.map","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../../engine';\nimport { SparseSegmentMean } from '../../kernel_names';\nimport { convertToTensor } from '../../tensor_util_env';\nimport { op } from '../operation';\n/**\n * Computes the mean along sparse segments of a tensor.\n *\n * ```js\n * const c = tf.tensor2d([[1,2,3,4], [-1,-2,-3,-4], [6,7,8,9]]);\n * // Select two rows, one segment.\n * const result1 = tf.sparse.sparseSegmentMean(c,\n *                                           tf.tensor1d([0, 1], 'int32'),\n *                                           tf.tensor1d([0, 0], 'int32'));\n * result1.print(); // [[0, 0, 0, 0]]\n *\n * // Select two rows, two segments.\n * const result2 = tf.sparse.sparseSegmentMean(c,\n *                                             tf.tensor1d([0, 1], 'int32'),\n *                                             tf.tensor1d([0, 1], 'int32'));\n * result2.print(); // [[1, 2, 3, 4], [-1, -2, -3, -4]]\n *\n * // Select all rows, two segments.\n * const result3 = tf.sparse.sparseSegmentMean(c,\n *                                             tf.tensor1d([0, 1, 2], 'int32'),\n *                                             tf.tensor1d([0, 1, 1], 'int32'));\n * result3.print(); // [[1.0, 2.0, 3.0, 4.0], [2.5, 2.5, 2.5, 2.5]]\n * ```\n * @param data: A Tensor of at least one dimension with data that will be\n *     assembled in the output.\n * @param indices: A 1-D Tensor with indices into data. Has same rank as\n *     segmentIds.\n * @param segmentIds: A 1-D Tensor with indices into the output Tensor. Values\n *     should be sorted and can be repeated.\n * @return Has same shape as data, except for dimension 0 which has equal to\n *         the number of segments.\n *\n * @doc {heading: 'Operations', subheading: 'Sparse'}\n */\nfunction sparseSegmentMean_(data, indices, segmentIds) {\n    const $data = convertToTensor(data, 'data', 'sparseSegmentMean');\n    const $indices = convertToTensor(indices, 'indices', 'sparseSegmentMean');\n    const $segmentIds = convertToTensor(segmentIds, 'segmentIds', 'sparseSegmentMean');\n    if ($data.rank < 1) {\n        throw new Error(`Data should be at least 1 dimensional but received scalar`);\n    }\n    if ($indices.rank !== 1) {\n        throw new Error(`Indices should be Tensor1D but received shape\n          ${$indices.shape}`);\n    }\n    if ($segmentIds.rank !== 1) {\n        throw new Error(`Segment ids should be Tensor1D but received shape\n          ${$segmentIds.shape}`);\n    }\n    const inputs = {\n        data: $data,\n        indices: $indices,\n        segmentIds: $segmentIds\n    };\n    return ENGINE.runKernel(SparseSegmentMean, inputs);\n}\nexport const sparseSegmentMean = op({ sparseSegmentMean_ });\n//# sourceMappingURL=sparse_segment_mean.js.map","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../../engine';\nimport { SparseSegmentSum } from '../../kernel_names';\nimport { convertToTensor } from '../../tensor_util_env';\nimport { op } from '../operation';\n/**\n * Computes the sum along sparse segments of a tensor.\n *\n * ```js\n * const c = tf.tensor2d([[1,2,3,4], [-1,-2,-3,-4], [5,6,7,8]]);\n * // Select two rows, one segment.\n * const result1 = tf.sparse.sparseSegmentSum(c,\n *                                           tf.tensor1d([0, 1], 'int32'),\n *                                           tf.tensor1d([0, 0], 'int32'));\n * result1.print(); // [[0, 0, 0, 0]]\n *\n * // Select two rows, two segment.\n * const result2 = tf.sparse.sparseSegmentSum(c,\n *                                           tf.tensor1d([0, 1], 'int32'),\n *                                           tf.tensor1d([0, 1], 'int32'));\n * result2.print(); // [[1, 2, 3, 4], [-1, -2, -3, -4]]\n *\n * // Select all rows, two segments.\n * const result3 = tf.sparse.sparseSegmentSum(c,\n *                                           tf.tensor1d([0, 1, 2], 'int32'),\n *                                           tf.tensor1d([0, 0, 1], 'int32'));\n * result3.print(); // [[0, 0, 0, 0], [5, 6, 7, 8]]\n * ```\n * @param data: A Tensor of at least one dimension with data that will be\n *     assembled in the output.\n * @param indices: A 1-D Tensor with indices into data. Has same rank as\n *     segmentIds.\n * @param segmentIds: A 1-D Tensor with indices into the output Tensor. Values\n *     should be sorted and can be repeated.\n * @return Has same shape as data, except for dimension 0 which has equal to\n *         the number of segments.\n *\n * @doc {heading: 'Operations', subheading: 'Sparse'}\n */\nfunction sparseSegmentSum_(data, indices, segmentIds) {\n    const $data = convertToTensor(data, 'data', 'sparseSegmentSum');\n    const $indices = convertToTensor(indices, 'indices', 'sparseSegmentSum');\n    const $segmentIds = convertToTensor(segmentIds, 'segmentIds', 'sparseSegmentSum');\n    if ($data.rank < 1) {\n        throw new Error(`Data should be at least 1 dimensional but received scalar`);\n    }\n    if ($indices.rank !== 1) {\n        throw new Error(`Indices should be Tensor1D but received shape\n         ${$indices.shape}`);\n    }\n    if ($segmentIds.rank !== 1) {\n        throw new Error(`Segment ids should be Tensor1D but received shape\n         ${$segmentIds.shape}`);\n    }\n    const inputs = {\n        data: $data,\n        indices: $indices,\n        segmentIds: $segmentIds\n    };\n    return ENGINE.runKernel(SparseSegmentSum, inputs);\n}\nexport const sparseSegmentSum = op({ sparseSegmentSum_ });\n//# sourceMappingURL=sparse_segment_sum.js.map","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../../engine';\nimport { StringNGrams } from '../../kernel_names';\nimport { convertToTensor } from '../../tensor_util_env';\nimport { op } from '../operation';\n/**\n * Creates ngrams from ragged string data.\n *\n * This op accepts a ragged tensor with 1 ragged dimension containing only\n * strings and outputs a ragged tensor with 1 ragged dimension containing ngrams\n * of that string, joined along the innermost axis.\n *\n * ```js\n * const result = tf.string.stringNGrams(\n *   ['a', 'b', 'c', 'd'], tf.tensor1d([0, 2, 4], 'int32'),\n *   '|', [1, 2], 'LP', 'RP', -1, false);\n * result['nGrams'].print(); // ['a', 'b', 'LP|a', 'a|b', 'b|RP',\n *                           //  'c', 'd', 'LP|c', 'c|d', 'd|RP']\n * result['nGramsSplits'].print(); // [0, 5, 10]\n * ```\n * @param data: The values tensor of the ragged string tensor to make ngrams out\n *     of. Must be a 1D string tensor.\n * @param dataSplits: The splits tensor of the ragged string tensor to make\n *     ngrams out of.\n * @param separator: The string to append between elements of the token. Use \"\"\n *     for no separator.\n * @param nGramWidths: The sizes of the ngrams to create.\n * @param leftPad: The string to use to pad the left side of the ngram sequence.\n *     Only used if pad_width !== 0.\n * @param rightPad: The string to use to pad the right side of the ngram\n *     sequence. Only used if pad_width !== 0.\n * @param padWidth: The number of padding elements to add to each side of each\n *     sequence. Note that padding will never be greater than `nGramWidths`-1\n *     regardless of this value. If `padWidth`=-1 , then add max(`nGramWidths)-1\n *     elements.\n * @param preserveShortSequences: If true, then ensure that at least one ngram\n *     is generated for each input sequence. In particular, if an input sequence\n *     is shorter than min(ngramWidth) + 2*padWidth, then generate a single\n *     ngram containing the entire sequence. If false, then no ngrams are\n *     generated for these short input sequences.\n * @return A map with the following properties:\n *     - nGrams: The values tensor of the output ngrams ragged tensor.\n *     - nGramsSplits: The splits tensor of the output ngrams ragged tensor.\n *\n * @doc {heading: 'Operations', subheading: 'String'}\n */\nfunction stringNGrams_(data, dataSplits, separator, nGramWidths, leftPad, rightPad, padWidth, preserveShortSequences) {\n    const $data = convertToTensor(data, 'data', 'stringNGrams', 'string');\n    if ($data.dtype !== 'string') {\n        throw new Error('Data must be of datatype string');\n    }\n    if ($data.shape.length !== 1) {\n        throw new Error(`Data must be a vector, saw: ${$data.shape}`);\n    }\n    const $dataSplits = convertToTensor(dataSplits, 'dataSplits', 'stringNGrams');\n    if ($dataSplits.dtype !== 'int32') {\n        throw new Error('Data splits must be of datatype int32');\n    }\n    const attrs = {\n        separator,\n        nGramWidths,\n        leftPad,\n        rightPad,\n        padWidth,\n        preserveShortSequences\n    };\n    const inputs = { data: $data, dataSplits: $dataSplits };\n    const result = ENGINE.runKernel(StringNGrams, inputs, attrs);\n    return { nGrams: result[0], nGramsSplits: result[1] };\n}\nexport const stringNGrams = op({ stringNGrams_ });\n//# sourceMappingURL=string_n_grams.js.map","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../../engine';\nimport { StringSplit } from '../../kernel_names';\nimport { convertToTensor } from '../../tensor_util_env';\nimport { op } from '../operation';\n/**\n * Split elements of `input` based on `delimiter` into a SparseTensor .\n *\n * Let N be the size of source (typically N will be the batch size). Split each\n * element of `input` based on `delimiter` and return a SparseTensor containing\n * the splitted tokens. Empty tokens are ignored if `skipEmpty` is set to True.\n *\n * `delimiter` can be empty, or a string of split characters. If `delimiter` is\n * an empty string, each element of `input` is split into individual\n * character strings. Otherwise every character of `delimiter` is a potential\n * split point.\n *\n * ```js\n * const result = tf.string.stringSplit(['hello world',  'a b c'], ' ');\n * result['indices'].print(); // [[0, 0], [0, 1], [1, 0], [1, 1], [1, 2]]\n * result['values'].print(); // ['hello', 'world', 'a', 'b', 'c']\n * result['shape'].print(); // [2, 3]\n * ```\n * @param input: 1-D. Strings to split.\n * @param delimiter: 0-D. Delimiter characters, or empty string.\n * @param skipEmpty: Optional. If true, skip the empty strings from the result.\n *     Defaults to true.\n * @return A map with the following properties:\n *     - indices: A dense matrix of int32 representing the indices of the sparse\n *       tensor.\n *     - values: A vector of strings corresponding to the splited values.\n *     - shape: a length-2 vector of int32 representing the shape of the sparse\n * tensor, where the first value is N and the second value is the maximum number\n * of tokens in a single input entry.\n *\n * @doc {heading: 'Operations', subheading: 'String'}\n */\nfunction stringSplit_(input, delimiter, skipEmpty = true) {\n    const $input = convertToTensor(input, 'input', 'stringSplit', 'string');\n    const $delimiter = convertToTensor(delimiter, 'delimiter', 'stringSplit', 'string');\n    if ($input.rank !== 1) {\n        throw new Error(`Input should be Tensor1D but received shape ${$input.shape}`);\n    }\n    if ($delimiter.rank !== 0) {\n        throw new Error(`Delimiter should be a scalar but received shape ${$delimiter.shape}`);\n    }\n    const attrs = { skipEmpty };\n    const inputs = { input: $input, delimiter: $delimiter };\n    const result = ENGINE.runKernel(StringSplit, inputs, attrs);\n    return { indices: result[0], values: result[1], shape: result[2] };\n}\nexport const stringSplit = op({ stringSplit_ });\n//# sourceMappingURL=string_split.js.map","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../../engine';\nimport { StringToHashBucketFast } from '../../kernel_names';\nimport { convertToTensor } from '../../tensor_util_env';\nimport { op } from '../operation';\n/**\n * Converts each string in the input Tensor to its hash mod by a number of\n * buckets.\n *\n * The hash function is deterministic on the content of the string within the\n * process and will never change. However, it is not suitable for cryptography.\n * This function may be used when CPU time is scarce and inputs are trusted or\n * unimportant. There is a risk of adversaries constructing inputs that all hash\n * to the same bucket.\n *\n * ```js\n * const result = tf.string.stringToHashBucketFast(\n *   ['Hello', 'TensorFlow', '2.x'], 3);\n * result.print(); // [0, 2, 2]\n * ```\n * @param input: The strings to assign a hash bucket.\n * @param numBuckets: The number of buckets.\n * @return A Tensor of the same shape as the input tensor.\n *\n * @doc {heading: 'Operations', subheading: 'String'}\n */\nfunction stringToHashBucketFast_(input, numBuckets) {\n    const $input = convertToTensor(input, 'input', 'stringToHashBucketFast', 'string');\n    const attrs = { numBuckets };\n    if (numBuckets <= 0) {\n        throw new Error(`Number of buckets must be at least 1`);\n    }\n    const inputs = { input: $input };\n    return ENGINE.runKernel(StringToHashBucketFast, inputs, attrs);\n}\nexport const stringToHashBucketFast = op({ stringToHashBucketFast_ });\n//# sourceMappingURL=string_to_hash_bucket_fast.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n// Modularized ops.\nexport { abs } from './abs';\nexport { acos } from './acos';\nexport { acosh } from './acosh';\nexport { add } from './add';\nexport { addN } from './add_n';\nexport { all } from './all';\nexport { any } from './any';\nexport { argMax } from './arg_max';\nexport { argMin } from './arg_min';\nexport { asin } from './asin';\nexport { asinh } from './asinh';\nexport { atan } from './atan';\nexport { atan2 } from './atan2';\nexport { atanh } from './atanh';\nexport { avgPool } from './avg_pool';\nexport { avgPool3d } from './avg_pool_3d';\nexport { basicLSTMCell } from './basic_lstm_cell';\nexport { batchToSpaceND } from './batch_to_space_nd';\nexport { batchNorm } from './batchnorm';\nexport { batchNorm2d } from './batchnorm2d';\nexport { batchNorm3d } from './batchnorm3d';\nexport { batchNorm4d } from './batchnorm4d';\nexport { bincount } from './bincount';\nexport { broadcastTo } from './broadcast_to';\nexport { buffer } from './buffer';\nexport { cast } from './cast';\nexport { ceil } from './ceil';\nexport { clipByValue } from './clip_by_value';\nexport { clone } from './clone';\nexport { complex } from './complex';\nexport { concat } from './concat';\nexport { concat1d } from './concat_1d';\nexport { concat2d } from './concat_2d';\nexport { concat3d } from './concat_3d';\nexport { concat4d } from './concat_4d';\nexport { conv1d } from './conv1d';\nexport { conv2d } from './conv2d';\nexport { conv2dTranspose } from './conv2d_transpose';\nexport { conv3d } from './conv3d';\nexport { conv3dTranspose } from './conv3d_transpose';\nexport { cos } from './cos';\nexport { cosh } from './cosh';\nexport { cumsum } from './cumsum';\nexport { denseBincount } from './dense_bincount';\nexport { depthToSpace } from './depth_to_space';\nexport { depthwiseConv2d } from './depthwise_conv2d';\nexport { diag } from './diag';\nexport { dilation2d } from './dilation2d';\nexport { div } from './div';\nexport { divNoNan } from './div_no_nan';\nexport { dot } from './dot';\nexport { einsum } from './einsum';\nexport { elu } from './elu';\nexport { equal } from './equal';\nexport { erf } from './erf';\nexport { exp } from './exp';\nexport { expandDims } from './expand_dims';\nexport { expm1 } from './expm1';\nexport { eye } from './eye';\nexport { fill } from './fill';\nexport { floor } from './floor';\nexport { floorDiv } from './floorDiv';\nexport { gather } from './gather';\nexport { greater } from './greater';\nexport { greaterEqual } from './greater_equal';\nexport { imag } from './imag';\nexport { isFinite } from './is_finite';\nexport { isInf } from './is_inf';\nexport { isNaN } from './is_nan';\nexport { leakyRelu } from './leaky_relu';\nexport { less } from './less';\nexport { lessEqual } from './less_equal';\nexport { linspace } from './linspace';\nexport { localResponseNormalization } from './local_response_normalization';\nexport { log } from './log';\nexport { log1p } from './log1p';\nexport { logSigmoid } from './log_sigmoid';\nexport { logSoftmax } from './log_softmax';\nexport { logSumExp } from './log_sum_exp';\nexport { logicalAnd } from './logical_and';\nexport { logicalNot } from './logical_not';\nexport { logicalOr } from './logical_or';\nexport { logicalXor } from './logical_xor';\nexport { matMul } from './mat_mul';\nexport { max } from './max';\nexport { maxPool } from './max_pool';\nexport { maxPool3d } from './max_pool_3d';\nexport { maxPoolWithArgmax } from './max_pool_with_argmax';\nexport { maximum } from './maximum';\nexport { mean } from './mean';\nexport { meshgrid } from './meshgrid';\nexport { min } from './min';\nexport { minimum } from './minimum';\nexport { mirrorPad } from './mirror_pad';\nexport { mod } from './mod';\nexport { moments } from './moments';\nexport { mul } from './mul';\nexport { multiRNNCell } from './multi_rnn_cell';\nexport { multinomial } from './multinomial';\nexport { neg } from './neg';\nexport { notEqual } from './not_equal';\nexport { oneHot } from './one_hot';\nexport { ones } from './ones';\nexport { onesLike } from './ones_like';\nexport { outerProduct } from './outer_product';\nexport { pad } from './pad';\nexport { pad1d } from './pad1d';\nexport { pad2d } from './pad2d';\nexport { pad3d } from './pad3d';\nexport { pad4d } from './pad4d';\nexport { pool } from './pool';\nexport { pow } from './pow';\nexport { prelu } from './prelu';\nexport { print } from './print';\nexport { prod } from './prod';\nexport { rand } from './rand';\nexport { randomGamma } from './random_gamma';\nexport { randomNormal } from './random_normal';\nexport { randomUniform } from './random_uniform';\nexport { range } from './range';\nexport { real } from './real';\nexport { reciprocal } from './reciprocal';\nexport { relu } from './relu';\nexport { relu6 } from './relu6';\nexport { reshape } from './reshape';\nexport { reverse } from './reverse';\nexport { reverse1d } from './reverse_1d';\nexport { reverse2d } from './reverse_2d';\nexport { reverse3d } from './reverse_3d';\nexport { reverse4d } from './reverse_4d';\nexport { round } from './round';\nexport { rsqrt } from './rsqrt';\nexport { scalar } from './scalar';\nexport { selu } from './selu';\nexport { separableConv2d } from './separable_conv2d';\nexport { setdiff1dAsync } from './setdiff1d_async';\nexport { sigmoid } from './sigmoid';\nexport { sign } from './sign';\nexport { sin } from './sin';\nexport { sinh } from './sinh';\nexport { slice } from './slice';\nexport { slice1d } from './slice1d';\nexport { slice2d } from './slice2d';\nexport { slice3d } from './slice3d';\nexport { slice4d } from './slice4d';\nexport { softmax } from './softmax';\nexport { softplus } from './softplus';\nexport { spaceToBatchND } from './space_to_batch_nd';\nexport { fft } from './spectral/fft';\nexport { ifft } from './spectral/ifft';\nexport { irfft } from './spectral/irfft';\nexport { rfft } from './spectral/rfft';\nexport { split } from './split';\nexport { sqrt } from './sqrt';\nexport { square } from './square';\nexport { squaredDifference } from './squared_difference';\nexport { squeeze } from './squeeze';\nexport { stack } from './stack';\nexport { step } from './step';\nexport { stridedSlice } from './strided_slice';\nexport { sub } from './sub';\nexport { sum } from './sum';\nexport { tan } from './tan';\nexport { tanh } from './tanh';\nexport { tensor } from './tensor';\nexport { tensor1d } from './tensor1d';\nexport { tensor2d } from './tensor2d';\nexport { tensor3d } from './tensor3d';\nexport { tensor4d } from './tensor4d';\nexport { tensor5d } from './tensor5d';\nexport { tensor6d } from './tensor6d';\nexport { tile } from './tile';\nexport { topk } from './topk';\nexport { truncatedNormal } from './truncated_normal';\nexport { unique } from './unique';\nexport { unsortedSegmentSum } from './unsorted_segment_sum';\nexport { unstack } from './unstack';\nexport { variable } from './variable';\nexport { where } from './where';\nexport { whereAsync } from './where_async';\nexport { zeros } from './zeros';\nexport { zerosLike } from './zeros_like';\nexport * from './boolean_mask';\nexport * from './transpose';\nexport * from './norm';\nexport * from './moving_average';\nexport * from './scatter_nd';\nexport * from './sparse_to_dense';\nexport * from './gather_nd';\nexport * from './dropout';\nexport * from './signal_ops_util';\nexport * from './in_top_k';\nexport { op, OP_SCOPE_SUFFIX } from './operation';\nimport { rfft } from './spectral/rfft';\nimport { fft } from './spectral/fft';\nimport { ifft } from './spectral/ifft';\nimport { irfft } from './spectral/irfft';\nconst spectral = {\n    fft,\n    ifft,\n    rfft,\n    irfft\n};\nimport * as fused from './fused_ops';\nimport { hammingWindow } from './signal/hamming_window';\nimport { hannWindow } from './signal/hann_window';\nimport { frame } from './signal/frame';\nimport { stft } from './signal/stft';\nconst signal = {\n    hammingWindow,\n    hannWindow,\n    frame,\n    stft,\n};\n// Image Ops namespace\nimport { cropAndResize } from './image/crop_and_resize';\nimport { flipLeftRight } from './image/flip_left_right';\nimport { rotateWithOffset } from './image/rotate_with_offset';\nimport { nonMaxSuppression } from './image/non_max_suppression';\nimport { nonMaxSuppressionAsync } from './image/non_max_suppression_async';\nimport { nonMaxSuppressionWithScore } from './image/non_max_suppression_with_score';\nimport { nonMaxSuppressionWithScoreAsync } from './image/non_max_suppression_with_score_async';\nimport { nonMaxSuppressionPadded } from './image/non_max_suppression_padded';\nimport { nonMaxSuppressionPaddedAsync } from './image/non_max_suppression_padded_async';\nimport { resizeBilinear } from './image/resize_bilinear';\nimport { resizeNearestNeighbor } from './image/resize_nearest_neighbor';\nimport { threshold } from './image/threshold';\nimport { transform } from './image/transform';\nconst image = {\n    flipLeftRight,\n    resizeNearestNeighbor,\n    resizeBilinear,\n    rotateWithOffset,\n    cropAndResize,\n    nonMaxSuppression,\n    nonMaxSuppressionAsync,\n    nonMaxSuppressionWithScore,\n    nonMaxSuppressionWithScoreAsync,\n    nonMaxSuppressionPadded,\n    nonMaxSuppressionPaddedAsync,\n    threshold,\n    transform\n};\n// linalg namespace\nimport { bandPart } from './linalg/band_part';\nimport { gramSchmidt } from './linalg/gram_schmidt';\nimport { qr } from './linalg/qr';\nconst linalg = {\n    bandPart,\n    gramSchmidt,\n    qr\n};\n// losses namespace;\nimport { absoluteDifference } from './losses/absolute_difference';\nimport { computeWeightedLoss } from './losses/compute_weighted_loss';\nimport { cosineDistance } from './losses/cosine_distance';\nimport { hingeLoss } from './losses/hinge_loss';\nimport { huberLoss } from './losses/huber_loss';\nimport { logLoss } from './losses/log_loss';\nimport { meanSquaredError } from './losses/mean_squared_error';\nimport { sigmoidCrossEntropy } from './losses/sigmoid_cross_entropy';\nimport { softmaxCrossEntropy } from './losses/softmax_cross_entropy';\nconst losses = {\n    absoluteDifference,\n    computeWeightedLoss,\n    cosineDistance,\n    hingeLoss,\n    huberLoss,\n    logLoss,\n    meanSquaredError,\n    sigmoidCrossEntropy,\n    softmaxCrossEntropy\n};\nimport { sparseFillEmptyRows } from './sparse/sparse_fill_empty_rows';\nimport { sparseReshape } from './sparse/sparse_reshape';\nimport { sparseSegmentMean } from './sparse/sparse_segment_mean';\nimport { sparseSegmentSum } from './sparse/sparse_segment_sum';\nconst sparse = {\n    sparseFillEmptyRows,\n    sparseReshape,\n    sparseSegmentMean,\n    sparseSegmentSum\n};\nimport { stringNGrams } from './string/string_n_grams';\nimport { stringSplit } from './string/string_split';\nimport { stringToHashBucketFast } from './string/string_to_hash_bucket_fast';\n// tslint:disable-next-line:variable-name\nconst string = {\n    stringNGrams,\n    stringSplit,\n    stringToHashBucketFast\n};\n// Second level exports.\nexport { image, linalg, losses, spectral, fused, signal, sparse, string };\n//# sourceMappingURL=ops.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { env } from './environment';\nimport * as util from './util';\nexport class Profiler {\n    constructor(backendTimer, logger) {\n        this.backendTimer = backendTimer;\n        this.logger = logger;\n        if (logger == null) {\n            this.logger = new Logger();\n        }\n    }\n    profileKernel(kernelName, inputs, f) {\n        let outputs;\n        const holdResultWrapperFn = () => {\n            outputs = f();\n        };\n        let timer;\n        const start = util.now();\n        if (this.backendTimer.timerAvailable()) {\n            timer = this.backendTimer.time(holdResultWrapperFn);\n        }\n        else {\n            holdResultWrapperFn();\n            for (const output of outputs) {\n                output.dataSync();\n            }\n            timer = Promise.resolve({ kernelMs: util.now() - start });\n        }\n        if (env().getBool('CHECK_COMPUTATION_FOR_ERRORS')) {\n            for (let i = 0; i < outputs.length; i++) {\n                const output = outputs[i];\n                // Dangling promise here because we don't want to propagate up\n                // asynchronicity.\n                output.data().then(tensorVals => {\n                    checkComputationForErrors(tensorVals, output.dtype, kernelName);\n                });\n            }\n        }\n        const kernelProfile = {\n            kernelName,\n            outputs,\n            inputs,\n            timeMs: timer.then(timing => timing.kernelMs),\n            extraInfo: timer.then(timing => timing.getExtraProfileInfo != null ?\n                timing.getExtraProfileInfo() :\n                '')\n        };\n        return kernelProfile;\n    }\n    logKernelProfile(kernelProfile) {\n        const { kernelName, outputs, timeMs, inputs, extraInfo } = kernelProfile;\n        outputs.forEach(result => {\n            Promise.all([result.data(), timeMs, extraInfo]).then(valueContainer => {\n                this.logger.logKernelProfile(kernelName, result, valueContainer[0], valueContainer[1], inputs, valueContainer[2]);\n            });\n        });\n    }\n}\nexport function checkComputationForErrors(vals, dtype, kernelName) {\n    if (dtype !== 'float32') {\n        // Only floating point computations will generate NaN values\n        return false;\n    }\n    for (let i = 0; i < vals.length; i++) {\n        const num = vals[i];\n        if (isNaN(num) || !isFinite(num)) {\n            // Throwing custom exception so behavior is testable.\n            console.warn(`Found ${num} in the result of '${kernelName}'`);\n            return true;\n        }\n    }\n    return false;\n}\nexport class Logger {\n    logKernelProfile(name, result, vals, timeMs, inputs, extraInfo) {\n        const time = typeof timeMs === 'number' ? util.rightPad(`${timeMs}ms`, 9) :\n            timeMs['error'];\n        const paddedName = util.rightPad(name, 25);\n        const rank = result.rank;\n        const size = result.size;\n        const shape = util.rightPad(result.shape.toString(), 14);\n        let inputShapesDescription = '';\n        for (const name in inputs) {\n            const input = inputs[name];\n            if (input != null) {\n                // The input might be a non-tensor (e.g HTMLImageElement), in which case\n                // we claim the output shape as input shape.\n                const inputShape = input.shape || result.shape;\n                const inputRank = inputShape.length;\n                inputShapesDescription +=\n                    `${name}: ${inputRank}D ${inputRank > 0 ? inputShape : ''} `;\n            }\n        }\n        console.log(`%c${paddedName}\\t%c${time}\\t%c${rank}D ${shape}\\t%c${size}\\t%c${inputShapesDescription}\\t%c${extraInfo}`, 'font-weight:bold', 'color:red', 'color:blue', 'color: orange', 'color: green', 'color: steelblue');\n    }\n}\n//# sourceMappingURL=profiler.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { inferShape } from '../tensor_util_env';\nimport { assertNonNull } from '../util';\nimport { makeTensor } from './tensor_ops_util';\n/**\n * Creates rank-1 `tf.Tensor` with the provided values, shape and dtype.\n *\n * The same functionality can be achieved with `tf.tensor`, but in general\n * we recommend using `tf.tensor1d` as it makes the code more readable.\n *\n * ```js\n * tf.tensor1d([1, 2, 3]).print();\n * ```\n *\n * @param values The values of the tensor. Can be array of numbers,\n *     or a `TypedArray`.\n * @param dtype The data type.\n *\n * @doc {heading: 'Tensors', subheading: 'Creation'}\n */\nexport function tensor1d(values, dtype) {\n    assertNonNull(values);\n    const inferredShape = inferShape(values, dtype);\n    if (inferredShape.length !== 1) {\n        throw new Error('tensor1d() requires values to be a flat/TypedArray');\n    }\n    const shape = null;\n    return makeTensor(values, shape, inferredShape, dtype);\n}\n//# sourceMappingURL=tensor1d.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { isPromise } from '../util';\nexport const OP_SCOPE_SUFFIX = '__op';\n/**\n * Used for wrapping functions that perform math operations on\n * Tensors. The function will be wrapped in a named scope that cleans all\n * memory usage after the function is done.\n */\nexport function op(f) {\n    const keys = Object.keys(f);\n    if (keys.length !== 1) {\n        throw new Error(`Please provide an object with a single key ` +\n            `(operation name) mapping to a function. Got an object with ` +\n            `${keys.length} keys.`);\n    }\n    let opName = keys[0];\n    const fn = f[opName];\n    // Strip the underscore from the end of the function name.\n    if (opName.endsWith('_')) {\n        opName = opName.substring(0, opName.length - 1);\n    }\n    // add an __op suffix to distinguish ops from kernels in tf.profile\n    opName = opName + OP_SCOPE_SUFFIX;\n    // tslint:disable-next-line:no-any\n    const f2 = (...args) => {\n        ENGINE.startScope(opName);\n        try {\n            const result = fn(...args);\n            if (isPromise(result)) {\n                console.error('Cannot return a Promise inside of tidy.');\n            }\n            ENGINE.endScope(result);\n            return result;\n        }\n        catch (ex) {\n            ENGINE.endScope(null);\n            throw ex;\n        }\n    };\n    Object.defineProperty(f2, 'name', { value: opName, configurable: true });\n    // tslint:disable-next-line:no-any\n    return f2;\n}\n//# sourceMappingURL=operation.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport * as util from '../util';\nfunction nonMaxSuppSanityCheck(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma) {\n    if (iouThreshold == null) {\n        iouThreshold = 0.5;\n    }\n    if (scoreThreshold == null) {\n        scoreThreshold = Number.NEGATIVE_INFINITY;\n    }\n    if (softNmsSigma == null) {\n        softNmsSigma = 0.0;\n    }\n    const numBoxes = boxes.shape[0];\n    maxOutputSize = Math.min(maxOutputSize, numBoxes);\n    util.assert(0 <= iouThreshold && iouThreshold <= 1, () => `iouThreshold must be in [0, 1], but was '${iouThreshold}'`);\n    util.assert(boxes.rank === 2, () => `boxes must be a 2D tensor, but was of rank '${boxes.rank}'`);\n    util.assert(boxes.shape[1] === 4, () => `boxes must have 4 columns, but 2nd dimension was ${boxes.shape[1]}`);\n    util.assert(scores.rank === 1, () => 'scores must be a 1D tensor');\n    util.assert(scores.shape[0] === numBoxes, () => `scores has incompatible shape with boxes. Expected ${numBoxes}, ` +\n        `but was ${scores.shape[0]}`);\n    util.assert(0 <= softNmsSigma && softNmsSigma <= 1, () => `softNmsSigma must be in [0, 1], but was '${softNmsSigma}'`);\n    return { maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma };\n}\nexport { nonMaxSuppSanityCheck };\n//# sourceMappingURL=nonmax_util.js.map","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport '../flags';\nimport { env } from '../environment';\nimport { BrowserIndexedDB, BrowserIndexedDBManager } from '../io/indexed_db';\nimport { BrowserLocalStorage, BrowserLocalStorageManager } from '../io/local_storage';\nimport { ModelStoreManagerRegistry } from '../io/model_management';\nexport class PlatformBrowser {\n    fetch(path, init) {\n        return fetch(path, init);\n    }\n    now() {\n        return performance.now();\n    }\n    encode(text, encoding) {\n        if (encoding !== 'utf-8' && encoding !== 'utf8') {\n            throw new Error(`Browser's encoder only supports utf-8, but got ${encoding}`);\n        }\n        if (this.textEncoder == null) {\n            this.textEncoder = new TextEncoder();\n        }\n        return this.textEncoder.encode(text);\n    }\n    decode(bytes, encoding) {\n        return new TextDecoder(encoding).decode(bytes);\n    }\n}\nif (env().get('IS_BROWSER')) {\n    env().setPlatform('browser', new PlatformBrowser());\n    // Register LocalStorage IOHandler\n    try {\n        ModelStoreManagerRegistry.registerManager(BrowserLocalStorage.URL_SCHEME, new BrowserLocalStorageManager());\n    }\n    catch (err) {\n    }\n    // Register IndexedDB IOHandler\n    try {\n        ModelStoreManagerRegistry.registerManager(BrowserIndexedDB.URL_SCHEME, new BrowserIndexedDBManager());\n    }\n    catch (err) {\n    }\n}\n//# sourceMappingURL=platform_browser.js.map","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { env } from '../environment';\n// We are wrapping this within an object so it can be stubbed by Jasmine.\nexport const getNodeFetch = {\n    // tslint:disable-next-line:no-require-imports\n    importFetch: () => require('node-fetch')\n};\nlet systemFetch;\n// These getters and setters are for testing so we don't export a mutable\n// variable.\nexport function resetSystemFetch() {\n    systemFetch = null;\n}\nexport function setSystemFetch(fetchFn) {\n    systemFetch = fetchFn;\n}\nexport function getSystemFetch() {\n    return systemFetch;\n}\nexport class PlatformNode {\n    constructor() {\n        // tslint:disable-next-line:no-require-imports\n        this.util = require('util');\n        // According to the spec, the built-in encoder can do only UTF-8 encoding.\n        // https://developer.mozilla.org/en-US/docs/Web/API/TextEncoder/TextEncoder\n        this.textEncoder = new this.util.TextEncoder();\n    }\n    fetch(path, requestInits) {\n        if (env().global.fetch != null) {\n            return env().global.fetch(path, requestInits);\n        }\n        if (systemFetch == null) {\n            systemFetch = getNodeFetch.importFetch();\n        }\n        return systemFetch(path, requestInits);\n    }\n    now() {\n        const time = process.hrtime();\n        return time[0] * 1000 + time[1] / 1000000;\n    }\n    encode(text, encoding) {\n        if (encoding !== 'utf-8' && encoding !== 'utf8') {\n            throw new Error(`Node built-in encoder only supports utf-8, but got ${encoding}`);\n        }\n        return this.textEncoder.encode(text);\n    }\n    decode(bytes, encoding) {\n        if (bytes.length === 0) {\n            return '';\n        }\n        return new this.util.TextDecoder(encoding).decode(bytes);\n    }\n}\nif (env().get('IS_NODE')) {\n    env().setPlatform('node', new PlatformNode());\n}\n//# sourceMappingURL=platform_node.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Select } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { broadcastTo } from './broadcast_to';\nimport { assertAndGetBroadcastShape } from './broadcast_util';\nimport { op } from './operation';\n/**\n * Returns the elements, either `a` or `b` depending on the `condition`.\n *\n * If the condition is true, select from `a`, otherwise select from `b`.\n *\n * ```js\n * const cond = tf.tensor1d([false, false, true], 'bool');\n * const a = tf.tensor1d([1 , 2, 3]);\n * const b = tf.tensor1d([-1, -2, -3]);\n *\n * a.where(cond, b).print();\n * ```\n *\n * @param condition The input condition. Must be of dtype bool.\n * @param a If `condition` is rank 1, `a` may have a higher rank but\n *     its first dimension must match the size of `condition`.\n * @param b A tensor with the same dtype as `a` and with shape that is\n *     compatible with `a`.\n * @return A tensor with same dtype as `a` and `b`, and shape that is\n *     broadcastable from `a` and `b`.\n *\n * @doc {heading: 'Operations', subheading: 'Logical'}\n */\nfunction where_(condition, a, b) {\n    const $a = convertToTensor(a, 'a', 'where');\n    const $b = convertToTensor(b, 'b', 'where');\n    const $condition = convertToTensor(condition, 'condition', 'where', 'bool');\n    // TODO: move this logic to forward function when the broadcastTo op is\n    // implemented in WASM.\n    // Find the broadcastable shape for $condition, $a, and $b.\n    const broadcastShape = assertAndGetBroadcastShape(assertAndGetBroadcastShape($condition.shape, $a.shape), $b.shape);\n    const $broadcastedCondition = broadcastTo($condition, broadcastShape);\n    const $broadcastedA = broadcastTo($a, broadcastShape);\n    const $broadcastedB = broadcastTo($b, broadcastShape);\n    const inputs = {\n        condition: $broadcastedCondition,\n        t: $broadcastedA,\n        e: $broadcastedB\n    };\n    return ENGINE.runKernel(Select, inputs);\n}\nexport const where = op({ where_ });\n//# sourceMappingURL=where.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { assert, assertNonNegativeIntegerDimensions, flatten, inferDtype, isTypedArray, sizeFromShape, toTypedArray } from '../util';\n/** This is shared code across all tensor creation methods. */\nexport function makeTensor(values, shape, inferredShape, dtype) {\n    if (dtype == null) {\n        dtype = inferDtype(values);\n    }\n    if (dtype === 'complex64') {\n        throw new Error(`Cannot construct a complex64 tensor directly. ` +\n            `Please use tf.complex(real, imag).`);\n    }\n    if (!isTypedArray(values) && !Array.isArray(values) &&\n        typeof values !== 'number' && typeof values !== 'boolean' &&\n        typeof values !== 'string') {\n        throw new Error('values passed to tensor(values) must be a number/boolean/string or ' +\n            'an array of numbers/booleans/strings, or a TypedArray');\n    }\n    if (shape != null) {\n        assertNonNegativeIntegerDimensions(shape);\n        const providedSize = sizeFromShape(shape);\n        const inferredSize = sizeFromShape(inferredShape);\n        assert(providedSize === inferredSize, () => `Based on the provided shape, [${shape}], the tensor should have ` +\n            `${providedSize} values but has ${inferredSize}`);\n        for (let i = 0; i < inferredShape.length; ++i) {\n            const inferred = inferredShape[i];\n            const flatDimsDontMatch = i === inferredShape.length - 1 ?\n                inferred !== sizeFromShape(shape.slice(i)) :\n                true;\n            assert(inferredShape[i] === shape[i] || !flatDimsDontMatch, () => `Error creating a new Tensor. Inferred shape ` +\n                `(${inferredShape}) does not match the provided ` +\n                `shape (${shape}). `);\n        }\n    }\n    if (!isTypedArray(values) && !Array.isArray(values)) {\n        values = [values];\n    }\n    shape = shape || inferredShape;\n    values = dtype !== 'string' ?\n        toTypedArray(values, dtype) :\n        flatten(values, [], true);\n    return ENGINE.makeTensor(values, shape, dtype);\n}\n//# sourceMappingURL=tensor_ops_util.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Pack } from '../kernel_names';\nimport { convertToTensorArray } from '../tensor_util_env';\nimport * as util from '../util';\nimport { op } from './operation';\n/**\n * Stacks a list of rank-`R` `tf.Tensor`s into one rank-`(R+1)` `tf.Tensor`.\n *\n * ```js\n * const a = tf.tensor1d([1, 2]);\n * const b = tf.tensor1d([3, 4]);\n * const c = tf.tensor1d([5, 6]);\n * tf.stack([a, b, c]).print();\n * ```\n *\n * @param tensors A list of tensor objects with the same shape and dtype.\n * @param axis The axis to stack along. Defaults to 0 (the first dim).\n *\n * @doc {heading: 'Tensors', subheading: 'Slicing and Joining'}\n */\nfunction stack_(tensors, axis = 0) {\n    const $tensors = convertToTensorArray(tensors, 'tensors', 'stack', 'string_or_numeric');\n    util.assert($tensors.length >= 1, () => 'Pass at least one tensor to tf.stack');\n    if ($tensors.length > 0) {\n        util.assert(axis <= $tensors[0].rank, () => 'Axis must be <= rank of the tensor');\n    }\n    const inputs = $tensors;\n    const attrs = { axis };\n    return ENGINE.runKernel(Pack, inputs, attrs);\n}\nexport const stack = op({ stack_ });\n//# sourceMappingURL=stack.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { SplitV } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Splits a `tf.Tensor` into sub tensors.\n *\n * If `numOrSizeSplits` is a number, splits `x` along dimension `axis`\n * into `numOrSizeSplits` smaller tensors.\n * Requires that `numOrSizeSplits` evenly divides `x.shape[axis]`.\n *\n * If `numOrSizeSplits` is a number array, splits `x` into\n * `numOrSizeSplits.length` pieces. The shape of the `i`-th piece has the\n * same size as `x` except along dimension `axis` where the size is\n * `numOrSizeSplits[i]`.\n *\n * ```js\n * const x = tf.tensor2d([1, 2, 3, 4, 5, 6, 7, 8], [2, 4]);\n * const [a, b] = tf.split(x, 2, 1);\n * a.print();\n * b.print();\n *\n * const [c, d, e] = tf.split(x, [1, 2, 1], 1);\n * c.print();\n * d.print();\n * e.print();\n * ```\n *\n * @param x The input tensor to split.\n * @param numOrSizeSplits Either an integer indicating the number of\n * splits along the axis or an array of integers containing the sizes of\n * each output tensor along the axis. If a number then it must evenly divide\n * `x.shape[axis]`; otherwise the sum of sizes must match `x.shape[axis]`.\n * Can contain one -1 indicating that dimension is to be inferred.\n * @param axis The dimension along which to split. Defaults to 0 (the first\n * dim).\n *\n * @doc {heading: 'Tensors', subheading: 'Slicing and Joining'}\n */\nfunction split_(x, numOrSizeSplits, axis = 0) {\n    const $x = convertToTensor(x, 'x', 'split');\n    const inputs = { x: $x };\n    const attr = { numOrSizeSplits, axis };\n    return ENGINE.runKernel(SplitV, inputs, attr);\n}\nexport const split = op({ split_ });\n//# sourceMappingURL=split.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { makeZerosTypedArray, sizeFromShape } from '../util';\nimport { complex } from './complex';\n/**\n * Creates a `tf.Tensor` with all elements set to 0.\n *\n * ```js\n * tf.zeros([2, 2]).print();\n * ```\n *\n * @param shape An array of integers defining the output tensor shape.\n * @param dtype The type of an element in the resulting tensor. Can\n *     be 'float32', 'int32' or 'bool'. Defaults to 'float'.\n *\n * @doc {heading: 'Tensors', subheading: 'Creation'}\n */\nexport function zeros(shape, dtype = 'float32') {\n    if (dtype === 'complex64') {\n        const real = zeros(shape, 'float32');\n        const imag = zeros(shape, 'float32');\n        return complex(real, imag);\n    }\n    const values = makeZerosTypedArray(sizeFromShape(shape), dtype);\n    return ENGINE.makeTensor(values, shape, dtype);\n}\n//# sourceMappingURL=zeros.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Relu } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes rectified linear element-wise: `max(x, 0)`.\n *\n * ```js\n * const x = tf.tensor1d([-1, 2, -3, 4]);\n *\n * x.relu().print();  // or tf.relu(x)\n * ```\n * @param x The input tensor. If the dtype is `bool`, the output dtype will be\n *     `int32'.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction relu_(x) {\n    const $x = convertToTensor(x, 'x', 'relu');\n    const inputs = { x: $x };\n    return ENGINE.runKernel(Relu, inputs);\n}\nexport const relu = op({ relu_ });\n//# sourceMappingURL=relu.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { inferShape } from '../tensor_util_env';\nimport { makeTensor } from './tensor_ops_util';\n/**\n * Creates a `tf.Tensor` with the provided values, shape and dtype.\n *\n * ```js\n * // Pass an array of values to create a vector.\n * tf.tensor([1, 2, 3, 4]).print();\n * ```\n *\n * ```js\n * // Pass a nested array of values to make a matrix or a higher\n * // dimensional tensor.\n * tf.tensor([[1, 2], [3, 4]]).print();\n * ```\n *\n * ```js\n * // Pass a flat array and specify a shape yourself.\n * tf.tensor([1, 2, 3, 4], [2, 2]).print();\n * ```\n *\n * @param values The values of the tensor. Can be nested array of numbers,\n *     or a flat array, or a `TypedArray`. If the values are strings,\n *     they will be encoded as utf-8 and kept as `Uint8Array[]`.\n * @param shape The shape of the tensor. Optional. If not provided,\n *   it is inferred from `values`.\n * @param dtype The data type.\n *\n * @doc {heading: 'Tensors', subheading: 'Creation'}\n */\nexport function tensor(values, shape, dtype) {\n    const inferredShape = inferShape(values, dtype);\n    return makeTensor(values, shape, inferredShape, dtype);\n}\n//# sourceMappingURL=tensor.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { inferShape } from '../tensor_util_env';\nimport { assertNonNull } from '../util';\nimport { makeTensor } from './tensor_ops_util';\n/**\n * Creates rank-2 `tf.Tensor` with the provided values, shape and dtype.\n *\n * The same functionality can be achieved with `tf.tensor`, but in general\n * we recommend using `tf.tensor2d` as it makes the code more readable.\n *\n *  ```js\n * // Pass a nested array.\n * tf.tensor2d([[1, 2], [3, 4]]).print();\n * ```\n * ```js\n * // Pass a flat array and specify a shape.\n * tf.tensor2d([1, 2, 3, 4], [2, 2]).print();\n * ```\n *\n * @param values The values of the tensor. Can be nested array of numbers,\n *     or a flat array, or a `TypedArray`.\n * @param shape The shape of the tensor. If not provided, it is inferred from\n *     `values`.\n * @param dtype The data type.\n *\n * @doc {heading: 'Tensors', subheading: 'Creation'}\n */\nexport function tensor2d(values, shape, dtype) {\n    assertNonNull(values);\n    if (shape != null && shape.length !== 2) {\n        throw new Error('tensor2d() requires shape to have two numbers');\n    }\n    const inferredShape = inferShape(values, dtype);\n    if (inferredShape.length !== 2 && inferredShape.length !== 1) {\n        throw new Error('tensor2d() requires values to be number[][] or flat/TypedArray');\n    }\n    if (inferredShape.length === 1 && shape == null) {\n        throw new Error('tensor2d() requires shape to be provided when `values` ' +\n            'are a flat/TypedArray');\n    }\n    return makeTensor(values, shape, inferredShape, dtype);\n}\n//# sourceMappingURL=tensor2d.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Range } from '../kernel_names';\n/**\n * Creates a new `tf.Tensor1D` filled with the numbers in the range provided.\n *\n * The tensor is a is half-open interval meaning it includes start, but\n * excludes stop. Decrementing ranges and negative step values are also\n * supported.sv\n *\n *\n * ```js\n * tf.range(0, 9, 2).print();\n * ```\n *\n * @param start An integer start value\n * @param stop An integer stop value\n * @param step An integer increment (will default to 1 or -1)\n * @param dtype The data type of the output tensor. Defaults to 'float32'.\n *\n * @doc {heading: 'Tensors', subheading: 'Creation'}\n */\nexport function range(start, stop, step = 1, dtype = 'float32') {\n    if (step === 0) {\n        throw new Error('Cannot have a step of zero');\n    }\n    const attrs = { start, stop, step, dtype };\n    return ENGINE.runKernel(Range, {} /* inputs */, attrs);\n}\n//# sourceMappingURL=range.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../../engine';\nimport { IFFT } from '../../kernel_names';\nimport { assert } from '../../util';\nimport { op } from '../operation';\n/**\n * Inverse fast Fourier transform.\n *\n * Computes the inverse 1-dimensional discrete Fourier transform over the\n * inner-most dimension of input.\n *\n * ```js\n * const real = tf.tensor1d([1, 2, 3]);\n * const imag = tf.tensor1d([1, 2, 3]);\n * const x = tf.complex(real, imag);\n *\n * x.ifft().print();  // tf.spectral.ifft(x).print();\n * ```\n * @param input The complex input to compute an ifft over.\n *\n * @doc {heading: 'Operations', subheading: 'Spectral', namespace: 'spectral'}\n */\nfunction ifft_(input) {\n    assert(input.dtype === 'complex64', () => `The dtype for tf.spectral.ifft() must be complex64 ` +\n        `but got ${input.dtype}.`);\n    const inputs = { input };\n    return ENGINE.runKernel(IFFT, inputs);\n}\nexport const ifft = op({ ifft_ });\n//# sourceMappingURL=ifft.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Real } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Returns the real part of a complex (or real) tensor.\n *\n * Given a tensor input, this operation returns a tensor of type float that is\n * the real part of each element in input considered as a complex number.\n *\n * If the input is real, it simply makes a clone.\n *\n * ```js\n * const x = tf.complex([-2.25, 3.25], [4.75, 5.75]);\n * tf.real(x).print();\n * ```\n *\n * @doc {heading: 'Tensors', subheading: 'Creation'}\n */\nfunction real_(input) {\n    const $input = convertToTensor(input, 'input', 'real');\n    const inputs = { input: $input };\n    return ENGINE.runKernel(Real, inputs);\n}\nexport const real = op({ real_ });\n//# sourceMappingURL=real.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Reshape } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Reshapes a `tf.Tensor` to a given shape.\n *\n * Given an input tensor, returns a new tensor with the same values as the\n * input tensor with shape `shape`.\n *\n * If one component of shape is the special value -1, the size of that\n * dimension is computed so that the total size remains constant. In\n * particular, a shape of [-1] flattens into 1-D. At most one component of\n * shape can be -1.\n *\n * If shape is 1-D or higher, then the operation returns a tensor with shape\n * shape filled with the values of tensor. In this case, the number of\n * elements implied by shape must be the same as the number of elements in\n * tensor.\n *\n * ```js\n * const x = tf.tensor1d([1, 2, 3, 4]);\n * x.reshape([2, 2]).print();\n * ```\n *\n * @param x The input tensor to be reshaped.\n * @param shape An array of integers defining the output tensor shape.\n *\n * @doc {heading: 'Tensors', subheading: 'Transformations'}\n */\nfunction reshape_(x, shape) {\n    const $x = convertToTensor(x, 'x', 'reshape', 'string_or_numeric');\n    const inputs = { x: $x };\n    const attrs = { shape };\n    return ENGINE.runKernel(Reshape, inputs, attrs);\n}\nexport const reshape = op({ reshape_ });\n//# sourceMappingURL=reshape.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Unpack } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport * as util from '../util';\nimport { op } from './operation';\n/**\n * Unstacks a `tf.Tensor` of rank-`R` into a list of rank-`(R-1)` `tf.Tensor`s.\n *\n * ```js\n * const a = tf.tensor2d([1, 2, 3, 4], [2, 2]);\n *\n * tf.unstack(a).forEach(tensor => tensor.print());\n * ```\n *\n * @param x A tensor object.\n * @param axis The axis to unstack along. Defaults to 0 (the first dim).\n *\n * @doc {heading: 'Tensors', subheading: 'Slicing and Joining'}\n */\nfunction unstack_(x, axis = 0) {\n    const $x = convertToTensor(x, 'x', 'unstack', 'string_or_numeric');\n    util.assert(axis >= -$x.shape.length && axis < $x.shape.length, () => `Axis = ${axis} is not in [-${$x.shape.length}, ${$x.shape.length})`);\n    const inputs = { value: $x };\n    const attrs = { axis };\n    return ENGINE.runKernel(Unpack, inputs, attrs);\n}\nexport const unstack = op({ unstack_ });\n//# sourceMappingURL=unstack.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../../engine';\nimport { FFT } from '../../kernel_names';\nimport { assert } from '../../util';\nimport { op } from '../operation';\n/**\n * Fast Fourier transform.\n *\n * Computes the 1-dimensional discrete Fourier transform over the inner-most\n * dimension of input.\n *\n * ```js\n * const real = tf.tensor1d([1, 2, 3]);\n * const imag = tf.tensor1d([1, 2, 3]);\n * const x = tf.complex(real, imag);\n *\n * x.fft().print();  // tf.spectral.fft(x).print();\n * ```\n * @param input The complex input to compute an fft over.\n *\n * @doc {heading: 'Operations', subheading: 'Spectral', namespace: 'spectral'}\n */\nfunction fft_(input) {\n    assert(input.dtype === 'complex64', () => `The dtype for tf.spectral.fft() must be complex64 ` +\n        `but got ${input.dtype}.`);\n    const inputs = { input };\n    return ENGINE.runKernel(FFT, inputs);\n}\nexport const fft = op({ fft_ });\n//# sourceMappingURL=fft.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { assert } from '../../util';\nimport { complex } from '../complex';\nimport { concat } from '../concat';\nimport { imag } from '../imag';\nimport { op } from '../operation';\nimport { real } from '../real';\nimport { reshape } from '../reshape';\nimport { slice } from '../slice';\nimport { split } from '../split';\nimport { zeros } from '../zeros';\nimport { zerosLike } from '../zeros_like';\nimport { fft } from './fft';\n/**\n * Real value input fast Fourier transform.\n *\n * Computes the 1-dimensional discrete Fourier transform over the\n * inner-most dimension of the real input.\n *\n * ```js\n * const real = tf.tensor1d([1, 2, 3]);\n *\n * real.rfft().print();\n * ```\n * @param input The real value input to compute an rfft over.\n *\n * @doc {heading: 'Operations', subheading: 'Spectral', namespace: 'spectral'}\n */\nfunction rfft_(input, fftLength) {\n    assert(input.dtype === 'float32', () => `The dtype for rfft() must be real value but got ${input.dtype}`);\n    let innerDimensionSize = input.shape[input.shape.length - 1];\n    const batch = input.size / innerDimensionSize;\n    let adjustedInput;\n    if (fftLength != null && fftLength < innerDimensionSize) {\n        // Need to crop\n        const begin = input.shape.map(v => 0);\n        const size = input.shape.map(v => v);\n        size[input.shape.length - 1] = fftLength;\n        adjustedInput = slice(input, begin, size);\n        innerDimensionSize = fftLength;\n    }\n    else if (fftLength != null && fftLength > innerDimensionSize) {\n        // Need to pad with zeros\n        const zerosShape = input.shape.map(v => v);\n        zerosShape[input.shape.length - 1] = fftLength - innerDimensionSize;\n        adjustedInput = concat([input, zeros(zerosShape)], input.shape.length - 1);\n        innerDimensionSize = fftLength;\n    }\n    else {\n        adjustedInput = input;\n    }\n    // Complement the input with zero imaginary numbers.\n    const zerosInput = zerosLike(adjustedInput);\n    const complexInput = reshape(complex(adjustedInput, zerosInput), [batch, innerDimensionSize]);\n    const ret = fft(complexInput);\n    // Exclude complex conjugations. These conjugations are put symmetrically.\n    const half = Math.floor(innerDimensionSize / 2) + 1;\n    const realValues = real(ret);\n    const imagValues = imag(ret);\n    const realComplexConjugate = split(realValues, [half, innerDimensionSize - half], realValues.shape.length - 1);\n    const imagComplexConjugate = split(imagValues, [half, innerDimensionSize - half], imagValues.shape.length - 1);\n    const outputShape = adjustedInput.shape.slice();\n    outputShape[adjustedInput.shape.length - 1] = half;\n    return reshape(complex(realComplexConjugate[0], imagComplexConjugate[0]), outputShape);\n}\nexport const rfft = op({ rfft_ });\n//# sourceMappingURL=rfft.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { convertToTensor } from '../tensor_util_env';\nimport { parseAxisParam } from '../util';\nimport { abs } from './abs';\nimport * as axis_util from './axis_util';\nimport { max } from './max';\nimport { min } from './min';\nimport { op } from './operation';\nimport { pow } from './pow';\nimport { reshape } from './reshape';\nimport { scalar } from './scalar';\nimport { sqrt } from './sqrt';\nimport { square } from './square';\nimport { sum } from './sum';\n/**\n * Computes the norm of scalar, vectors, and matrices.\n * This function can compute several different vector norms (the 1-norm, the\n * Euclidean or 2-norm, the inf-norm, and in general the p-norm for p > 0)\n * and matrix norms (Frobenius, 1-norm, and inf-norm).\n *\n * ```js\n * const x = tf.tensor1d([1, 2, 3, 4]);\n *\n * x.norm().print();  // or tf.norm(x)\n * ```\n *\n * @param x The input array.\n * @param ord Optional. Order of the norm. Supported norm types are\n * following:\n *\n *  | ord        | norm for matrices         | norm for vectors\n *  |------------|---------------------------|---------------------\n *  |'euclidean' |Frobenius norm             |2-norm\n *  |'fro'       |Frobenius norm\t           |\n *  |Infinity    |max(sum(abs(x), axis=1))   |max(abs(x))\n *  |-Infinity   |min(sum(abs(x), axis=1))   |min(abs(x))\n *  |1           |max(sum(abs(x), axis=0))   |sum(abs(x))\n *  |2           |                           |sum(abs(x)^2)^1/2*\n *\n * @param axis Optional. If axis is null (the default), the input is\n * considered a vector and a single vector norm is computed over the entire\n * set of values in the Tensor, i.e. norm(x, ord) is equivalent\n * to norm(x.reshape([-1]), ord). If axis is a integer, the input\n * is considered a batch of vectors, and axis determines the axis in x\n * over which to compute vector norms. If axis is a 2-tuple of integer it is\n * considered a batch of matrices and axis determines the axes in NDArray\n * over which to compute a matrix norm.\n * @param keepDims Optional. If true, the norm have the same dimensionality\n * as the input.\n *\n * @doc {heading: 'Operations', subheading: 'Matrices'}\n */\nfunction norm_(x, ord = 'euclidean', axis = null, keepDims = false) {\n    x = convertToTensor(x, 'x', 'norm');\n    const norm = normImpl(x, ord, axis);\n    let keepDimsShape = norm.shape;\n    if (keepDims) {\n        const axes = parseAxisParam(axis, x.shape);\n        keepDimsShape = axis_util.expandShapeToKeepDim(norm.shape, axes);\n    }\n    return reshape(norm, keepDimsShape);\n}\nfunction normImpl(x, p, axis = null) {\n    if (x.rank === 0) {\n        return abs(x);\n    }\n    // consider vector when no axis is specified\n    if (x.rank !== 1 && axis === null) {\n        return normImpl(reshape(x, [-1]), p, axis);\n    }\n    // vector\n    if (x.rank === 1 || typeof axis === 'number' ||\n        Array.isArray(axis) && axis.length === 1) {\n        if (p === 1) {\n            return sum(abs(x), axis);\n        }\n        if (p === Infinity) {\n            return max(abs(x), axis);\n        }\n        if (p === -Infinity) {\n            return min(abs(x), axis);\n        }\n        if (p === 'euclidean' || p === 2) {\n            // norm(x, 2) = sum(abs(xi) ^ 2) ^ 1/2\n            return sqrt(sum(pow(abs(x), scalar(2, 'int32')), axis));\n        }\n        throw new Error(`Error in norm: invalid ord value: ${p}`);\n    }\n    // matrix (assumption axis[0] < axis[1])\n    if (Array.isArray(axis) && axis.length === 2) {\n        if (p === 1) {\n            return max(sum(abs(x), axis[0]), axis[1] - 1);\n        }\n        if (p === Infinity) {\n            return max(sum(abs(x), axis[1]), axis[0]);\n        }\n        if (p === -Infinity) {\n            return min(sum(abs(x), axis[1]), axis[0]);\n        }\n        if (p === 'fro' || p === 'euclidean') {\n            // norm(x) = sqrt(sum(pow(x, 2)))\n            return sqrt(sum(square(x), axis));\n        }\n        throw new Error(`Error in norm: invalid ord value: ${p}`);\n    }\n    throw new Error(`Error in norm: invalid axis: ${axis}`);\n}\nexport const norm = op({ norm_ });\n//# sourceMappingURL=norm.js.map","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes square of `x` element-wise: `x ^ 2`\n *\n * ```js\n * const x = tf.tensor1d([1, 2, Math.sqrt(2), -1]);\n *\n * x.square().print();  // or tf.square(x)\n * ```\n * @param x The input Tensor.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction square_(x) {\n    const $x = convertToTensor(x, 'x', 'square');\n    const attrs = {};\n    return ENGINE.runKernel('Square', { x: $x }, attrs);\n}\nexport const square = op({ square_ });\n//# sourceMappingURL=square.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Tile } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport * as util from '../util';\nimport { op } from './operation';\n/**\n * Construct a tensor by repeating it the number of times given by reps.\n *\n * This operation creates a new tensor by replicating `input` `reps`\n * times. The output tensor's i'th dimension has `input.shape[i] *\n * reps[i]` elements, and the values of `input` are replicated\n * `reps[i]` times along the i'th dimension. For example, tiling\n * `[a, b, c, d]` by `[2]` produces `[a, b, c, d, a, b, c, d]`.\n *\n * ```js\n * const a = tf.tensor1d([1, 2]);\n *\n * a.tile([2]).print();    // or a.tile([2])\n * ```\n *\n * ```js\n * const a = tf.tensor2d([1, 2, 3, 4], [2, 2]);\n *\n * a.tile([1, 2]).print();  // or a.tile([1, 2])\n * ```\n * @param x The tensor to tile.\n * @param reps Determines the number of replications per dimension.\n *\n * @doc {heading: 'Tensors', subheading: 'Slicing and Joining'}\n */\nfunction tile_(x, reps) {\n    const $x = convertToTensor(x, 'x', 'tile', 'string_or_numeric');\n    util.assert($x.rank === reps.length, () => `Error in transpose: rank of input ${$x.rank} ` +\n        `must match length of reps ${reps}.`);\n    const inputs = { x: $x };\n    const attrs = { reps };\n    return ENGINE.runKernel(Tile, inputs, attrs);\n}\nexport const tile = op({ tile_ });\n//# sourceMappingURL=tile.js.map","import { computeStrides, sizeFromShape } from '../util';\n/**\n * Check whether updates.shape = indices.shape[:batchDim] +\n * shape[sliceDim:]\n *\n * @param x The input tensor.\n */\nexport function validateUpdateShape(shape, indices, updates) {\n    const sliceDim = (indices.rank > 1) ? indices.shape[indices.rank - 1] : 1;\n    const batchDim = (indices.rank > 1) ? indices.rank - 1 : 1;\n    const shapeError = 'Must have updates.shape = indices.shape[:batchDim] + ' +\n        `shape[sliceDim:], got updates.shape: ${updates.shape}` +\n        `, indices.shape: ${indices.shape}, shape: ${shape}` +\n        `, sliceDim: ${sliceDim}, and batchDim: ${batchDim}.`;\n    if (updates.rank < batchDim) {\n        throw new Error(shapeError + ` update.rank < ${batchDim}. `);\n    }\n    if (shape.length < sliceDim + (updates.rank - batchDim)) {\n        throw new Error(shapeError +\n            ` Output shape length < ${sliceDim + (updates.rank - batchDim)}`);\n    }\n    if (updates.rank !== batchDim + shape.length - sliceDim) {\n        throw new Error(shapeError + ` update.rank != ${batchDim + shape.length - sliceDim}`);\n    }\n    for (let d = 0; d < batchDim; ++d) {\n        if (updates.shape[d] !== indices.shape[d]) {\n            throw new Error(shapeError +\n                ` updates.shape[${d}] (${updates.shape[d]}) != indices.shape[${d}] (${indices.shape[d]}).`);\n        }\n    }\n    for (let d = 0; d < updates.rank - batchDim; ++d) {\n        if (updates.shape[d + batchDim] !== shape[d + sliceDim]) {\n            throw new Error(shapeError +\n                ` updates.shape[${d + batchDim}] (${updates.shape[d + batchDim]}) != shape[${d + batchDim}] (${shape[d + batchDim]})`);\n        }\n    }\n}\n/**\n * Validate scatter nd inputs.\n *\n * @param update The tensor contains the update values.\n * @param indices The tensor contains the indices for the update values.\n * @param shape The shape of the output tensor.\n */\nexport function validateInput(updates, indices, shape) {\n    if (indices.rank < 1) {\n        throw new Error('tf.scatterND() expects the indices to be rank 1 or higher,' +\n            ` but the rank was ${indices.rank}.`);\n    }\n    if (updates.rank < 1) {\n        throw new Error('tf.scatterND() expects the updates to be rank 1 or higher,' +\n            ` but the rank was ${updates.rank}.`);\n    }\n    if (indices.dtype !== 'int32') {\n        throw new Error(`The dtype of 'indices' should be int32, but got dtype: ${indices.dtype}`);\n    }\n    if (shape.length < 1) {\n        throw new Error(`Output rank must be greater or equal to 1, but got shape: ${shape}`);\n    }\n    if (shape.length === 0) {\n        if (indices.size === 0) {\n            throw new Error(`Indices specified for empty output. indices shape: ${indices.shape}`);\n        }\n        if (updates.size === 0) {\n            throw new Error(`Updates specified for empty output. updates shape: ${updates.shape}`);\n        }\n    }\n    validateUpdateShape(shape, indices, updates);\n}\n/**\n * Calculate the shape information for the output.\n *\n * @param update The tensor contains the update values.\n * @param indices The tensor contains the indices for the update values.\n * @param shape The shape of the output tensor.\n *\n * @returns ScatterShapeInfo\n */\nexport function calculateShapes(updates, indices, shape) {\n    // Calculate the number of dimensions in indices\n    const indicesRank = indices.shape.length;\n    const sliceRank = (indicesRank > 1) ? indices.shape[indicesRank - 1] : 1;\n    // Calculate the number of elements that make up each slice of our updated\n    // tensor. This allows us to work with flattened tensors and copy over whole\n    // slices at a time.\n    const totalNd = shape.length;\n    let sliceSize = 1;\n    for (let i = sliceRank; i < totalNd; ++i) {\n        sliceSize *= shape[i];\n    }\n    const safeSliceDim = (sliceRank < 1) ? 1 : sliceRank;\n    const numUpdates = sizeFromShape(indices.shape) / safeSliceDim;\n    const strides = [...computeStrides(shape.slice(0, sliceRank)), 1];\n    const outputSize = sizeFromShape(shape);\n    return { sliceRank, numUpdates, sliceSize, strides, outputSize };\n}\n//# sourceMappingURL=scatter_nd_util.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { ZerosLike } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Creates a `tf.Tensor` with all elements set to 0 with the same shape as the\n * given tensor.\n *\n * ```js\n * const x = tf.tensor([1, 2]);\n * tf.zerosLike(x).print();\n * ```\n *\n * @param x The tensor of required shape.\n *\n * @doc {heading: 'Tensors', subheading: 'Creation'}\n */\nfunction zerosLike_(x) {\n    const $x = convertToTensor(x, 'x', 'zerosLike');\n    const inputs = { x: $x };\n    return ENGINE.runKernel(ZerosLike, inputs);\n}\nexport const zerosLike = op({ zerosLike_ });\n//# sourceMappingURL=zeros_like.js.map"],"sourceRoot":""}