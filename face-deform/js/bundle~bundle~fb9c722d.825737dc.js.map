{"version":3,"sources":["webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/non_max_suppression_util.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/non_max_suppression_impl.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/flags.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/backend.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/device_util.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/environment.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/complex_util.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/backend_util.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/engine.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/base_side_effects.js"],"names":["binaryInsert","arr","element","comparator","index","target","left","right","length","middle","found","compareResult","binarySearch_","defaultComparator","binarySearch","insertionPoint","splice","a","b","nonMaxSuppressionV3Impl","boxes","scores","maxOutputSize","iouThreshold","scoreThreshold","nonMaxSuppressionImpl_","nonMaxSuppressionV4Impl","padToMaxOutputSize","nonMaxSuppressionV5Impl","softNmsSigma","returnScoresTensor","returnValidOutputs","candidates","i","push","score","boxIndex","suppressBeginIndex","sort","ascendingComparator","scale","selectedIndices","selectedScores","candidate","pop","originalScore","ignoreCandidate","j","iou","intersectionOverUnion","suppressWeight","validOutputs","elemsToPad","Array","fill","result","iCoord","subarray","jCoord","yminI","Math","min","xminI","ymaxI","max","xmaxI","yminJ","xminJ","ymaxJ","xmaxJ","areaI","areaJ","intersectionYmin","intersectionXmin","intersectionYmax","intersectionXmax","intersectionArea","weight","exp","c1","c2","ENV","registerFlag","debugValue","console","warn","process","versions","node","navigator","userAgent","test","vendor","getBool","DataStorage","backend","dataMover","this","data","WeakMap","dataIdsCount","dataId","has","moveData","get","value","set","delete","KernelBackend","f","notYetImplemented","values","shape","dtype","floatPrecision","transposeA","transposeB","bias","activation","preluActivationWeights","x","begin","size","end","strides","axis","tensors","axes","segmentIds","numSegments","condition","k","sorted","dim","dy","y","alpha","input","filter","convInfo","dY","reps","paddings","constantValue","perm","indices","batchDims","updates","blockShape","crops","newHeight","newWidth","alignCorners","halfPixelCenters","newHEight","mean","variance","offset","varianceEpsilon","radius","beta","inputImage","outputImage","logits","normalized","numSamples","seed","depth","onValue","offValue","exclusive","reverse","real","imag","image","cropSize","method","extrapolationValue","blockSize","dataFormat","sizeSplits","sparseIndices","sparseValues","outputShape","defaultValue","start","stop","num","kernelName","Error","isBrowser","window","document","WorkerGlobalScope","TENSORFLOWJS_FLAGS_PREFIX","Environment","global","flags","flagRegistry","urlFlags","populateURLFlags","platformName","platform","flagName","evaluationFn","setHook","flagValue","evaluateFlag","Object","assign","location","search","urlParams","queryString","params","replace","s","t","name","decodeURIComponent","decodeParam","join","getQueryParams","split","forEach","keyValue","key","toLowerCase","parseValue","env","setEnvironmentGlobal","environment","mergeRealAndImagArrays","Float32Array","splitRealAndImagArrays","complex","complexWithEvenIndex","len","ceil","floor","complexWithOddIndex","getComplexWithIndex","assignToTypedArray","exponents","n","inverse","PI","cos","sin","exponent","castTensor","clone","zerosTensor","zeros","floatX","cast","dispose","makeTensorFromDataId","int","zero","scalar","notEqual","reshapeTensor","fromUint8ToStringArray","vals","map","val","err","fromStringArrayToUint8","strings","EngineState","registeredVariables","nextTapeNodeId","numBytes","numTensors","numStringTensors","numDataBuffers","gradientDepth","kernelDepth","scopeStack","numDataMovesStack","nextScopeId","tensorInfo","profiling","activeProfile","newBytes","newTensors","peakBytes","kernels","from","Set","variableName","Engine","registry","registryFactory","pendingBackendInitId","state","pendingBackendInit","then","backendInstance","sortedBackends","getSortedBackends","backendName","initializeBackend","success","setBackend","asyncInit","initializeBackendsAndReturnBest","keys","factory","priority","setupRegisteredKernels","profiler","kernel","setupFunc","disposeFunc","registryFactoryEntry","promiseId","catch","stack","message","disposeRegisteredKernels","info","srcBackend","readSync","disposeData","move","shouldCheckForMemLeaks","nameOrFn","fn","String","scopedRun","startScope","endScope","Promise","error","res","ex","nextTensorId","nextVariableId","inputs","addTapeNode","activeScope","gradInputs","attrs","ENGINE","runKernelFunc","inputsToSave","outputsToSave","numDataIdsBefore","outInfos","numDataIdsAfter","numDataIds","numOutputDataIds","numMoves","dataIdsLeaked","forwardFunc","backwardsFunc","outputs","saved","isTapeOn","startingBytecount","startingNumTensors","kernelFunc","out","kernelProfile","isArray","checkKernelForMemLeak","outTensors","outInfo","rank","tensorsToSave","getTensorsForGradient","outsToSave","_","slice","concat","saveTensorsForBackwardMode","saveFunc","tensor","keep","tidy","outs","profileKernel","logKernelProfile","bytesAdded","totalBytesSnapshot","tensorsAdded","totalTensorsSnapshot","inputShapes","outputShapes","item","kernelTimeMs","timeMs","extraInfo","gradConfig","inputTensorsToSave","saveAllInputs","inputName","outputTensorsToSave","backendVals","d","write","incRef","bytes","initialValue","trainable","toString","v","refCount","track","decComplexRef","varName","disposeVariable","disposeTensor","memory","unreliable","reasons","query","startBytes","startNumTensors","gradientsFunc","tapeNode","id","gradFunc","gradient","dys","output","makeTensor","activeTape","kept","scopeInfo","tensorsToTrackInParent","tensorsToTrackInParentSet","oldScope","scopeId","xs","allowNoGradients","startTape","endTape","filteredTape","accumulatedGradientMap","ones","add","grads","every","inputMap","save","gradRes","gradMap","grad","read","timingInfo","time","wallMs","reset","getOrMakeEngine","ns","_tfengine","runKernel","opHandler","buffer","print"],"mappings":";uJA6BO,SAASA,EAAaC,EAAKC,EAASC,GACvC,MAAMC,EAmBH,SAAsBH,EAAKI,EAAQF,GACtC,OAYJ,SAAuBF,EAAKI,EAAQF,GAChC,IAAIG,EAAO,EACPC,EAAQN,EAAIO,OACZC,EAAS,EACTC,GAAQ,EACZ,KAAOJ,EAAOC,GAAO,CACjBE,EAASH,GAASC,EAAQD,IAAU,GACpC,MAAMK,EAAgBR,EAAWE,EAAQJ,EAAIQ,IACzCE,EAAgB,EAChBL,EAAOG,EAAS,GAGhBF,EAAQE,EAGRC,GAASC,GAGjB,OAAOD,EAAQJ,GAAQA,EAAO,EA9BvBM,CAAcX,EAAKI,EAAQF,GAAcU,GApBlCC,CAAab,EAAKC,EAASC,GACnCY,EAAiBX,EAAQ,IAAMA,EAAQ,GAAKA,EAClDH,EAAIe,OAAOD,EAAgB,EAAGb,GA2BlC,SAASW,EAAkBI,EAAGC,GAC1B,OAAOD,EAAIC,EAAI,EAAID,EAAIC,GAAK,EAAI,EC3C7B,SAASC,EAAwBC,EAAOC,EAAQC,EAAeC,EAAcC,GAChF,OAAOC,EAAuBL,EAAOC,EAAQC,EAAeC,EAAcC,EAAgB,GAEvF,SAASE,EAAwBN,EAAOC,EAAQC,EAAeC,EAAcC,EAAgBG,GAChG,OAAOF,EAAuBL,EAAOC,EAAQC,EAAeC,EAAcC,EAAgB,GAAsB,EAAgCG,GAA6C,GAG1L,SAASC,EAAwBR,EAAOC,EAAQC,EAAeC,EAAcC,EAAgBK,GAChG,OAAOJ,EAAuBL,EAAOC,EAAQC,EAAeC,EAAcC,EAAgBK,GAAc,GAE5G,SAASJ,EAAuBL,EAAOC,EAAQC,EAAeC,EAAcC,EAAgBK,EAAcC,GAAqB,EAAOH,GAAqB,EAAOI,GAAqB,GAGnL,MAAMC,EAAa,GACnB,IAAK,IAAIC,EAAI,EAAGA,EAAIZ,EAAOb,OAAQyB,IAC3BZ,EAAOY,GAAKT,GACZQ,EAAWE,KAAK,CAAEC,MAAOd,EAAOY,GAAIG,SAAUH,EAAGI,mBAAoB,IAG7EL,EAAWM,KAAKC,GAGhB,MAAMC,EAAQX,EAAe,GAAM,GAAMA,EAAgB,EACnDY,EAAkB,GAClBC,EAAiB,GACvB,KAAOD,EAAgBjC,OAASc,GAAiBU,EAAWxB,OAAS,GAAG,CACpE,MAAMmC,EAAYX,EAAWY,OACrBT,MAAOU,EAAa,SAAET,EAAQ,mBAAEC,GAAuBM,EAC/D,GAAIE,EAAgBrB,EAChB,MAQJ,IAAIsB,GAAkB,EACtB,IAAK,IAAIC,EAAIN,EAAgBjC,OAAS,EAAGuC,GAAKV,IAAsBU,EAAG,CACnE,MAAMC,EAAMC,EAAsB7B,EAAOgB,EAAUK,EAAgBM,IACnE,GAAIC,GAAOzB,EAAc,CACrBuB,GAAkB,EAClB,MAIJ,GAFAH,EAAUR,MACNQ,EAAUR,MAAQe,EAAe3B,EAAciB,EAAOQ,GACtDL,EAAUR,OAASX,EACnB,MAURmB,EAAUN,mBAAqBI,EAAgBjC,OAC1CsC,IAGGH,EAAUR,QAAUU,GACpBJ,EAAgBP,KAAKE,GACrBM,EAAeR,KAAKS,EAAUR,QAEzBQ,EAAUR,MAAQX,GAGvBxB,EAAagC,EAAYW,EAAWJ,IAKhD,MAAMY,EAAeV,EAAgBjC,OAC/B4C,EAAa9B,EAAgB6B,EAC/BxB,GAAsByB,EAAa,IACnCX,EAAgBP,QAAQ,IAAImB,MAAMD,GAAYE,KAAK,IACnDZ,EAAeR,QAAQ,IAAImB,MAAMD,GAAYE,KAAK,KAEtD,MAAMC,EAAS,CAAEd,mBAOjB,OANIX,IACAyB,EAAuB,eAAIb,GAE3BX,IACAwB,EAAqB,aAAIJ,GAEtBI,EAEX,SAASN,EAAsB7B,EAAOa,EAAGc,GACrC,MAAMS,EAASpC,EAAMqC,SAAa,EAAJxB,EAAW,EAAJA,EAAQ,GACvCyB,EAAStC,EAAMqC,SAAa,EAAJV,EAAW,EAAJA,EAAQ,GACvCY,EAAQC,KAAKC,IAAIL,EAAO,GAAIA,EAAO,IACnCM,EAAQF,KAAKC,IAAIL,EAAO,GAAIA,EAAO,IACnCO,EAAQH,KAAKI,IAAIR,EAAO,GAAIA,EAAO,IACnCS,EAAQL,KAAKI,IAAIR,EAAO,GAAIA,EAAO,IACnCU,EAAQN,KAAKC,IAAIH,EAAO,GAAIA,EAAO,IACnCS,EAAQP,KAAKC,IAAIH,EAAO,GAAIA,EAAO,IACnCU,EAAQR,KAAKI,IAAIN,EAAO,GAAIA,EAAO,IACnCW,EAAQT,KAAKI,IAAIN,EAAO,GAAIA,EAAO,IACnCY,GAASP,EAAQJ,IAAUM,EAAQH,GACnCS,GAASH,EAAQF,IAAUG,EAAQF,GACzC,GAAIG,GAAS,GAAKC,GAAS,EACvB,OAAO,EAEX,MAAMC,EAAmBZ,KAAKI,IAAIL,EAAOO,GACnCO,EAAmBb,KAAKI,IAAIF,EAAOK,GACnCO,EAAmBd,KAAKC,IAAIE,EAAOK,GACnCO,EAAmBf,KAAKC,IAAII,EAAOI,GACnCO,EAAmBhB,KAAKI,IAAIU,EAAmBF,EAAkB,GACnEZ,KAAKI,IAAIW,EAAmBF,EAAkB,GAClD,OAAOG,GAAoBN,EAAQC,EAAQK,GAM/C,SAAS1B,EAAe3B,EAAciB,EAAOQ,GACzC,MAAM6B,EAASjB,KAAKkB,IAAItC,EAAQQ,EAAMA,GACtC,OAAOA,GAAOzB,EAAesD,EAAS,EAE1C,SAAStC,EAAoBwC,EAAIC,GAK7B,OAAQD,EAAG5C,MAAQ6C,EAAG7C,OAChB4C,EAAG5C,QAAU6C,EAAG7C,OAAW6C,EAAG5C,SAAW2C,EAAG3C,S,yIC/ItD,sCAmBA,MAAM6C,EAAM,cAKZA,EAAIC,aAAa,SAAS,KAAM,IAAOC,IAC/BA,GACAC,QAAQC,KAAK,kJAMrBJ,EAAIC,aAAa,cAAc,IAAM,QAErCD,EAAIC,aAAa,WAAW,SAA0B,IAAZI,QACT,IAArBA,EAAQC,eACkB,IAA1BD,EAAQC,SAASC,OAE7BP,EAAIC,aAAa,aAAa,IAA2B,oBAAdO,WAA0C,MAAbA,WAC7C,MAAvBA,UAAUC,WAAqB,SAASC,KAAKF,UAAUC,YACvD,aAAaC,KAAKF,UAAUG,UAKhCX,EAAIC,aAAa,QAAQ,KAAM,IAK/BD,EAAIC,aAAa,sCAAsC,IAAMD,EAAIY,QAAQ,WAEzEZ,EAAIC,aAAa,gCAAgC,KAAM,IAEvDD,EAAIC,aAAa,WAAW,KAAM,IAElCD,EAAIC,aAAa,gCAAgC,KAAM,M,oDCxDvD,oEAmBO,MAAMY,EACT,YAAYC,EAASC,GACjBC,KAAKF,QAAUA,EACfE,KAAKD,UAAYA,EACjBC,KAAKC,KAAO,IAAIC,QAChBF,KAAKG,aAAe,EAExB,IAAIC,GAIA,OAHKJ,KAAKC,KAAKI,IAAID,IACfJ,KAAKD,UAAUO,SAASN,KAAKF,QAASM,GAEnCJ,KAAKC,KAAKM,IAAIH,GAEzB,IAAIA,EAAQI,GACRR,KAAKG,eACLH,KAAKC,KAAKQ,IAAIL,EAAQI,GAE1B,IAAIJ,GACA,OAAOJ,KAAKC,KAAKI,IAAID,GAEzB,OAAOA,GAEH,OADAJ,KAAKG,eACEH,KAAKC,KAAKS,OAAON,GAE5B,aACI,OAAOJ,KAAKG,cASb,MAAMQ,EAQT,cAAcP,IAGd,KAAKQ,GACD,OAAOC,EAAkB,QAE7B,KAAKT,GACD,OAAOS,EAAkB,QAE7B,SAAST,GACL,OAAOS,EAAkB,YAE7B,aACI,OAAOA,EAAkB,cAE7B,YAAYT,GACR,OAAOS,EAAkB,eAE7B,MAAMC,EAAQC,EAAOC,GACjB,OAAOH,EAAkB,SAE7B,KAAKT,EAAQU,EAAQC,EAAOC,GACxB,OAAOH,EAAkB,QAE7B,SACI,OAAOA,EAAkB,UAG7B,iBACI,OAAOA,EAAkB,kBAG7B,UACI,OAAiC,KAA1Bb,KAAKiB,iBA9EW,KACA,KA+E3B,YAAYjG,EAAGC,EAAGiG,EAAYC,GAC1B,OAAON,EAAkB,eAE7B,kBAAiB,EAAE7F,EAAC,EAAEC,EAAC,WAAEiG,EAAU,WAAEC,EAAU,KAAEC,EAAI,WAAEC,EAAU,uBAAEC,IAC/D,OAAOT,EAAkB,oBAE7B,MAAMU,EAAGC,EAAOC,GACZ,OAAOZ,EAAkB,SAE7B,aAAaU,EAAGC,EAAOE,EAAKC,GACxB,OAAOd,EAAkB,gBAE7B,QAAQU,EAAGK,GACP,OAAOf,EAAkB,WAE7B,QAAQ7F,EAAG4G,GACP,OAAOf,EAAkB,WAE7B,OAAOgB,EAASD,GACZ,OAAOf,EAAkB,UAE7B,IAAI7F,GACA,OAAO6F,EAAkB,OAE7B,IAAI7F,EAAGC,GACH,OAAO4F,EAAkB,OAE7B,KAAKgB,GACD,OAAOhB,EAAkB,QAE7B,SAAS7F,EAAGC,GACR,OAAO4F,EAAkB,YAE7B,SAAS7F,EAAGC,GACR,OAAO4F,EAAkB,YAE7B,WAAW7F,EAAGC,GACV,OAAO4F,EAAkB,cAE7B,SAAS7F,EAAGC,GACR,OAAO4F,EAAkB,YAE7B,IAAIU,EAAGO,GACH,OAAOjB,EAAkB,OAE7B,KAAKU,EAAGO,GACJ,OAAOjB,EAAkB,QAE7B,mBAAmBU,EAAGQ,EAAYC,GAC9B,OAAOnB,EAAkB,sBAE7B,OAAOU,EAAGK,GACN,OAAOf,EAAkB,UAE7B,OAAOU,EAAGK,GACN,OAAOf,EAAkB,UAE7B,MAAM7F,EAAGC,GACL,OAAO4F,EAAkB,SAE7B,SAAS7F,EAAGC,GACR,OAAO4F,EAAkB,YAE7B,KAAK7F,EAAGC,GACJ,OAAO4F,EAAkB,QAE7B,UAAU7F,EAAGC,GACT,OAAO4F,EAAkB,aAE7B,QAAQ7F,EAAGC,GACP,OAAO4F,EAAkB,WAE7B,aAAa7F,EAAGC,GACZ,OAAO4F,EAAkB,gBAE7B,WAAW7F,GACP,OAAO6F,EAAkB,cAE7B,WAAW7F,EAAGC,GACV,OAAO4F,EAAkB,cAE7B,UAAU7F,EAAGC,GACT,OAAO4F,EAAkB,aAE7B,MAAMoB,GACF,OAAOpB,EAAkB,SAE7B,OAAOoB,EAAWjH,EAAGC,GACjB,OAAO4F,EAAkB,UAE7B,KAAKU,EAAGW,EAAGC,GACP,OAAOtB,EAAkB,QAE7B,IAAIU,EAAGO,GACH,OAAOjB,EAAkB,OAE7B,QAAQ7F,EAAGC,GACP,OAAO4F,EAAkB,WAE7B,IAAI7F,EAAGC,GACH,OAAO4F,EAAkB,OAE7B,IAAIU,EAAGO,GACH,OAAOjB,EAAkB,OAE7B,QAAQ7F,EAAGC,GACP,OAAO4F,EAAkB,WAE7B,IAAIU,EAAGO,GACH,OAAOjB,EAAkB,OAE7B,IAAIU,EAAGO,GACH,OAAOjB,EAAkB,OAE7B,kBAAkB7F,EAAGC,GACjB,OAAO4F,EAAkB,qBAE7B,KAAKU,GACD,OAAOV,EAAkB,QAE7B,MAAMU,GACF,OAAOV,EAAkB,SAE7B,MAAMU,GACF,OAAOV,EAAkB,SAE7B,KAAKU,GACD,OAAOV,EAAkB,QAE7B,MAAMU,GACF,OAAOV,EAAkB,SAE7B,MAAMU,GACF,OAAOV,EAAkB,SAE7B,SAASU,GACL,OAAOV,EAAkB,YAE7B,IAAI7F,EAAGC,GACH,OAAO4F,EAAkB,OAE7B,IAAIU,GACA,OAAOV,EAAkB,OAE7B,MAAMU,GACF,OAAOV,EAAkB,SAE7B,QAAQU,EAAGa,GACP,OAAOvB,EAAkB,WAE7B,IAAIU,GACA,OAAOV,EAAkB,OAE7B,MAAMU,GACF,OAAOV,EAAkB,SAE7B,KAAKU,GACD,OAAOV,EAAkB,QAE7B,MAAMU,GACF,OAAOV,EAAkB,SAE7B,OAAOU,GACH,OAAOV,EAAkB,UAE7B,WAAWU,GACP,OAAOV,EAAkB,cAE7B,KAAKU,GACD,OAAOV,EAAkB,QAE7B,MAAMU,GACF,OAAOV,EAAkB,SAE7B,MAAMU,EAAGvG,GACL,OAAO6F,EAAkB,SAE7B,IAAIU,GACA,OAAOV,EAAkB,OAE7B,OAAOwB,EAAIC,GACP,OAAOzB,EAAkB,UAE7B,KAAKU,GACD,OAAOV,EAAkB,QAE7B,IAAIU,GACA,OAAOV,EAAkB,OAE7B,KAAKU,EAAG3D,EAAKG,GACT,OAAO8C,EAAkB,QAE7B,IAAIU,GACA,OAAOV,EAAkB,OAE7B,WAAWU,GACP,OAAOV,EAAkB,cAE7B,QAAQU,GACJ,OAAOV,EAAkB,WAE7B,SAASU,GACL,OAAOV,EAAkB,YAE7B,IAAIU,GACA,OAAOV,EAAkB,OAE7B,IAAIU,GACA,OAAOV,EAAkB,OAE7B,IAAIU,GACA,OAAOV,EAAkB,OAE7B,KAAKU,GACD,OAAOV,EAAkB,QAE7B,KAAKU,GACD,OAAOV,EAAkB,QAE7B,KAAKU,GACD,OAAOV,EAAkB,QAE7B,MAAM7F,EAAGC,GACL,OAAO4F,EAAkB,SAE7B,KAAKU,GACD,OAAOV,EAAkB,QAE7B,KAAKU,GACD,OAAOV,EAAkB,QAE7B,KAAKU,GACD,OAAOV,EAAkB,QAE7B,MAAMU,GACF,OAAOV,EAAkB,SAE7B,MAAMU,GACF,OAAOV,EAAkB,SAE7B,MAAMU,GACF,OAAOV,EAAkB,SAE7B,IAAIU,GACA,OAAOV,EAAkB,OAE7B,KAAKU,EAAGgB,GACJ,OAAO1B,EAAkB,QAE7B,aAAY,MAAE2B,EAAK,OAAEC,EAAM,SAAEC,EAAQ,KAAEtB,EAAI,WAAEC,EAAU,uBAAEC,IACrD,OAAOT,EAAkB,eAE7B,OAAOU,EAAGkB,EAAQC,GACd,OAAO7B,EAAkB,UAE7B,eAAewB,EAAII,EAAQC,GACvB,OAAO7B,EAAkB,kBAE7B,gBAAgBU,EAAGoB,EAAID,GACnB,OAAO7B,EAAkB,mBAE7B,sBAAqB,MAAE2B,EAAK,OAAEC,EAAM,SAAEC,EAAQ,KAAEtB,EAAI,WAAEC,EAAU,uBAAEC,IAC9D,OAAOT,EAAkB,wBAE7B,gBAAgB2B,EAAOC,EAAQC,GAC3B,OAAO7B,EAAkB,mBAE7B,wBAAwBwB,EAAII,EAAQC,GAChC,OAAO7B,EAAkB,2BAE7B,yBAAyBU,EAAGoB,EAAID,GAC5B,OAAO7B,EAAkB,4BAE7B,OAAOU,EAAGkB,EAAQC,GACd,OAAO7B,EAAkB,UAE7B,eAAewB,EAAII,EAAQC,GACvB,OAAO7B,EAAkB,kBAE7B,gBAAgBU,EAAGoB,EAAID,GACnB,OAAO7B,EAAkB,mBAE7B,QAAQU,EAAGmB,GACP,OAAO7B,EAAkB,WAE7B,gBAAgBwB,EAAId,EAAGe,EAAGI,GACtB,OAAO7B,EAAkB,mBAE7B,QAAQU,EAAGmB,GACP,OAAO7B,EAAkB,WAE7B,gBAAgBwB,EAAId,EAAGmB,GACnB,OAAO7B,EAAkB,mBAE7B,UAAUU,EAAGmB,GACT,OAAO7B,EAAkB,aAE7B,kBAAkBwB,EAAId,EAAGmB,GACrB,OAAO7B,EAAkB,qBAE7B,UAAUU,EAAGmB,GACT,OAAO7B,EAAkB,aAE7B,kBAAkBwB,EAAId,EAAGe,EAAGI,GACxB,OAAO7B,EAAkB,qBAE7B,QAAQU,EAAGR,GACP,OAAOF,EAAkB,WAE7B,KAAKU,EAAGP,GACJ,OAAOH,EAAkB,QAE7B,KAAKU,EAAGqB,GACJ,OAAO/B,EAAkB,QAE7B,IAAIU,EAAGsB,EAAUC,GACb,OAAOjC,EAAkB,OAE7B,UAAUU,EAAGwB,GACT,OAAOlC,EAAkB,aAE7B,OAAOU,EAAGyB,EAASpB,EAAMqB,EAAY,GACjC,OAAOpC,EAAkB,UAE7B,SAASU,EAAGyB,GACR,OAAOnC,EAAkB,YAE7B,UAAUmC,EAASE,EAASnC,GACxB,OAAOF,EAAkB,aAE7B,eAAeU,EAAG4B,EAAYC,GAC1B,OAAOvC,EAAkB,kBAE7B,eAAeU,EAAG4B,EAAYN,GAC1B,OAAOhC,EAAkB,kBAE7B,eAAeU,EAAG8B,EAAWC,EAAUC,EAAcC,GACjD,OAAO3C,EAAkB,kBAE7B,uBAAuBwB,EAAId,EAAGgC,GAC1B,OAAO1C,EAAkB,0BAE7B,sBAAsBU,EAAGkC,EAAWH,EAAUC,EAAcC,GACxD,OAAO3C,EAAkB,yBAE7B,8BAA8BwB,EAAId,EAAGgC,GACjC,OAAO1C,EAAkB,iCAE7B,UAAUU,EAAGmC,EAAMC,EAAUC,EAAQrH,EAAOsH,GACxC,OAAOhD,EAAkB,aAE7B,6BAA6BU,EAAGuC,EAAQ1C,EAAMmB,EAAOwB,GACjD,OAAOlD,EAAkB,gCAE7B,QAAQwB,EAAI2B,EAAYC,EAAaH,EAAQ1C,EAAMmB,EAAOwB,GACtD,OAAOlD,EAAkB,WAE7B,YAAYqD,EAAQC,EAAYC,EAAYC,GACxC,OAAOxD,EAAkB,eAE7B,OAAOmC,EAASsB,EAAOC,EAASC,GAC5B,OAAO3D,EAAkB,UAE7B,OAAOU,EAAGK,EAAM6C,EAAWC,GACvB,OAAO7D,EAAkB,UAE7B,kBAAkB1F,EAAOC,EAAQC,EAAeC,EAAcC,GAC1D,OAAOsF,EAAkB,qBAE7B,IAAIU,GACA,OAAOV,EAAkB,OAE7B,KAAKU,GACD,OAAOV,EAAkB,QAE7B,QAAQ8D,EAAMC,GACV,OAAO/D,EAAkB,WAE7B,KAAK2B,GACD,OAAO3B,EAAkB,QAE7B,KAAK2B,GACD,OAAO3B,EAAkB,QAE7B,cAAcgE,EAAO1J,EAAOgB,EAAU2I,EAAUC,EAAQC,GACpD,OAAOnE,EAAkB,iBAE7B,aAAaU,EAAG0D,EAAWC,GACvB,OAAOrE,EAAkB,gBAG7B,MAAML,EAAO2E,EAAYvD,GACrB,OAAOf,EAAkB,SAE7B,cAAcuE,EAAeC,EAAcC,EAAaC,GACpD,OAAO1E,EAAkB,iBAE7B,KAAKU,GACD,OAAOV,EAAkB,QAE7B,KAAKE,EAAOP,EAAOQ,GACf,OAAOH,EAAkB,QAE7B,SAASU,GACL,OAAOV,EAAkB,YAE7B,UAAUU,GACN,OAAOV,EAAkB,aAE7B,SAAS2E,EAAOC,EAAMC,GAClB,OAAO7E,EAAkB,YAE7B,UACI,OAAOA,EAAkB,YAGjC,SAASA,EAAkB8E,GACvB,MAAM,IAAIC,MAAM,IAAID,+H,iCChejB,SAASE,IACZ,MAA0B,oBAAXC,QAA6C,MAAnBA,OAAOC,UAEd,oBAAtBC,kBApChB,mC,gCCAA,iHAkBA,MAAMC,EAA4B,YAQ3B,MAAMC,EAET,YAAYC,GACRnG,KAAKmG,OAASA,EACdnG,KAAKoG,MAAQ,GACbpG,KAAKqG,aAAe,GACpBrG,KAAKsG,SAAW,GAChBtG,KAAKuG,mBAET,YAAYC,EAAcC,GACD,MAAjBzG,KAAKyG,UACLtH,QAAQC,KAAK,YAAYY,KAAKwG,oEACOC,MAEzCzG,KAAKwG,aAAeA,EACpBxG,KAAKyG,SAAWA,EAEpB,aAAaC,EAAUC,EAAcC,GAIjC,GAHA5G,KAAKqG,aAAaK,GAAY,CAAEC,eAAcC,WAGf,MAA3B5G,KAAKsG,SAASI,GAAmB,CACjC,MAAMG,EAAY7G,KAAKsG,SAASI,GAChCvH,QAAQC,KAAK,qCAAqCsH,MAAaG,MAC/D7G,KAAKS,IAAIiG,EAAUG,IAG3B,eAAeH,GACX,OAAIA,KAAY1G,KAAKoG,QAGrBpG,KAAKoG,MAAMM,SAAkB1G,KAAK8G,aAAaJ,IAFpC1G,KAAKoG,MAAMM,GAK1B,IAAIA,GACA,GAAIA,KAAY1G,KAAKoG,MACjB,OAAOpG,KAAKoG,MAAMM,GAEtB,MAAMG,EAAY7G,KAAK8G,aAAaJ,GACpC,GAAI,YAAUG,GACV,MAAM,IAAIjB,MAAM,QAAQc,uEAI5B,OADA1G,KAAKoG,MAAMM,GAAYG,EAChB7G,KAAKoG,MAAMM,GAEtB,UAAUA,GACN,OAAO1G,KAAKO,IAAImG,GAEpB,QAAQA,GACJ,OAAO1G,KAAKO,IAAImG,GAEpB,WACI,OAAO1G,KAAKoG,MAGhB,eACI,OAAOpG,KAAKoG,MAEhB,IAAIM,EAAUlG,GACV,GAAmC,MAA/BR,KAAKqG,aAAaK,GAClB,MAAM,IAAId,MAAM,mBAAmBc,oCAEvC1G,KAAKoG,MAAMM,GAAYlG,EACoB,MAAvCR,KAAKqG,aAAaK,GAAUE,SAC5B5G,KAAKqG,aAAaK,GAAUE,QAAQpG,GAG5C,aAAakG,GACT,GAAmC,MAA/B1G,KAAKqG,aAAaK,GAClB,MAAM,IAAId,MAAM,yBAAyBc,qCAE7C,OAAO1G,KAAKqG,aAAaK,GAAUC,eAEvC,SAASP,GACLpG,KAAKoG,MAAQW,OAAOC,OAAO,GAAIZ,GAEnC,QACIpG,KAAKoG,MAAQ,GACbpG,KAAKsG,SAAW,GAChBtG,KAAKuG,mBAET,mBACI,QAA2B,IAAhBvG,KAAKmG,aACoB,IAAzBnG,KAAKmG,OAAOc,eACoB,IAAhCjH,KAAKmG,OAAOc,SAASC,OAC5B,OAEJ,MAAMC,EAUP,SAAwBC,GAC3B,MAAMC,EAAS,GAKf,OAJAD,EAAYE,QAAQ,+BAA+B,CAACC,KAAMC,KAM9D,SAAqBH,EAAQI,EAAMjH,GAC/B6G,EAAOK,mBAAmBD,IAASC,mBAAmBlH,GAAS,IAN3DmH,CAAYN,EAAQG,EAAE,GAAIA,EAAE,IACrBA,EAAEI,KAAK,QAEXP,EAhBeQ,CAAe7H,KAAKmG,OAAOc,SAASC,QACtD,GAAIjB,KAA6BkB,EAAW,CACtBA,EAAmC,UAAEW,MAAM,KACnDC,SAAQC,IACd,MAAOC,EAAKzH,GAASwH,EAASF,MAAM,KACpC9H,KAAKsG,SAAS2B,GAgB9B,SAAoBvB,EAAUlG,GAE1B,GAAc,UADdA,EAAQA,EAAM0H,gBACoB,UAAV1H,EACpB,MAAiB,SAAVA,EAEN,GAAI,KAAIA,IAAYA,EACrB,OAAQA,EAEZ,MAAM,IAAIoF,MAAM,oCAAoCpF,cAAkBkG,MAxBrCyB,CAAWF,EAAKzH,QAkC9C,SAAS4H,IACZ,OAAOpJ,EAEJ,IAAIA,EAAM,KACV,SAASqJ,EAAqBC,GACjCtJ,EAAMsJ,I,4iQChIH,SAASC,EAAuB5D,EAAMC,GACzC,GAAID,EAAKpK,SAAWqK,EAAKrK,OACrB,MAAM,IAAIqL,MACN,gEAAGjB,EAAKpK,iBAAiBqK,EAAKrK,WAEtC,MAAM+C,EAAS,IAAIkL,aAA2B,EAAd7D,EAAKpK,QACrC,IAAK,IAAIyB,EAAI,EAAGA,EAAIsB,EAAO/C,OAAQyB,GAAK,EACpCsB,EAAOtB,GAAK2I,EAAK3I,EAAI,GACrBsB,EAAOtB,EAAI,GAAK4I,EAAK5I,EAAI,GAE7B,OAAOsB,EAgBJ,SAASmL,EAAuBC,GACnC,MAAM/D,EAAO,IAAI6D,aAAaE,EAAQnO,OAAS,GACzCqK,EAAO,IAAI4D,aAAaE,EAAQnO,OAAS,GAC/C,IAAK,IAAIyB,EAAI,EAAGA,EAAI0M,EAAQnO,OAAQyB,GAAK,EACrC2I,EAAK3I,EAAI,GAAK0M,EAAQ1M,GACtB4I,EAAK5I,EAAI,GAAK0M,EAAQ1M,EAAI,GAE9B,MAAO,CAAE2I,OAAMC,QAMZ,SAAS+D,EAAqBD,GACjC,MAAME,EAAMjL,KAAKkL,KAAKH,EAAQnO,OAAS,GACjCoK,EAAO,IAAI6D,aAAaI,GACxBhE,EAAO,IAAI4D,aAAaI,GAC9B,IAAK,IAAI5M,EAAI,EAAGA,EAAI0M,EAAQnO,OAAQyB,GAAK,EACrC2I,EAAKhH,KAAKmL,MAAM9M,EAAI,IAAM0M,EAAQ1M,GAClC4I,EAAKjH,KAAKmL,MAAM9M,EAAI,IAAM0M,EAAQ1M,EAAI,GAE1C,MAAO,CAAE2I,OAAMC,QAMZ,SAASmE,EAAoBL,GAChC,MAAME,EAAMjL,KAAKmL,MAAMJ,EAAQnO,OAAS,GAClCoK,EAAO,IAAI6D,aAAaI,GACxBhE,EAAO,IAAI4D,aAAaI,GAC9B,IAAK,IAAI5M,EAAI,EAAGA,EAAI0M,EAAQnO,OAAQyB,GAAK,EACrC2I,EAAKhH,KAAKmL,MAAM9M,EAAI,IAAM0M,EAAQ1M,GAClC4I,EAAKjH,KAAKmL,MAAM9M,EAAI,IAAM0M,EAAQ1M,EAAI,GAE1C,MAAO,CAAE2I,OAAMC,QAOZ,SAASoE,EAAoBN,EAASvO,GAGzC,MAAO,CAAEwK,KAFI+D,EAAgB,EAARvO,GAENyK,KADF8D,EAAgB,EAARvO,EAAY,IAS9B,SAAS8O,EAAmBhJ,EAAM0E,EAAMC,EAAMzK,GACjD8F,EAAa,EAAR9F,GAAawK,EAClB1E,EAAa,EAAR9F,EAAY,GAAKyK,EAKnB,SAASsE,EAAUC,EAAGC,GACzB,MAAMzE,EAAO,IAAI6D,aAAaW,EAAI,GAC5BvE,EAAO,IAAI4D,aAAaW,EAAI,GAClC,IAAK,IAAInN,EAAI,EAAGA,EAAI2B,KAAKkL,KAAKM,EAAI,GAAInN,IAAK,CACvC,MAAMuF,GAAK6H,EAAU,GAAK,GAAKzL,KAAK0L,IAAMrN,EAAImN,GAC9CxE,EAAK3I,GAAK2B,KAAK2L,IAAI/H,GACnBqD,EAAK5I,GAAK2B,KAAK4L,IAAIhI,GAEvB,MAAO,CAAEoD,OAAMC,QAKZ,SAAS4E,EAAStH,EAAGiH,EAAGC,GAC3B,MAAM7H,GAAK6H,EAAU,GAAK,GAAKzL,KAAK0L,IAAMnH,EAAIiH,GAG9C,MAAO,CAAExE,KAFIhH,KAAK2L,IAAI/H,GAEPqD,KADFjH,KAAK4L,IAAIhI,I,sBCzFnB,SAASkI,EAAWlI,EAAGP,EAAOlB,GACjC,GAAc,cAAVkB,EAAuB,CACvB,GAAgB,cAAZO,EAAEP,MACF,OAAOO,EAAEmI,QAEb,MAAMC,EAAc,OAAAC,EAAA,GAAMrI,EAAER,OACtB8I,EAAS,OAAAC,EAAA,GAAKvI,EAAG,WACjBjE,EAASwC,EAAQ4I,QAAQmB,EAAQF,GAGvC,OAFAA,EAAYI,UACZF,EAAOE,UACAzM,EAEX,IAAK,YAAgBiE,EAAEP,MAAOA,GAG1B,OAAO,IAAOgJ,qBAAqBzI,EAAEnB,OAAQmB,EAAER,MAAOC,GAE1D,GAAgB,cAAZO,EAAEP,MAAuB,CACzB,MAAM2D,EAAO7E,EAAQ6E,KAAKpD,GACpBjE,EAAS,OAAAwM,EAAA,GAAKnF,EAAM3D,GAE1B,OADA2D,EAAKoF,UACEzM,EAEX,GAAc,UAAV0D,EACA,OAAOlB,EAAQmK,IAAI1I,GAElB,GAAc,SAAVP,EAAkB,CACvB,MAAMkJ,EAAO,OAAAC,EAAA,GAAO,EAAG5I,EAAEP,OACnB1D,EAASwC,EAAQsK,SAAS7I,EAAG2I,GAEnC,OADAA,EAAKH,UACEzM,EAGP,MAAM,IAAIsI,MAAM,iCAAiCrE,EAAEP,YAAYA,KAGhE,SAASqJ,EAAc9I,EAAGR,GAC7B,OAAO,IAAOiJ,qBAAqBzI,EAAEnB,OAAQW,EAAOQ,EAAEP,OAEnD,SAASsJ,EAAuBC,GACnC,IAEI,OAAOA,EAAKC,KAAIC,GAAO,uBAAaA,KAExC,MAAOC,GACH,MAAM,IAAI9E,MAAM,4DAA4D8E,MAG7E,SAASC,EAAuBC,GACnC,OAAOA,EAAQJ,KAAIjD,GAAK,uBAAaA,K,oDC5FzC,iKA2BA,MAAMsD,EACF,cAEI7K,KAAK8K,oBAAsB,GAC3B9K,KAAK+K,eAAiB,EACtB/K,KAAKgL,SAAW,EAChBhL,KAAKiL,WAAa,EAClBjL,KAAKkL,iBAAmB,EACxBlL,KAAKmL,eAAiB,EAItBnL,KAAKoL,cAAgB,EAGrBpL,KAAKqL,YAAc,EACnBrL,KAAKsL,WAAa,GAKlBtL,KAAKuL,kBAAoB,GACzBvL,KAAKwL,YAAc,EACnBxL,KAAKyL,WAAa,IAAIvL,QACtBF,KAAK0L,WAAY,EACjB1L,KAAK2L,cAAgB,CACjBC,SAAU,EACVC,WAAY,EACZC,UAAW,EACXC,QAAS,GACTzO,OAAQ,KACR,kBACI,OAAOF,MAAM4O,KAAK,IAAIC,IAAIjM,KAAK+L,QAAQvB,KAAItI,GAAKA,EAAEuF,WAI9D,UACI,IAAK,MAAMyE,KAAgBlM,KAAK8K,oBAC5B9K,KAAK8K,oBAAoBoB,GAAcnC,WAI5C,MAAMoC,EACT,YAAYnN,GACRgB,KAAKhB,IAAMA,EACXgB,KAAKoM,SAAW,GAChBpM,KAAKqM,gBAAkB,GACvBrM,KAAKsM,qBAAuB,EAC5BtM,KAAKuM,MAAQ,IAAI1B,EAErB,cACI,GAA+B,MAA3B7K,KAAKwM,mBACL,OAAOxM,KAAKwM,mBAAmBC,MAAK,SAExC,GAA4B,MAAxBzM,KAAK0M,gBACL,OAEJ,MAAMC,EAAiB3M,KAAK4M,oBAC5B,IAAK,IAAI5Q,EAAI,EAAGA,EAAI2Q,EAAepS,OAAQyB,IAAK,CAC5C,MAAM6Q,EAAcF,EAAe3Q,GAEnC,SADsBgE,KAAK8M,kBAAkBD,GAAaE,QAGtD,kBADM/M,KAAKgN,WAAWH,GAI9B,MAAM,IAAIjH,MAAM,0EAGpB,cACI,GAA+B,MAA3B5F,KAAKwM,mBACL,MAAM,IAAI5G,MAAM,YAAY5F,KAAK6M,kIAIrC,GAA4B,MAAxB7M,KAAK0M,gBAAyB,CAC9B,MAAM,KAAEjF,EAAI,UAAEwF,GAAcjN,KAAKkN,kCACjC,GAAID,EACA,MAAM,IAAIrH,MAAM,iCAAiC6B,wHAIrDzH,KAAKgN,WAAWvF,GAEpB,OAAOzH,KAAK0M,gBAEhB,eACI,OAAO3F,OAAOoG,KAAKnN,KAAKqM,iBAE5B,YAAYQ,GACR,KAAMA,KAAe7M,KAAKoM,UAAW,CAGjC,KAAIS,KAAe7M,KAAKqM,iBAQpB,OAAO,KAR8B,CACrC,MAAM,UAAEY,GAAcjN,KAAK8M,kBAAkBD,GAC7C,GAAII,EAEA,OAAO,MAOnB,OAAOjN,KAAKoM,SAASS,GAEzB,mBAAmBA,GACf,OAAMA,KAAe7M,KAAKqM,gBAGnBrM,KAAKqM,gBAAgBQ,GAAaO,QAF9B,KAIf,gBAAgBP,EAAaO,EAASC,EAAW,GAC7C,OAAIR,KAAe7M,KAAKqM,iBACpBlN,QAAQC,KAAK,GAAGyN,wEAET,IAEX7M,KAAKqM,gBAAgBQ,GAAe,CAAEO,UAASC,aACxC,GAEX,iBAAiBR,GACb,GAAyC,MAArC7M,KAAKqM,gBAAgBQ,GACrB,MAAM,IAAIjH,MAAM,iBAAiBiH,4BAGrC,GADA7M,KAAK6M,YAAcA,EACe,MAA9B7M,KAAKoM,SAASS,GAAsB,CACpC7M,KAAK0M,gBAAkB,KACvB,MAAM,QAAEK,EAAO,UAAEE,GAAcjN,KAAK8M,kBAAkBD,GAEtD,KADeI,QAAkBF,EAAUA,GAEvC,OAAO,EAOf,OAJA/M,KAAK0M,gBAAkB1M,KAAKoM,SAASS,GACrC7M,KAAKsN,yBAELtN,KAAKuN,SAAW,IAAI,IAASvN,KAAK0M,kBAC3B,EAEX,yBACoB,YAAqB1M,KAAK6M,aAClC9E,SAAQyF,IACY,MAApBA,EAAOC,WACPD,EAAOC,UAAUzN,KAAK0M,oBAIlC,yBAAyBG,GACL,YAAqBA,GAC7B9E,SAAQyF,IACc,MAAtBA,EAAOE,aACPF,EAAOE,YAAY1N,KAAKoM,SAASS,OAU7C,kBAAkBA,GACd,MAAMc,EAAuB3N,KAAKqM,gBAAgBQ,GAClD,GAA4B,MAAxBc,EACA,MAAM,IAAI/H,MAAM,6BAA6BiH,6BAEjD,IACI,MAAM/M,EAAU6N,EAAqBP,UAMrC,IAAItN,GAAaA,aAAmB,KACR,mBAAjBA,EAAQ2M,KA2Bf,OADAzM,KAAKoM,SAASS,GAAe/M,EACtB,CAAEiN,SAAS,EAAME,WAAW,GA3BC,CACpC,MAAMW,IAAc5N,KAAKsM,qBACnBS,EAAUjN,EACX2M,MAAKC,KAEFkB,EAAY5N,KAAKsM,wBAGrBtM,KAAKoM,SAASS,GAAeH,EAC7B1M,KAAKwM,mBAAqB,MACnB,KAENqB,OAAMnD,IAEHkD,EAAY5N,KAAKsM,uBAGrBtM,KAAKwM,mBAAqB,KAC1BrN,QAAQC,KAAK,6BAA6ByN,YAC1C1N,QAAQC,KAAKsL,EAAIoD,OAASpD,EAAIqD,WAJnB,KAQf,OADA/N,KAAKwM,mBAAqBO,EACnB,CAAEA,UAASE,WAAW,IAOrC,MAAOvC,GAGH,OAFAvL,QAAQC,KAAK,6BAA6ByN,YAC1C1N,QAAQC,KAAKsL,EAAIoD,OAASpD,EAAIqD,SACvB,CAAEhB,SAAS,EAAOE,WAAW,IAG5C,cAAcJ,GACV,KAAMA,KAAe7M,KAAKqM,iBACtB,MAAM,IAAIzG,MAAM,GAAGiH,mCAEnB7M,KAAK6M,cAAgBA,GAA0C,MAA3B7M,KAAKwM,oBAGzCxM,KAAKsM,uBAELO,KAAe7M,KAAKoM,WACpBpM,KAAKgO,yBAAyBnB,GAC9B7M,KAAKoM,SAASS,GAAa9C,iBACpB/J,KAAKoM,SAASS,WAElB7M,KAAKqM,gBAAgBQ,GAExB7M,KAAK6M,cAAgBA,IACrB7M,KAAKwM,mBAAqB,KAC1BxM,KAAK6M,YAAc,KACnB7M,KAAK0M,gBAAkB,MAG/B,oBACI,GAAiD,IAA7C3F,OAAOoG,KAAKnN,KAAKqM,iBAAiB9R,OAClC,MAAM,IAAIqL,MAAM,iCAEpB,OAAOmB,OAAOoG,KAAKnN,KAAKqM,iBAAiBhQ,MAAK,CAACrB,EAAGC,IAEvC+E,KAAKqM,gBAAgBpR,GAAGoS,SAC3BrN,KAAKqM,gBAAgBrR,GAAGqS,WAGpC,kCACI,MAAMV,EAAiB3M,KAAK4M,oBAC5B,IAAK,IAAI5Q,EAAI,EAAGA,EAAI2Q,EAAepS,OAAQyB,IAAK,CAC5C,MAAM6Q,EAAcF,EAAe3Q,IAC7B,QAAE+Q,EAAO,UAAEE,GAAcjN,KAAK8M,kBAAkBD,GACtD,GAAII,GAAaF,EACb,MAAO,CAAEtF,KAAMoF,EAAaI,aAGpC,MAAM,IAAIrH,MAAM,0EAGpB,SAAS9F,EAASM,GACd,MAAM6N,EAAOjO,KAAKuM,MAAMd,WAAWlL,IAAIH,GACjC8N,EAAaD,EAAKnO,QAClBgB,EAASd,KAAKmO,SAAS/N,GAG7B8N,EAAWE,YAAYhO,GACvB6N,EAAKnO,QAAUA,EACfA,EAAQuO,KAAKjO,EAAQU,EAAQmN,EAAKlN,MAAOkN,EAAKjN,OAC1ChB,KAAKsO,0BAGLtO,KAAKuM,MAAMhB,kBAAkBvL,KAAKuM,MAAMhB,kBAAkBhR,OAAS,KAG3E,KAAKgU,EAAUC,GACX,IAsBIlR,EAtBAmK,EAAO,KACX,GAAU,MAAN+G,EAAY,CAEZ,GAAwB,mBAAbD,EACP,MAAM,IAAI3I,MAAM,uCAEpB4I,EAAKD,MAEJ,CAED,GAAwB,iBAAbA,KAA2BA,aAAoBE,QACtD,MAAM,IAAI7I,MAAM,kFAGpB,GAAkB,mBAAP4I,EACP,MAAM,IAAI5I,MAAM,kFAGpB6B,EAAO8G,EAKX,OAAOvO,KAAK0O,WAAU,IAAM1O,KAAK2O,WAAWlH,KAAO,IAAMzH,KAAK4O,SAAStR,KAAS,KAC5EA,EAASkR,IACLlR,aAAkBuR,SAClB1P,QAAQ2P,MAAM,2CAEXxR,KAGf,UAAUkI,EAAO9D,EAAKd,GAClB4E,IACA,IACI,MAAMuJ,EAAMnO,IAEZ,OADAc,IACOqN,EAEX,MAAOC,GAEH,MADAtN,IACMsN,GAGd,eACI,OAAO7C,EAAO8C,eAElB,iBACI,OAAO9C,EAAO+C,iBAWlB,MAAM3N,GACF,MAAMe,EAAItC,KAAKgK,qBAAqBzI,EAAEnB,OAAQmB,EAAER,MAAOQ,EAAEP,OACnDmO,EAAS,CAAE5N,KAWjB,OADAvB,KAAKoP,YAAYpP,KAAKuM,MAAM8C,YAAY5H,KAAM0H,EAAQ,CAAC7M,IATzCD,IAAO,CACjBd,EAAG,KACC,MAAMP,EAAQ,UACRsO,EAAa,CAAE/N,EAAGc,GAClBkN,EAAQ,CAAEvO,SAChB,OAAOwO,EAAOC,eAAc3P,GAAWA,EAAQgK,KAAKzH,EAAIrB,IAAQsO,EAAY,KAAiB,IAAMC,OAG7F,GAC0D,IACjEjN,EAeX,UAAUqD,EAAYwJ,EAAQI,EAAOG,EAAcC,GAM/C,OAAO3P,KAAKyP,cALQ,KAKmBN,EAJjB,KAIwCxJ,EAAY4J,EAAOG,EAAcC,GAEnG,yBACI,OAAO3P,KAAKhB,IAAIY,QAAQ,WAE5B,sBAAsB+F,EAAYiK,EAAkBC,GAChD,MAAMC,EAAkB9P,KAAKF,QAAQiQ,aAErC,IAAIC,EAAmB,EACvBH,EAAS9H,SAAQkG,IAGb+B,GAAoC,cAAf/B,EAAKjN,MAAwB,EAAI,KAO1D,MAAMiP,EAAWjQ,KAAKuM,MAAMhB,kBAAkBvL,KAAKuM,MAAMhB,kBAAkBhR,OAAS,GAC9E2V,EAAgBJ,EAAkBF,EAAmBI,EAAmBC,EAC9E,GAAIC,EAAgB,EAChB,MAAM,IAAItK,MAAM,YAAY5F,KAAK6M,6CACzBqD,8BAA0CvK,MAO1D,cAAcwK,EAAahB,EAAQiB,EAAezK,EAAY4J,EAAOG,EAAcC,GAC/E,IAAIU,EACAC,EAAQ,GACZ,MAAMC,EAAWvQ,KAAKuQ,WACJ,MAAd5K,IACAA,EAC8B,MAA1B3F,KAAKuM,MAAM8C,YAAsBrP,KAAKuM,MAAM8C,YAAY5H,KAAO,IAEvE,MAAM+I,EAAoBxQ,KAAKuM,MAAMvB,SAC/ByF,EAAqBzQ,KAAKuM,MAAMtB,WAItC,IAAIyF,EAHA1Q,KAAKsO,0BACLtO,KAAKuM,MAAMhB,kBAAkBtP,KAAK,GAGd,MAApB+D,KAAK6M,aAML7M,KAAKF,QAET,MAAM0N,EAAS,YAAU7H,EAAY3F,KAAK6M,aAC1C,IAAI8D,EAiEAC,EAhEJ,GAAc,MAAVpD,EACAkD,EAAa,KACT,MAAMd,EAAmB5P,KAAKF,QAAQiQ,aACtCY,EAAMnD,EAAOkD,WAAW,CAAEvB,SAAQI,QAAOzP,QAASE,KAAKF,UACvD,MAAM+P,EAAWzS,MAAMyT,QAAQF,GAAOA,EAAM,CAACA,GACzC3Q,KAAKsO,0BACLtO,KAAK8Q,sBAAsBnL,EAAYiK,EAAkBC,GAE7D,MAAMkB,EAAalB,EAASrF,KAAKwG,IAI7B,GAAoB,MAAhBA,EAAQC,KACR,OAAOD,EAEX,MAAM,OAAE5Q,EAAM,MAAEW,EAAK,MAAEC,GAAUgQ,EACjC,OAAOhR,KAAKgK,qBAAqB5J,EAAQW,EAAOC,MAMpD,GAAIuP,EAAU,CACV,IAAIW,EAAgBlR,KAAKmR,sBAAsBxL,EAAYwJ,EAAQ4B,GACnE,GAAqB,MAAjBG,EAAuB,CAKF,MAAjBvB,IACAA,EAAgB,IAEpB,MAAMyB,EAAaL,EAAWtO,QAAO,CAAC4O,EAAGrV,IAAM2T,EAAc3T,KAC7DkV,GAAiBxB,GAAgB,IAAI4B,QAAQC,OAAOH,GAExDd,EAAQtQ,KAAKwR,2BAA2BN,GAE5C,OAAOH,OAGV,CACD,GAAmB,MAAfZ,EACA,MAAM,IAAIvK,MAAM,iBAAiBD,qDAErC,MAAM8L,EAAY5P,IAIT0O,IAGLD,EAAQzO,EAAQ2I,KAAIkH,GAAU1R,KAAK2R,KAAK3R,KAAK0J,MAAMgI,QAEvDhB,EAAa,KACT,MAAMd,EAAmB5P,KAAKF,QAAQiQ,aACtCY,EAAM3Q,KAAK4R,MAAK,IAAMzB,EAAYnQ,KAAKF,QAAS2R,KAChD,MAAMI,EAAQzU,MAAMyT,QAAQF,GAAOA,EAAM,CAACA,GAI1C,OAHI3Q,KAAKsO,0BACLtO,KAAK8Q,sBAAsBnL,EAAYiK,EAAkBiC,GAEtDA,GAiCf,OA5BA7R,KAAK0O,WAAU,IAAM1O,KAAKuM,MAAMlB,gBAAe,IAAMrL,KAAKuM,MAAMlB,gBAAe,KACtErL,KAAKhB,IAAIY,QAAQ,UAAaI,KAAKuM,MAAMb,WAI1CkF,EAAgB5Q,KAAKuN,SAASuE,cAAcnM,EAAYwJ,GAAQ,IAAMuB,MAClE1Q,KAAKhB,IAAIY,QAAQ,UACjBI,KAAKuN,SAASwE,iBAAiBnB,GAEnCP,EAAUO,EAAcP,SAPxBA,EAAUK,OAUdH,GACAvQ,KAAKoP,YAAYzJ,EAAYwJ,EAAQkB,EAASD,EAAeE,EAAOf,GAEpEvP,KAAKuM,MAAMb,WACX1L,KAAKuM,MAAMZ,cAAcI,QAAQ9P,KAAK,CAClCwL,KAAM9B,EACNqM,WAAYhS,KAAKuM,MAAMvB,SAAWwF,EAClCyB,mBAAoBjS,KAAKuM,MAAMvB,SAC/BkH,aAAclS,KAAKuM,MAAMtB,WAAawF,EACtC0B,qBAAsBnS,KAAKuM,MAAMtB,WACjCmH,YAAarL,OAAOoG,KAAKgC,GAAQ3E,KAAIvC,GAAsB,MAAfkH,EAAOlH,GAAekH,EAAOlH,GAAKlH,MAAQ,OACtFsR,aAAchC,EAAQ7F,KAAI8H,GAAQA,EAAKvR,QACvCwR,aAAc3B,EAAc4B,OAC5BC,UAAW7B,EAAc6B,YAGzBrV,MAAMyT,QAAQF,GAAON,EAAUA,EAAQ,GAOnD,2BAA2BxO,GAEvB,OADcA,EAAQ2I,KAAIkH,GAAU1R,KAAK2R,KAAK3R,KAAK0J,MAAMgI,MAa7D,sBAAsB/L,EAAYwJ,EAAQkB,GACtC,MAAMqC,EAAa,YAAY/M,GAC/B,GAAkB,MAAd+M,EAAoB,CACpB,MAAMhD,EAAegD,EAAWhD,cAAgB,GAC1CC,EAAgB+C,EAAW/C,eAAiB,GAGlD,IAAIgD,EACAD,EAAWE,eACX,IAAYxV,MAAMyT,QAAQ1B,IAAS,IAAM,2DACzCwD,EAAqB5L,OAAOoG,KAAKgC,GAAQ3E,KAAKvC,GAAQkH,EAAOlH,MAG7D0K,EAAqBjD,EAAalF,KAAKqI,GAAc1D,EAAO0D,KAEhE,MAAMC,EAAsBzC,EAAQ5N,QAAO,CAAC4O,EAAGrV,IAAM2T,EAAc3T,KACnE,OAAO2W,EAAmBpB,OAAOuB,GAIrC,OAAO,KAOX,WAAWhS,EAAQC,EAAOC,EAAOlB,GAC7B,GAAc,MAAVgB,EACA,MAAM,IAAI8E,MAAM,iDAEpB5E,EAAQA,GAAS,UACjBlB,EAAUA,GAAWE,KAAKF,QAC1B,IAAIiT,EAAcjS,EACJ,WAAVE,GAAsB,IAAcF,EAAO,MAC3CiS,EAAcjS,EAAO0J,KAAIwI,GAAK,eAAkBA,MAEpD,MAAM5S,EAASN,EAAQmT,MAAMF,EAAahS,EAAOC,GAC3CwG,EAAI,IAAI,IAAOzG,EAAOC,EAAOZ,EAAQJ,KAAKiP,gBAGhD,GAFAjP,KAAKkT,OAAO1L,EAAG1H,GAED,WAAVkB,EAAoB,CACpB,MAAMiN,EAAOjO,KAAKuM,MAAMd,WAAWlL,IAAIH,GACjCwL,EAAW,YAAqBmH,GACtC/S,KAAKuM,MAAMvB,UAAYY,EAAWqC,EAAKkF,MACvClF,EAAKkF,MAAQvH,EAEjB,OAAOpE,EAOX,qBAAqBpH,EAAQW,EAAOC,EAAOlB,GACvCkB,EAAQA,GAAS,UACjB,MAAMwG,EAAI,IAAI,IAAOzG,EAAOC,EAAOZ,EAAQJ,KAAKiP,gBAEhD,OADAjP,KAAKkT,OAAO1L,EAAG1H,GACR0H,EAEX,aAAa4L,EAAcC,GAAY,EAAM5L,EAAMzG,GAC/CyG,EAAOA,GAAQzH,KAAKkP,iBAAiBoE,WACxB,MAATtS,GAAiBA,IAAUoS,EAAapS,QACxCoS,EAAeA,EAAatJ,KAAK9I,IAErC,MAAMuS,EAAI,IAAI,IAASH,EAAcC,EAAW5L,EAAMzH,KAAKiP,gBAC3D,GAA8C,MAA1CjP,KAAKuM,MAAMzB,oBAAoByI,EAAE9L,MACjC,MAAM,IAAI7B,MAAM,sBAAsB2N,EAAE9L,+BAI5C,OAFAzH,KAAKuM,MAAMzB,oBAAoByI,EAAE9L,MAAQ8L,EACzCvT,KAAKkT,OAAOK,EAAGvT,KAAKF,SACbyT,EAEX,OAAOvY,EAAG8E,GACN,MAAM0T,EAAWxT,KAAKuM,MAAMd,WAAWpL,IAAIrF,EAAEoF,QACzCJ,KAAKuM,MAAMd,WAAWlL,IAAIvF,EAAEoF,QAAQoT,SACpC,EAKJ,GAJAxT,KAAKuM,MAAMtB,aACK,WAAZjQ,EAAEgG,OACFhB,KAAKuM,MAAMrB,mBAEE,IAAbsI,EAAgB,CAChBxT,KAAKuM,MAAMpB,iBAGX,IAAIgI,EAAQ,EACI,cAAZnY,EAAEgG,OAAqC,WAAZhG,EAAEgG,QAC7BmS,EAAQnY,EAAEyG,KAAO,IAAqBzG,EAAEgG,QAE5ChB,KAAKuM,MAAMd,WAAWhL,IAAIzF,EAAEoF,OAAQ,CAChCN,QAASA,GAAWE,KAAKF,QACzBkB,MAAOhG,EAAEgG,MACTD,MAAO/F,EAAE+F,MACToS,QACAK,SAAU,IAEdxT,KAAKuM,MAAMvB,UAAYmI,EAE3BnT,KAAKuM,MAAMd,WAAWlL,IAAIvF,EAAEoF,QAAQoT,WAC9BxY,aAAa,KACfgF,KAAKyT,MAAMzY,GAGnB,cAAcA,GACV,IAAKgF,KAAKuM,MAAMd,WAAWpL,IAAIrF,EAAEoF,QAC7B,OAEJJ,KAAKuM,MAAMtB,aACK,WAAZjQ,EAAEgG,OACFhB,KAAKuM,MAAMrB,mBAEf,MAAM+C,EAAOjO,KAAKuM,MAAMd,WAAWlL,IAAIvF,EAAEoF,QACxB6N,EAAKuF,UACN,GAGI,cAAZxY,EAAEgG,QACFhB,KAAKuM,MAAMvB,UAAYiD,EAAKkF,OAEhCnT,KAAKuM,MAAMpB,iBACX8C,EAAKnO,QAAQsO,YAAYpT,EAAEoF,QAC3BJ,KAAKuM,MAAMd,WAAW/K,OAAO1F,EAAEoF,UAO/B6N,EAAKnO,QAAQ4T,cAAc1Y,EAAEoF,QAC7BJ,KAAKuM,MAAMd,WAAWlL,IAAIvF,EAAEoF,QAAQoT,YAM5C,mBACI,IAAK,MAAMG,KAAW3T,KAAKuM,MAAMzB,oBAAqB,CAClD,MAAMyI,EAAIvT,KAAKuM,MAAMzB,oBAAoB6I,GACzC3T,KAAK4T,gBAAgBL,IAG7B,gBAAgBA,GACZvT,KAAK6T,cAAcN,GAC2B,MAA1CvT,KAAKuM,MAAMzB,oBAAoByI,EAAE9L,cAC1BzH,KAAKuM,MAAMzB,oBAAoByI,EAAE9L,MAGhD,SACI,MAAMwG,EAAOjO,KAAKF,QAAQgU,SAY1B,OAXA7F,EAAKhD,WAAajL,KAAKuM,MAAMtB,WAC7BgD,EAAK9C,eAAiBnL,KAAKuM,MAAMpB,eACjC8C,EAAKjD,SAAWhL,KAAKuM,MAAMvB,SACvBhL,KAAKuM,MAAMrB,iBAAmB,IAC9B+C,EAAK8F,YAAa,EACE,MAAhB9F,EAAK+F,UACL/F,EAAK+F,QAAU,IAEnB/F,EAAK+F,QAAQ/X,KAAK,0EAGfgS,EAEX,cAAcgG,GACVjU,KAAKuM,MAAMb,WAAY,EACvB,MAAMwI,EAAalU,KAAKuM,MAAMvB,SACxBmJ,EAAkBnU,KAAKuM,MAAMtB,WACnCjL,KAAKuM,MAAMZ,cAAcI,QAAU,GACnC/L,KAAKuM,MAAMZ,cAAcrO,aAAe2W,IACxCjU,KAAKuM,MAAMb,WAAY,EACvB1L,KAAKuM,MAAMZ,cAAcG,UAAYnO,KAAKI,OAAOiC,KAAKuM,MAAMZ,cAAcI,QAAQvB,KAAIwI,GAAKA,EAAEf,sBAC7FjS,KAAKuM,MAAMZ,cAAcC,SAAW5L,KAAKuM,MAAMvB,SAAWkJ,EAC1DlU,KAAKuM,MAAMZ,cAAcE,WACrB7L,KAAKuM,MAAMtB,WAAakJ,EAC5B,IAAK,MAAM3G,KAAUxN,KAAKuM,MAAMZ,cAAcI,QAC1CyB,EAAO+E,mBAAqB/E,EAAO+E,aACnC/E,EAAOiF,gBAAkBjF,EAAOiF,UAEpC,OAAOzS,KAAKuM,MAAMZ,cAEtB,WACI,OAAO3L,KAAKuM,MAAMnB,cAAgB,GAAgC,IAA3BpL,KAAKuM,MAAMlB,YAEtD,YAAY1F,EAAYwJ,EAAQkB,EAAS+D,EAAe9D,EAAOf,GAC3D,MAAM8E,EAAW,CAAEC,GAAItU,KAAKuM,MAAMxB,iBAAkBpF,aAAYwJ,SAAQkB,UAASC,SAC3EoC,EAAa,YAAY/M,GACb,MAAd+M,IACA0B,EAAgB1B,EAAW6B,UAEV,MAAjBH,IACAC,EAASG,SAAYC,IAGjBA,EAAMA,EAAIjK,KAAI,CAACnI,EAAIrG,KACf,GAAU,MAANqG,EAAY,CACZ,MAAMqS,EAASrE,EAAQrU,GACjBuO,EAAO,IAAyBmK,EAAOjT,KAAMiT,EAAO1T,OAC1D,OAAOhB,KAAK2U,WAAWpK,EAAMmK,EAAO3T,MAAO2T,EAAO1T,OAEtD,OAAOqB,KAIJ+R,EAAcK,EAAIla,OAAS,EAAIka,EAAMA,EAAI,GAAInE,EAAOf,KAGnEvP,KAAKuM,MAAMqI,WAAW3Y,KAAKoY,GAE/B,KAAK/W,GAED,OADAA,EAAOuX,MAAO,EACPvX,EAEX,YACqC,IAA7B0C,KAAKuM,MAAMnB,gBACXpL,KAAKuM,MAAMqI,WAAa,IAE5B5U,KAAKuM,MAAMnB,gBAEf,UACIpL,KAAKuM,MAAMnB,gBAMf,WAAW3D,GACP,MAAMqN,EAAY,CACdrB,MAAO,GACPhM,KAAM,gBACN6M,GAAItU,KAAKuM,MAAMf,eAEf/D,IACAqN,EAAUrN,KAAOA,GAErBzH,KAAKuM,MAAMjB,WAAWrP,KAAK6Y,GAC3B9U,KAAKuM,MAAM8C,YAAcyF,EAM7B,SAASxX,GACL,MAAMyX,EAAyB,YAAsBzX,GAC/C0X,EAA4B,IAAI/I,IAAI8I,EAAuBvK,KAAIhD,GAAKA,EAAE8M,MAE5E,IAAK,IAAItY,EAAI,EAAGA,EAAIgE,KAAKuM,MAAM8C,YAAYoE,MAAMlZ,OAAQyB,IAAK,CAC1D,MAAM0V,EAAS1R,KAAKuM,MAAM8C,YAAYoE,MAAMzX,GACvC0V,EAAOmD,MAASG,EAA0B3U,IAAIqR,EAAO4C,KACtD5C,EAAO3H,UAGf,MAAMkL,EAAWjV,KAAKuM,MAAMjB,WAAW3O,MACvCqD,KAAKuM,MAAM8C,YAA+C,IAAjCrP,KAAKuM,MAAMjB,WAAW/Q,OAC3C,KACAyF,KAAKuM,MAAMjB,WAAWtL,KAAKuM,MAAMjB,WAAW/Q,OAAS,GAEzDwa,EAAuBhN,SAAQ2J,IAGtBA,EAAOmD,MAAQnD,EAAOwD,UAAYD,EAASX,IAC5CtU,KAAKyT,MAAM/B,MAUvB,UAAU9Q,EAAGuU,EAAI9S,EAAI+S,GAAmB,GAEpC,GADA,IAAYD,EAAG5a,OAAS,GAAG,IAAM,8CACvB,MAAN8H,GAA2B,YAAbA,EAAGrB,MACjB,MAAM,IAAI4E,MAAM,0CAA0CvD,EAAGrB,UAEjE,MAAMsB,EAAItC,KAAK0O,WAAU,IAAM1O,KAAKqV,cAAa,IAAMrV,KAAKsV,YAAW,IAAMtV,KAAK4R,KAAK,UAAWhR,KAClG,IAAY0B,aAAa,KAAQ,IAAM,mDAEvC,MAAMiT,EAAe,YAAqBvV,KAAKuM,MAAMqI,WAAYO,EAAI7S,GACrE,IAAK8S,GAA4C,IAAxBG,EAAahb,QAAgB4a,EAAG5a,OAAS,EAC9D,MAAM,IAAIqL,MAAM,uIAIpB,OAAO5F,KAAK4R,KAAK,YAAY,KACzB,MAAM4D,EAAyB,GAC/BA,EAAuBlT,EAAEgS,IAAa,MAANjS,EA6G5C,SAActB,GACV,MAAMD,EAAS,YAAmB,YAAcC,GAAQ,WACxD,OAAOyO,EAAOmF,WAAW7T,EAAQC,EAAO,WA/Gc0U,CAAKnT,EAAEvB,OAASsB,EAE9D,YAAuBmT,EAAwBD,GAE/C3U,GAAKZ,KAAK4R,KAAKhR,IAEf8U,GACA,MAAMC,EAAQR,EAAG3K,KAAIjJ,GAAKiU,EAAuBjU,EAAE+S,MAWnD,OAViC,IAA7BtU,KAAKuM,MAAMnB,gBAGXpL,KAAKuM,MAAMqI,WAAW7M,SAAQxI,IAC1B,IAAK,MAAMmS,KAAUnS,EAAK+Q,MACtBoB,EAAO3H,aAGf/J,KAAKuM,MAAMqI,WAAa,MAErB,CAAEpU,MAAO8B,EAAGqT,YAG3B,WAAW/U,GAEP,OADA,IAAY,IAAgBA,IAAI,IAAM,sDAC/B,IAAIuO,KAGP,IAAIJ,EAFJ,IAAYI,EAAOyG,OAAMpO,GAAKA,aAAa,OAAS,IAAM,qEAG1D,MAAMqO,EAAW,GAIjB,OAHA1G,EAAOpH,SAAQ,CAACvF,EAAOxG,KACnB6Z,EAAS7Z,GAAKwG,KAEXxC,KAAKyP,eAAc,CAAC4B,EAAGyE,KAC1B/G,EAAMnO,KAASuO,EAAQ2G,GACvB,IAAY/G,EAAIvO,iBAAiB,KAAQ,IAAM,+FAE/C,IAAY,IAAgBuO,EAAIwF,WAAW,IAAM,qGAE1CxF,EAAIvO,QACZqV,GAAU,CAACxT,EAAIiO,KACd,MAAMyF,EAAUhH,EAAIwF,SAASlS,EAAIiO,GAC3BqF,EAAQvY,MAAMyT,QAAQkF,GAAWA,EAAU,CAACA,GAClD,IAAYJ,EAAMpb,SAAW4U,EAAO5U,QAAQ,IAAM,wKAGlD,IAAYob,EAAMC,OAAMpO,GAAKA,aAAa,OAAS,IAAM,yIAGzD,MAAMwO,EAAU,GAIhB,OAHAL,EAAM5N,SAAQ,CAACkO,EAAMja,KACjBga,EAAQha,GAAK,IAAMia,KAEhBD,MAInB,SAAS5V,GAGL,OADaJ,KAAKuM,MAAMd,WAAWlL,IAAIH,GAC3BN,QAAQqO,SAAS/N,GAEjC,KAAKA,GAGD,OADaJ,KAAKuM,MAAMd,WAAWlL,IAAIH,GAC3BN,QAAQoW,KAAK9V,GAE7B,WAAW6T,GACP,MAAMzO,EAAQ,gBACR2Q,QAAmBnW,KAAKF,QAAQsW,KAAKnC,GAE3C,OADAkC,EAAWE,OAAS,gBAAQ7Q,EACrB2Q,EAQX,MAAM7Y,GAKF,OAJ8B,MAA1B0C,KAAKuM,MAAM8C,cACX/R,EAAO4X,QAAUlV,KAAKuM,MAAM8C,YAAYiF,GACxCtU,KAAKuM,MAAM8C,YAAYoE,MAAMxX,KAAKqB,IAE/BA,EAEX,0BACI,OAAO0C,KAAKuM,MAAMzB,oBAMtB,QAEI9K,KAAKsM,uBACLtM,KAAKuM,MAAMxC,UACX/J,KAAKhB,IAAIsX,QACTtW,KAAKuM,MAAQ,IAAI1B,EACjB,IAAK,MAAMgC,KAAe7M,KAAKoM,SAC3BpM,KAAKgO,yBAAyBnB,GAC9B7M,KAAKoM,SAASS,GAAa9C,iBACpB/J,KAAKoM,SAASS,GAEzB7M,KAAK6M,YAAc,KACnB7M,KAAK0M,gBAAkB,KACvB1M,KAAKwM,mBAAqB,MAS3B,SAAS+J,IACZ,MAAMC,EAAK,cACX,GAAoB,MAAhBA,EAAGC,UAAmB,CACtB,MAAMnO,EAAc,IAAI,IAAYkO,GACpCA,EAAGC,UAAY,IAAItK,EAAO7D,GAM9B,OAJA,YAAqBkO,EAAGC,UAAUzX,KAGlC,aAAiB,IAAMwX,EAAGC,YACnBD,EAAGC,UAhBdtK,EAAO8C,aAAe,EACtB9C,EAAO+C,eAAiB,EAiBjB,MAAMM,EAAS+G,IAOf,SAASb,EAAI1a,EAAGC,GAEnB,MAAMkU,EAAS,CAAEnU,IAAGC,KACpB,OAAOuU,EAAOkH,UAAU,IAAKvH,K,iCCl9BjC,0EAmBA,cAYA,MAAMwH,EAAY,CACdC,OAAA,IACA9M,KAAA,IACAJ,MAAA,IACAmN,MAAA,KAEJ,YAAaF","file":"js/bundle~bundle~fb9c722d.825737dc.js","sourcesContent":["/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n/**\n * Inserts a value into a sorted array. This method allows duplicate, meaning it\n * allows inserting duplicate value, in which case, the element will be inserted\n * at the lowest index of the value.\n * @param arr The array to modify.\n * @param element The element to insert.\n * @param comparator Optional. If no comparator is specified, elements are\n * compared using array_util.defaultComparator, which is suitable for Strings\n * and Numbers in ascending arrays. If the array contains multiple instances of\n * the target value, the left-most instance will be returned. To provide a\n * comparator, it should take 2 arguments to compare and return a negative,\n * zero, or a positive number.\n */\nexport function binaryInsert(arr, element, comparator) {\n    const index = binarySearch(arr, element, comparator);\n    const insertionPoint = index < 0 ? -(index + 1) : index;\n    arr.splice(insertionPoint, 0, element);\n}\n/**\n * Searches the array for the target using binary search, returns the index\n * of the found element, or position to insert if element not found. If no\n * comparator is specified, elements are compared using array_\n * util.defaultComparator, which is suitable for Strings and Numbers in\n * ascending arrays. If the array contains multiple instances of the target\n * value, the left-most instance will be returned.\n * @param arr The array to be searched in.\n * @param target The target to be searched for.\n * @param comparator Should take 2 arguments to compare and return a negative,\n *    zero, or a positive number.\n * @return Lowest index of the target value if found, otherwise the insertion\n *    point where the target should be inserted, in the form of\n *    (-insertionPoint - 1).\n */\nexport function binarySearch(arr, target, comparator) {\n    return binarySearch_(arr, target, comparator || defaultComparator);\n}\n/**\n * Compares its two arguments for order.\n * @param a The first element to be compared.\n * @param b The second element to be compared.\n * @return A negative number, zero, or a positive number as the first\n *     argument is less than, equal to, or greater than the second.\n */\nfunction defaultComparator(a, b) {\n    return a > b ? 1 : a < b ? -1 : 0;\n}\nfunction binarySearch_(arr, target, comparator) {\n    let left = 0;\n    let right = arr.length;\n    let middle = 0;\n    let found = false;\n    while (left < right) {\n        middle = left + ((right - left) >>> 1);\n        const compareResult = comparator(target, arr[middle]);\n        if (compareResult > 0) {\n            left = middle + 1;\n        }\n        else {\n            right = middle;\n            // If compareResult is 0, the value is found. We record it is found,\n            // and then keep looking because there may be duplicate.\n            found = !compareResult;\n        }\n    }\n    return found ? left : -left - 1;\n}\n//# sourceMappingURL=non_max_suppression_util.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { binaryInsert } from './non_max_suppression_util';\nexport function nonMaxSuppressionV3Impl(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold) {\n    return nonMaxSuppressionImpl_(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, 0 /* softNmsSigma */);\n}\nexport function nonMaxSuppressionV4Impl(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, padToMaxOutputSize) {\n    return nonMaxSuppressionImpl_(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, 0 /* softNmsSigma */, false /* returnScoresTensor */, padToMaxOutputSize /* padToMaxOutputSize */, true\n    /* returnValidOutputs */ );\n}\nexport function nonMaxSuppressionV5Impl(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma) {\n    return nonMaxSuppressionImpl_(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma, true /* returnScoresTensor */);\n}\nfunction nonMaxSuppressionImpl_(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma, returnScoresTensor = false, padToMaxOutputSize = false, returnValidOutputs = false) {\n    // The list is sorted in ascending order, so that we can always pop the\n    // candidate with the largest score in O(1) time.\n    const candidates = [];\n    for (let i = 0; i < scores.length; i++) {\n        if (scores[i] > scoreThreshold) {\n            candidates.push({ score: scores[i], boxIndex: i, suppressBeginIndex: 0 });\n        }\n    }\n    candidates.sort(ascendingComparator);\n    // If softNmsSigma is 0, the outcome of this algorithm is exactly same as\n    // before.\n    const scale = softNmsSigma > 0 ? (-0.5 / softNmsSigma) : 0.0;\n    const selectedIndices = [];\n    const selectedScores = [];\n    while (selectedIndices.length < maxOutputSize && candidates.length > 0) {\n        const candidate = candidates.pop();\n        const { score: originalScore, boxIndex, suppressBeginIndex } = candidate;\n        if (originalScore < scoreThreshold) {\n            break;\n        }\n        // Overlapping boxes are likely to have similar scores, therefore we\n        // iterate through the previously selected boxes backwards in order to\n        // see if candidate's score should be suppressed. We use\n        // suppressBeginIndex to track and ensure a candidate can be suppressed\n        // by a selected box no more than once. Also, if the overlap exceeds\n        // iouThreshold, we simply ignore the candidate.\n        let ignoreCandidate = false;\n        for (let j = selectedIndices.length - 1; j >= suppressBeginIndex; --j) {\n            const iou = intersectionOverUnion(boxes, boxIndex, selectedIndices[j]);\n            if (iou >= iouThreshold) {\n                ignoreCandidate = true;\n                break;\n            }\n            candidate.score =\n                candidate.score * suppressWeight(iouThreshold, scale, iou);\n            if (candidate.score <= scoreThreshold) {\n                break;\n            }\n        }\n        // At this point, if `candidate.score` has not dropped below\n        // `scoreThreshold`, then we know that we went through all of the\n        // previous selections and can safely update `suppressBeginIndex` to the\n        // end of the selected array. Then we can re-insert the candidate with\n        // the updated score and suppressBeginIndex back in the candidate list.\n        // If on the other hand, `candidate.score` has dropped below the score\n        // threshold, we will not add it back to the candidates list.\n        candidate.suppressBeginIndex = selectedIndices.length;\n        if (!ignoreCandidate) {\n            // Candidate has passed all the tests, and is not suppressed, so\n            // select the candidate.\n            if (candidate.score === originalScore) {\n                selectedIndices.push(boxIndex);\n                selectedScores.push(candidate.score);\n            }\n            else if (candidate.score > scoreThreshold) {\n                // Candidate's score is suppressed but is still high enough to be\n                // considered, so add back to the candidates list.\n                binaryInsert(candidates, candidate, ascendingComparator);\n            }\n        }\n    }\n    // NonMaxSuppressionV4 feature: padding output to maxOutputSize.\n    const validOutputs = selectedIndices.length;\n    const elemsToPad = maxOutputSize - validOutputs;\n    if (padToMaxOutputSize && elemsToPad > 0) {\n        selectedIndices.push(...new Array(elemsToPad).fill(0));\n        selectedScores.push(...new Array(elemsToPad).fill(0.0));\n    }\n    const result = { selectedIndices };\n    if (returnScoresTensor) {\n        result['selectedScores'] = selectedScores;\n    }\n    if (returnValidOutputs) {\n        result['validOutputs'] = validOutputs;\n    }\n    return result;\n}\nfunction intersectionOverUnion(boxes, i, j) {\n    const iCoord = boxes.subarray(i * 4, i * 4 + 4);\n    const jCoord = boxes.subarray(j * 4, j * 4 + 4);\n    const yminI = Math.min(iCoord[0], iCoord[2]);\n    const xminI = Math.min(iCoord[1], iCoord[3]);\n    const ymaxI = Math.max(iCoord[0], iCoord[2]);\n    const xmaxI = Math.max(iCoord[1], iCoord[3]);\n    const yminJ = Math.min(jCoord[0], jCoord[2]);\n    const xminJ = Math.min(jCoord[1], jCoord[3]);\n    const ymaxJ = Math.max(jCoord[0], jCoord[2]);\n    const xmaxJ = Math.max(jCoord[1], jCoord[3]);\n    const areaI = (ymaxI - yminI) * (xmaxI - xminI);\n    const areaJ = (ymaxJ - yminJ) * (xmaxJ - xminJ);\n    if (areaI <= 0 || areaJ <= 0) {\n        return 0.0;\n    }\n    const intersectionYmin = Math.max(yminI, yminJ);\n    const intersectionXmin = Math.max(xminI, xminJ);\n    const intersectionYmax = Math.min(ymaxI, ymaxJ);\n    const intersectionXmax = Math.min(xmaxI, xmaxJ);\n    const intersectionArea = Math.max(intersectionYmax - intersectionYmin, 0.0) *\n        Math.max(intersectionXmax - intersectionXmin, 0.0);\n    return intersectionArea / (areaI + areaJ - intersectionArea);\n}\n// A Gaussian penalty function, this method always returns values in [0, 1].\n// The weight is a function of similarity, the more overlap two boxes are, the\n// smaller the weight is, meaning highly overlapping boxe will be significantly\n// penalized. On the other hand, a non-overlapping box will not be penalized.\nfunction suppressWeight(iouThreshold, scale, iou) {\n    const weight = Math.exp(scale * iou * iou);\n    return iou <= iouThreshold ? weight : 0.0;\n}\nfunction ascendingComparator(c1, c2) {\n    // For objects with same scores, we make the object with the larger index go\n    // first. In an array that pops from the end, this means that the object with\n    // the smaller index will be popped first. This ensures the same output as\n    // the TensorFlow python version.\n    return (c1.score - c2.score) ||\n        ((c1.score === c2.score) && (c2.boxIndex - c1.boxIndex));\n}\n//# sourceMappingURL=non_max_suppression_impl.js.map","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport './engine';\nimport * as device_util from './device_util';\nimport { env } from './environment';\nconst ENV = env();\n/**\n * This file contains environment-related flag registrations.\n */\n/** Whether to enable debug mode. */\nENV.registerFlag('DEBUG', () => false, debugValue => {\n    if (debugValue) {\n        console.warn('Debugging mode is ON. The output of every math call will ' +\n            'be downloaded to CPU and checked for NaNs. ' +\n            'This significantly impacts performance.');\n    }\n});\n/** Whether we are in a browser (as versus, say, node.js) environment. */\nENV.registerFlag('IS_BROWSER', () => device_util.isBrowser());\n/** Whether we are in a browser (as versus, say, node.js) environment. */\nENV.registerFlag('IS_NODE', () => (typeof process !== 'undefined') &&\n    (typeof process.versions !== 'undefined') &&\n    (typeof process.versions.node !== 'undefined'));\n/** Whether this browser is Chrome. */\nENV.registerFlag('IS_CHROME', () => typeof navigator !== 'undefined' && navigator != null &&\n    navigator.userAgent != null && /Chrome/.test(navigator.userAgent) &&\n    /Google Inc/.test(navigator.vendor));\n/**\n * True when the environment is \"production\" where we disable safety checks\n * to gain performance.\n */\nENV.registerFlag('PROD', () => false);\n/**\n * Whether to do sanity checks when inferring a shape from user-provided\n * values, used when creating a new tensor.\n */\nENV.registerFlag('TENSORLIKE_CHECK_SHAPE_CONSISTENCY', () => ENV.getBool('DEBUG'));\n/** Whether deprecation warnings are enabled. */\nENV.registerFlag('DEPRECATION_WARNINGS_ENABLED', () => true);\n/** True if running unit tests. */\nENV.registerFlag('IS_TEST', () => false);\n/** Whether to check computation result for errors. */\nENV.registerFlag('CHECK_COMPUTATION_FOR_ERRORS', () => true);\n//# sourceMappingURL=flags.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nexport const EPSILON_FLOAT32 = 1e-7;\nexport const EPSILON_FLOAT16 = 1e-4;\n/** Convenient class for storing tensor-related data. */\nexport class DataStorage {\n    constructor(backend, dataMover) {\n        this.backend = backend;\n        this.dataMover = dataMover;\n        this.data = new WeakMap();\n        this.dataIdsCount = 0;\n    }\n    get(dataId) {\n        if (!this.data.has(dataId)) {\n            this.dataMover.moveData(this.backend, dataId);\n        }\n        return this.data.get(dataId);\n    }\n    set(dataId, value) {\n        this.dataIdsCount++;\n        this.data.set(dataId, value);\n    }\n    has(dataId) {\n        return this.data.has(dataId);\n    }\n    delete(dataId) {\n        this.dataIdsCount--;\n        return this.data.delete(dataId);\n    }\n    numDataIds() {\n        return this.dataIdsCount;\n    }\n}\n/**\n * The interface that defines the kernels that should be implemented when\n * adding a new backend. New backends don't need to implement every one of the\n * methods, this can be done gradually (throw an error for unimplemented\n * methods).\n */\nexport class KernelBackend {\n    /**\n     * Decrease the complex ref count for the dataId, this is useful for WebGL\n     * backend to keep the real and imag components of the complex tensor in sync\n     * with the engine. WASM and node do not have internal ref count, they will\n     * use on the default implementation.\n     * @param dataId\n     */\n    decComplexRef(dataId) {\n        return;\n    }\n    time(f) {\n        return notYetImplemented('time');\n    }\n    read(dataId) {\n        return notYetImplemented('read');\n    }\n    readSync(dataId) {\n        return notYetImplemented('readSync');\n    }\n    numDataIds() {\n        return notYetImplemented('numDataIds');\n    }\n    disposeData(dataId) {\n        return notYetImplemented('disposeData');\n    }\n    write(values, shape, dtype) {\n        return notYetImplemented('write');\n    }\n    move(dataId, values, shape, dtype) {\n        return notYetImplemented('move');\n    }\n    memory() {\n        return notYetImplemented('memory');\n    }\n    /** Returns the highest precision for floats in bits (e.g. 16 or 32) */\n    floatPrecision() {\n        return notYetImplemented('floatPrecision');\n    }\n    /** Returns the smallest representable number.  */\n    epsilon() {\n        return this.floatPrecision() === 32 ? EPSILON_FLOAT32 : EPSILON_FLOAT16;\n    }\n    batchMatMul(a, b, transposeA, transposeB) {\n        return notYetImplemented('batchMatMul');\n    }\n    fusedBatchMatMul({ a, b, transposeA, transposeB, bias, activation, preluActivationWeights }) {\n        return notYetImplemented('fusedBatchMatMul');\n    }\n    slice(x, begin, size) {\n        return notYetImplemented('slice');\n    }\n    stridedSlice(x, begin, end, strides) {\n        return notYetImplemented('stridedSlice');\n    }\n    unstack(x, axis) {\n        return notYetImplemented('unstack');\n    }\n    reverse(a, axis) {\n        return notYetImplemented('reverse');\n    }\n    concat(tensors, axis) {\n        return notYetImplemented('concat');\n    }\n    neg(a) {\n        return notYetImplemented('neg');\n    }\n    add(a, b) {\n        return notYetImplemented('add');\n    }\n    addN(tensors) {\n        return notYetImplemented('addN');\n    }\n    subtract(a, b) {\n        return notYetImplemented('subtract');\n    }\n    multiply(a, b) {\n        return notYetImplemented('multiply');\n    }\n    realDivide(a, b) {\n        return notYetImplemented('realDivide');\n    }\n    floorDiv(a, b) {\n        return notYetImplemented('floorDiv');\n    }\n    sum(x, axes) {\n        return notYetImplemented('sum');\n    }\n    prod(x, axes) {\n        return notYetImplemented('prod');\n    }\n    unsortedSegmentSum(x, segmentIds, numSegments) {\n        return notYetImplemented('unsortedSegmentSum');\n    }\n    argMin(x, axis) {\n        return notYetImplemented('argMin');\n    }\n    argMax(x, axis) {\n        return notYetImplemented('argMax');\n    }\n    equal(a, b) {\n        return notYetImplemented('equal');\n    }\n    notEqual(a, b) {\n        return notYetImplemented('notEqual');\n    }\n    less(a, b) {\n        return notYetImplemented('less');\n    }\n    lessEqual(a, b) {\n        return notYetImplemented('lessEqual');\n    }\n    greater(a, b) {\n        return notYetImplemented('greater');\n    }\n    greaterEqual(a, b) {\n        return notYetImplemented('greaterEqual');\n    }\n    logicalNot(a) {\n        return notYetImplemented('logicalNot');\n    }\n    logicalAnd(a, b) {\n        return notYetImplemented('logicalAnd');\n    }\n    logicalOr(a, b) {\n        return notYetImplemented('logicalOr');\n    }\n    where(condition) {\n        return notYetImplemented('where');\n    }\n    select(condition, a, b) {\n        return notYetImplemented('select');\n    }\n    topk(x, k, sorted) {\n        return notYetImplemented('topk');\n    }\n    min(x, axes) {\n        return notYetImplemented('min');\n    }\n    minimum(a, b) {\n        return notYetImplemented('minimum');\n    }\n    mod(a, b) {\n        return notYetImplemented('mod');\n    }\n    max(x, axes) {\n        return notYetImplemented('max');\n    }\n    maximum(a, b) {\n        return notYetImplemented('maximum');\n    }\n    all(x, axes) {\n        return notYetImplemented('all');\n    }\n    any(x, axes) {\n        return notYetImplemented('any');\n    }\n    squaredDifference(a, b) {\n        return notYetImplemented('squaredDifference');\n    }\n    ceil(x) {\n        return notYetImplemented('ceil');\n    }\n    floor(x) {\n        return notYetImplemented('floor');\n    }\n    round(x) {\n        return notYetImplemented('round');\n    }\n    sign(x) {\n        return notYetImplemented('sign');\n    }\n    isNaN(x) {\n        return notYetImplemented('isNaN');\n    }\n    isInf(x) {\n        return notYetImplemented('isInf');\n    }\n    isFinite(x) {\n        return notYetImplemented('isFinite');\n    }\n    pow(a, b) {\n        return notYetImplemented('pow');\n    }\n    exp(x) {\n        return notYetImplemented('exp');\n    }\n    expm1(x) {\n        return notYetImplemented('expm1');\n    }\n    softmax(x, dim) {\n        return notYetImplemented('softmax');\n    }\n    log(x) {\n        return notYetImplemented('log');\n    }\n    log1p(x) {\n        return notYetImplemented('log1p');\n    }\n    sqrt(x) {\n        return notYetImplemented('sqrt');\n    }\n    rsqrt(x) {\n        return notYetImplemented('rsqrt');\n    }\n    square(x) {\n        return notYetImplemented('square');\n    }\n    reciprocal(x) {\n        return notYetImplemented('reciprocal');\n    }\n    relu(x) {\n        return notYetImplemented('relu');\n    }\n    relu6(x) {\n        return notYetImplemented('relu6');\n    }\n    prelu(x, a) {\n        return notYetImplemented('prelu');\n    }\n    elu(x) {\n        return notYetImplemented('elu');\n    }\n    eluDer(dy, y) {\n        return notYetImplemented('eluDer');\n    }\n    selu(x) {\n        return notYetImplemented('selu');\n    }\n    int(x) {\n        return notYetImplemented('int');\n    }\n    clip(x, min, max) {\n        return notYetImplemented('clip');\n    }\n    abs(x) {\n        return notYetImplemented('abs');\n    }\n    complexAbs(x) {\n        return notYetImplemented('complexAbs');\n    }\n    sigmoid(x) {\n        return notYetImplemented('sigmoid');\n    }\n    softplus(x) {\n        return notYetImplemented('softplus');\n    }\n    sin(x) {\n        return notYetImplemented('sin');\n    }\n    cos(x) {\n        return notYetImplemented('cos');\n    }\n    tan(x) {\n        return notYetImplemented('tan');\n    }\n    asin(x) {\n        return notYetImplemented('asin');\n    }\n    acos(x) {\n        return notYetImplemented('acos');\n    }\n    atan(x) {\n        return notYetImplemented('atan');\n    }\n    atan2(a, b) {\n        return notYetImplemented('atan2');\n    }\n    sinh(x) {\n        return notYetImplemented('sinh');\n    }\n    cosh(x) {\n        return notYetImplemented('cosh');\n    }\n    tanh(x) {\n        return notYetImplemented('tanh');\n    }\n    asinh(x) {\n        return notYetImplemented('asinh');\n    }\n    acosh(x) {\n        return notYetImplemented('acosh');\n    }\n    atanh(x) {\n        return notYetImplemented('atanh');\n    }\n    erf(x) {\n        return notYetImplemented('erf');\n    }\n    step(x, alpha) {\n        return notYetImplemented('step');\n    }\n    fusedConv2d({ input, filter, convInfo, bias, activation, preluActivationWeights }) {\n        return notYetImplemented('fusedConv2d');\n    }\n    conv2d(x, filter, convInfo) {\n        return notYetImplemented('conv2d');\n    }\n    conv2dDerInput(dy, filter, convInfo) {\n        return notYetImplemented('conv2dDerInput');\n    }\n    conv2dDerFilter(x, dY, convInfo) {\n        return notYetImplemented('conv2dDerFilter');\n    }\n    fusedDepthwiseConv2D({ input, filter, convInfo, bias, activation, preluActivationWeights }) {\n        return notYetImplemented('fusedDepthwiseConv2D');\n    }\n    depthwiseConv2D(input, filter, convInfo) {\n        return notYetImplemented('depthwiseConv2D');\n    }\n    depthwiseConv2DDerInput(dy, filter, convInfo) {\n        return notYetImplemented('depthwiseConv2DDerInput');\n    }\n    depthwiseConv2DDerFilter(x, dY, convInfo) {\n        return notYetImplemented('depthwiseConv2DDerFilter');\n    }\n    conv3d(x, filter, convInfo) {\n        return notYetImplemented('conv3d');\n    }\n    conv3dDerInput(dy, filter, convInfo) {\n        return notYetImplemented('conv3dDerInput');\n    }\n    conv3dDerFilter(x, dY, convInfo) {\n        return notYetImplemented('conv3dDerFilter');\n    }\n    maxPool(x, convInfo) {\n        return notYetImplemented('maxPool');\n    }\n    maxPoolBackprop(dy, x, y, convInfo) {\n        return notYetImplemented('maxPoolBackprop');\n    }\n    avgPool(x, convInfo) {\n        return notYetImplemented('avgPool');\n    }\n    avgPoolBackprop(dy, x, convInfo) {\n        return notYetImplemented('avgPoolBackprop');\n    }\n    avgPool3d(x, convInfo) {\n        return notYetImplemented('avgPool3d');\n    }\n    avgPool3dBackprop(dy, x, convInfo) {\n        return notYetImplemented('avgPool3dBackprop');\n    }\n    maxPool3d(x, convInfo) {\n        return notYetImplemented('maxPool3d');\n    }\n    maxPool3dBackprop(dy, x, y, convInfo) {\n        return notYetImplemented('maxPool3dBackprop');\n    }\n    reshape(x, shape) {\n        return notYetImplemented('reshape');\n    }\n    cast(x, dtype) {\n        return notYetImplemented('cast');\n    }\n    tile(x, reps) {\n        return notYetImplemented('tile');\n    }\n    pad(x, paddings, constantValue) {\n        return notYetImplemented('pad');\n    }\n    transpose(x, perm) {\n        return notYetImplemented('transpose');\n    }\n    gather(x, indices, axis, batchDims = 0) {\n        return notYetImplemented('gather');\n    }\n    gatherND(x, indices) {\n        return notYetImplemented('gatherND');\n    }\n    scatterND(indices, updates, shape) {\n        return notYetImplemented('scatterND');\n    }\n    batchToSpaceND(x, blockShape, crops) {\n        return notYetImplemented('batchToSpaceND');\n    }\n    spaceToBatchND(x, blockShape, paddings) {\n        return notYetImplemented('spaceToBatchND');\n    }\n    resizeBilinear(x, newHeight, newWidth, alignCorners, halfPixelCenters) {\n        return notYetImplemented('resizeBilinear');\n    }\n    resizeBilinearBackprop(dy, x, alignCorners) {\n        return notYetImplemented('resizeBilinearBackprop');\n    }\n    resizeNearestNeighbor(x, newHEight, newWidth, alignCorners, halfPixelCenters) {\n        return notYetImplemented('resizeNearestNeighbor');\n    }\n    resizeNearestNeighborBackprop(dy, x, alignCorners) {\n        return notYetImplemented('resizeNearestNeighborBackprop');\n    }\n    batchNorm(x, mean, variance, offset, scale, varianceEpsilon) {\n        return notYetImplemented('batchNorm');\n    }\n    localResponseNormalization4D(x, radius, bias, alpha, beta) {\n        return notYetImplemented('localResponseNormalization4D');\n    }\n    LRNGrad(dy, inputImage, outputImage, radius, bias, alpha, beta) {\n        return notYetImplemented('LRNGrad');\n    }\n    multinomial(logits, normalized, numSamples, seed) {\n        return notYetImplemented('multinomial');\n    }\n    oneHot(indices, depth, onValue, offValue) {\n        return notYetImplemented('oneHot');\n    }\n    cumsum(x, axis, exclusive, reverse) {\n        return notYetImplemented('cumsum');\n    }\n    nonMaxSuppression(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold) {\n        return notYetImplemented('nonMaxSuppression');\n    }\n    fft(x) {\n        return notYetImplemented('fft');\n    }\n    ifft(x) {\n        return notYetImplemented('ifft');\n    }\n    complex(real, imag) {\n        return notYetImplemented('complex');\n    }\n    real(input) {\n        return notYetImplemented('real');\n    }\n    imag(input) {\n        return notYetImplemented('imag');\n    }\n    cropAndResize(image, boxes, boxIndex, cropSize, method, extrapolationValue) {\n        return notYetImplemented('cropAndResize');\n    }\n    depthToSpace(x, blockSize, dataFormat) {\n        return notYetImplemented('depthToSpace');\n    }\n    // Aligns with the \"SplitV\" kernel in TensorFlow.\n    split(value, sizeSplits, axis) {\n        return notYetImplemented('split');\n    }\n    sparseToDense(sparseIndices, sparseValues, outputShape, defaultValue) {\n        return notYetImplemented('sparseToDense');\n    }\n    diag(x) {\n        return notYetImplemented('diag');\n    }\n    fill(shape, value, dtype) {\n        return notYetImplemented('fill');\n    }\n    onesLike(x) {\n        return notYetImplemented('onesLike');\n    }\n    zerosLike(x) {\n        return notYetImplemented('zerosLike');\n    }\n    linspace(start, stop, num) {\n        return notYetImplemented('linspace');\n    }\n    dispose() {\n        return notYetImplemented('dispose');\n    }\n}\nfunction notYetImplemented(kernelName) {\n    throw new Error(`'${kernelName}' not yet implemented or not found in the registry. ` +\n        `This kernel may not be supported by the tfjs backend you have chosen`);\n}\n//# sourceMappingURL=backend.js.map","/**\n * @license\n * Copyright 2017 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n// tslint:disable-next-line:no-any\nfunction _isNavigatorDefined() {\n    return typeof navigator !== 'undefined' && navigator != null;\n}\nexport function isMobile() {\n    if (_isNavigatorDefined()) {\n        // tslint:disable-next-line:no-any\n        const a = navigator.userAgent || navigator.vendor || window.opera;\n        // tslint:disable-next-line:max-line-length\n        return /(android|bb\\d+|meego).+mobile|avantgo|bada\\/|blackberry|blazer|compal|elaine|fennec|hiptop|iemobile|ip(hone|od)|iris|kindle|lge |maemo|midp|mmp|mobile.+firefox|netfront|opera m(ob|in)i|palm( os)?|phone|p(ixi|re)\\/|plucker|pocket|psp|series(4|6)0|symbian|treo|up\\.(browser|link)|vodafone|wap|windows ce|xda|xiino/i\n            .test(a) ||\n            // tslint:disable-next-line:max-line-length\n            /1207|6310|6590|3gso|4thp|50[1-6]i|770s|802s|a wa|abac|ac(er|oo|s\\-)|ai(ko|rn)|al(av|ca|co)|amoi|an(ex|ny|yw)|aptu|ar(ch|go)|as(te|us)|attw|au(di|\\-m|r |s )|avan|be(ck|ll|nq)|bi(lb|rd)|bl(ac|az)|br(e|v)w|bumb|bw\\-(n|u)|c55\\/|capi|ccwa|cdm\\-|cell|chtm|cldc|cmd\\-|co(mp|nd)|craw|da(it|ll|ng)|dbte|dc\\-s|devi|dica|dmob|do(c|p)o|ds(12|\\-d)|el(49|ai)|em(l2|ul)|er(ic|k0)|esl8|ez([4-7]0|os|wa|ze)|fetc|fly(\\-|_)|g1 u|g560|gene|gf\\-5|g\\-mo|go(\\.w|od)|gr(ad|un)|haie|hcit|hd\\-(m|p|t)|hei\\-|hi(pt|ta)|hp( i|ip)|hs\\-c|ht(c(\\-| |_|a|g|p|s|t)|tp)|hu(aw|tc)|i\\-(20|go|ma)|i230|iac( |\\-|\\/)|ibro|idea|ig01|ikom|im1k|inno|ipaq|iris|ja(t|v)a|jbro|jemu|jigs|kddi|keji|kgt( |\\/)|klon|kpt |kwc\\-|kyo(c|k)|le(no|xi)|lg( g|\\/(k|l|u)|50|54|\\-[a-w])|libw|lynx|m1\\-w|m3ga|m50\\/|ma(te|ui|xo)|mc(01|21|ca)|m\\-cr|me(rc|ri)|mi(o8|oa|ts)|mmef|mo(01|02|bi|de|do|t(\\-| |o|v)|zz)|mt(50|p1|v )|mwbp|mywa|n10[0-2]|n20[2-3]|n30(0|2)|n50(0|2|5)|n7(0(0|1)|10)|ne((c|m)\\-|on|tf|wf|wg|wt)|nok(6|i)|nzph|o2im|op(ti|wv)|oran|owg1|p800|pan(a|d|t)|pdxg|pg(13|\\-([1-8]|c))|phil|pire|pl(ay|uc)|pn\\-2|po(ck|rt|se)|prox|psio|pt\\-g|qa\\-a|qc(07|12|21|32|60|\\-[2-7]|i\\-)|qtek|r380|r600|raks|rim9|ro(ve|zo)|s55\\/|sa(ge|ma|mm|ms|ny|va)|sc(01|h\\-|oo|p\\-)|sdk\\/|se(c(\\-|0|1)|47|mc|nd|ri)|sgh\\-|shar|sie(\\-|m)|sk\\-0|sl(45|id)|sm(al|ar|b3|it|t5)|so(ft|ny)|sp(01|h\\-|v\\-|v )|sy(01|mb)|t2(18|50)|t6(00|10|18)|ta(gt|lk)|tcl\\-|tdg\\-|tel(i|m)|tim\\-|t\\-mo|to(pl|sh)|ts(70|m\\-|m3|m5)|tx\\-9|up(\\.b|g1|si)|utst|v400|v750|veri|vi(rg|te)|vk(40|5[0-3]|\\-v)|vm40|voda|vulc|vx(52|53|60|61|70|80|81|83|85|98)|w3c(\\-| )|webc|whit|wi(g |nc|nw)|wmlb|wonu|x700|yas\\-|your|zeto|zte\\-/i\n                .test(a.substr(0, 4));\n    }\n    return false;\n}\nexport function isBrowser() {\n    return (typeof window !== 'undefined' && window.document != null) ||\n        //@ts-ignore\n        (typeof WorkerGlobalScope !== 'undefined');\n}\n//# sourceMappingURL=device_util.js.map","/**\n * @license\n * Copyright 2017 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { isPromise } from './util_base';\n// Expects flags from URL in the format ?tfjsflags=FLAG1:1,FLAG2:true.\nconst TENSORFLOWJS_FLAGS_PREFIX = 'tfjsflags';\n/**\n * The environment contains evaluated flags as well as the registered platform.\n * This is always used as a global singleton and can be retrieved with\n * `tf.env()`.\n *\n * @doc {heading: 'Environment'}\n */\nexport class Environment {\n    // tslint:disable-next-line: no-any\n    constructor(global) {\n        this.global = global;\n        this.flags = {};\n        this.flagRegistry = {};\n        this.urlFlags = {};\n        this.populateURLFlags();\n    }\n    setPlatform(platformName, platform) {\n        if (this.platform != null) {\n            console.warn(`Platform ${this.platformName} has already been set. ` +\n                `Overwriting the platform with ${platform}.`);\n        }\n        this.platformName = platformName;\n        this.platform = platform;\n    }\n    registerFlag(flagName, evaluationFn, setHook) {\n        this.flagRegistry[flagName] = { evaluationFn, setHook };\n        // Override the flag value from the URL. This has to happen here because the\n        // environment is initialized before flags get registered.\n        if (this.urlFlags[flagName] != null) {\n            const flagValue = this.urlFlags[flagName];\n            console.warn(`Setting feature override from URL ${flagName}: ${flagValue}.`);\n            this.set(flagName, flagValue);\n        }\n    }\n    async getAsync(flagName) {\n        if (flagName in this.flags) {\n            return this.flags[flagName];\n        }\n        this.flags[flagName] = await this.evaluateFlag(flagName);\n        return this.flags[flagName];\n    }\n    get(flagName) {\n        if (flagName in this.flags) {\n            return this.flags[flagName];\n        }\n        const flagValue = this.evaluateFlag(flagName);\n        if (isPromise(flagValue)) {\n            throw new Error(`Flag ${flagName} cannot be synchronously evaluated. ` +\n                `Please use getAsync() instead.`);\n        }\n        this.flags[flagName] = flagValue;\n        return this.flags[flagName];\n    }\n    getNumber(flagName) {\n        return this.get(flagName);\n    }\n    getBool(flagName) {\n        return this.get(flagName);\n    }\n    getFlags() {\n        return this.flags;\n    }\n    // For backwards compatibility.\n    get features() {\n        return this.flags;\n    }\n    set(flagName, value) {\n        if (this.flagRegistry[flagName] == null) {\n            throw new Error(`Cannot set flag ${flagName} as it has not been registered.`);\n        }\n        this.flags[flagName] = value;\n        if (this.flagRegistry[flagName].setHook != null) {\n            this.flagRegistry[flagName].setHook(value);\n        }\n    }\n    evaluateFlag(flagName) {\n        if (this.flagRegistry[flagName] == null) {\n            throw new Error(`Cannot evaluate flag '${flagName}': no evaluation function found.`);\n        }\n        return this.flagRegistry[flagName].evaluationFn();\n    }\n    setFlags(flags) {\n        this.flags = Object.assign({}, flags);\n    }\n    reset() {\n        this.flags = {};\n        this.urlFlags = {};\n        this.populateURLFlags();\n    }\n    populateURLFlags() {\n        if (typeof this.global === 'undefined' ||\n            typeof this.global.location === 'undefined' ||\n            typeof this.global.location.search === 'undefined') {\n            return;\n        }\n        const urlParams = getQueryParams(this.global.location.search);\n        if (TENSORFLOWJS_FLAGS_PREFIX in urlParams) {\n            const keyValues = urlParams[TENSORFLOWJS_FLAGS_PREFIX].split(',');\n            keyValues.forEach(keyValue => {\n                const [key, value] = keyValue.split(':');\n                this.urlFlags[key] = parseValue(key, value);\n            });\n        }\n    }\n}\nexport function getQueryParams(queryString) {\n    const params = {};\n    queryString.replace(/[?&]([^=?&]+)(?:=([^&]*))?/g, (s, ...t) => {\n        decodeParam(params, t[0], t[1]);\n        return t.join('=');\n    });\n    return params;\n}\nfunction decodeParam(params, name, value) {\n    params[decodeURIComponent(name)] = decodeURIComponent(value || '');\n}\nfunction parseValue(flagName, value) {\n    value = value.toLowerCase();\n    if (value === 'true' || value === 'false') {\n        return value === 'true';\n    }\n    else if (`${+value}` === value) {\n        return +value;\n    }\n    throw new Error(`Could not parse value flag value ${value} for flag ${flagName}.`);\n}\n/**\n * Returns the current environment (a global singleton).\n *\n * The environment object contains the evaluated feature values as well as the\n * active platform.\n *\n * @doc {heading: 'Environment'}\n */\nexport function env() {\n    return ENV;\n}\nexport let ENV = null;\nexport function setEnvironmentGlobal(environment) {\n    ENV = environment;\n}\n//# sourceMappingURL=environment.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n/**\n * Merges real and imaginary Float32Arrays into a single complex Float32Array.\n *\n * The memory layout is interleaved as follows:\n * real: [r0, r1, r2]\n * imag: [i0, i1, i2]\n * complex: [r0, i0, r1, i1, r2, i2]\n *\n * This is the inverse of splitRealAndImagArrays.\n *\n * @param real The real values of the complex tensor values.\n * @param imag The imag values of the complex tensor values.\n * @returns A complex tensor as a Float32Array with merged values.\n */\nexport function mergeRealAndImagArrays(real, imag) {\n    if (real.length !== imag.length) {\n        throw new Error(`Cannot merge real and imag arrays of different lengths. real:` +\n            `${real.length}, imag: ${imag.length}.`);\n    }\n    const result = new Float32Array(real.length * 2);\n    for (let i = 0; i < result.length; i += 2) {\n        result[i] = real[i / 2];\n        result[i + 1] = imag[i / 2];\n    }\n    return result;\n}\n/**\n * Splits a complex Float32Array into real and imag parts.\n *\n * The memory layout is interleaved as follows:\n * complex: [r0, i0, r1, i1, r2, i2]\n * real: [r0, r1, r2]\n * imag: [i0, i1, i2]\n *\n * This is the inverse of mergeRealAndImagArrays.\n *\n * @param complex The complex tensor values.\n * @returns An object with real and imag Float32Array components of the complex\n *     tensor.\n */\nexport function splitRealAndImagArrays(complex) {\n    const real = new Float32Array(complex.length / 2);\n    const imag = new Float32Array(complex.length / 2);\n    for (let i = 0; i < complex.length; i += 2) {\n        real[i / 2] = complex[i];\n        imag[i / 2] = complex[i + 1];\n    }\n    return { real, imag };\n}\n/**\n * Extracts even indexed complex values in the given array.\n * @param complex The complex tensor values\n */\nexport function complexWithEvenIndex(complex) {\n    const len = Math.ceil(complex.length / 4);\n    const real = new Float32Array(len);\n    const imag = new Float32Array(len);\n    for (let i = 0; i < complex.length; i += 4) {\n        real[Math.floor(i / 4)] = complex[i];\n        imag[Math.floor(i / 4)] = complex[i + 1];\n    }\n    return { real, imag };\n}\n/**\n * Extracts odd indexed comple values in the given array.\n * @param complex The complex tensor values\n */\nexport function complexWithOddIndex(complex) {\n    const len = Math.floor(complex.length / 4);\n    const real = new Float32Array(len);\n    const imag = new Float32Array(len);\n    for (let i = 2; i < complex.length; i += 4) {\n        real[Math.floor(i / 4)] = complex[i];\n        imag[Math.floor(i / 4)] = complex[i + 1];\n    }\n    return { real, imag };\n}\n/**\n * Get the map representing a complex value in the given array.\n * @param complex The complex tensor values.\n * @param index An index of the target complex value.\n */\nexport function getComplexWithIndex(complex, index) {\n    const real = complex[index * 2];\n    const imag = complex[index * 2 + 1];\n    return { real, imag };\n}\n/**\n * Insert a given complex value into the TypedArray.\n * @param data The array in which the complex value is inserted.\n * @param c The complex value to be inserted.\n * @param index An index of the target complex value.\n */\nexport function assignToTypedArray(data, real, imag, index) {\n    data[index * 2] = real;\n    data[index * 2 + 1] = imag;\n}\n/**\n * Make the list of exponent terms used by FFT.\n */\nexport function exponents(n, inverse) {\n    const real = new Float32Array(n / 2);\n    const imag = new Float32Array(n / 2);\n    for (let i = 0; i < Math.ceil(n / 2); i++) {\n        const x = (inverse ? 2 : -2) * Math.PI * (i / n);\n        real[i] = Math.cos(x);\n        imag[i] = Math.sin(x);\n    }\n    return { real, imag };\n}\n/**\n * Make the exponent term used by FFT.\n */\nexport function exponent(k, n, inverse) {\n    const x = (inverse ? 2 : -2) * Math.PI * (k / n);\n    const real = Math.cos(x);\n    const imag = Math.sin(x);\n    return { real, imag };\n}\n//# sourceMappingURL=complex_util.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { cast } from '../ops/cast';\nimport { scalar } from '../ops/scalar';\nimport { zeros } from '../ops/zeros';\nimport { decodeString, encodeString, hasEncodingLoss } from '../util';\n// Utilities needed by backend consumers of tf-core.\nexport * from '../ops/axis_util';\nexport * from '../ops/broadcast_util';\nexport * from '../ops/concat_util';\nexport * from '../ops/conv_util';\nexport * from '../ops/fused_util';\nexport * from '../ops/reduce_util';\nimport * as slice_util from '../ops/slice_util';\nexport { slice_util };\nexport { upcastType } from '../types';\nexport * from '../ops/rotate_util';\nexport * from '../ops/array_ops_util';\nexport * from '../ops/gather_nd_util';\nexport * from '../ops/scatter_nd_util';\nexport * from '../ops/selu_util';\nexport * from '../ops/fused_util';\nexport * from '../ops/erf_util';\nexport * from '../log';\nexport * from '../backends/complex_util';\nexport * from '../ops/split_util';\nimport * as segment_util from '../ops/segment_util';\nexport { segment_util };\nexport function castTensor(x, dtype, backend) {\n    if (dtype === 'complex64') {\n        if (x.dtype === 'complex64') {\n            return x.clone();\n        }\n        const zerosTensor = zeros(x.shape);\n        const floatX = cast(x, 'float32');\n        const result = backend.complex(floatX, zerosTensor);\n        zerosTensor.dispose();\n        floatX.dispose();\n        return result;\n    }\n    if (!hasEncodingLoss(x.dtype, dtype)) {\n        // We don't change the underlying data, since we cast to higher\n        // precision.\n        return ENGINE.makeTensorFromDataId(x.dataId, x.shape, dtype);\n    }\n    if (x.dtype === 'complex64') {\n        const real = backend.real(x);\n        const result = cast(real, dtype);\n        real.dispose();\n        return result;\n    }\n    if (dtype === 'int32') {\n        return backend.int(x);\n    }\n    else if (dtype === 'bool') {\n        const zero = scalar(0, x.dtype);\n        const result = backend.notEqual(x, zero);\n        zero.dispose();\n        return result;\n    }\n    else {\n        throw new Error(`Error in Cast: failed to cast ${x.dtype} to ${dtype}`);\n    }\n}\nexport function reshapeTensor(x, shape) {\n    return ENGINE.makeTensorFromDataId(x.dataId, shape, x.dtype);\n}\nexport function fromUint8ToStringArray(vals) {\n    try {\n        // Decode the bytes into string.\n        return vals.map(val => decodeString(val));\n    }\n    catch (err) {\n        throw new Error(`Failed to decode encoded string bytes into utf-8, error: ${err}`);\n    }\n}\nexport function fromStringArrayToUint8(strings) {\n    return strings.map(s => encodeString(s));\n}\n//# sourceMappingURL=backend_util.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { KernelBackend } from './backends/backend';\nimport { Environment, setEnvironmentGlobal } from './environment';\nimport { getGlobalNamespace } from './global_util';\nimport { Add, Cast } from './kernel_names';\nimport { getGradient, getKernel, getKernelsForBackend } from './kernel_registry';\nimport { Profiler } from './profiler';\nimport { backpropagateGradients, getFilteredNodesXToY } from './tape';\nimport { setTensorTracker, Tensor, Variable } from './tensor';\nimport { getTensorsInContainer } from './tensor_util';\nimport * as util from './util';\nimport { bytesFromStringArray, makeOnesTypedArray, now, sizeFromShape } from './util';\nclass EngineState {\n    constructor() {\n        // Public since optimizers will use it.\n        this.registeredVariables = {};\n        this.nextTapeNodeId = 0;\n        this.numBytes = 0;\n        this.numTensors = 0;\n        this.numStringTensors = 0;\n        this.numDataBuffers = 0;\n        // Number of nested tf.grad() statements when computing higher-order\n        // gradients. E.g. `1` for first-order gradients and `2` for second-order\n        // gradients. Used to track if the tape should be removed after a backprop.\n        this.gradientDepth = 0;\n        // Number of nested kernel calls. When kernel depth is greater than 1, we turn\n        // off the tape.\n        this.kernelDepth = 0;\n        this.scopeStack = [];\n        /**\n         * Keeps track of the number of data moves during a kernel execution. We\n         * maintain a stack since kernels can call other kernels, recursively.\n         */\n        this.numDataMovesStack = [];\n        this.nextScopeId = 0;\n        this.tensorInfo = new WeakMap();\n        this.profiling = false;\n        this.activeProfile = {\n            newBytes: 0,\n            newTensors: 0,\n            peakBytes: 0,\n            kernels: [],\n            result: null,\n            get kernelNames() {\n                return Array.from(new Set(this.kernels.map(k => k.name)));\n            }\n        };\n    }\n    dispose() {\n        for (const variableName in this.registeredVariables) {\n            this.registeredVariables[variableName].dispose();\n        }\n    }\n}\nexport class Engine {\n    constructor(ENV) {\n        this.ENV = ENV;\n        this.registry = {};\n        this.registryFactory = {};\n        this.pendingBackendInitId = 0;\n        this.state = new EngineState();\n    }\n    async ready() {\n        if (this.pendingBackendInit != null) {\n            return this.pendingBackendInit.then(() => { });\n        }\n        if (this.backendInstance != null) {\n            return;\n        }\n        const sortedBackends = this.getSortedBackends();\n        for (let i = 0; i < sortedBackends.length; i++) {\n            const backendName = sortedBackends[i];\n            const success = await this.initializeBackend(backendName).success;\n            if (success) {\n                await this.setBackend(backendName);\n                return;\n            }\n        }\n        throw new Error(`Could not initialize any backends, all backend initializations ` +\n            `failed.`);\n    }\n    get backend() {\n        if (this.pendingBackendInit != null) {\n            throw new Error(`Backend '${this.backendName}' has not yet been initialized. Make ` +\n                `sure to await tf.ready() or await tf.setBackend() before calling ` +\n                `other methods`);\n        }\n        if (this.backendInstance == null) {\n            const { name, asyncInit } = this.initializeBackendsAndReturnBest();\n            if (asyncInit) {\n                throw new Error(`The highest priority backend '${name}' has not yet been ` +\n                    `initialized. Make sure to await tf.ready() or ` +\n                    `await tf.setBackend() before calling other methods`);\n            }\n            this.setBackend(name);\n        }\n        return this.backendInstance;\n    }\n    backendNames() {\n        return Object.keys(this.registryFactory);\n    }\n    findBackend(backendName) {\n        if (!(backendName in this.registry)) {\n            // If the backend hasn't been initialized but we have a registry entry for\n            // it, initialize it and return it.\n            if (backendName in this.registryFactory) {\n                const { asyncInit } = this.initializeBackend(backendName);\n                if (asyncInit) {\n                    // Backend is not ready yet.\n                    return null;\n                }\n            }\n            else {\n                return null;\n            }\n        }\n        return this.registry[backendName];\n    }\n    findBackendFactory(backendName) {\n        if (!(backendName in this.registryFactory)) {\n            return null;\n        }\n        return this.registryFactory[backendName].factory;\n    }\n    registerBackend(backendName, factory, priority = 1) {\n        if (backendName in this.registryFactory) {\n            console.warn(`${backendName} backend was already registered. ` +\n                `Reusing existing backend factory.`);\n            return false;\n        }\n        this.registryFactory[backendName] = { factory, priority };\n        return true;\n    }\n    async setBackend(backendName) {\n        if (this.registryFactory[backendName] == null) {\n            throw new Error(`Backend name '${backendName}' not found in registry`);\n        }\n        this.backendName = backendName;\n        if (this.registry[backendName] == null) {\n            this.backendInstance = null;\n            const { success, asyncInit } = this.initializeBackend(backendName);\n            const result = asyncInit ? await success : success;\n            if (!result) {\n                return false;\n            }\n        }\n        this.backendInstance = this.registry[backendName];\n        this.setupRegisteredKernels();\n        // Reset the profiler.\n        this.profiler = new Profiler(this.backendInstance);\n        return true;\n    }\n    setupRegisteredKernels() {\n        const kernels = getKernelsForBackend(this.backendName);\n        kernels.forEach(kernel => {\n            if (kernel.setupFunc != null) {\n                kernel.setupFunc(this.backendInstance);\n            }\n        });\n    }\n    disposeRegisteredKernels(backendName) {\n        const kernels = getKernelsForBackend(backendName);\n        kernels.forEach(kernel => {\n            if (kernel.disposeFunc != null) {\n                kernel.disposeFunc(this.registry[backendName]);\n            }\n        });\n    }\n    /**\n     * Initializes a backend by looking up the backend name in the factory\n     * registry and calling the factory method. Returns a boolean representing\n     * whether the initialization of the backend suceeded. Throws an error if\n     * there is no backend in the factory registry.\n     */\n    initializeBackend(backendName) {\n        const registryFactoryEntry = this.registryFactory[backendName];\n        if (registryFactoryEntry == null) {\n            throw new Error(`Cannot initialize backend ${backendName}, no registration found.`);\n        }\n        try {\n            const backend = registryFactoryEntry.factory();\n            /* Test if the factory returns a promise.\n            Done in a more liberal way than\n            previous 'Promise.resolve(backend)===backend'\n            as we needed to account for custom Promise\n            implementations (e.g. Angular) */\n            if (backend && !(backend instanceof KernelBackend) &&\n                typeof backend.then === 'function') {\n                const promiseId = ++this.pendingBackendInitId;\n                const success = backend\n                    .then(backendInstance => {\n                    // Outdated promise. Another backend was set in the meantime.\n                    if (promiseId < this.pendingBackendInitId) {\n                        return false;\n                    }\n                    this.registry[backendName] = backendInstance;\n                    this.pendingBackendInit = null;\n                    return true;\n                })\n                    .catch(err => {\n                    // Outdated promise. Another backend was set in the meantime.\n                    if (promiseId < this.pendingBackendInitId) {\n                        return false;\n                    }\n                    this.pendingBackendInit = null;\n                    console.warn(`Initialization of backend ${backendName} failed`);\n                    console.warn(err.stack || err.message);\n                    return false;\n                });\n                this.pendingBackendInit = success;\n                return { success, asyncInit: true };\n            }\n            else {\n                this.registry[backendName] = backend;\n                return { success: true, asyncInit: false };\n            }\n        }\n        catch (err) {\n            console.warn(`Initialization of backend ${backendName} failed`);\n            console.warn(err.stack || err.message);\n            return { success: false, asyncInit: false };\n        }\n    }\n    removeBackend(backendName) {\n        if (!(backendName in this.registryFactory)) {\n            throw new Error(`${backendName} backend not found in registry`);\n        }\n        if (this.backendName === backendName && this.pendingBackendInit != null) {\n            // There is a pending promise of the backend we want to remove. Make it\n            // obsolete.\n            this.pendingBackendInitId++;\n        }\n        if (backendName in this.registry) {\n            this.disposeRegisteredKernels(backendName);\n            this.registry[backendName].dispose();\n            delete this.registry[backendName];\n        }\n        delete this.registryFactory[backendName];\n        // Unset the backend if it is active.\n        if (this.backendName === backendName) {\n            this.pendingBackendInit = null;\n            this.backendName = null;\n            this.backendInstance = null;\n        }\n    }\n    getSortedBackends() {\n        if (Object.keys(this.registryFactory).length === 0) {\n            throw new Error('No backend found in registry.');\n        }\n        return Object.keys(this.registryFactory).sort((a, b) => {\n            // Highest priority comes first.\n            return this.registryFactory[b].priority -\n                this.registryFactory[a].priority;\n        });\n    }\n    initializeBackendsAndReturnBest() {\n        const sortedBackends = this.getSortedBackends();\n        for (let i = 0; i < sortedBackends.length; i++) {\n            const backendName = sortedBackends[i];\n            const { success, asyncInit } = this.initializeBackend(backendName);\n            if (asyncInit || success) {\n                return { name: backendName, asyncInit };\n            }\n        }\n        throw new Error(`Could not initialize any backends, all backend initializations ` +\n            `failed.`);\n    }\n    moveData(backend, dataId) {\n        const info = this.state.tensorInfo.get(dataId);\n        const srcBackend = info.backend;\n        const values = this.readSync(dataId);\n        // Delete the tensor from the old backend and move it to the new\n        // backend.\n        srcBackend.disposeData(dataId);\n        info.backend = backend;\n        backend.move(dataId, values, info.shape, info.dtype);\n        if (this.shouldCheckForMemLeaks()) {\n            // Track the number of moves during a kernel execution to correctly\n            // detect memory leaks.\n            this.state.numDataMovesStack[this.state.numDataMovesStack.length - 1]++;\n        }\n    }\n    tidy(nameOrFn, fn) {\n        let name = null;\n        if (fn == null) {\n            // Called with only 1 argument.\n            if (typeof nameOrFn !== 'function') {\n                throw new Error('Please provide a function to tidy()');\n            }\n            fn = nameOrFn;\n        }\n        else {\n            // Called with 2 arguments.\n            if (typeof nameOrFn !== 'string' && !(nameOrFn instanceof String)) {\n                throw new Error('When calling with two arguments, the first argument ' +\n                    'to tidy() must be a string');\n            }\n            if (typeof fn !== 'function') {\n                throw new Error('When calling with two arguments, the 2nd argument ' +\n                    'to tidy() must be a function');\n            }\n            name = nameOrFn;\n            // TODO(nsthorat,smilkov): Do operation logging and performance\n            // profiling.\n        }\n        let result;\n        return this.scopedRun(() => this.startScope(name), () => this.endScope(result), () => {\n            result = fn();\n            if (result instanceof Promise) {\n                console.error('Cannot return a Promise inside of tidy.');\n            }\n            return result;\n        });\n    }\n    scopedRun(start, end, f) {\n        start();\n        try {\n            const res = f();\n            end();\n            return res;\n        }\n        catch (ex) {\n            end();\n            throw ex;\n        }\n    }\n    nextTensorId() {\n        return Engine.nextTensorId++;\n    }\n    nextVariableId() {\n        return Engine.nextVariableId++;\n    }\n    /**\n     * This method is called instead of the public-facing tensor.clone() when\n     * saving a tensor for backwards pass. It makes sure to add the clone\n     * operation to the tape regardless of being called inside a kernel\n     * execution.\n     *\n     * This method will go away once all kernels are modularized since we won't\n     * need to turn off the tape inside runKernel().\n     */\n    clone(x) {\n        const y = this.makeTensorFromDataId(x.dataId, x.shape, x.dtype);\n        const inputs = { x };\n        const grad = (dy) => ({\n            x: () => {\n                const dtype = 'float32';\n                const gradInputs = { x: dy };\n                const attrs = { dtype };\n                return ENGINE.runKernelFunc(backend => backend.cast(dy, dtype), gradInputs, null /* grad */, Cast, attrs);\n            }\n        });\n        const saved = [];\n        this.addTapeNode(this.state.activeScope.name, inputs, [y], grad, saved, {});\n        return y;\n    }\n    /**\n     * Execute a kernel with the given name and return the output tensor.\n     *\n     * @param kernelName The name of the kernel to execute.\n     * @param inputs A map of input names to tensors.\n     * @param attrs A map of attribute names to their values. An attribute is a\n     *     primitive (non-tensor) input to the kernel.\n     * @param inputsToSave A list of tensors, inputs to save for the backprop\n     *     computation.\n     * @param outputsToSave A list of booleans, specifying which output to save\n     *     for the backprop computation. These are booleans since the output\n     * tensors are not visible to the user.\n     */\n    runKernel(kernelName, inputs, attrs, inputsToSave, outputsToSave) {\n        const forwardFunc = null;\n        const backwardsFunc = null;\n        // Call runKernel as a stop-gap until we modularize all kernels.\n        // Once we modularize all kernels, we will remove the existing\n        // `runKernelFunc`.\n        return this.runKernelFunc(forwardFunc, inputs, backwardsFunc, kernelName, attrs, inputsToSave, outputsToSave);\n    }\n    shouldCheckForMemLeaks() {\n        return this.ENV.getBool('IS_TEST');\n    }\n    checkKernelForMemLeak(kernelName, numDataIdsBefore, outInfos) {\n        const numDataIdsAfter = this.backend.numDataIds();\n        // Count the number of data ids associated with the result of the kernel.\n        let numOutputDataIds = 0;\n        outInfos.forEach(info => {\n            // Complex numbers allocate 3 data ids, one for 'real', one for\n            // 'imaginary', and one for the container that holds the former two.\n            numOutputDataIds += (info.dtype === 'complex64' ? 3 : 1);\n        });\n        // Account for the number of moves during kernel execution. A \"data move\"\n        // can happen in the middle of a kernel execution, placing a new (key,value)\n        // pair in the data storage. Since data moves have net zero effect (we\n        // always remove the data from the old backend), we have to cancel them out\n        // when detecting memory leaks.\n        const numMoves = this.state.numDataMovesStack[this.state.numDataMovesStack.length - 1];\n        const dataIdsLeaked = numDataIdsAfter - numDataIdsBefore - numOutputDataIds - numMoves;\n        if (dataIdsLeaked > 0) {\n            throw new Error(`Backend '${this.backendName}' has an internal memory leak ` +\n                `(${dataIdsLeaked} data ids) after running '${kernelName}'`);\n        }\n    }\n    /**\n     * @deprecated Use `runKernel` for newly added kernels. Keep using this method\n     *     only for kernels that are not yet fully modularized.\n     */\n    runKernelFunc(forwardFunc, inputs, backwardsFunc, kernelName, attrs, inputsToSave, outputsToSave) {\n        let outputs;\n        let saved = [];\n        const isTapeOn = this.isTapeOn();\n        if (kernelName == null) {\n            kernelName =\n                this.state.activeScope != null ? this.state.activeScope.name : '';\n        }\n        const startingBytecount = this.state.numBytes;\n        const startingNumTensors = this.state.numTensors;\n        if (this.shouldCheckForMemLeaks()) {\n            this.state.numDataMovesStack.push(0);\n        }\n        let kernelFunc;\n        if (this.backendName == null) {\n            // backend has not been initialized yet (backend initialization is lazy\n            // can be deferred until an op/ kernel is run).\n            // The below getter has side effects that will try to initialize the\n            // backend and set properties like this.backendName\n            // tslint:disable-next-line: no-unused-expression\n            this.backend;\n        }\n        const kernel = getKernel(kernelName, this.backendName);\n        let out;\n        if (kernel != null) {\n            kernelFunc = () => {\n                const numDataIdsBefore = this.backend.numDataIds();\n                out = kernel.kernelFunc({ inputs, attrs, backend: this.backend });\n                const outInfos = Array.isArray(out) ? out : [out];\n                if (this.shouldCheckForMemLeaks()) {\n                    this.checkKernelForMemLeak(kernelName, numDataIdsBefore, outInfos);\n                }\n                const outTensors = outInfos.map((outInfo) => {\n                    // todo (yassogba) remove this option (Tensor) when node backend\n                    // methods have been modularized and they all return tensorInfo.\n                    // TensorInfos do not have a rank attribute.\n                    if (outInfo.rank != null) {\n                        return outInfo;\n                    }\n                    const { dataId, shape, dtype } = outInfo;\n                    return this.makeTensorFromDataId(dataId, shape, dtype);\n                });\n                // Save the inputs and outputs.\n                // Do not save unless we are recording to the tape. Otherwise it would\n                // cause a mem leak since we would never run backprop, which disposes\n                // the kept tensors.\n                if (isTapeOn) {\n                    let tensorsToSave = this.getTensorsForGradient(kernelName, inputs, outTensors);\n                    if (tensorsToSave == null) {\n                        // Fallback for ops that call runKernelFunc and pass in\n                        // inputsToSave and outputsToSave. Currently this is the set of ops\n                        // with kernel support in the WASM backend. Once those ops and\n                        // respective gradients are modularised we can remove this path.\n                        if (outputsToSave == null) {\n                            outputsToSave = [];\n                        }\n                        const outsToSave = outTensors.filter((_, i) => outputsToSave[i]);\n                        tensorsToSave = (inputsToSave || []).slice().concat(outsToSave);\n                    }\n                    saved = this.saveTensorsForBackwardMode(tensorsToSave);\n                }\n                return outTensors;\n            };\n        }\n        else {\n            if (forwardFunc == null) {\n                throw new Error(`Error running ${kernelName}: Neither modular kernel nor forward func passed`);\n            }\n            const saveFunc = (tensors) => {\n                // Do not save unless we are recording to the tape. Otherwise it would\n                // cause a mem leak since we would never run backprop, which disposes\n                // the kept tensors.\n                if (!isTapeOn) {\n                    return;\n                }\n                saved = tensors.map(tensor => this.keep(this.clone(tensor)));\n            };\n            kernelFunc = () => {\n                const numDataIdsBefore = this.backend.numDataIds();\n                out = this.tidy(() => forwardFunc(this.backend, saveFunc));\n                const outs = (Array.isArray(out) ? out : [out]);\n                if (this.shouldCheckForMemLeaks()) {\n                    this.checkKernelForMemLeak(kernelName, numDataIdsBefore, outs);\n                }\n                return outs;\n            };\n        }\n        // Stop recording to a tape when running a kernel.\n        let kernelProfile;\n        this.scopedRun(() => this.state.kernelDepth++, () => this.state.kernelDepth--, () => {\n            if (!this.ENV.getBool('DEBUG') && !this.state.profiling) {\n                outputs = kernelFunc();\n            }\n            else {\n                kernelProfile = this.profiler.profileKernel(kernelName, inputs, () => kernelFunc());\n                if (this.ENV.getBool('DEBUG')) {\n                    this.profiler.logKernelProfile(kernelProfile);\n                }\n                outputs = kernelProfile.outputs;\n            }\n        });\n        if (isTapeOn) {\n            this.addTapeNode(kernelName, inputs, outputs, backwardsFunc, saved, attrs);\n        }\n        if (this.state.profiling) {\n            this.state.activeProfile.kernels.push({\n                name: kernelName,\n                bytesAdded: this.state.numBytes - startingBytecount,\n                totalBytesSnapshot: this.state.numBytes,\n                tensorsAdded: this.state.numTensors - startingNumTensors,\n                totalTensorsSnapshot: this.state.numTensors,\n                inputShapes: Object.keys(inputs).map(key => inputs[key] != null ? inputs[key].shape : null),\n                outputShapes: outputs.map(item => item.shape),\n                kernelTimeMs: kernelProfile.timeMs,\n                extraInfo: kernelProfile.extraInfo\n            });\n        }\n        return (Array.isArray(out) ? outputs : outputs[0]);\n    }\n    /**\n     * Saves tensors used in forward mode for use in backward mode.\n     *\n     * @param tensors the list of tensors to save.\n     */\n    saveTensorsForBackwardMode(tensors) {\n        const saved = tensors.map(tensor => this.keep(this.clone(tensor)));\n        return saved;\n    }\n    /**\n     * Returns a list of tensors to save for a given gradient calculation.\n     *\n     * Returns undefined if their is no registered gradient for this kernel in the\n     * gradient registry.\n     *\n     * @param kernelName name of kernel to look up gradient for.\n     * @param inputs a map of input tensors.\n     * @param outputs an array of output tensors from forward mode of kernel.\n     */\n    getTensorsForGradient(kernelName, inputs, outputs) {\n        const gradConfig = getGradient(kernelName);\n        if (gradConfig != null) {\n            const inputsToSave = gradConfig.inputsToSave || [];\n            const outputsToSave = gradConfig.outputsToSave || [];\n            // If saveAllInputs is true, all inputs will be saved. Otherwise, inputs\n            // specified in inputsToSave will be saved.\n            let inputTensorsToSave;\n            if (gradConfig.saveAllInputs) {\n                util.assert(Array.isArray(inputs), () => 'saveAllInputs is true, expected inputs to be an array.');\n                inputTensorsToSave = Object.keys(inputs).map((key) => inputs[key]);\n            }\n            else {\n                inputTensorsToSave = inputsToSave.map((inputName) => inputs[inputName]);\n            }\n            const outputTensorsToSave = outputs.filter((_, i) => outputsToSave[i]);\n            return inputTensorsToSave.concat(outputTensorsToSave);\n        }\n        // TODO(yassogba) throw exception here once all runkernelFunc calls with\n        // inputsToSave/outputsToSave are removed\n        return null;\n    }\n    /**\n     * Internal method used by public APIs for tensor creation. Makes a new\n     * tensor with the provided shape, dtype and values. It always\n     * creates a new data id and writes the values to the underlying backend.\n     */\n    makeTensor(values, shape, dtype, backend) {\n        if (values == null) {\n            throw new Error('Values passed to engine.makeTensor() are null');\n        }\n        dtype = dtype || 'float32';\n        backend = backend || this.backend;\n        let backendVals = values;\n        if (dtype === 'string' && util.isString(values[0])) {\n            backendVals = values.map(d => util.encodeString(d));\n        }\n        const dataId = backend.write(backendVals, shape, dtype);\n        const t = new Tensor(shape, dtype, dataId, this.nextTensorId());\n        this.incRef(t, backend);\n        // Count bytes for string tensors.\n        if (dtype === 'string') {\n            const info = this.state.tensorInfo.get(dataId);\n            const newBytes = bytesFromStringArray(backendVals);\n            this.state.numBytes += newBytes - info.bytes;\n            info.bytes = newBytes;\n        }\n        return t;\n    }\n    /**\n     * Internal method used by backends. Makes a new tensor\n     * that is a wrapper around an existing data id. It doesn't create\n     * a new data id, only increments the ref count used in memory tracking.\n     */\n    makeTensorFromDataId(dataId, shape, dtype, backend) {\n        dtype = dtype || 'float32';\n        const t = new Tensor(shape, dtype, dataId, this.nextTensorId());\n        this.incRef(t, backend);\n        return t;\n    }\n    makeVariable(initialValue, trainable = true, name, dtype) {\n        name = name || this.nextVariableId().toString();\n        if (dtype != null && dtype !== initialValue.dtype) {\n            initialValue = initialValue.cast(dtype);\n        }\n        const v = new Variable(initialValue, trainable, name, this.nextTensorId());\n        if (this.state.registeredVariables[v.name] != null) {\n            throw new Error(`Variable with name ${v.name} was already registered`);\n        }\n        this.state.registeredVariables[v.name] = v;\n        this.incRef(v, this.backend);\n        return v;\n    }\n    incRef(a, backend) {\n        const refCount = this.state.tensorInfo.has(a.dataId) ?\n            this.state.tensorInfo.get(a.dataId).refCount :\n            0;\n        this.state.numTensors++;\n        if (a.dtype === 'string') {\n            this.state.numStringTensors++;\n        }\n        if (refCount === 0) {\n            this.state.numDataBuffers++;\n            // Bytes for complex numbers are counted by their components. Bytes for\n            // string tensors are counted when writing values.\n            let bytes = 0;\n            if (a.dtype !== 'complex64' && a.dtype !== 'string') {\n                bytes = a.size * util.bytesPerElement(a.dtype);\n            }\n            this.state.tensorInfo.set(a.dataId, {\n                backend: backend || this.backend,\n                dtype: a.dtype,\n                shape: a.shape,\n                bytes,\n                refCount: 0\n            });\n            this.state.numBytes += bytes;\n        }\n        this.state.tensorInfo.get(a.dataId).refCount++;\n        if (!(a instanceof Variable)) {\n            this.track(a);\n        }\n    }\n    disposeTensor(a) {\n        if (!this.state.tensorInfo.has(a.dataId)) {\n            return;\n        }\n        this.state.numTensors--;\n        if (a.dtype === 'string') {\n            this.state.numStringTensors--;\n        }\n        const info = this.state.tensorInfo.get(a.dataId);\n        const refCount = info.refCount;\n        if (refCount <= 1) {\n            // Don't count bytes for complex numbers as they are counted by their\n            // components.\n            if (a.dtype !== 'complex64') {\n                this.state.numBytes -= info.bytes;\n            }\n            this.state.numDataBuffers--;\n            info.backend.disposeData(a.dataId);\n            this.state.tensorInfo.delete(a.dataId);\n        }\n        else {\n            // Notify the backend to descrease the ref count for complex tensor\n            // components. This method is only implemented in WebGL right now. When\n            // there are multiple references, complex tensor cannot dispose the\n            // components if ref count is not in sync with engine.\n            info.backend.decComplexRef(a.dataId);\n            this.state.tensorInfo.get(a.dataId).refCount--;\n        }\n        // TODO(nsthorat): Construct an error and save the stack trace for\n        // debugging when in debug mode. Creating a stack trace is too expensive\n        // to do unconditionally.\n    }\n    disposeVariables() {\n        for (const varName in this.state.registeredVariables) {\n            const v = this.state.registeredVariables[varName];\n            this.disposeVariable(v);\n        }\n    }\n    disposeVariable(v) {\n        this.disposeTensor(v);\n        if (this.state.registeredVariables[v.name] != null) {\n            delete this.state.registeredVariables[v.name];\n        }\n    }\n    memory() {\n        const info = this.backend.memory();\n        info.numTensors = this.state.numTensors;\n        info.numDataBuffers = this.state.numDataBuffers;\n        info.numBytes = this.state.numBytes;\n        if (this.state.numStringTensors > 0) {\n            info.unreliable = true;\n            if (info.reasons == null) {\n                info.reasons = [];\n            }\n            info.reasons.push('Memory usage by string tensors is approximate ' +\n                '(2 bytes per character)');\n        }\n        return info;\n    }\n    async profile(query) {\n        this.state.profiling = true;\n        const startBytes = this.state.numBytes;\n        const startNumTensors = this.state.numTensors;\n        this.state.activeProfile.kernels = [];\n        this.state.activeProfile.result = await query();\n        this.state.profiling = false;\n        this.state.activeProfile.peakBytes = Math.max(...this.state.activeProfile.kernels.map(d => d.totalBytesSnapshot));\n        this.state.activeProfile.newBytes = this.state.numBytes - startBytes;\n        this.state.activeProfile.newTensors =\n            this.state.numTensors - startNumTensors;\n        for (const kernel of this.state.activeProfile.kernels) {\n            kernel.kernelTimeMs = await kernel.kernelTimeMs;\n            kernel.extraInfo = await kernel.extraInfo;\n        }\n        return this.state.activeProfile;\n    }\n    isTapeOn() {\n        return this.state.gradientDepth > 0 && this.state.kernelDepth === 0;\n    }\n    addTapeNode(kernelName, inputs, outputs, gradientsFunc, saved, attrs) {\n        const tapeNode = { id: this.state.nextTapeNodeId++, kernelName, inputs, outputs, saved };\n        const gradConfig = getGradient(kernelName);\n        if (gradConfig != null) {\n            gradientsFunc = gradConfig.gradFunc;\n        }\n        if (gradientsFunc != null) {\n            tapeNode.gradient = (dys) => {\n                // TODO(smilkov): To optimize back-prop, pass dys that are not used in\n                // the backprop graph to the user as null instead of zeros\n                dys = dys.map((dy, i) => {\n                    if (dy == null) {\n                        const output = outputs[i];\n                        const vals = util.makeZerosTypedArray(output.size, output.dtype);\n                        return this.makeTensor(vals, output.shape, output.dtype);\n                    }\n                    return dy;\n                });\n                // Grad functions of ops with single outputs expect a dy, while ops\n                // with multiple outputs expect dys (array of dy).\n                return gradientsFunc(dys.length > 1 ? dys : dys[0], saved, attrs);\n            };\n        }\n        this.state.activeTape.push(tapeNode);\n    }\n    keep(result) {\n        result.kept = true;\n        return result;\n    }\n    startTape() {\n        if (this.state.gradientDepth === 0) {\n            this.state.activeTape = [];\n        }\n        this.state.gradientDepth++;\n    }\n    endTape() {\n        this.state.gradientDepth--;\n    }\n    /**\n     * Start a scope. Use this with endScope() to achieve the same functionality\n     * as scope() without the need for a function closure.\n     */\n    startScope(name) {\n        const scopeInfo = {\n            track: [],\n            name: 'unnamed scope',\n            id: this.state.nextScopeId++\n        };\n        if (name) {\n            scopeInfo.name = name;\n        }\n        this.state.scopeStack.push(scopeInfo);\n        this.state.activeScope = scopeInfo;\n    }\n    /**\n     * End a scope. Use this with startScope() to achieve the same functionality\n     * as scope() without the need for a function closure.\n     */\n    endScope(result) {\n        const tensorsToTrackInParent = getTensorsInContainer(result);\n        const tensorsToTrackInParentSet = new Set(tensorsToTrackInParent.map(t => t.id));\n        // Dispose the arrays tracked in this scope.\n        for (let i = 0; i < this.state.activeScope.track.length; i++) {\n            const tensor = this.state.activeScope.track[i];\n            if (!tensor.kept && !tensorsToTrackInParentSet.has(tensor.id)) {\n                tensor.dispose();\n            }\n        }\n        const oldScope = this.state.scopeStack.pop();\n        this.state.activeScope = this.state.scopeStack.length === 0 ?\n            null :\n            this.state.scopeStack[this.state.scopeStack.length - 1];\n        // Track the current result in the parent scope.\n        tensorsToTrackInParent.forEach(tensor => {\n            // Only track the tensor if was allocated in the inner scope and is not\n            // globally kept.\n            if (!tensor.kept && tensor.scopeId === oldScope.id) {\n                this.track(tensor);\n            }\n        });\n    }\n    /**\n     * Returns gradients of `f` with respect to each of the `xs`. The gradients\n     * returned are of the same length as `xs`, but some might be null if `f`\n     * was not a function of that `x`. It also takes optional dy to multiply the\n     * gradient, which defaults to `1`.\n     */\n    gradients(f, xs, dy, allowNoGradients = false) {\n        util.assert(xs.length > 0, () => 'gradients() received an empty list of xs.');\n        if (dy != null && dy.dtype !== 'float32') {\n            throw new Error(`dy must have 'float32' dtype, but has '${dy.dtype}'`);\n        }\n        const y = this.scopedRun(() => this.startTape(), () => this.endTape(), () => this.tidy('forward', f));\n        util.assert(y instanceof Tensor, () => 'The result y returned by f() must be a tensor.');\n        // Filter out the nodes that don't connect x => y.\n        const filteredTape = getFilteredNodesXToY(this.state.activeTape, xs, y);\n        if (!allowNoGradients && filteredTape.length === 0 && xs.length > 0) {\n            throw new Error('Cannot compute gradient of y=f(x) with respect to x. Make sure ' +\n                'that the f you passed encloses all operations that lead from x ' +\n                'to y.');\n        }\n        return this.tidy('backward', () => {\n            const accumulatedGradientMap = {};\n            accumulatedGradientMap[y.id] = (dy == null) ? ones(y.shape) : dy;\n            // Backprop gradients through the filtered nodes.\n            backpropagateGradients(accumulatedGradientMap, filteredTape, \n            // Pass the tidy function to avoid circular dep with `tape.ts`.\n            f => this.tidy(f), \n            // Pass an add function to avoide a circular dep with `tape.ts`.\n            add);\n            const grads = xs.map(x => accumulatedGradientMap[x.id]);\n            if (this.state.gradientDepth === 0) {\n                // This means that we are not computing higher-order gradients\n                // and can clean up the tape.\n                this.state.activeTape.forEach(node => {\n                    for (const tensor of node.saved) {\n                        tensor.dispose();\n                    }\n                });\n                this.state.activeTape = null;\n            }\n            return { value: y, grads };\n        });\n    }\n    customGrad(f) {\n        util.assert(util.isFunction(f), () => 'The f passed in customGrad(f) must be a function.');\n        return (...inputs) => {\n            util.assert(inputs.every(t => t instanceof Tensor), () => 'The args passed in customGrad(f)(x1, x2,...) must all be ' +\n                'tensors');\n            let res;\n            const inputMap = {};\n            inputs.forEach((input, i) => {\n                inputMap[i] = input;\n            });\n            return this.runKernelFunc((_, save) => {\n                res = f(...[...inputs, save]);\n                util.assert(res.value instanceof Tensor, () => 'The function f passed in customGrad(f) must return an ' +\n                    'object where `obj.value` is a tensor');\n                util.assert(util.isFunction(res.gradFunc), () => 'The function f passed in customGrad(f) must return an ' +\n                    'object where `obj.gradFunc` is a function.');\n                return res.value;\n            }, inputMap, (dy, saved) => {\n                const gradRes = res.gradFunc(dy, saved);\n                const grads = Array.isArray(gradRes) ? gradRes : [gradRes];\n                util.assert(grads.length === inputs.length, () => 'The function f passed in customGrad(f) must return an ' +\n                    'object where `obj.gradFunc` is a function that returns ' +\n                    'the same number of tensors as inputs passed to f(...).');\n                util.assert(grads.every(t => t instanceof Tensor), () => 'The function f passed in customGrad(f) must return an ' +\n                    'object where `obj.gradFunc` is a function that returns ' +\n                    'a list of only tensors.');\n                const gradMap = {};\n                grads.forEach((grad, i) => {\n                    gradMap[i] = () => grad;\n                });\n                return gradMap;\n            });\n        };\n    }\n    readSync(dataId) {\n        // Route the read to the correct backend.\n        const info = this.state.tensorInfo.get(dataId);\n        return info.backend.readSync(dataId);\n    }\n    read(dataId) {\n        // Route the read to the correct backend.\n        const info = this.state.tensorInfo.get(dataId);\n        return info.backend.read(dataId);\n    }\n    async time(query) {\n        const start = now();\n        const timingInfo = await this.backend.time(query);\n        timingInfo.wallMs = now() - start;\n        return timingInfo;\n    }\n    /**\n     * Tracks a Tensor in the current scope to be automatically cleaned up\n     * when the current scope ends, and returns the value.\n     *\n     * @param result The Tensor to track in the current scope.\n     */\n    track(result) {\n        if (this.state.activeScope != null) {\n            result.scopeId = this.state.activeScope.id;\n            this.state.activeScope.track.push(result);\n        }\n        return result;\n    }\n    get registeredVariables() {\n        return this.state.registeredVariables;\n    }\n    /**\n     * Resets the engine state. Removes all backends but does not remove\n     * registered backend factories.\n     */\n    reset() {\n        // Make any pending promise obsolete.\n        this.pendingBackendInitId++;\n        this.state.dispose();\n        this.ENV.reset();\n        this.state = new EngineState();\n        for (const backendName in this.registry) {\n            this.disposeRegisteredKernels(backendName);\n            this.registry[backendName].dispose();\n            delete this.registry[backendName];\n        }\n        this.backendName = null;\n        this.backendInstance = null;\n        this.pendingBackendInit = null;\n    }\n}\nEngine.nextTensorId = 0;\nEngine.nextVariableId = 0;\nfunction ones(shape) {\n    const values = makeOnesTypedArray(sizeFromShape(shape), 'float32');\n    return ENGINE.makeTensor(values, shape, 'float32');\n}\nexport function getOrMakeEngine() {\n    const ns = getGlobalNamespace();\n    if (ns._tfengine == null) {\n        const environment = new Environment(ns);\n        ns._tfengine = new Engine(environment);\n    }\n    setEnvironmentGlobal(ns._tfengine.ENV);\n    // Tell the current tensor interface that the global engine is responsible\n    // for tracking.\n    setTensorTracker(() => ns._tfengine);\n    return ns._tfengine;\n}\nexport const ENGINE = getOrMakeEngine();\n/**\n * A implementation of the add op for use within engine and tape.\n *\n * This allows us to avoid a circular dependency between add.ts and engine.\n * It is exported to be available in tape tests.\n */\nexport function add(a, b) {\n    // We duplicate Add here to avoid a circular dependency with add.ts.\n    const inputs = { a, b };\n    return ENGINE.runKernel(Add, inputs);\n}\n//# sourceMappingURL=engine.js.map","/**\n * @license\n * Copyright 2020 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n// Required side effectful code for tfjs-core\n// Set up Engine and ENV\nimport { getOrMakeEngine } from './engine';\ngetOrMakeEngine();\n// Register backend-agnostic flags.\nimport './flags';\n// Register platforms\nimport './platforms/platform_browser';\nimport './platforms/platform_node';\n// Set up OpHandler\nimport { buffer } from './ops/buffer';\nimport { cast } from './ops/cast';\nimport { clone } from './ops/clone';\nimport { print } from './ops/print';\nimport { setOpHandler } from './tensor';\nconst opHandler = {\n    buffer,\n    cast,\n    clone,\n    print\n};\nsetOpHandler(opHandler);\n//# sourceMappingURL=base_side_effects.js.map"],"sourceRoot":""}