{"version":3,"sources":["webpack:///./node_modules/@tensorflow/tfjs-core/dist/io/types.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/io/indexed_db.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/kernel_names.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/io/local_storage.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/io/browser_files.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/io/progress.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/io/weights_loader.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/io/http.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/io/passthrough.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/io/io_utils.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/io/router_registry.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/kernel_registry.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/io/model_management.js"],"names":["DTYPE_VALUE_SIZE_MAP","DATABASE_NAME","MODEL_STORE_NAME","INFO_STORE_NAME","getIndexedDBFactory","getBool","Error","theWindow","window","self","factory","indexedDB","mozIndexedDB","webkitIndexedDB","msIndexedDB","shimIndexedDB","setUpDatabase","openRequest","db","result","createObjectStore","keyPath","BrowserIndexedDB","modelPath","this","modelArtifacts","modelTopology","ArrayBuffer","databaseAction","Promise","resolve","reject","open","onupgradeneeded","onsuccess","modelTx","transaction","getRequest","objectStore","get","close","onerror","error","oncomplete","modelArtifactsInfo","infoTx","infoStore","putInfoRequest","put","putModelRequest","deleteInfoRequest","delete","URL_SCHEME","indexedDBRouter","url","Array","isArray","startsWith","slice","length","registerSaveRouter","registerLoadRouter","BrowserIndexedDBManager","tx","getAllInfoRequest","getAll","out","item","path","key","getInfoRequest","deleteModelData","deleteModelRequest","Abs","Acos","Acosh","Add","AddN","All","Any","ArgMax","ArgMin","Asin","Asinh","Atan","Atanh","Atan2","AvgPool","AvgPoolBackprop","AvgPool3D","AvgPool3DBackprop","BatchMatMul","BatchToSpaceND","BroadcastTo","Cast","Ceil","ClipByValue","Complex","Concat","Conv2D","Conv2DBackpropFilter","Conv2DBackpropInput","Conv3D","Conv3DBackpropFilterV2","Conv3DBackpropInputV2","Cos","Cosh","Cumsum","CropAndResize","DepthToSpace","DepthwiseConv2dNative","DepthwiseConv2dNativeBackpropFilter","DepthwiseConv2dNativeBackpropInput","Dilation2D","Dilation2DBackpropInput","Dilation2DBackpropFilter","Div","Elu","EluGrad","Erf","Equal","Exp","Expm1","FFT","Fill","FlipLeftRight","Floor","FloorDiv","FusedBatchNorm","GatherV2","GatherNd","Greater","GreaterEqual","Identity","IFFT","Imag","IsFinite","IsInf","IsNan","Less","LessEqual","LinSpace","Log","Log1p","LogicalAnd","LogicalNot","LogicalOr","LogSoftmax","LRN","LRNBackprop","Max","Maximum","MaxPool","MaxPoolBackprop","MaxPool3D","MaxPool3DBackprop","MaxPoolWithArgmax","Mean","Min","Minimum","Mod","Multiply","Negate","NotEqual","NonMaxSuppressionV3","NonMaxSuppressionV4","NonMaxSuppressionV5","OnesLike","OneHot","PadV2","Pow","Prelu","Prod","Range","Real","Reciprocal","Relu","Reshape","ResizeNearestNeighbor","ResizeNearestNeighborGrad","ResizeBilinear","ResizeBilinearGrad","Relu6","Reverse","Round","Rsqrt","ScatterNd","SelectV2","Selu","Slice","Sin","Sinh","Sign","Sigmoid","Softplus","Sqrt","Sum","SpaceToBatchND","SplitV","Softmax","SquaredDifference","Square","Sub","SparseToDense","StridedSlice","Tan","Tanh","Tile","TopK","Transpose","Unpack","UnsortedSegmentSum","ZerosLike","Step","FromPixels","RotateWithOffset","_FusedMatMul","FusedConv2D","FusedDepthwiseConv2D","PATH_SEPARATOR","PATH_PREFIX","INFO_SUFFIX","MODEL_TOPOLOGY_SUFFIX","WEIGHT_SPECS_SUFFIX","WEIGHT_DATA_SUFFIX","MODEL_METADATA_SUFFIX","getModelKeys","info","join","topology","weightSpecs","weightData","modelMetadata","getModelPathFromKey","items","split","BrowserLocalStorage","localStorage","LS","keys","JSON","stringify","setItem","format","generatedBy","convertedBy","userDefinedMetadata","err","removeItem","modelTopologyBytes","weightSpecsBytes","weightDataBytes","parse","getItem","modelTopologyType","metadataString","metadata","weightDataBase64","localStorageRouter","BrowserLocalStorageManager","prefix","suffix","i","endsWith","defer","f","setTimeout","then","fileNamePrefix","modelTopologyFileName","weightDataFileName","weightsURL","URL","createObjectURL","Blob","type","weightsManifest","paths","weights","modelTopologyAndWeightManifest","modelTopologyAndWeightManifestURL","jsonAnchor","document","createElement","download","href","dispatchEvent","MouseEvent","weightDataAnchor","files","jsonFile","weightFiles","jsonReader","FileReader","onload","event","modelJSON","target","name","pathToFile","checkManifestAndWeightFiles","perFileBuffers","forEach","weightsGroup","push","weightFileReader","index","indexOf","readAsArrayBuffer","readAsText","manifest","basenames","fileNames","map","file","group","pathBasename","browserFiles","browserDownloads","monitorPromisesProgress","promises","onProgress","startFraction","endFraction","checkPromises","checkFraction","resolvedPromise","all","promise","value","fraction","async","loadWeightsAsArrayBuffer","fetchURLs","loadOptions","fetchFunc","platform","fetch","requests","fetchURL","requestInit","isBinary","bufferPromises","response","arrayBuffer","loadWeights","filePathPrefix","weightNames","weightsLoaderFactory","fetchUrls","fetchWeightsFunction","groupIndicesToFetchMap","groupWeightsToFetch","weightsFound","allManifestWeightNames","manifestGroupConfig","groupIndex","groupOffset","weightsEntry","rawDtype","quantization","dtype","weightsBytes","util","shape","enqueueWeightsForFetchingFn","manifestEntry","sizeBytes","weightName","weightIndex","every","found","weightsNotFound","filter","_","groupIndicesToFetch","reduce","accumulator","shouldFetch","filepath","fetchUrl","buffers","weightsTensorMap","bufferIndexOffset","numBuffers","groupBytes","byteLength","groupBuffer","groupByteBuffer","Uint8Array","groupBufferOffset","buffer","set","byteBuffer","nameToTensorMap","DEFAULT_METHOD","weightPathPrefix","weightUrlConverter","body","init","Object","assign","method","FormData","append","ok","responses","status","modelConfigRequest","modelConfig","json","e","message","results","weightPath","lastSlash","lastIndexOf","lastSearchParam","substring","parseUrl","pathPrefix","entry","urlPromises","isHTTPScheme","match","URL_SCHEME_REGEX","httpRouter","isHTTP","urlItem","http","browserHTTPRequest","PassthroughLoader","PassthroughSaver","saveHandler","fromMemory","trainingConfig","arguments","console","warn","withSaveHandler","encodeWeights","tensors","specs","dataPromises","names","tensor","t","spec","utf8bytes","vals","bytes","totalNumBytes","p","c","offset","val","bytesOfLength","Uint32Array","data","concatenateTypedArrays","decodeWeights","float16Decode","size","values","quantizationSizeFactor","quantizedArray","Uint16Array","Float32Array","v","scale","min","undefined","getFloat16Decoder","Int32Array","Math","round","dtypeFactor","real","image","realTensor","imageTensor","xs","totalByteLength","normalizedXs","x","constructor","y","useNodeBuffer","Buffer","atob","btoa","stringByteLength","str","arrayBufferToBase64String","from","toString","buf","s","l","String","fromCharCode","base64StringToArrayBuffer","byteOffset","charCodeAt","concatenateArrayBuffers","temp","basename","trim","getModelArtifactsInfoForJSON","dateSaved","Date","mantisaTable","convertMantissa","m","computeFloat16MantisaTable","exponentTable","computeFloat16ExponentTable","offsetTable","computeFloat16OffsetTable","bufferUint32View","float16Bits","float32Bits","IORouterRegistry","saveRouters","loadRouters","instance","saveRouter","getInstance","loadRouter","getHandlers","handlerType","validHandlers","router","handler","loudRouter","getSaveHandlers","getLoadHandlers","kernelRegistry","Map","gradRegistry","getKernel","kernelName","backendName","makeKey","getGradient","getKernelsForBackend","it","entries","done","next","config","backend","registerKernel","has","registerGradient","URL_SCHEME_SUFFIX","ModelStoreManagerRegistry","managers","scheme","manager","registry","parseURL","getSchemes","cloneModelInternal","sourceURL","destURL","deleteSource","loadHandlers","loadHandler","saveHandlers","sourceScheme","sourcePath","sameMedium","load","getManager","removeModel","saveResult","save","listModels","schemes","schemeOut","schemeAndPath","copyModel","moveModel"],"mappings":";sJAAA,kCAoBO,MAAMA,EAAuB,CAChC,QAAW,EACX,QAAW,EACX,MAAS,EACT,OAAU,EACV,MAAS,EACT,KAAQ,EACR,UAAa,I,iCC3BjB,uGAoBA,MAAMC,EAAgB,eAKhBC,EAAmB,eAInBC,EAAkB,mBAYxB,SAASC,IACL,IAAK,cAAMC,QAAQ,cAIf,MAAM,IAAIC,MAAM,2FAIpB,MAAMC,EAA8B,oBAAXC,OAAyBC,KAAOD,OACnDE,EAAUH,EAAUI,WAAaJ,EAAUK,cAC7CL,EAAUM,iBAAmBN,EAAUO,aACvCP,EAAUQ,cACd,GAAe,MAAXL,EACA,MAAM,IAAIJ,MAAM,6DAEpB,OAAOI,EAEX,SAASM,EAAcC,GACnB,MAAMC,EAAKD,EAAYE,OACvBD,EAAGE,kBAAkBlB,EAAkB,CAAEmB,QAAS,cAClDH,EAAGE,kBAAkBjB,EAAiB,CAAEkB,QAAS,cAO9C,MAAMC,EACT,YAAYC,GAER,GADAC,KAAKb,UAAYP,IACA,MAAbmB,IAAsBA,EACtB,MAAM,IAAIjB,MAAM,kEAEpBkB,KAAKD,UAAYA,EAErB,WAAWE,GAEP,GAAIA,EAAeC,yBAAyBC,YACxC,MAAM,IAAIrB,MAAM,4FAGpB,OAAOkB,KAAKI,eAAeJ,KAAKD,UAAWE,GAE/C,aACI,OAAOD,KAAKI,eAAeJ,KAAKD,WAgBpC,eAAeA,EAAWE,GACtB,OAAO,IAAII,SAAQ,CAACC,EAASC,KACzB,MAAMd,EAAcO,KAAKb,UAAUqB,KAAK/B,EAnF3B,GAoFbgB,EAAYgB,gBAAkB,IAAMjB,EAAcC,GAClDA,EAAYiB,UAAY,KACpB,MAAMhB,EAAKD,EAAYE,OACvB,GAAsB,MAAlBM,EAAwB,CAExB,MAAMU,EAAUjB,EAAGkB,YAAYlC,EAAkB,YAE3CmC,EADaF,EAAQG,YAAYpC,GACTqC,IAAIf,KAAKD,WACvCc,EAAWH,UAAY,KACnB,GAAyB,MAArBG,EAAWlB,OAEX,OADAD,EAAGsB,QACIT,EAAO,IAAIzB,MAAM,gCAAgCkB,KAAKD,6BAI7DO,EAAQO,EAAWlB,OAAOM,iBAGlCY,EAAWI,QAAUC,IACjBxB,EAAGsB,QACIT,EAAOM,EAAWK,QAE7BP,EAAQQ,WAAa,IAAMzB,EAAGsB,YAE7B,CAED,MAAMI,EAAqB,YAA6BnB,GAElDoB,EAAS3B,EAAGkB,YAAYjC,EAAiB,aAC/C,IAAI2C,EAAYD,EAAOP,YAAYnC,GACnC,MAAM4C,EAAiBD,EAAUE,IAAI,CAAEzB,UAAWC,KAAKD,UAAWqB,uBAClE,IAAIT,EACJY,EAAeb,UAAY,KAEvBC,EAAUjB,EAAGkB,YAAYlC,EAAkB,aAC3C,MACM+C,EADad,EAAQG,YAAYpC,GACJ8C,IAAI,CACnCzB,UAAWC,KAAKD,UAChBE,iBACAmB,uBAEJK,EAAgBf,UAAY,IAAMJ,EAAQ,CAAEc,uBAC5CK,EAAgBR,QAAUC,IAGtBI,EAAYD,EAAOP,YAAYnC,GAC/B,MAAM+C,EAAoBJ,EAAUK,OAAO3B,KAAKD,WAChD2B,EAAkBhB,UAAY,KAC1BhB,EAAGsB,QACIT,EAAOkB,EAAgBP,QAElCQ,EAAkBT,QAAUC,IACxBxB,EAAGsB,QACIT,EAAOkB,EAAgBP,UAI1CK,EAAeN,QAAUC,IACrBxB,EAAGsB,QACIT,EAAOgB,EAAeL,QAEjCG,EAAOF,WAAa,KACD,MAAXR,EACAjB,EAAGsB,QAGHL,EAAQQ,WAAa,IAAMzB,EAAGsB,WAK9CvB,EAAYwB,QAAUC,GAASX,EAAOd,EAAYyB,WAI9DpB,EAAiB8B,WAAa,eACvB,MAAMC,EAAmBC,IAC5B,OAAK,cAAMjD,QAAQ,gBAIVkD,MAAMC,QAAQF,IAAQA,EAAIG,WAAWnC,EAAiB8B,aA2BlC7B,EA1BG+B,EAAII,MAAMpC,EAAiB8B,WAAWO,QA2B/D,IAAIrC,EAAiBC,IA/BjB,KA8BR,IAA0BA,GAnBjC,IAAiBqC,mBAAmBP,GACpC,IAAiBQ,mBAAmBR,GA0B7B,MAAMS,EACT,cACItC,KAAKb,UAAYP,IAErB,mBACI,OAAO,IAAIyB,SAAQ,CAACC,EAASC,KACzB,MAAMd,EAAcO,KAAKb,UAAUqB,KAAK/B,EA9M3B,GA+MbgB,EAAYgB,gBAAkB,IAAMjB,EAAcC,GAClDA,EAAYiB,UAAY,KACpB,MAAMhB,EAAKD,EAAYE,OACjB4C,EAAK7C,EAAGkB,YAAYjC,EAAiB,YAUrC6D,EATQD,EAAGzB,YAAYnC,GASG8D,SAChCD,EAAkB9B,UAAY,KAC1B,MAAMgC,EAAM,GACZ,IAAK,MAAMC,KAAQH,EAAkB7C,OACjC+C,EAAIC,EAAK5C,WAAa4C,EAAKvB,mBAE/Bd,EAAQoC,IAEZF,EAAkBvB,QAAUC,IACxBxB,EAAGsB,QACIT,EAAOiC,EAAkBtB,QAEpCqB,EAAGpB,WAAa,IAAMzB,EAAGsB,SAE7BvB,EAAYwB,QAAUC,GAASX,EAAOd,EAAYyB,UAG1D,kBAAkB0B,GA1CtB,IAA0BC,EA4ClB,OADAD,GA3CkBC,EA2CMD,GA1CjBX,WAAWnC,EAAiB8B,YACnCiB,EAAIX,MAAMpC,EAAiB8B,WAAWO,QACtCU,EAyCO,IAAIxC,SAAQ,CAACC,EAASC,KACzB,MAAMd,EAAcO,KAAKb,UAAUqB,KAAK/B,EAhP3B,GAiPbgB,EAAYgB,gBAAkB,IAAMjB,EAAcC,GAClDA,EAAYiB,UAAY,KACpB,MAAMhB,EAAKD,EAAYE,OACjB0B,EAAS3B,EAAGkB,YAAYjC,EAAiB,aACzC2C,EAAYD,EAAOP,YAAYnC,GAC/BmE,EAAiBxB,EAAUP,IAAI6B,GACrC,IAAIjC,EACJmC,EAAepC,UAAY,KACvB,GAA6B,MAAzBoC,EAAenD,OAEf,OADAD,EAAGsB,QACIT,EAAO,IAAIzB,MAAM,gCAAgC8D,qBAGvD,CAED,MAAMlB,EAAoBJ,EAAUK,OAAOiB,GACrCG,EAAkB,KAEpBpC,EAAUjB,EAAGkB,YAAYlC,EAAkB,aAC3C,MACMsE,EADarC,EAAQG,YAAYpC,GACDiD,OAAOiB,GAC7CI,EAAmBtC,UAAY,IAAMJ,EAAQwC,EAAenD,OAAOyB,oBACnE4B,EAAmB/B,QAAUC,GAASX,EAAOuC,EAAe5B,QAIhEQ,EAAkBhB,UAAYqC,EAC9BrB,EAAkBT,QAAUC,IACxB6B,IACArD,EAAGsB,QACIT,EAAOuC,EAAe5B,UAIzC4B,EAAe7B,QAAUC,IACrBxB,EAAGsB,QACIT,EAAOuC,EAAe5B,QAEjCG,EAAOF,WAAa,KACD,MAAXR,EACAjB,EAAGsB,QAGHL,EAAQQ,WAAa,IAAMzB,EAAGsB,UAI1CvB,EAAYwB,QAAUC,GAASX,EAAOd,EAAYyB,a,+BCrT9D,iiKAAO,MAAM+B,EAAM,MACNC,EAAO,OACPC,EAAQ,QACRC,EAAM,MACNC,EAAO,OACPC,EAAM,MACNC,EAAM,MACNC,EAAS,SACTC,EAAS,SACTC,EAAO,OACPC,EAAQ,QACRC,EAAO,OACPC,EAAQ,QACRC,EAAQ,QACRC,EAAU,UACVC,EAAkB,kBAClBC,EAAY,YACZC,EAAoB,oBACpBC,EAAc,cACdC,EAAiB,iBACjBC,EAAc,cACdC,EAAO,OACPC,EAAO,OACPC,EAAc,cACdC,EAAU,UACVC,EAAS,SACTC,EAAS,SACTC,EAAuB,uBACvBC,EAAsB,sBACtBC,EAAS,SACTC,EAAyB,yBACzBC,EAAwB,wBACxBC,EAAM,MACNC,EAAO,OACPC,EAAS,SACTC,EAAgB,gBAChBC,EAAe,eACfC,EAAwB,wBACxBC,EAAsC,sCACtCC,EAAqC,qCAErCC,EAAa,aACbC,EAA0B,0BAC1BC,EAA2B,2BAC3BC,EAAM,MACNC,EAAM,MACNC,EAAU,UACVC,EAAM,MACNC,EAAQ,QACRC,EAAM,MACNC,EAAQ,QACRC,EAAM,MACNC,GAAO,OACPC,GAAgB,gBAChBC,GAAQ,QACRC,GAAW,WACXC,GAAiB,iBACjBC,GAAW,WACXC,GAAW,WACXC,GAAU,UACVC,GAAe,eACfC,GAAW,WACXC,GAAO,OACPC,GAAO,OACPC,GAAW,WACXC,GAAQ,QACRC,GAAQ,QACRC,GAAO,OACPC,GAAY,YACZC,GAAW,WACXC,GAAM,MACNC,GAAQ,QACRC,GAAa,aACbC,GAAa,aACbC,GAAY,YACZC,GAAa,aACbC,GAAM,MACNC,GAAc,cACdC,GAAM,MACNC,GAAU,UACVC,GAAU,UACVC,GAAkB,kBAClBC,GAAY,YACZC,GAAoB,oBACpBC,GAAoB,oBACpBC,GAAO,OACPC,GAAM,MACNC,GAAU,UACVC,GAAM,MACNC,GAAW,WACXC,GAAS,SACTC,GAAW,WACXC,GAAsB,sBACtBC,GAAsB,sBACtBC,GAAsB,sBACtBC,GAAW,WACXC,GAAS,SACTC,GAAQ,QAERC,GAAM,MACNC,GAAQ,QACRC,GAAO,OACPC,GAAQ,QACRC,GAAO,OACPC,GAAa,aACbC,GAAO,OACPC,GAAU,UACVC,GAAwB,wBACxBC,GAA4B,4BAC5BC,GAAiB,iBACjBC,GAAqB,qBACrBC,GAAQ,QACRC,GAAU,UACVC,GAAQ,QACRC,GAAQ,QACRC,GAAY,YACZC,GAAW,WACXC,GAAO,OACPC,GAAQ,QACRC,GAAM,MACNC,GAAO,OACPC,GAAO,OACPC,GAAU,UACVC,GAAW,WACXC,GAAO,OACPC,GAAM,MACNC,GAAiB,iBACjBC,GAAS,SACTC,GAAU,UACVC,GAAoB,oBACpBC,GAAS,SACTC,GAAM,MACNC,GAAgB,gBAChBC,GAAe,eACfC,GAAM,MACNC,GAAO,OACPC,GAAO,OACPC,GAAO,OACPC,GAAY,YACZC,GAAS,SACTC,GAAqB,qBACrBC,GAAY,YAIZC,GAAO,OACPC,GAAa,aACbC,GAAmB,mBACnBC,GAAe,eACfC,GAAc,cACdC,GAAuB,wB,iCCtJpC,8GAqBA,MAAMC,EAAiB,IACjBC,EAAc,sBACdC,EAAc,OACdC,EAAwB,iBACxBC,EAAsB,eACtBC,EAAqB,cACrBC,EAAwB,iBA2B9B,SAASC,EAAa9J,GAClB,MAAO,CACH+J,KAAM,CAACP,EAAaxJ,EAAMyJ,GAAaO,KAAKT,GAC5CU,SAAU,CAACT,EAAaxJ,EAAM0J,GAAuBM,KAAKT,GAC1DW,YAAa,CAACV,EAAaxJ,EAAM2J,GAAqBK,KAAKT,GAC3DY,WAAY,CAACX,EAAaxJ,EAAM4J,GAAoBI,KAAKT,GACzDa,cAAe,CAACZ,EAAaxJ,EAAM6J,GAAuBG,KAAKT,IAUvE,SAASc,EAAoBpK,GACzB,MAAMqK,EAAQrK,EAAIsK,MAAMhB,GACxB,GAAIe,EAAM/K,OAAS,EACf,MAAM,IAAIrD,MAAM,uBAAuB+D,KAE3C,OAAOqK,EAAMhL,MAAM,EAAGgL,EAAM/K,OAAS,GAAGyK,KAAKT,GAY1C,MAAMiB,EACT,YAAYrN,GACR,IAAK,cAAMlB,QAAQ,eAAmC,oBAAXG,aACR,IAAxBA,OAAOqO,aAKd,MAAM,IAAIvO,MAAM,2DAGpB,GADAkB,KAAKsN,GAAKtO,OAAOqO,aACA,MAAbtN,IAAsBA,EACtB,MAAM,IAAIjB,MAAM,sEAEpBkB,KAAKD,UAAYA,EACjBC,KAAKuN,KAAOb,EAAa1M,KAAKD,WAWlC,WAAWE,GACP,GAAIA,EAAeC,yBAAyBC,YACxC,MAAM,IAAIrB,MAAM,4FAGf,CACD,MAAM+N,EAAWW,KAAKC,UAAUxN,EAAeC,eACzC4M,EAAcU,KAAKC,UAAUxN,EAAe6M,aAC5C1L,EAAqB,YAA6BnB,GACxD,IAWI,OAVAD,KAAKsN,GAAGI,QAAQ1N,KAAKuN,KAAKZ,KAAMa,KAAKC,UAAUrM,IAC/CpB,KAAKsN,GAAGI,QAAQ1N,KAAKuN,KAAKV,SAAUA,GACpC7M,KAAKsN,GAAGI,QAAQ1N,KAAKuN,KAAKT,YAAaA,GACvC9M,KAAKsN,GAAGI,QAAQ1N,KAAKuN,KAAKR,WAAY,YAA0B9M,EAAe8M,aAC/E/M,KAAKsN,GAAGI,QAAQ1N,KAAKuN,KAAKP,cAAeQ,KAAKC,UAAU,CACpDE,OAAQ1N,EAAe0N,OACvBC,YAAa3N,EAAe2N,YAC5BC,YAAa5N,EAAe4N,YAC5BC,oBAAqB7N,EAAe6N,uBAEjC,CAAE1M,sBAEb,MAAO2M,GAOH,MALA/N,KAAKsN,GAAGU,WAAWhO,KAAKuN,KAAKZ,MAC7B3M,KAAKsN,GAAGU,WAAWhO,KAAKuN,KAAKV,UAC7B7M,KAAKsN,GAAGU,WAAWhO,KAAKuN,KAAKT,aAC7B9M,KAAKsN,GAAGU,WAAWhO,KAAKuN,KAAKR,YAC7B/M,KAAKsN,GAAGU,WAAWhO,KAAKuN,KAAKP,eACvB,IAAIlO,MAAM,yBAAyBkB,KAAKD,kHAEpBqB,EAAmB6M,wCACrB7M,EAAmB8M,qCACpB9M,EAAmB+M,sBAYtD,aACI,MAAMxB,EAAOa,KAAKY,MAAMpO,KAAKsN,GAAGe,QAAQrO,KAAKuN,KAAKZ,OAClD,GAAY,MAARA,EACA,MAAM,IAAI7N,MAAM,kDAAkDkB,KAAKD,cAE3E,GAA+B,SAA3B4M,EAAK2B,kBACL,MAAM,IAAIxP,MAAM,6EAGpB,MAAM4D,EAAM,GAENmK,EAAWW,KAAKY,MAAMpO,KAAKsN,GAAGe,QAAQrO,KAAKuN,KAAKV,WACtD,GAAgB,MAAZA,EACA,MAAM,IAAI/N,MAAM,4CAA4CkB,KAAKD,0BAGrE2C,EAAIxC,cAAgB2M,EAEpB,MAAMC,EAAcU,KAAKY,MAAMpO,KAAKsN,GAAGe,QAAQrO,KAAKuN,KAAKT,cACzD,GAAmB,MAAfA,EACA,MAAM,IAAIhO,MAAM,gDAAgDkB,KAAKD,2BAGzE2C,EAAIoK,YAAcA,EAElB,MAAMyB,EAAiBvO,KAAKsN,GAAGe,QAAQrO,KAAKuN,KAAKP,eACjD,GAAsB,MAAlBuB,EAAwB,CACxB,MAAMC,EAAWhB,KAAKY,MAAMG,GAC5B7L,EAAIiL,OAASa,EAAiB,OAC9B9L,EAAIkL,YAAcY,EAAsB,YACxC9L,EAAImL,YAAcW,EAAsB,YACxC9L,EAAIoL,oBAAsBU,EAA8B,oBAG5D,MAAMC,EAAmBzO,KAAKsN,GAAGe,QAAQrO,KAAKuN,KAAKR,YACnD,GAAwB,MAApB0B,EACA,MAAM,IAAI3P,MACN,wDAAIkB,KAAKD,2BAGjB,OADA2C,EAAIqK,WAAa,YAA0B0B,GACpC/L,GAGf0K,EAAoBxL,WAAa,kBAC1B,MAAM8M,EAAsB5M,IAC/B,OAAK,cAAMjD,QAAQ,gBAIVkD,MAAMC,QAAQF,IAAQA,EAAIG,WAAWmL,EAAoBxL,aAkClC7B,EAjCG+B,EAAII,MAAMkL,EAAoBxL,WAAWO,QAkCrE,IAAIiL,EAAoBrN,IAtCpB,KAqCR,IAA6BA,GA1BpC,IAAiBqC,mBAAmBsM,GACpC,IAAiBrM,mBAAmBqM,GA4B7B,MAAMC,EACT,cACI,iBAAO,cAAM9P,QAAQ,eAAe,IAAM,6CAC1C,iBAAyB,oBAAXG,aACqB,IAAxBA,OAAOqO,cAA8B,IAAM,4DACtDrN,KAAKsN,GAAKtO,OAAOqO,aAErB,mBACI,MAAM3K,EAAM,GACNkM,EAASxC,EAAcD,EACvB0C,EAAS1C,EAAiBE,EAChC,IAAK,IAAIyC,EAAI,EAAGA,EAAI9O,KAAKsN,GAAGnL,SAAU2M,EAAG,CACrC,MAAMjM,EAAM7C,KAAKsN,GAAGzK,IAAIiM,GACxB,GAAIjM,EAAIZ,WAAW2M,IAAW/L,EAAIkM,SAASF,GAAS,CAEhDnM,EADkBuK,EAAoBpK,IACrB2K,KAAKY,MAAMpO,KAAKsN,GAAGe,QAAQxL,KAGpD,OAAOH,EAEX,kBAAkBE,GA3LtB,IAA0BC,EA6LlB,MAAM0K,EAAOb,EADb9J,GA5LkBC,EA4LMD,GA3LjBX,WAAWmL,EAAoBxL,YACtCiB,EAAIX,MAAMkL,EAAoBxL,WAAWO,QACzCU,GA2LA,GAAkC,MAA9B7C,KAAKsN,GAAGe,QAAQd,EAAKZ,MACrB,MAAM,IAAI7N,MAAM,8BAA8B8D,MAElD,MAAM+J,EAAOa,KAAKY,MAAMpO,KAAKsN,GAAGe,QAAQd,EAAKZ,OAK7C,OAJA3M,KAAKsN,GAAGU,WAAWT,EAAKZ,MACxB3M,KAAKsN,GAAGU,WAAWT,EAAKV,UACxB7M,KAAKsN,GAAGU,WAAWT,EAAKT,aACxB9M,KAAKsN,GAAGU,WAAWT,EAAKR,YACjBJ,K,iiCCxPf,SAASqC,EAAMC,GACX,OAAO,IAAI5O,SAAQC,GAAW4O,WAAW5O,KAAU6O,KAAKF,GAErD,MAAM,EACT,YAAYG,GACR,IAAK,cAAMvQ,QAAQ,cAGf,MAAM,IAAIC,MAAM,uFAGhBsQ,EAAenN,WAAW,EAAiBL,cAC3CwN,EAAiBA,EAAelN,MAAM,EAAiBN,WAAWO,SAEhD,MAAlBiN,GAAoD,IAA1BA,EAAejN,SACzCiN,EAlBqB,SAoBzBpP,KAAKqP,sBAAwBD,EAnBD,QAoB5BpP,KAAKsP,mBACDF,EApB+B,eAsBvC,WAAWnP,GACP,GAA0B,oBAAf,SACP,MAAM,IAAInB,MAAM,2FAGpB,MAAMyQ,EAAavQ,OAAOwQ,IAAIC,gBAAgB,IAAIC,KAAK,CAACzP,EAAe8M,YAAa,CAAE4C,KAAM,8BAC5F,GAAI1P,EAAeC,yBAAyBC,YACxC,MAAM,IAAIrB,MAAM,yFAGf,CACD,MAAM8Q,EAAkB,CAAC,CACjBC,MAAO,CAAC,KAAO7P,KAAKsP,oBACpBQ,QAAS7P,EAAe6M,cAE1BiD,EAAiC,CACnC7P,cAAeD,EAAeC,cAC9ByN,OAAQ1N,EAAe0N,OACvBC,YAAa3N,EAAe2N,YAC5BC,YAAa5N,EAAe4N,YAC5B+B,mBAEEI,EAAoChR,OAAOwQ,IAAIC,gBAAgB,IAAIC,KAAK,CAAClC,KAAKC,UAAUsC,IAAkC,CAAEJ,KAAM,sBAGlIM,EAAgC,MAAnBjQ,KAAKiQ,WAAqBC,SAASC,cAAc,KAChEnQ,KAAKiQ,WAOT,GANAA,EAAWG,SAAWpQ,KAAKqP,sBAC3BY,EAAWI,KAAOL,QAIZhB,GAAM,IAAMiB,EAAWK,cAAc,IAAIC,WAAW,YACzB,MAA7BtQ,EAAe8M,WAAoB,CACnC,MAAMyD,EAA4C,MAAzBxQ,KAAKwQ,iBAC1BN,SAASC,cAAc,KACvBnQ,KAAKwQ,iBACTA,EAAiBJ,SAAWpQ,KAAKsP,mBACjCkB,EAAiBH,KAAOd,QAClBP,GAAM,IAAMwB,EAAiBF,cAAc,IAAIC,WAAW,YAEpE,MAAO,CAAEnP,mBAAoB,YAA6BnB,MAItE,EAAiB2B,WAAa,eAC9B,MAAM,EACF,YAAY6O,GACR,GAAa,MAATA,GAAiBA,EAAMtO,OAAS,EAChC,MAAM,IAAIrD,MACN,wEAAgB2R,KAExBzQ,KAAKyQ,MAAQA,EAEjB,aACI,MAAMC,EAAW1Q,KAAKyQ,MAAM,GACtBE,EAAc3Q,KAAKyQ,MAAMvO,MAAM,GACrC,OAAO,IAAI7B,SAAQ,CAACC,EAASC,KACzB,MAAMqQ,EAAa,IAAIC,WACvBD,EAAWE,OAAUC,IAEjB,MAAMC,EAAYxD,KAAKY,MAAM2C,EAAME,OAAOtR,QACpCO,EAAgB8Q,EAAU9Q,cAChC,GAAqB,MAAjBA,EAEA,YADAK,EAAO,IAAIzB,MAAM,4CAA4C4R,EAASQ,SAG/C,IAAvBP,EAAYxO,QACZ7B,EAAQ,CAAEJ,kBAEd,MAAM0P,EAAkBoB,EAAUpB,gBAClC,GAAuB,MAAnBA,EAEA,YADArP,EAAO,IAAIzB,MAAM,6CAA6C4R,EAASQ,SAG3E,IAAIC,EACJ,IACIA,EACInR,KAAKoR,4BAA4BxB,EAAiBe,GAE1D,MAAO5C,GAEH,YADAxN,EAAOwN,GAGX,MAAMjB,EAAc,GACd+C,EAAQ,GACRwB,EAAiB,GACvBzB,EAAgB0B,SAAQC,IACpBA,EAAa1B,MAAMyB,SAAQ1O,IACvBiN,EAAM2B,KAAK5O,GACXyO,EAAeG,KAAK,SAExB1E,EAAY0E,QAAQD,EAAazB,YAErCF,EAAgB0B,SAAQC,IACpBA,EAAa1B,MAAMyB,SAAQ1O,IACvB,MAAM6O,EAAmB,IAAIZ,WAC7BY,EAAiBX,OAAUC,IAEvB,MAAMhE,EAAagE,EAAME,OAAOtR,OAC1B+R,EAAQ7B,EAAM8B,QAAQ/O,GAC5ByO,EAAeK,GAAS3E,GACc,IAAlCsE,EAAeM,QAAQ,OACvBrR,EAAQ,CACJJ,gBACA4M,cACAC,WAAY,YAAwBsE,GACpC1D,OAAQqD,EAAUrD,OAClBC,YAAaoD,EAAUpD,YACvBC,YAAamD,EAAUnD,YACvBC,oBAAqBkD,EAAUlD,uBAI3C2D,EAAiBxQ,QAAUC,GAASX,EAAO,6CAA6CqC,OACxF6O,EAAiBG,kBAAkBT,EAAWvO,WAI1DgO,EAAW3P,QAAUC,GAASX,EAC1B,sEAAcmQ,EAASQ,6EAE3BN,EAAWiB,WAAWnB,MAM9B,4BAA4BoB,EAAUrB,GAClC,MAAMsB,EAAY,GACZC,EAAYvB,EAAMwB,KAAIC,GAAQ,YAASA,EAAKhB,QAC5CC,EAAa,GACnB,IAAK,MAAMgB,KAASL,EAChBK,EAAMtC,MAAMyB,SAAQ1O,IAChB,MAAMwP,EAAe,YAASxP,GAC9B,IAAyC,IAArCmP,EAAUJ,QAAQS,GAClB,MAAM,IAAItT,MACN,uDAAIsT,MAGZ,GADAL,EAAUP,KAAKY,IAC0B,IAArCJ,EAAUL,QAAQS,GAClB,MAAM,IAAItT,MAAM,8BAA8BsT,uBAG9CjB,EAAWvO,GAAQ6N,EAAMuB,EAAUL,QAAQS,OAIvD,GAAIL,EAAU5P,SAAWsO,EAAMtO,OAC3B,MAAM,IAAIrD,MACN,wDAAIiT,EAAU5P,oDACVsO,EAAMtO,YAElB,OAAOgP,GAmGR,SAASkB,EAAa5B,GACzB,OAAO,IAAI,EAAaA,GApF5B,IAAiBrO,oBAbsBN,GAC9B,cAAMjD,QAAQ,gBAIVkD,MAAMC,QAAQF,IAAQA,EAAIG,WAAW,EAAiBL,YAgD5D,SAA0BwN,EAAiB,SAC9C,OAAO,IAAI,EAAiBA,GAhDbkD,CAAiBxQ,EAAII,MAAM,EAAiBN,WAAWO,SAJ3D,O,WCrLR,SAASoQ,EAAwBC,EAAUC,EAAYC,EAAeC,IAgBzE,SAAuBH,GACnB,iBAAmB,MAAZA,GAAoBzQ,MAAMC,QAAQwQ,IAAaA,EAASrQ,OAAS,GAAG,IAAM,wCAhBrFyQ,CAAcJ,GAkBd,SAAuBE,EAAeC,GAClC,iBAAOD,GAAiB,GAAKA,GAAiB,GAAG,IAC7C,oEAAqBA,MACzB,iBAAOC,GAAe,GAAKA,GAAe,GAAG,IACzC,kEAAmBA,MACvB,iBAAOA,GAAeD,GAAe,IACjC,yEAAqBA,qBAClBC,MAtBXE,CAFAH,EAAiC,MAAjBA,EAAwB,EAAIA,EAC5CC,EAA6B,MAAfA,EAAsB,EAAIA,GAExC,IAAIG,EAAkB,EAuBtB,OAAOzS,QAAQ0S,IAAIP,EAASP,KAtBHe,IACrBA,EAAQ7D,MAAK8D,IACT,MAAMC,EAAWR,KACXI,EAAkBN,EAASrQ,QAAUwQ,EAAcD,GAGzD,OADAD,EAAWS,GACJD,KAEJD,M,aCPRG,eAAeC,EAAyBC,EAAWC,GACnC,MAAfA,IACAA,EAAc,IAElB,MAAMC,EAAqC,MAAzBD,EAAYC,UAAoB,cAAMC,SAASC,MAC7DH,EAAYC,UAEVG,EAAWL,EAAUpB,KAAI0B,GAAYJ,EAAUI,EAAUL,EAAYM,YAAa,CAAEC,UAAU,MAM9FC,GAHsC,MAA1BR,EAAYb,iBACpBpS,QAAQ0S,IAAIW,SACZnB,EAAwBmB,EAAUJ,EAAYb,WAJ7B,EACF,KAIQR,KAAI8B,GAAYA,EAASC,gBAM1D,OAH0C,MAA1BV,EAAYb,iBAClBpS,QAAQ0S,IAAIe,SACZvB,EAAwBuB,EAAgBR,EAAYb,WAJlC,GACF,GAevBU,eAAec,EAAYnC,EAAUoC,EAAiB,GAAIC,EAAaP,GAQ1E,OADoBQ,GADEC,GAAcjB,EAAyBiB,EAAW,CAAET,iBAEnEK,CAAYnC,EAAUoC,EAAgBC,GA0B1C,SAASC,EAAqBE,GACjC,OAAOnB,MAAOrB,EAAUoC,EAAiB,GAAIC,KAGzC,MAAMI,EAAyBzC,EAASG,KAAI,KAAM,IAC5CuC,EAAsB,GACtBC,EAA8B,MAAfN,EAAsBA,EAAYlC,KAAI,KAAM,IAAS,GACpEyC,EAAyB,GAmC/B,GAlCA5C,EAASR,SAAQ,CAACqD,EAAqBC,KACnC,IAAIC,EAAc,EAClBF,EAAoB7E,QAAQwB,SAAQwD,IAChC,MAAMC,EAAY,iBAAkBD,EAChCA,EAAaE,aAAaC,MAC1BH,EAAaG,MACXC,EAAe,IAAqBH,GACtCI,EAAA,cAAmBL,EAAaM,OAC9BC,EAA8B,KAChCd,EAAuBK,IAAc,EACE,MAAnCJ,EAAoBI,KACpBJ,EAAoBI,GAAc,IAEtCJ,EAAoBI,GAAYpD,KAAK,CACjC8D,cAAeR,EACfD,cACAU,UAAWL,KAGA,MAAff,EACAA,EAAY7C,SAAQ,CAACkE,EAAYC,KACzBD,IAAeV,EAAa5D,OAC5BmE,IACAZ,EAAagB,IAAe,MAKpCJ,IAEJX,EAAuBlD,KAAKsD,EAAa5D,MACzC2D,GAAeK,SAGlBT,EAAaiB,OAAMC,GAASA,IAAQ,CACrC,MAAMC,EAAkBzB,EAAY0B,QAAO,CAACC,EAAGhH,KAAO2F,EAAa3F,KACnE,MAAM,IAAIhQ,MACN,kDAAG8W,EAAgBhJ,KAAK,kDAErB8H,EAAuB9H,KAAK,UAIvC,MAAMmJ,EAAsBxB,EAAuByB,QAAO,CAACC,EAAaC,EAAapH,KAC7EoH,GACAD,EAAYzE,KAAK1C,GAEdmH,IACR,IACG5B,EAAY,GAClB0B,EAAoBzE,SAAQxC,IACxBgD,EAAShD,GAAGe,MAAMyB,SAAQ6E,IACtB,MAAMC,EAAWlC,GACXA,EAAenF,SAAS,KAAa,GAAN,KAAYoH,EACjD9B,EAAU7C,KAAK4E,SAGvB,MAAMC,QAAgB/B,EAAqBD,GACrCiC,EAAmB,GACzB,IAAIC,EAAoB,EA0BxB,OAzBAR,EAAoBzE,SAAQxC,IACxB,MAAM0H,EAAa1E,EAAShD,GAAGe,MAAM1N,OACrC,IAAIsU,EAAa,EACjB,IAAK,IAAI3H,EAAI,EAAGA,EAAI0H,EAAY1H,IAC5B2H,GAAcJ,EAAQE,EAAoBzH,GAAG4H,WAGjD,MAAMC,EAAc,IAAIxW,YAAYsW,GAC9BG,EAAkB,IAAIC,WAAWF,GACvC,IAAIG,EAAoB,EACxB,IAAK,IAAIhI,EAAI,EAAGA,EAAI0H,EAAY1H,IAAK,CACjC,MAAMiI,EAAS,IAAIF,WAAWR,EAAQE,EAAoBzH,IAC1D8H,EAAgBI,IAAID,EAAQD,GAC5BA,GAAqBC,EAAOL,WAETlC,EAAoB1F,GAC5BwC,SAAQwD,IACnB,MAAMmC,EAAaN,EAAYzU,MAAM4S,EAAaD,YAAaC,EAAaD,YAAcC,EAAaS,WACjG2B,EAAkB,YAAcD,EAAY,CAACnC,EAAaQ,gBAChE,IAAK,MAAMpE,KAAQgG,EACfZ,EAAiBpF,GAAQgG,EAAgBhG,MAGjDqF,GAAqBC,KAElBF,GCjKR,MAAM,EACT,YAAY1T,EAAM0Q,GAwBd,GAvBAtT,KAAKmX,eAAiB,OACH,MAAf7D,IACAA,EAAc,IAElBtT,KAAKoX,iBAAmB9D,EAAY8D,iBACpCpX,KAAKyS,WAAaa,EAAYb,WAC9BzS,KAAKqX,mBAAqB/D,EAAY+D,mBACT,MAAzB/D,EAAYC,WACZ,iBAAwC,mBAA1BD,EAAYC,WAA0B,IAAM,gIAG1DvT,KAAKyT,MAAQH,EAAYC,WAGzBvT,KAAKyT,MAAQ,cAAMD,SAASC,MAEhC,iBAAe,MAAR7Q,GAAgBA,EAAKT,OAAS,GAAG,IAAM,4DAE1CJ,MAAMC,QAAQY,IACd,iBAAuB,IAAhBA,EAAKT,QAAc,IACtB,iEAAqBS,EAAKT,aAElCnC,KAAK4C,KAAOA,EACmB,MAA3B0Q,EAAYM,aACoB,MAAhCN,EAAYM,YAAY0D,KACxB,MAAM,IAAIxY,MAAM,sEAEpBkB,KAAK4T,YAAcN,EAAYM,aAAe,GAElD,WAAW3T,GACP,GAAIA,EAAeC,yBAAyBC,YACxC,MAAM,IAAIrB,MAAM,2FAGpB,MAAMyY,EAAOC,OAAOC,OAAO,CAAEC,OAAQ1X,KAAKmX,gBAAkBnX,KAAK4T,aACjE2D,EAAKD,KAAO,IAAIK,SAChB,MAAM/H,EAAkB,CAAC,CACjBC,MAAO,CAAC,uBACRC,QAAS7P,EAAe6M,cAE1BiD,EAAiC,CACnC7P,cAAeD,EAAeC,cAC9ByN,OAAQ1N,EAAe0N,OACvBC,YAAa3N,EAAe2N,YAC5BC,YAAa5N,EAAe4N,YAC5BC,oBAAqB7N,EAAe6N,oBACpC8B,mBAEJ2H,EAAKD,KAAKM,OAAO,aAAc,IAAIlI,KAAK,CAAClC,KAAKC,UAAUsC,IAAkC,CAAEJ,KAnDlF,qBAmDsG,cAC/E,MAA7B1P,EAAe8M,YACfwK,EAAKD,KAAKM,OAAO,oBAAqB,IAAIlI,KAAK,CAACzP,EAAe8M,YAAa,CAAE4C,KAtD3D,6BAsD4F,qBAEnH,MAAMoE,QAAiB/T,KAAKyT,MAAMzT,KAAK4C,KAAM2U,GAC7C,GAAIxD,EAAS8D,GACT,MAAO,CACHzW,mBAAoB,YAA6BnB,GACjD6X,UAAW,CAAC/D,IAIhB,MAAM,IAAIjV,MACN,gEAAGiV,EAASgE,WAWxB,aACI,MAAMC,QAA2BhY,KAAKyT,MAAMzT,KAAK4C,KAAM5C,KAAK4T,aAC5D,IAAKoE,EAAmBH,GACpB,MAAM,IAAI/Y,MAAM,cAAckB,KAAK4C,gCAC5BoV,EAAmBD,iFAG9B,IAAIE,EACJ,IACIA,QAAoBD,EAAmBE,OAE3C,MAAOC,GACH,IAAIC,EAAU,+CAA+CpY,KAAK4C,QAelE,MAZI5C,KAAK4C,KAAKmM,SAAS,OACnBqJ,GAAW,+UAQXA,GAAW,uEAGT,IAAItZ,MAAMsZ,GAEpB,MAAMlY,EAAgB+X,EAAY/X,cAC5B0P,EAAkBqI,EAAYrI,gBAC9BhC,EAAcqK,EAAYrK,YAC1BC,EAAcoK,EAAYpK,YAC1BF,EAASsK,EAAYtK,OACrBG,EAAsBmK,EAAYnK,oBAExC,GAAqB,MAAjB5N,GAA4C,MAAnB0P,EACzB,MAAM,IAAI9Q,MAAM,2BAA2BkB,KAAK4C,iEAGpD,IAAIkK,EACAC,EACJ,GAAuB,MAAnB6C,EAAyB,CACzB,MAAMyI,QAAgBrY,KAAKiU,YAAYrE,IACtC9C,EAAaC,GAAcsL,EAEhC,MAAO,CACHnY,gBACA4M,cACAC,aACAe,sBACAF,cACAC,cACAF,UAGR,kBAAkBiC,GACd,MAAM0I,EAAavW,MAAMC,QAAQhC,KAAK4C,MAAQ5C,KAAK4C,KAAK,GAAK5C,KAAK4C,MAC3DgM,EAAQC,GAyChB,SAAkB/M,GACrB,MAAMyW,EAAYzW,EAAI0W,YAAY,KAC5BC,EAAkB3W,EAAI0W,YAAY,KAClC5J,EAAS9M,EAAI4W,UAAU,EAAGH,GAC1B1J,EAAS4J,EAAkBF,EAAYzW,EAAI4W,UAAUD,GAAmB,GAC9E,MAAO,CAAC7J,EAAS,IAAKC,GA9CO8J,CAASL,GAC5BM,EAAa5Y,KAAKoX,kBAAoBxI,EACtC9B,EAAc,GACpB,IAAK,MAAM+L,KAASjJ,EAChB9C,EAAY0E,QAAQqH,EAAM/I,SAE9B,MAAMuD,EAAY,GACZyF,EAAc,GACpB,IAAK,MAAMvH,KAAgB3B,EACvB,IAAK,MAAMhN,KAAQ2O,EAAa1B,MACG,MAA3B7P,KAAKqX,mBACLyB,EAAYtH,KAAKxR,KAAKqX,mBAAmBzU,IAGzCyQ,EAAU7B,KAAKoH,EAAahW,EAAOiM,GAI3C7O,KAAKqX,oBACLhE,EAAU7B,cAAcnR,QAAQ0S,IAAI+F,IAExC,MAAMzC,QAAgBjD,EAAyBC,EAAW,CACtDO,YAAa5T,KAAK4T,YAClBL,UAAWvT,KAAKyT,MAChBhB,WAAYzS,KAAKyS,aAErB,MAAO,CAAC3F,EAAa,YAAwBuJ,KAsB9C,SAAS0C,EAAajX,GACzB,OAAkD,MAA3CA,EAAIkX,MAAM,EAAYC,kBApBjC,EAAYA,iBAAmB,eAsBxB,MAAMC,EAAa,CAACpX,EAAKwR,KAC5B,GAAqB,oBAAVG,QACS,MAAfH,GAAgD,MAAzBA,EAAYC,WAIpC,OAAO,KAEN,CACD,IAAI4F,GAAS,EAOb,GALIA,EADApX,MAAMC,QAAQF,GACLA,EAAI4T,OAAM0D,GAAWL,EAAaK,KAGlCL,EAAajX,GAEtBqX,EACA,OAAOE,EAAKvX,EAAKwR,GAGzB,OAAO,MA0EJ,SAAS+F,EAAKzW,EAAM0Q,GACvB,OAAO,IAAI,EAAY1Q,EAAM0Q,GAO1B,SAASgG,EAAmB1W,EAAM0Q,GACrC,OAAO+F,EAAKzW,EAAM0Q,GAjFtB,IAAiBlR,mBAAmB8W,GACpC,IAAiB7W,mBAAmB6W,GC1NpC,MAAMK,EACF,YAAYtZ,GACRD,KAAKC,eAAiBA,EAE1B,aACI,OAAOD,KAAKC,gBAGpB,MAAMuZ,EACF,YAAYC,GACRzZ,KAAKyZ,YAAcA,EAEvB,WAAWxZ,GACP,OAAOD,KAAKyZ,YAAYxZ,IAwBzB,SAASyZ,EAAWzZ,EAAgB6M,EAAaC,EAAY4M,GAChE,GAAyB,IAArBC,UAAUzX,OAAc,CAGxB,OAFyD,MAAhClC,EAAeC,eACN,MAA9BD,EAAe6M,YAER,IAAIyM,EAAkBtZ,IAK7B4Z,QAAQC,KAAK,yNAIN,IAAIP,EAAkB,CAAErZ,cAAeD,KAUlD,OAJA4Z,QAAQC,KAAK,yNAIN,IAAIP,EAAkB,CACzBrZ,cAAeD,EACf6M,cACAC,aACA4M,mBAmBL,SAASI,EAAgBN,GAC5B,OAAO,IAAID,EAAiBC,G,8CCrGhC,8RAuCOtG,eAAe6G,EAAcC,EAAS9H,GAEzC,MAAM+H,EAAQ,GACRC,EAAe,GACfC,EAAQrY,MAAMC,QAAQiY,GACxBA,EAAQhI,KAAIoI,GAAUA,EAAOnJ,OAC7BsG,OAAOjK,KAAK0M,GAChB,IAAK,IAAInL,EAAI,EAAGA,EAAIsL,EAAMjY,SAAU2M,EAAG,CACnC,MAAMoC,EAAOkJ,EAAMtL,GACbwL,EAAIvY,MAAMC,QAAQiY,GAAWA,EAAQnL,GAAGuL,OAASJ,EAAQ/I,GAC/D,GAAgB,YAAZoJ,EAAErF,OAAmC,UAAZqF,EAAErF,OAAiC,SAAZqF,EAAErF,OACtC,WAAZqF,EAAErF,OAAkC,cAAZqF,EAAErF,MAC1B,MAAM,IAAInW,MAAM,gCAAgCoS,OAAUoJ,EAAErF,SAEhE,MAAMsF,EAAO,CAAErJ,OAAMkE,MAAOkF,EAAElF,MAAOH,MAAOqF,EAAErF,OAC9C,GAAgB,WAAZqF,EAAErF,MAAoB,CACtB,MAAMuF,EAAY,IAAIna,SAAQ8S,MAAO7S,IACjC,MAAMma,QAAaH,EAAEI,QACfC,EAAgBF,EAAKzE,QAAO,CAAC4E,EAAGC,IAAMD,EAAIC,EAAE1Y,QAAQ,GApC1C,EAqCcsY,EAAKtY,OAC7BuY,EAAQ,IAAI7D,WAAW8D,GAC7B,IAAIG,EAAS,EACb,IAAK,IAAIhM,EAAI,EAAGA,EAAI2L,EAAKtY,OAAQ2M,IAAK,CAClC,MAAMiM,EAAMN,EAAK3L,GACXkM,EAAgB,IAAInE,WAAW,IAAIoE,YAAY,CAACF,EAAI5Y,SAAS4U,QACnE2D,EAAM1D,IAAIgE,EAAeF,GACzBA,GA5CY,EA6CZJ,EAAM1D,IAAI+D,EAAKD,GACfA,GAAUC,EAAI5Y,OAElB7B,EAAQoa,MAEZP,EAAa3I,KAAKgJ,QAGlBL,EAAa3I,KAAK8I,EAAEY,QAEX,MAAT/I,IACAoI,EAAKpI,MAAQA,GAEjB+H,EAAM1I,KAAK+I,GAGf,MAAO,CAAEW,KAAMC,QADY9a,QAAQ0S,IAAIoH,IACcD,SAiBlD,SAASkB,EAAcrE,EAAQmD,GAElC,MAAMxX,EAAM,GACZ,IAAI2Y,EACAP,EAAS,EACb,IAAK,MAAMP,KAAQL,EAAO,CACtB,MAAMhJ,EAAOqJ,EAAKrJ,KACZ+D,EAAQsF,EAAKtF,MACbG,EAAQmF,EAAKnF,MACbkG,EAAO,wBAAclG,GAC3B,IAAImG,EACJ,GAAI,iBAAkBhB,EAAM,CACxB,MAAMvF,EAAeuF,EAAKvF,aAC1B,GAA2B,UAAvBA,EAAaC,OAA4C,WAAvBD,EAAaC,OAC/C,KAAM,QAASD,MAAgB,UAAWA,GACtC,MAAM,IAAIlW,MAAM,UAAUyb,EAAKrJ,0BAA0B8D,EAAaC,gEAIzE,IAA2B,YAAvBD,EAAaC,MAOlB,MAAM,IAAInW,MAAM,UAAUyb,EAAKrJ,uCACL8D,EAAaC,+EAPvC,GAAc,YAAVA,EACA,MAAM,IAAInW,MAAM,UAAUyb,EAAKrJ,0BAA0B8D,EAAaC,yDACfA,MAS/D,MAAMuG,EAAyB,IAAqBxG,EAAaC,OAC3DgC,EAAaF,EAAO7U,MAAM4Y,EAAQA,EAASQ,EAAOE,GAClDC,EAAyC,UAAvBzG,EAAaC,MACjC,IAAI4B,WAAWI,GACf,IAAIyE,YAAYzE,GACpB,GAAc,YAAVhC,EACA,GAA2B,UAAvBD,EAAaC,OAA4C,WAAvBD,EAAaC,MAAoB,CACnEsG,EAAS,IAAII,aAAaF,EAAetZ,QACzC,IAAK,IAAI2M,EAAI,EAAGA,EAAI2M,EAAetZ,OAAQ2M,IAAK,CAC5C,MAAM8M,EAAIH,EAAe3M,GACzByM,EAAOzM,GAAK8M,EAAI5G,EAAa6G,MAAQ7G,EAAa8G,SAGrD,IAA2B,YAAvB9G,EAAaC,MAOlB,MAAM,IAAInW,MAAM,iCAAiCkW,EAAaC,uCANxC8G,IAAlBV,IACAA,EAAgBW,KAEpBT,EAASF,EAAcI,OAO1B,IAAc,UAAVxG,EAYL,MAAM,IAAInW,MAAM,gCAAgCoS,OAAU+D,KAX1D,GAA2B,UAAvBD,EAAaC,OAA4C,WAAvBD,EAAaC,MAC/C,MAAM,IAAInW,MAAM,iCAAiCkW,EAAaC,gCAGlEsG,EAAS,IAAIU,WAAWR,EAAetZ,QACvC,IAAK,IAAI2M,EAAI,EAAGA,EAAI2M,EAAetZ,OAAQ2M,IAAK,CAC5C,MAAM8M,EAAIH,EAAe3M,GACzByM,EAAOzM,GAAKoN,KAAKC,MAAMP,EAAI5G,EAAa6G,MAAQ7G,EAAa8G,MAMrEhB,GAAUQ,EAAOE,OAEhB,GAAc,WAAVvG,EAAoB,CACzB,MAAMqG,EAAO,wBAAcf,EAAKnF,OAChCmG,EAAS,GACT,IAAK,IAAIzM,EAAI,EAAGA,EAAIwM,EAAMxM,IAAK,CAC3B,MAAM4H,EAAa,IAAIuE,YAAYlE,EAAO7U,MAAM4Y,EAAQA,EAzJxC,IAyJ2E,GAC3FA,GA1JgB,EA2JhB,MAAMJ,EAAQ,IAAI7D,WAAWE,EAAO7U,MAAM4Y,EAAQA,EAASpE,IAC3D6E,EAAO/J,KAAKkJ,GACZI,GAAUpE,OAGb,CACD,MAAM0F,EAAc,IAAqBnH,GACnCgC,EAAaF,EAAO7U,MAAM4Y,EAAQA,EAASQ,EAAOc,GACxD,GAAc,YAAVnH,EACAsG,EAAS,IAAII,aAAa1E,QAEzB,GAAc,UAAVhC,EACLsG,EAAS,IAAIU,WAAWhF,QAEvB,GAAc,SAAVhC,EACLsG,EAAS,IAAI1E,WAAWI,OAEvB,IAAc,cAAVhC,EAaL,MAAM,IAAInW,MAAM,gCAAgCoS,OAAU+D,KAb9B,CAC5BsG,EAAS,IAAII,aAAa1E,GAC1B,MAAMoF,EAAO,IAAIV,aAAaJ,EAAOpZ,OAAS,GACxCma,EAAQ,IAAIX,aAAaJ,EAAOpZ,OAAS,GAC/C,IAAK,IAAI2M,EAAI,EAAGA,EAAIuN,EAAKla,OAAQ2M,IAC7BuN,EAAKvN,GAAKyM,EAAW,EAAJzM,GACjBwN,EAAMxN,GAAKyM,EAAW,EAAJzM,EAAQ,GAE9B,MAAMyN,EAAa,YAAOF,EAAMjH,EAAO,WACjCoH,EAAc,YAAOF,EAAOlH,EAAO,WACzC1S,EAAIwO,GAAQ,YAAQqL,EAAYC,IAKpC1B,GAAUQ,EAAOc,EAEP,cAAVnH,IACAvS,EAAIwO,GAAQ,YAAOqK,EAAQnG,EAAOH,IAG1C,OAAOvS,EAKJ,SAASyY,EAAuBsB,GAEnC,GAAW,OAAPA,EACA,MAAM,IAAI3d,MAAM,wBAAwB0O,KAAKC,UAAUgP,MAE3D,IAAIC,EAAkB,EAQtB,MAAMC,EAAe,GACrBF,EAAGnL,SAASsL,IAKR,GAJAF,GAAmBE,EAAElG,WAErBiG,EAAanL,KAAKoL,EAAElG,aAAekG,EAAE7F,OAAOL,WAAakG,EACrD,IAAIA,EAAEC,YAAYD,MAChBA,aAAajB,cAAgBiB,aAAaX,YAC5CW,aAAa/F,YACb,MAAM,IAAI/X,MAAM,mCAAmC8d,EAAEC,YAAY3L,WAIzE,MAAM4L,EAAI,IAAIjG,WAAW6F,GACzB,IAAI5B,EAAS,EAKb,OAJA6B,EAAarL,SAASsL,IAClBE,EAAE9F,IAAI,IAAIH,WAAW+F,EAAE7F,QAAS+D,GAChCA,GAAU8B,EAAElG,cAEToG,EAAE/F,OAGb,MAAMgG,OAAkC,IAAXC,IACR,oBAATtN,MAAwC,oBAATuN,MACnB,oBAATC,MAUR,SAASC,EAAiBC,GAC7B,OAAIL,EACOC,EAAOtG,WAAW0G,GAEtB,IAAI1N,KAAK,CAAC0N,IAAM9B,KAQpB,SAAS+B,EAA0BtG,GACtC,GAAIgG,EACA,OAAOC,EAAOM,KAAKvG,GAAQwG,SAAS,UAExC,MAAMC,EAAM,IAAI3G,WAAWE,GAC3B,IAAI0G,EAAI,GACR,IAAK,IAAI3O,EAAI,EAAG4O,EAAIF,EAAIrb,OAAQ2M,EAAI4O,EAAG5O,IACnC2O,GAAKE,OAAOC,aAAaJ,EAAI1O,IAEjC,OAAOoO,KAAKO,GAQT,SAASI,EAA0BT,GACtC,GAAIL,EAAe,CACf,MAAMS,EAAMR,EAAOM,KAAKF,EAAK,UAC7B,OAAOI,EAAIzG,OAAO7U,MAAMsb,EAAIM,WAAYN,EAAIM,WAAaN,EAAI9G,YAEjE,MAAM+G,EAAIR,KAAKG,GACTrG,EAAS,IAAIF,WAAW4G,EAAEtb,QAChC,IAAK,IAAI2M,EAAI,EAAGA,EAAI2O,EAAEtb,SAAU2M,EAC5BiI,EAAOC,IAAI,CAACyG,EAAEM,WAAWjP,IAAKA,GAElC,OAAOiI,EAAOA,OAQX,SAASiH,EAAwB3H,GACpC,GAAuB,IAAnBA,EAAQlU,OACR,OAAOkU,EAAQ,GAEnB,IAAIqG,EAAkB,EACtBrG,EAAQ/E,SAASyF,IACb2F,GAAmB3F,EAAOL,cAE9B,MAAMuH,EAAO,IAAIpH,WAAW6F,GAC5B,IAAI5B,EAAS,EAKb,OAJAzE,EAAQ/E,SAASyF,IACbkH,EAAKjH,IAAI,IAAIH,WAAWE,GAAS+D,GACjCA,GAAU/D,EAAOL,cAEduH,EAAKlH,OAST,SAASmH,EAAStb,GAGrB,IADAA,EAAOA,EAAKub,OACLvb,EAAKmM,SAFM,MAGdnM,EAAOA,EAAKV,MAAM,EAAGU,EAAKT,OAAS,GAEvC,MAAM+K,EAAQtK,EAAKuK,MALD,KAMlB,OAAOD,EAAMA,EAAM/K,OAAS,GAOzB,SAASic,EAA6Bne,GACzC,GAAIA,EAAeC,yBAAyBC,YACxC,MAAM,IAAIrB,MAAM,uDAEpB,MAAO,CACHuf,UAAW,IAAIC,KACfhQ,kBAAmB,OACnBL,mBAAoD,MAAhChO,EAAeC,cAC/B,EACAid,EAAiB3P,KAAKC,UAAUxN,EAAeC,gBACnDgO,iBAAgD,MAA9BjO,EAAe6M,YAC7B,EACAqQ,EAAiB3P,KAAKC,UAAUxN,EAAe6M,cACnDqB,gBAA8C,MAA7BlO,EAAe8M,WAC5B,EACA9M,EAAe8M,WAAW2J,YAwE/B,SAASsF,IAIZ,MAAMuC,EAnEV,WACI,MAAMC,EAAmB1P,IACrB,IAAI2P,EAAI3P,GAAK,GACTqJ,EAAI,EACR,KAA4B,IAAhB,QAAJsG,IACJtG,GAAK,QACLsG,IAAM,EAIV,OAFAA,IAAK,QACLtG,GAAK,UACEsG,EAAItG,GAEToG,EAAe,IAAItD,YAAY,MACrCsD,EAAa,GAAK,EAClB,IAAK,IAAIzP,EAAI,EAAGA,EAAI,KAAMA,IACtByP,EAAazP,GAAK0P,EAAgB1P,GAEtC,IAAK,IAAIA,EAAI,KAAMA,EAAI,KAAMA,IACzByP,EAAazP,GAAK,WAAeA,EAAI,MAAS,IAElD,OAAOyP,EA+CcG,GACfC,EAxCV,WACI,MAAMA,EAAgB,IAAI1D,YAAY,IACtC0D,EAAc,GAAK,EACnBA,EAAc,IAAM,WACpBA,EAAc,IAAM,WACpBA,EAAc,IAAM,WACpB,IAAK,IAAI7P,EAAI,EAAGA,EAAI,GAAIA,IACpB6P,EAAc7P,GAAKA,GAAK,GAE5B,IAAK,IAAIA,EAAI,GAAIA,EAAI,GAAIA,IACrB6P,EAAc7P,GAAK,YAAeA,EAAI,IAAO,IAEjD,OAAO6P,EA4BeC,GAChBC,EArBV,WACI,MAAMA,EAAc,IAAI5D,YAAY,IACpC,IAAK,IAAInM,EAAI,EAAGA,EAAI,GAAIA,IACpB+P,EAAY/P,GAAK,KAGrB,OADA+P,EAAY,GAAKA,EAAY,IAAM,EAC5BA,EAeaC,GACpB,OAAQrD,IACJ,MAAM1E,EAAS,IAAI5W,YAAY,EAAIsb,EAAetZ,QAC5C4c,EAAmB,IAAI9D,YAAYlE,GACzC,IAAK,IAAIrF,EAAQ,EAAGA,EAAQ+J,EAAetZ,OAAQuP,IAAS,CACxD,MAAMsN,EAAcvD,EAAe/J,GAC7BuN,EAAcV,EAAaM,EAAYG,GAAe,KAAqB,KAAdA,IAC/DL,EAAcK,GAAe,IACjCD,EAAiBrN,GAASuN,EAE9B,OAAO,IAAItD,aAAa5E,O,0DCpchC,0KAgBO,MAAMmI,EACT,cACIlf,KAAKmf,YAAc,GACnBnf,KAAKof,YAAc,GAEvB,qBAII,OAHiC,MAA7BF,EAAiBG,WACjBH,EAAiBG,SAAW,IAAIH,GAE7BA,EAAiBG,SAQ5B,0BAA0BC,GACtBJ,EAAiBK,cAAcJ,YAAY3N,KAAK8N,GAQpD,0BAA0BE,GACtBN,EAAiBK,cAAcH,YAAY5N,KAAKgO,GAUpD,uBAAuB1d,GACnB,OAAOod,EAAiBO,YAAY3d,EAAK,QAU7C,uBAAuBA,EAAKwR,GACxB,OAAO4L,EAAiBO,YAAY3d,EAAK,OAAQwR,GAErD,mBAAmBxR,EAAK4d,EAAapM,GACjC,MAAMqM,EAAgB,GAUtB,OATgC,SAAhBD,EACZR,EAAiBK,cAAcH,YAC/BF,EAAiBK,cAAcJ,aAC3B7N,SAAQsO,IACZ,MAAMC,EAAUD,EAAO9d,EAAKwR,GACZ,OAAZuM,GACAF,EAAcnO,KAAKqO,MAGpBF,GAGR,MAAMvd,EAAsB0d,GAAeZ,EAAiB9c,mBAAmB0d,GACzEzd,EAAsByd,GAAeZ,EAAiB7c,mBAAmByd,GACzEC,EAAmBje,GAAQod,EAAiBa,gBAAgBje,GAC5Dke,EAAkB,CAACle,EAAKwR,IAAgB4L,EAAiBc,gBAAgBle,EAAKwR,I,gCCpF3F,+LAkBA,MAAM2M,EAAiB,YAAU,kBAAkB,IAAM,IAAIC,MACvDC,EAAe,YAAU,gBAAgB,IAAM,IAAID,MAOlD,SAASE,EAAUC,EAAYC,GAClC,MAAMzd,EAAM0d,EAAQF,EAAYC,GAChC,OAAOL,EAAelf,IAAI8B,GAMvB,SAAS2d,EAAYH,GACxB,OAAOF,EAAapf,IAAIsf,GAErB,SAASI,EAAqBH,GACjC,MAAMI,EAAKT,EAAeU,UACpBhhB,EAAS,GACf,OAAa,CACT,MAAM,KAAEihB,EAAI,MAAE3N,GAAUyN,EAAGG,OAC3B,GAAID,EACA,MAEJ,MAAO/d,EAAKie,GAAU7N,GACf8N,GAAYle,EAAIsK,MAAM,KACzB4T,IAAYT,GACZ3gB,EAAO6R,KAAKsP,GAGpB,OAAOnhB,EAaJ,SAASqhB,EAAeF,GAC3B,MAAM,WAAET,EAAU,YAAEC,GAAgBQ,EAC9Bje,EAAM0d,EAAQF,EAAYC,GAC5BL,EAAegB,IAAIpe,IACnBgX,QAAQC,KAAK,eAAeuG,mBACpBC,4BAEZL,EAAejJ,IAAInU,EAAKie,GAUrB,SAASI,EAAiBJ,GAC7B,MAAM,WAAET,GAAeS,EACnBX,EAAac,IAAIZ,IAGb,cAAMxhB,QAAQ,UACdgb,QAAQC,KAAK,gCAAgCuG,MAGrDF,EAAanJ,IAAIqJ,EAAYS,GAwBjC,SAASP,EAAQF,EAAYC,GACzB,MAAO,GAAGA,KAAeD,M,gCCnH7B,6LA4BA,MAAMc,EAAoB,MACnB,MAAMC,EACT,cACIphB,KAAKqhB,SAAW,GAEpB,qBAII,OAH0C,MAAtCD,EAA0B/B,WAC1B+B,EAA0B/B,SAAW,IAAI+B,GAEtCA,EAA0B/B,SAQrC,uBAAuBiC,EAAQC,GAC3B,iBAAiB,MAAVD,GAAgB,IAAM,0CACzBA,EAAOvS,SAASoS,KAChBG,EAASA,EAAOpf,MAAM,EAAGof,EAAO3P,QAAQwP,KAE5C,iBAAOG,EAAOnf,OAAS,GAAG,IAAM,wCAChC,MAAMqf,EAAWJ,EAA0B7B,cAC3C,iBAAoC,MAA7BiC,EAASH,SAASC,IAAiB,IAAM,2DAA2DA,QAC3GE,EAASH,SAASC,GAAUC,EAEhC,kBAAkBD,GACd,MAAMC,EAAUvhB,KAAKuf,cAAc8B,SAASC,GAC5C,GAAe,MAAXC,EACA,MAAM,IAAIziB,MAAM,yCAAyCwiB,MAE7D,OAAOC,EAEX,oBACI,OAAO/J,OAAOjK,KAAKvN,KAAKuf,cAAc8B,WAW9C,SAASI,EAAS3f,GACd,IAAwC,IAApCA,EAAI6P,QAAQwP,GACZ,MAAM,IAAIriB,MAEN,6EAAGsiB,EAA0BM,aAAa9U,KAAK,QAEvD,MAAO,CACH0U,OAAQxf,EAAIqL,MAAMgU,GAAmB,GACrCve,KAAMd,EAAIqL,MAAMgU,GAAmB,IAG3ChO,eAAewO,EAAmBC,EAAWC,EAASC,GAAe,GACjE,iBAAOF,IAAcC,GAAS,IAAM,wCAAwCD,OAC5E,MAAMG,EAAe,IAAiB/B,gBAAgB4B,GACtD,iBAAOG,EAAa5f,OAAS,GAAG,IAAM,kEAAkEyf,OACxG,iBAAOG,EAAa5f,OAAS,GAAG,IAAM,yCAAyC4f,EAAa5f,wCACxDyf,OACpC,MAAMI,EAAcD,EAAa,GAC3BE,EAAe,IAAiBlC,gBAAgB8B,GACtD,iBAAOI,EAAa9f,OAAS,GAAG,IAC5B,uEAAO0f,OACX,iBAAOI,EAAa9f,OAAS,GAAG,IAAM,yCAAyC4f,EAAa5f,6CACnD0f,OACzC,MAAMpI,EAAcwI,EAAa,GAC3BC,EAAeT,EAASG,GAAWN,OACnCa,EAAaV,EAASG,GAAWhf,KACjCwf,EAAaF,IAAiBT,EAASG,GAAWN,OAClDrhB,QAAuB+hB,EAAYK,OAIrCP,GAAgBM,SACVhB,EAA0BkB,WAAWJ,GACtCK,YAAYJ,GAErB,MAAMK,QAAmB/I,EAAYgJ,KAAKxiB,GAQ1C,OAJI6hB,IAAiBM,SACXhB,EAA0BkB,WAAWJ,GACtCK,YAAYJ,GAEdK,EAAWphB,mBAqCtB+R,eAAeuP,IACX,MAAMC,EAAUvB,EAA0BM,aACpChf,EAAM,GACZ,IAAK,MAAM4e,KAAUqB,EAAS,CAC1B,MAAMC,QAAkBxB,EAA0BkB,WAAWhB,GAAQoB,aACrE,IAAK,MAAM9f,KAAQggB,EAAW,CAE1BlgB,EADY4e,EAASH,EAAoBve,GAC9BggB,EAAUhgB,IAG7B,OAAOF,EAmCXyQ,eAAeoP,EAAYzgB,GACvB,MAAM+gB,EAAgBpB,EAAS3f,GAE/B,OADgBsf,EAA0BkB,WAAWO,EAAcvB,QACpDiB,YAAYM,EAAcjgB,MAiD7CuQ,eAAe2P,EAAUlB,EAAWC,GAEhC,OAAOF,EAAmBC,EAAWC,GADhB,GAiDzB1O,eAAe4P,EAAUnB,EAAWC,GAEhC,OAAOF,EAAmBC,EAAWC,GADhB","file":"js/bundle~bundle~18ffb1da.339c1579.js","sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n/* Type definitions for exporting and importing of models. */\n/**\n * A map from Tensor dtype to number of bytes per element of the Tensor.\n */\nexport const DTYPE_VALUE_SIZE_MAP = {\n    'float32': 4,\n    'float16': 2,\n    'int32': 4,\n    'uint16': 2,\n    'uint8': 1,\n    'bool': 1,\n    'complex64': 8\n};\n//# sourceMappingURL=types.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport '../flags';\nimport { env } from '../environment';\nimport { getModelArtifactsInfoForJSON } from './io_utils';\nimport { IORouterRegistry } from './router_registry';\nconst DATABASE_NAME = 'tensorflowjs';\nconst DATABASE_VERSION = 1;\n// Model data and ModelArtifactsInfo (metadata) are stored in two separate\n// stores for efficient access of the list of stored models and their metadata.\n// 1. The object store for model data: topology, weights and weight manifests.\nconst MODEL_STORE_NAME = 'models_store';\n// 2. The object store for ModelArtifactsInfo, including meta-information such\n//    as the type of topology (JSON vs binary), byte size of the topology, byte\n//    size of the weights, etc.\nconst INFO_STORE_NAME = 'model_info_store';\n/**\n * Delete the entire database for tensorflow.js, including the models store.\n */\nexport async function deleteDatabase() {\n    const idbFactory = getIndexedDBFactory();\n    return new Promise((resolve, reject) => {\n        const deleteRequest = idbFactory.deleteDatabase(DATABASE_NAME);\n        deleteRequest.onsuccess = () => resolve();\n        deleteRequest.onerror = error => reject(error);\n    });\n}\nfunction getIndexedDBFactory() {\n    if (!env().getBool('IS_BROWSER')) {\n        // TODO(cais): Add more info about what IOHandler subtypes are available.\n        //   Maybe point to a doc page on the web and/or automatically determine\n        //   the available IOHandlers and print them in the error message.\n        throw new Error('Failed to obtain IndexedDB factory because the current environment' +\n            'is not a web browser.');\n    }\n    // tslint:disable-next-line:no-any\n    const theWindow = typeof window === 'undefined' ? self : window;\n    const factory = theWindow.indexedDB || theWindow.mozIndexedDB ||\n        theWindow.webkitIndexedDB || theWindow.msIndexedDB ||\n        theWindow.shimIndexedDB;\n    if (factory == null) {\n        throw new Error('The current browser does not appear to support IndexedDB.');\n    }\n    return factory;\n}\nfunction setUpDatabase(openRequest) {\n    const db = openRequest.result;\n    db.createObjectStore(MODEL_STORE_NAME, { keyPath: 'modelPath' });\n    db.createObjectStore(INFO_STORE_NAME, { keyPath: 'modelPath' });\n}\n/**\n * IOHandler subclass: Browser IndexedDB.\n *\n * See the doc string of `browserIndexedDB` for more details.\n */\nexport class BrowserIndexedDB {\n    constructor(modelPath) {\n        this.indexedDB = getIndexedDBFactory();\n        if (modelPath == null || !modelPath) {\n            throw new Error('For IndexedDB, modelPath must not be null, undefined or empty.');\n        }\n        this.modelPath = modelPath;\n    }\n    async save(modelArtifacts) {\n        // TODO(cais): Support saving GraphDef models.\n        if (modelArtifacts.modelTopology instanceof ArrayBuffer) {\n            throw new Error('BrowserLocalStorage.save() does not support saving model topology ' +\n                'in binary formats yet.');\n        }\n        return this.databaseAction(this.modelPath, modelArtifacts);\n    }\n    async load() {\n        return this.databaseAction(this.modelPath);\n    }\n    /**\n     * Perform database action to put model artifacts into or read model artifacts\n     * from IndexedDB object store.\n     *\n     * Whether the action is put or get depends on whether `modelArtifacts` is\n     * specified. If it is specified, the action will be put; otherwise the action\n     * will be get.\n     *\n     * @param modelPath A unique string path for the model.\n     * @param modelArtifacts If specified, it will be the model artifacts to be\n     *   stored in IndexedDB.\n     * @returns A `Promise` of `SaveResult`, if the action is put, or a `Promise`\n     *   of `ModelArtifacts`, if the action is get.\n     */\n    databaseAction(modelPath, modelArtifacts) {\n        return new Promise((resolve, reject) => {\n            const openRequest = this.indexedDB.open(DATABASE_NAME, DATABASE_VERSION);\n            openRequest.onupgradeneeded = () => setUpDatabase(openRequest);\n            openRequest.onsuccess = () => {\n                const db = openRequest.result;\n                if (modelArtifacts == null) {\n                    // Read model out from object store.\n                    const modelTx = db.transaction(MODEL_STORE_NAME, 'readonly');\n                    const modelStore = modelTx.objectStore(MODEL_STORE_NAME);\n                    const getRequest = modelStore.get(this.modelPath);\n                    getRequest.onsuccess = () => {\n                        if (getRequest.result == null) {\n                            db.close();\n                            return reject(new Error(`Cannot find model with path '${this.modelPath}' ` +\n                                `in IndexedDB.`));\n                        }\n                        else {\n                            resolve(getRequest.result.modelArtifacts);\n                        }\n                    };\n                    getRequest.onerror = error => {\n                        db.close();\n                        return reject(getRequest.error);\n                    };\n                    modelTx.oncomplete = () => db.close();\n                }\n                else {\n                    // Put model into object store.\n                    const modelArtifactsInfo = getModelArtifactsInfoForJSON(modelArtifacts);\n                    // First, put ModelArtifactsInfo into info store.\n                    const infoTx = db.transaction(INFO_STORE_NAME, 'readwrite');\n                    let infoStore = infoTx.objectStore(INFO_STORE_NAME);\n                    const putInfoRequest = infoStore.put({ modelPath: this.modelPath, modelArtifactsInfo });\n                    let modelTx;\n                    putInfoRequest.onsuccess = () => {\n                        // Second, put model data into model store.\n                        modelTx = db.transaction(MODEL_STORE_NAME, 'readwrite');\n                        const modelStore = modelTx.objectStore(MODEL_STORE_NAME);\n                        const putModelRequest = modelStore.put({\n                            modelPath: this.modelPath,\n                            modelArtifacts,\n                            modelArtifactsInfo\n                        });\n                        putModelRequest.onsuccess = () => resolve({ modelArtifactsInfo });\n                        putModelRequest.onerror = error => {\n                            // If the put-model request fails, roll back the info entry as\n                            // well.\n                            infoStore = infoTx.objectStore(INFO_STORE_NAME);\n                            const deleteInfoRequest = infoStore.delete(this.modelPath);\n                            deleteInfoRequest.onsuccess = () => {\n                                db.close();\n                                return reject(putModelRequest.error);\n                            };\n                            deleteInfoRequest.onerror = error => {\n                                db.close();\n                                return reject(putModelRequest.error);\n                            };\n                        };\n                    };\n                    putInfoRequest.onerror = error => {\n                        db.close();\n                        return reject(putInfoRequest.error);\n                    };\n                    infoTx.oncomplete = () => {\n                        if (modelTx == null) {\n                            db.close();\n                        }\n                        else {\n                            modelTx.oncomplete = () => db.close();\n                        }\n                    };\n                }\n            };\n            openRequest.onerror = error => reject(openRequest.error);\n        });\n    }\n}\nBrowserIndexedDB.URL_SCHEME = 'indexeddb://';\nexport const indexedDBRouter = (url) => {\n    if (!env().getBool('IS_BROWSER')) {\n        return null;\n    }\n    else {\n        if (!Array.isArray(url) && url.startsWith(BrowserIndexedDB.URL_SCHEME)) {\n            return browserIndexedDB(url.slice(BrowserIndexedDB.URL_SCHEME.length));\n        }\n        else {\n            return null;\n        }\n    }\n};\nIORouterRegistry.registerSaveRouter(indexedDBRouter);\nIORouterRegistry.registerLoadRouter(indexedDBRouter);\n/**\n * Creates a browser IndexedDB IOHandler for saving and loading models.\n *\n * ```js\n * const model = tf.sequential();\n * model.add(\n *     tf.layers.dense({units: 1, inputShape: [100], activation: 'sigmoid'}));\n *\n * const saveResult = await model.save('indexeddb://MyModel'));\n * console.log(saveResult);\n * ```\n *\n * @param modelPath A unique identifier for the model to be saved. Must be a\n *   non-empty string.\n * @returns An instance of `BrowserIndexedDB` (sublcass of `IOHandler`),\n *   which can be used with, e.g., `tf.Model.save`.\n */\nexport function browserIndexedDB(modelPath) {\n    return new BrowserIndexedDB(modelPath);\n}\nfunction maybeStripScheme(key) {\n    return key.startsWith(BrowserIndexedDB.URL_SCHEME) ?\n        key.slice(BrowserIndexedDB.URL_SCHEME.length) :\n        key;\n}\nexport class BrowserIndexedDBManager {\n    constructor() {\n        this.indexedDB = getIndexedDBFactory();\n    }\n    async listModels() {\n        return new Promise((resolve, reject) => {\n            const openRequest = this.indexedDB.open(DATABASE_NAME, DATABASE_VERSION);\n            openRequest.onupgradeneeded = () => setUpDatabase(openRequest);\n            openRequest.onsuccess = () => {\n                const db = openRequest.result;\n                const tx = db.transaction(INFO_STORE_NAME, 'readonly');\n                const store = tx.objectStore(INFO_STORE_NAME);\n                // tslint:disable:max-line-length\n                // Need to cast `store` as `any` here because TypeScript's DOM\n                // library does not have the `getAll()` method even though the\n                // method is supported in the latest version of most mainstream\n                // browsers:\n                // https://developer.mozilla.org/en-US/docs/Web/API/IDBObjectStore/getAll\n                // tslint:enable:max-line-length\n                // tslint:disable-next-line:no-any\n                const getAllInfoRequest = store.getAll();\n                getAllInfoRequest.onsuccess = () => {\n                    const out = {};\n                    for (const item of getAllInfoRequest.result) {\n                        out[item.modelPath] = item.modelArtifactsInfo;\n                    }\n                    resolve(out);\n                };\n                getAllInfoRequest.onerror = error => {\n                    db.close();\n                    return reject(getAllInfoRequest.error);\n                };\n                tx.oncomplete = () => db.close();\n            };\n            openRequest.onerror = error => reject(openRequest.error);\n        });\n    }\n    async removeModel(path) {\n        path = maybeStripScheme(path);\n        return new Promise((resolve, reject) => {\n            const openRequest = this.indexedDB.open(DATABASE_NAME, DATABASE_VERSION);\n            openRequest.onupgradeneeded = () => setUpDatabase(openRequest);\n            openRequest.onsuccess = () => {\n                const db = openRequest.result;\n                const infoTx = db.transaction(INFO_STORE_NAME, 'readwrite');\n                const infoStore = infoTx.objectStore(INFO_STORE_NAME);\n                const getInfoRequest = infoStore.get(path);\n                let modelTx;\n                getInfoRequest.onsuccess = () => {\n                    if (getInfoRequest.result == null) {\n                        db.close();\n                        return reject(new Error(`Cannot find model with path '${path}' ` +\n                            `in IndexedDB.`));\n                    }\n                    else {\n                        // First, delete the entry in the info store.\n                        const deleteInfoRequest = infoStore.delete(path);\n                        const deleteModelData = () => {\n                            // Second, delete the entry in the model store.\n                            modelTx = db.transaction(MODEL_STORE_NAME, 'readwrite');\n                            const modelStore = modelTx.objectStore(MODEL_STORE_NAME);\n                            const deleteModelRequest = modelStore.delete(path);\n                            deleteModelRequest.onsuccess = () => resolve(getInfoRequest.result.modelArtifactsInfo);\n                            deleteModelRequest.onerror = error => reject(getInfoRequest.error);\n                        };\n                        // Proceed with deleting model data regardless of whether deletion\n                        // of info data succeeds or not.\n                        deleteInfoRequest.onsuccess = deleteModelData;\n                        deleteInfoRequest.onerror = error => {\n                            deleteModelData();\n                            db.close();\n                            return reject(getInfoRequest.error);\n                        };\n                    }\n                };\n                getInfoRequest.onerror = error => {\n                    db.close();\n                    return reject(getInfoRequest.error);\n                };\n                infoTx.oncomplete = () => {\n                    if (modelTx == null) {\n                        db.close();\n                    }\n                    else {\n                        modelTx.oncomplete = () => db.close();\n                    }\n                };\n            };\n            openRequest.onerror = error => reject(openRequest.error);\n        });\n    }\n}\n//# sourceMappingURL=indexed_db.js.map","export const Abs = 'Abs';\nexport const Acos = 'Acos';\nexport const Acosh = 'Acosh';\nexport const Add = 'Add';\nexport const AddN = 'AddN';\nexport const All = 'All';\nexport const Any = 'Any';\nexport const ArgMax = 'ArgMax';\nexport const ArgMin = 'ArgMin';\nexport const Asin = 'Asin';\nexport const Asinh = 'Asinh';\nexport const Atan = 'Atan';\nexport const Atanh = 'Atanh';\nexport const Atan2 = 'Atan2';\nexport const AvgPool = 'AvgPool';\nexport const AvgPoolBackprop = 'AvgPoolBackprop';\nexport const AvgPool3D = 'AvgPool3D';\nexport const AvgPool3DBackprop = 'AvgPool3DBackprop';\nexport const BatchMatMul = 'BatchMatMul';\nexport const BatchToSpaceND = 'BatchToSpaceND';\nexport const BroadcastTo = 'BroadcastTo';\nexport const Cast = 'Cast';\nexport const Ceil = 'Ceil';\nexport const ClipByValue = 'ClipByValue';\nexport const Complex = 'Complex';\nexport const Concat = 'Concat';\nexport const Conv2D = 'Conv2D';\nexport const Conv2DBackpropFilter = 'Conv2DBackpropFilter';\nexport const Conv2DBackpropInput = 'Conv2DBackpropInput';\nexport const Conv3D = 'Conv3D';\nexport const Conv3DBackpropFilterV2 = 'Conv3DBackpropFilterV2';\nexport const Conv3DBackpropInputV2 = 'Conv3DBackpropInputV2';\nexport const Cos = 'Cos';\nexport const Cosh = 'Cosh';\nexport const Cumsum = 'Cumsum';\nexport const CropAndResize = 'CropAndResize';\nexport const DepthToSpace = 'DepthToSpace';\nexport const DepthwiseConv2dNative = 'DepthwiseConv2dNative';\nexport const DepthwiseConv2dNativeBackpropFilter = 'DepthwiseConv2dNativeBackpropFilter';\nexport const DepthwiseConv2dNativeBackpropInput = 'DepthwiseConv2dNativeBackpropInput';\nexport const Diag = 'Diag';\nexport const Dilation2D = 'Dilation2D';\nexport const Dilation2DBackpropInput = 'Dilation2DBackpropInput';\nexport const Dilation2DBackpropFilter = 'Dilation2DBackpropFilter';\nexport const Div = 'Div';\nexport const Elu = 'Elu';\nexport const EluGrad = 'EluGrad';\nexport const Erf = 'Erf';\nexport const Equal = 'Equal';\nexport const Exp = 'Exp';\nexport const Expm1 = 'Expm1';\nexport const FFT = 'FFT';\nexport const Fill = 'Fill';\nexport const FlipLeftRight = 'FlipLeftRight';\nexport const Floor = 'Floor';\nexport const FloorDiv = 'FloorDiv';\nexport const FusedBatchNorm = 'FusedBatchNorm';\nexport const GatherV2 = 'GatherV2';\nexport const GatherNd = 'GatherNd';\nexport const Greater = 'Greater';\nexport const GreaterEqual = 'GreaterEqual';\nexport const Identity = 'Identity';\nexport const IFFT = 'IFFT';\nexport const Imag = 'Imag';\nexport const IsFinite = 'IsFinite';\nexport const IsInf = 'IsInf';\nexport const IsNan = 'IsNan';\nexport const Less = 'Less';\nexport const LessEqual = 'LessEqual';\nexport const LinSpace = 'LinSpace';\nexport const Log = 'Log';\nexport const Log1p = 'Log1p';\nexport const LogicalAnd = 'LogicalAnd';\nexport const LogicalNot = 'LogicalNot';\nexport const LogicalOr = 'LogicalOr';\nexport const LogSoftmax = 'LogSoftmax';\nexport const LRN = 'LRN';\nexport const LRNBackprop = 'LRNBackprop';\nexport const Max = 'Max';\nexport const Maximum = 'Maximum';\nexport const MaxPool = 'MaxPool';\nexport const MaxPoolBackprop = 'MaxPoolBackprop';\nexport const MaxPool3D = 'MaxPool3D';\nexport const MaxPool3DBackprop = 'MaxPool3DBackprop';\nexport const MaxPoolWithArgmax = 'MaxPoolWithArgmax';\nexport const Mean = 'Mean';\nexport const Min = 'Min';\nexport const Minimum = 'Minimum';\nexport const Mod = 'Mod';\nexport const Multiply = 'Multiply';\nexport const Negate = 'Negate';\nexport const NotEqual = 'NotEqual';\nexport const NonMaxSuppressionV3 = 'NonMaxSuppressionV3';\nexport const NonMaxSuppressionV4 = 'NonMaxSuppressionV4';\nexport const NonMaxSuppressionV5 = 'NonMaxSuppressionV5';\nexport const OnesLike = 'OnesLike';\nexport const OneHot = 'OneHot';\nexport const PadV2 = 'PadV2';\nexport const Pool = 'Pool';\nexport const Pow = 'Pow';\nexport const Prelu = 'Prelu';\nexport const Prod = 'Prod';\nexport const Range = 'Range';\nexport const Real = 'Real';\nexport const Reciprocal = 'Reciprocal';\nexport const Relu = 'Relu';\nexport const Reshape = 'Reshape';\nexport const ResizeNearestNeighbor = 'ResizeNearestNeighbor';\nexport const ResizeNearestNeighborGrad = 'ResizeNearestNeighborGrad';\nexport const ResizeBilinear = 'ResizeBilinear';\nexport const ResizeBilinearGrad = 'ResizeBilinearGrad';\nexport const Relu6 = 'Relu6';\nexport const Reverse = 'Reverse';\nexport const Round = 'Round';\nexport const Rsqrt = 'Rsqrt';\nexport const ScatterNd = 'ScatterNd';\nexport const SelectV2 = 'SelectV2';\nexport const Selu = 'Selu';\nexport const Slice = 'Slice';\nexport const Sin = 'Sin';\nexport const Sinh = 'Sinh';\nexport const Sign = 'Sign';\nexport const Sigmoid = 'Sigmoid';\nexport const Softplus = 'Softplus';\nexport const Sqrt = 'Sqrt';\nexport const Sum = 'Sum';\nexport const SpaceToBatchND = 'SpaceToBatchND';\nexport const SplitV = 'SplitV';\nexport const Softmax = 'Softmax';\nexport const SquaredDifference = 'SquaredDifference';\nexport const Square = 'Square';\nexport const Sub = 'Sub';\nexport const SparseToDense = 'SparseToDense';\nexport const StridedSlice = 'StridedSlice';\nexport const Tan = 'Tan';\nexport const Tanh = 'Tanh';\nexport const Tile = 'Tile';\nexport const TopK = 'TopK';\nexport const Transpose = 'Transpose';\nexport const Unpack = 'Unpack';\nexport const UnsortedSegmentSum = 'UnsortedSegmentSum';\nexport const ZerosLike = 'ZerosLike';\n/**\n * TensorFlow.js-only kernels\n */\nexport const Step = 'Step';\nexport const FromPixels = 'FromPixels';\nexport const RotateWithOffset = 'RotateWithOffset';\nexport const _FusedMatMul = '_FusedMatMul';\nexport const FusedConv2D = 'FusedConv2D';\nexport const FusedDepthwiseConv2D = 'FusedDepthwiseConv2D';\n//# sourceMappingURL=kernel_names.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport '../flags';\nimport { env } from '../environment';\nimport { assert } from '../util';\nimport { arrayBufferToBase64String, base64StringToArrayBuffer, getModelArtifactsInfoForJSON } from './io_utils';\nimport { IORouterRegistry } from './router_registry';\nconst PATH_SEPARATOR = '/';\nconst PATH_PREFIX = 'tensorflowjs_models';\nconst INFO_SUFFIX = 'info';\nconst MODEL_TOPOLOGY_SUFFIX = 'model_topology';\nconst WEIGHT_SPECS_SUFFIX = 'weight_specs';\nconst WEIGHT_DATA_SUFFIX = 'weight_data';\nconst MODEL_METADATA_SUFFIX = 'model_metadata';\n/**\n * Purge all tensorflow.js-saved model artifacts from local storage.\n *\n * @returns Paths of the models purged.\n */\nexport function purgeLocalStorageArtifacts() {\n    if (!env().getBool('IS_BROWSER') || typeof window === 'undefined' ||\n        typeof window.localStorage === 'undefined') {\n        throw new Error('purgeLocalStorageModels() cannot proceed because local storage is ' +\n            'unavailable in the current environment.');\n    }\n    const LS = window.localStorage;\n    const purgedModelPaths = [];\n    for (let i = 0; i < LS.length; ++i) {\n        const key = LS.key(i);\n        const prefix = PATH_PREFIX + PATH_SEPARATOR;\n        if (key.startsWith(prefix) && key.length > prefix.length) {\n            LS.removeItem(key);\n            const modelName = getModelPathFromKey(key);\n            if (purgedModelPaths.indexOf(modelName) === -1) {\n                purgedModelPaths.push(modelName);\n            }\n        }\n    }\n    return purgedModelPaths;\n}\nfunction getModelKeys(path) {\n    return {\n        info: [PATH_PREFIX, path, INFO_SUFFIX].join(PATH_SEPARATOR),\n        topology: [PATH_PREFIX, path, MODEL_TOPOLOGY_SUFFIX].join(PATH_SEPARATOR),\n        weightSpecs: [PATH_PREFIX, path, WEIGHT_SPECS_SUFFIX].join(PATH_SEPARATOR),\n        weightData: [PATH_PREFIX, path, WEIGHT_DATA_SUFFIX].join(PATH_SEPARATOR),\n        modelMetadata: [PATH_PREFIX, path, MODEL_METADATA_SUFFIX].join(PATH_SEPARATOR)\n    };\n}\n/**\n * Get model path from a local-storage key.\n *\n * E.g., 'tensorflowjs_models/my/model/1/info' --> 'my/model/1'\n *\n * @param key\n */\nfunction getModelPathFromKey(key) {\n    const items = key.split(PATH_SEPARATOR);\n    if (items.length < 3) {\n        throw new Error(`Invalid key format: ${key}`);\n    }\n    return items.slice(1, items.length - 1).join(PATH_SEPARATOR);\n}\nfunction maybeStripScheme(key) {\n    return key.startsWith(BrowserLocalStorage.URL_SCHEME) ?\n        key.slice(BrowserLocalStorage.URL_SCHEME.length) :\n        key;\n}\n/**\n * IOHandler subclass: Browser Local Storage.\n *\n * See the doc string to `browserLocalStorage` for more details.\n */\nexport class BrowserLocalStorage {\n    constructor(modelPath) {\n        if (!env().getBool('IS_BROWSER') || typeof window === 'undefined' ||\n            typeof window.localStorage === 'undefined') {\n            // TODO(cais): Add more info about what IOHandler subtypes are\n            // available.\n            //   Maybe point to a doc page on the web and/or automatically determine\n            //   the available IOHandlers and print them in the error message.\n            throw new Error('The current environment does not support local storage.');\n        }\n        this.LS = window.localStorage;\n        if (modelPath == null || !modelPath) {\n            throw new Error('For local storage, modelPath must not be null, undefined or empty.');\n        }\n        this.modelPath = modelPath;\n        this.keys = getModelKeys(this.modelPath);\n    }\n    /**\n     * Save model artifacts to browser local storage.\n     *\n     * See the documentation to `browserLocalStorage` for details on the saved\n     * artifacts.\n     *\n     * @param modelArtifacts The model artifacts to be stored.\n     * @returns An instance of SaveResult.\n     */\n    async save(modelArtifacts) {\n        if (modelArtifacts.modelTopology instanceof ArrayBuffer) {\n            throw new Error('BrowserLocalStorage.save() does not support saving model topology ' +\n                'in binary formats yet.');\n        }\n        else {\n            const topology = JSON.stringify(modelArtifacts.modelTopology);\n            const weightSpecs = JSON.stringify(modelArtifacts.weightSpecs);\n            const modelArtifactsInfo = getModelArtifactsInfoForJSON(modelArtifacts);\n            try {\n                this.LS.setItem(this.keys.info, JSON.stringify(modelArtifactsInfo));\n                this.LS.setItem(this.keys.topology, topology);\n                this.LS.setItem(this.keys.weightSpecs, weightSpecs);\n                this.LS.setItem(this.keys.weightData, arrayBufferToBase64String(modelArtifacts.weightData));\n                this.LS.setItem(this.keys.modelMetadata, JSON.stringify({\n                    format: modelArtifacts.format,\n                    generatedBy: modelArtifacts.generatedBy,\n                    convertedBy: modelArtifacts.convertedBy,\n                    userDefinedMetadata: modelArtifacts.userDefinedMetadata\n                }));\n                return { modelArtifactsInfo };\n            }\n            catch (err) {\n                // If saving failed, clean up all items saved so far.\n                this.LS.removeItem(this.keys.info);\n                this.LS.removeItem(this.keys.topology);\n                this.LS.removeItem(this.keys.weightSpecs);\n                this.LS.removeItem(this.keys.weightData);\n                this.LS.removeItem(this.keys.modelMetadata);\n                throw new Error(`Failed to save model '${this.modelPath}' to local storage: ` +\n                    `size quota being exceeded is a possible cause of this failure: ` +\n                    `modelTopologyBytes=${modelArtifactsInfo.modelTopologyBytes}, ` +\n                    `weightSpecsBytes=${modelArtifactsInfo.weightSpecsBytes}, ` +\n                    `weightDataBytes=${modelArtifactsInfo.weightDataBytes}.`);\n            }\n        }\n    }\n    /**\n     * Load a model from local storage.\n     *\n     * See the documentation to `browserLocalStorage` for details on the saved\n     * artifacts.\n     *\n     * @returns The loaded model (if loading succeeds).\n     */\n    async load() {\n        const info = JSON.parse(this.LS.getItem(this.keys.info));\n        if (info == null) {\n            throw new Error(`In local storage, there is no model with name '${this.modelPath}'`);\n        }\n        if (info.modelTopologyType !== 'JSON') {\n            throw new Error('BrowserLocalStorage does not support loading non-JSON model ' +\n                'topology yet.');\n        }\n        const out = {};\n        // Load topology.\n        const topology = JSON.parse(this.LS.getItem(this.keys.topology));\n        if (topology == null) {\n            throw new Error(`In local storage, the topology of model '${this.modelPath}' ` +\n                `is missing.`);\n        }\n        out.modelTopology = topology;\n        // Load weight specs.\n        const weightSpecs = JSON.parse(this.LS.getItem(this.keys.weightSpecs));\n        if (weightSpecs == null) {\n            throw new Error(`In local storage, the weight specs of model '${this.modelPath}' ` +\n                `are missing.`);\n        }\n        out.weightSpecs = weightSpecs;\n        // Load meta-data fields.\n        const metadataString = this.LS.getItem(this.keys.modelMetadata);\n        if (metadataString != null) {\n            const metadata = JSON.parse(metadataString);\n            out.format = metadata['format'];\n            out.generatedBy = metadata['generatedBy'];\n            out.convertedBy = metadata['convertedBy'];\n            out.userDefinedMetadata = metadata['userDefinedMetadata'];\n        }\n        // Load weight data.\n        const weightDataBase64 = this.LS.getItem(this.keys.weightData);\n        if (weightDataBase64 == null) {\n            throw new Error(`In local storage, the binary weight values of model ` +\n                `'${this.modelPath}' are missing.`);\n        }\n        out.weightData = base64StringToArrayBuffer(weightDataBase64);\n        return out;\n    }\n}\nBrowserLocalStorage.URL_SCHEME = 'localstorage://';\nexport const localStorageRouter = (url) => {\n    if (!env().getBool('IS_BROWSER')) {\n        return null;\n    }\n    else {\n        if (!Array.isArray(url) && url.startsWith(BrowserLocalStorage.URL_SCHEME)) {\n            return browserLocalStorage(url.slice(BrowserLocalStorage.URL_SCHEME.length));\n        }\n        else {\n            return null;\n        }\n    }\n};\nIORouterRegistry.registerSaveRouter(localStorageRouter);\nIORouterRegistry.registerLoadRouter(localStorageRouter);\n/**\n * Factory function for local storage IOHandler.\n *\n * This `IOHandler` supports both `save` and `load`.\n *\n * For each model's saved artifacts, four items are saved to local storage.\n *   - `${PATH_SEPARATOR}/${modelPath}/info`: Contains meta-info about the\n *     model, such as date saved, type of the topology, size in bytes, etc.\n *   - `${PATH_SEPARATOR}/${modelPath}/topology`: Model topology. For Keras-\n *     style models, this is a stringized JSON.\n *   - `${PATH_SEPARATOR}/${modelPath}/weight_specs`: Weight specs of the\n *     model, can be used to decode the saved binary weight values (see\n *     item below).\n *   - `${PATH_SEPARATOR}/${modelPath}/weight_data`: Concatenated binary\n *     weight values, stored as a base64-encoded string.\n *\n * Saving may throw an `Error` if the total size of the artifacts exceed the\n * browser-specific quota.\n *\n * @param modelPath A unique identifier for the model to be saved. Must be a\n *   non-empty string.\n * @returns An instance of `IOHandler`, which can be used with, e.g.,\n *   `tf.Model.save`.\n */\nexport function browserLocalStorage(modelPath) {\n    return new BrowserLocalStorage(modelPath);\n}\nexport class BrowserLocalStorageManager {\n    constructor() {\n        assert(env().getBool('IS_BROWSER'), () => 'Current environment is not a web browser');\n        assert(typeof window === 'undefined' ||\n            typeof window.localStorage !== 'undefined', () => 'Current browser does not appear to support localStorage');\n        this.LS = window.localStorage;\n    }\n    async listModels() {\n        const out = {};\n        const prefix = PATH_PREFIX + PATH_SEPARATOR;\n        const suffix = PATH_SEPARATOR + INFO_SUFFIX;\n        for (let i = 0; i < this.LS.length; ++i) {\n            const key = this.LS.key(i);\n            if (key.startsWith(prefix) && key.endsWith(suffix)) {\n                const modelPath = getModelPathFromKey(key);\n                out[modelPath] = JSON.parse(this.LS.getItem(key));\n            }\n        }\n        return out;\n    }\n    async removeModel(path) {\n        path = maybeStripScheme(path);\n        const keys = getModelKeys(path);\n        if (this.LS.getItem(keys.info) == null) {\n            throw new Error(`Cannot find model at path '${path}'`);\n        }\n        const info = JSON.parse(this.LS.getItem(keys.info));\n        this.LS.removeItem(keys.info);\n        this.LS.removeItem(keys.topology);\n        this.LS.removeItem(keys.weightSpecs);\n        this.LS.removeItem(keys.weightData);\n        return info;\n    }\n}\n//# sourceMappingURL=local_storage.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n/**\n * IOHandlers related to files, such as browser-triggered file downloads,\n * user-selected files in browser.\n */\nimport '../flags';\nimport { env } from '../environment';\nimport { basename, concatenateArrayBuffers, getModelArtifactsInfoForJSON } from './io_utils';\nimport { IORouterRegistry } from './router_registry';\nconst DEFAULT_FILE_NAME_PREFIX = 'model';\nconst DEFAULT_JSON_EXTENSION_NAME = '.json';\nconst DEFAULT_WEIGHT_DATA_EXTENSION_NAME = '.weights.bin';\nfunction defer(f) {\n    return new Promise(resolve => setTimeout(resolve)).then(f);\n}\nexport class BrowserDownloads {\n    constructor(fileNamePrefix) {\n        if (!env().getBool('IS_BROWSER')) {\n            // TODO(cais): Provide info on what IOHandlers are available under the\n            //   current environment.\n            throw new Error('browserDownloads() cannot proceed because the current environment ' +\n                'is not a browser.');\n        }\n        if (fileNamePrefix.startsWith(BrowserDownloads.URL_SCHEME)) {\n            fileNamePrefix = fileNamePrefix.slice(BrowserDownloads.URL_SCHEME.length);\n        }\n        if (fileNamePrefix == null || fileNamePrefix.length === 0) {\n            fileNamePrefix = DEFAULT_FILE_NAME_PREFIX;\n        }\n        this.modelTopologyFileName = fileNamePrefix + DEFAULT_JSON_EXTENSION_NAME;\n        this.weightDataFileName =\n            fileNamePrefix + DEFAULT_WEIGHT_DATA_EXTENSION_NAME;\n    }\n    async save(modelArtifacts) {\n        if (typeof (document) === 'undefined') {\n            throw new Error('Browser downloads are not supported in ' +\n                'this environment since `document` is not present');\n        }\n        const weightsURL = window.URL.createObjectURL(new Blob([modelArtifacts.weightData], { type: 'application/octet-stream' }));\n        if (modelArtifacts.modelTopology instanceof ArrayBuffer) {\n            throw new Error('BrowserDownloads.save() does not support saving model topology ' +\n                'in binary formats yet.');\n        }\n        else {\n            const weightsManifest = [{\n                    paths: ['./' + this.weightDataFileName],\n                    weights: modelArtifacts.weightSpecs\n                }];\n            const modelTopologyAndWeightManifest = {\n                modelTopology: modelArtifacts.modelTopology,\n                format: modelArtifacts.format,\n                generatedBy: modelArtifacts.generatedBy,\n                convertedBy: modelArtifacts.convertedBy,\n                weightsManifest\n            };\n            const modelTopologyAndWeightManifestURL = window.URL.createObjectURL(new Blob([JSON.stringify(modelTopologyAndWeightManifest)], { type: 'application/json' }));\n            // If anchor elements are not provided, create them without attaching them\n            // to parents, so that the downloaded file names can be controlled.\n            const jsonAnchor = this.jsonAnchor == null ? document.createElement('a') :\n                this.jsonAnchor;\n            jsonAnchor.download = this.modelTopologyFileName;\n            jsonAnchor.href = modelTopologyAndWeightManifestURL;\n            // Trigger downloads by evoking a click event on the download anchors.\n            // When multiple downloads are started synchronously, Firefox will only\n            // save the last one.\n            await defer(() => jsonAnchor.dispatchEvent(new MouseEvent('click')));\n            if (modelArtifacts.weightData != null) {\n                const weightDataAnchor = this.weightDataAnchor == null ?\n                    document.createElement('a') :\n                    this.weightDataAnchor;\n                weightDataAnchor.download = this.weightDataFileName;\n                weightDataAnchor.href = weightsURL;\n                await defer(() => weightDataAnchor.dispatchEvent(new MouseEvent('click')));\n            }\n            return { modelArtifactsInfo: getModelArtifactsInfoForJSON(modelArtifacts) };\n        }\n    }\n}\nBrowserDownloads.URL_SCHEME = 'downloads://';\nclass BrowserFiles {\n    constructor(files) {\n        if (files == null || files.length < 1) {\n            throw new Error(`When calling browserFiles, at least 1 file is required, ` +\n                `but received ${files}`);\n        }\n        this.files = files;\n    }\n    async load() {\n        const jsonFile = this.files[0];\n        const weightFiles = this.files.slice(1);\n        return new Promise((resolve, reject) => {\n            const jsonReader = new FileReader();\n            jsonReader.onload = (event) => {\n                // tslint:disable-next-line:no-any\n                const modelJSON = JSON.parse(event.target.result);\n                const modelTopology = modelJSON.modelTopology;\n                if (modelTopology == null) {\n                    reject(new Error(`modelTopology field is missing from file ${jsonFile.name}`));\n                    return;\n                }\n                if (weightFiles.length === 0) {\n                    resolve({ modelTopology });\n                }\n                const weightsManifest = modelJSON.weightsManifest;\n                if (weightsManifest == null) {\n                    reject(new Error(`weightManifest field is missing from file ${jsonFile.name}`));\n                    return;\n                }\n                let pathToFile;\n                try {\n                    pathToFile =\n                        this.checkManifestAndWeightFiles(weightsManifest, weightFiles);\n                }\n                catch (err) {\n                    reject(err);\n                    return;\n                }\n                const weightSpecs = [];\n                const paths = [];\n                const perFileBuffers = [];\n                weightsManifest.forEach(weightsGroup => {\n                    weightsGroup.paths.forEach(path => {\n                        paths.push(path);\n                        perFileBuffers.push(null);\n                    });\n                    weightSpecs.push(...weightsGroup.weights);\n                });\n                weightsManifest.forEach(weightsGroup => {\n                    weightsGroup.paths.forEach(path => {\n                        const weightFileReader = new FileReader();\n                        weightFileReader.onload = (event) => {\n                            // tslint:disable-next-line:no-any\n                            const weightData = event.target.result;\n                            const index = paths.indexOf(path);\n                            perFileBuffers[index] = weightData;\n                            if (perFileBuffers.indexOf(null) === -1) {\n                                resolve({\n                                    modelTopology,\n                                    weightSpecs,\n                                    weightData: concatenateArrayBuffers(perFileBuffers),\n                                    format: modelJSON.format,\n                                    generatedBy: modelJSON.generatedBy,\n                                    convertedBy: modelJSON.convertedBy,\n                                    userDefinedMetadata: modelJSON.userDefinedMetadata\n                                });\n                            }\n                        };\n                        weightFileReader.onerror = error => reject(`Failed to weights data from file of path '${path}'.`);\n                        weightFileReader.readAsArrayBuffer(pathToFile[path]);\n                    });\n                });\n            };\n            jsonReader.onerror = error => reject(`Failed to read model topology and weights manifest JSON ` +\n                `from file '${jsonFile.name}'. BrowserFiles supports loading ` +\n                `Keras-style tf.Model artifacts only.`);\n            jsonReader.readAsText(jsonFile);\n        });\n    }\n    /**\n     * Check the compatibility between weights manifest and weight files.\n     */\n    checkManifestAndWeightFiles(manifest, files) {\n        const basenames = [];\n        const fileNames = files.map(file => basename(file.name));\n        const pathToFile = {};\n        for (const group of manifest) {\n            group.paths.forEach(path => {\n                const pathBasename = basename(path);\n                if (basenames.indexOf(pathBasename) !== -1) {\n                    throw new Error(`Duplicate file basename found in weights manifest: ` +\n                        `'${pathBasename}'`);\n                }\n                basenames.push(pathBasename);\n                if (fileNames.indexOf(pathBasename) === -1) {\n                    throw new Error(`Weight file with basename '${pathBasename}' is not provided.`);\n                }\n                else {\n                    pathToFile[path] = files[fileNames.indexOf(pathBasename)];\n                }\n            });\n        }\n        if (basenames.length !== files.length) {\n            throw new Error(`Mismatch in the number of files in weights manifest ` +\n                `(${basenames.length}) and the number of weight files provided ` +\n                `(${files.length}).`);\n        }\n        return pathToFile;\n    }\n}\nexport const browserDownloadsRouter = (url) => {\n    if (!env().getBool('IS_BROWSER')) {\n        return null;\n    }\n    else {\n        if (!Array.isArray(url) && url.startsWith(BrowserDownloads.URL_SCHEME)) {\n            return browserDownloads(url.slice(BrowserDownloads.URL_SCHEME.length));\n        }\n        else {\n            return null;\n        }\n    }\n};\nIORouterRegistry.registerSaveRouter(browserDownloadsRouter);\n/**\n * Creates an IOHandler that triggers file downloads from the browser.\n *\n * The returned `IOHandler` instance can be used as model exporting methods such\n * as `tf.Model.save` and supports only saving.\n *\n * ```js\n * const model = tf.sequential();\n * model.add(tf.layers.dense(\n *     {units: 1, inputShape: [10], activation: 'sigmoid'}));\n * const saveResult = await model.save('downloads://mymodel');\n * // This will trigger downloading of two files:\n * //   'mymodel.json' and 'mymodel.weights.bin'.\n * console.log(saveResult);\n * ```\n *\n * @param fileNamePrefix Prefix name of the files to be downloaded. For use with\n *   `tf.Model`, `fileNamePrefix` should follow either of the following two\n *   formats:\n *   1. `null` or `undefined`, in which case the default file\n *      names will be used:\n *      - 'model.json' for the JSON file containing the model topology and\n *        weights manifest.\n *      - 'model.weights.bin' for the binary file containing the binary weight\n *        values.\n *   2. A single string or an Array of a single string, as the file name prefix.\n *      For example, if `'foo'` is provided, the downloaded JSON\n *      file and binary weights file will be named 'foo.json' and\n *      'foo.weights.bin', respectively.\n * @param config Additional configuration for triggering downloads.\n * @returns An instance of `BrowserDownloads` `IOHandler`.\n *\n * @doc {\n *   heading: 'Models',\n *   subheading: 'Loading',\n *   namespace: 'io',\n *   ignoreCI: true\n * }\n */\nexport function browserDownloads(fileNamePrefix = 'model') {\n    return new BrowserDownloads(fileNamePrefix);\n}\n/**\n * Creates an IOHandler that loads model artifacts from user-selected files.\n *\n * This method can be used for loading from files such as user-selected files\n * in the browser.\n * When used in conjunction with `tf.loadLayersModel`, an instance of\n * `tf.LayersModel` (Keras-style) can be constructed from the loaded artifacts.\n *\n * ```js\n * // Note: This code snippet won't run properly without the actual file input\n * //   elements in the HTML DOM.\n *\n * // Suppose there are two HTML file input (`<input type=\"file\" ...>`)\n * // elements.\n * const uploadJSONInput = document.getElementById('upload-json');\n * const uploadWeightsInput = document.getElementById('upload-weights');\n * const model = await tf.loadLayersModel(tf.io.browserFiles(\n *     [uploadJSONInput.files[0], uploadWeightsInput.files[0]]));\n * ```\n *\n * @param files `File`s to load from. Currently, this function supports only\n *   loading from files that contain Keras-style models (i.e., `tf.Model`s), for\n *   which an `Array` of `File`s is expected (in that order):\n *   - A JSON file containing the model topology and weight manifest.\n *   - Optionally, One or more binary files containing the binary weights.\n *     These files must have names that match the paths in the `weightsManifest`\n *     contained by the aforementioned JSON file, or errors will be thrown\n *     during loading. These weights files have the same format as the ones\n *     generated by `tensorflowjs_converter` that comes with the `tensorflowjs`\n *     Python PIP package. If no weights files are provided, only the model\n *     topology will be loaded from the JSON file above.\n * @returns An instance of `Files` `IOHandler`.\n *\n * @doc {\n *   heading: 'Models',\n *   subheading: 'Loading',\n *   namespace: 'io',\n *   ignoreCI: true\n * }\n */\nexport function browserFiles(files) {\n    return new BrowserFiles(files);\n}\n//# sourceMappingURL=browser_files.js.map","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { assert } from '../util';\n/**\n * Monitor Promise.all progress, fire onProgress callback function.\n *\n * @param promises Promise list going to be monitored\n * @param onProgress Callback function. Fired when a promise resolved.\n * @param startFraction Optional fraction start. Default to 0.\n * @param endFraction Optional fraction end. Default to 1.\n */\nexport function monitorPromisesProgress(promises, onProgress, startFraction, endFraction) {\n    checkPromises(promises);\n    startFraction = startFraction == null ? 0 : startFraction;\n    endFraction = endFraction == null ? 1 : endFraction;\n    checkFraction(startFraction, endFraction);\n    let resolvedPromise = 0;\n    const registerMonitor = (promise) => {\n        promise.then(value => {\n            const fraction = startFraction +\n                ++resolvedPromise / promises.length * (endFraction - startFraction);\n            // pass fraction as parameter to callback function.\n            onProgress(fraction);\n            return value;\n        });\n        return promise;\n    };\n    function checkPromises(promises) {\n        assert(promises != null && Array.isArray(promises) && promises.length > 0, () => 'promises must be a none empty array');\n    }\n    function checkFraction(startFraction, endFraction) {\n        assert(startFraction >= 0 && startFraction <= 1, () => `Progress fraction must be in range [0, 1], but ` +\n            `got startFraction ${startFraction}`);\n        assert(endFraction >= 0 && endFraction <= 1, () => `Progress fraction must be in range [0, 1], but ` +\n            `got endFraction ${endFraction}`);\n        assert(endFraction >= startFraction, () => `startFraction must be no more than endFraction, but ` +\n            `got startFraction ${startFraction} and endFraction ` +\n            `${endFraction}`);\n    }\n    return Promise.all(promises.map(registerMonitor));\n}\n//# sourceMappingURL=progress.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { env } from '../environment';\nimport * as util from '../util';\nimport { decodeWeights } from './io_utils';\nimport { monitorPromisesProgress } from './progress';\nimport { DTYPE_VALUE_SIZE_MAP } from './types';\n/**\n * Reads binary weights data from a number of URLs.\n *\n * @param fetchURLs URLs to send the HTTP requests at, using `fetch` calls.\n * @param requestOptions RequestInit (options) for the HTTP requests.\n * @param fetchFunc Optional overriding value for the `window.fetch` function.\n * @param onProgress Optional, progress callback function, fired periodically\n *   before the load is completed.\n * @returns A `Promise` of an Array of `ArrayBuffer`. The Array has the same\n *   length as `fetchURLs`.\n */\nexport async function loadWeightsAsArrayBuffer(fetchURLs, loadOptions) {\n    if (loadOptions == null) {\n        loadOptions = {};\n    }\n    const fetchFunc = loadOptions.fetchFunc == null ? env().platform.fetch :\n        loadOptions.fetchFunc;\n    // Create the requests for all of the weights in parallel.\n    const requests = fetchURLs.map(fetchURL => fetchFunc(fetchURL, loadOptions.requestInit, { isBinary: true }));\n    const fetchStartFraction = 0;\n    const fetchEndFraction = 0.5;\n    const responses = loadOptions.onProgress == null ?\n        await Promise.all(requests) :\n        await monitorPromisesProgress(requests, loadOptions.onProgress, fetchStartFraction, fetchEndFraction);\n    const bufferPromises = responses.map(response => response.arrayBuffer());\n    const bufferStartFraction = 0.5;\n    const bufferEndFraction = 1;\n    const buffers = loadOptions.onProgress == null ?\n        await Promise.all(bufferPromises) :\n        await monitorPromisesProgress(bufferPromises, loadOptions.onProgress, bufferStartFraction, bufferEndFraction);\n    return buffers;\n}\n/**\n * Reads a weights manifest JSON configuration, fetches the weights and\n * returns them as `Tensor`s.\n *\n * @param manifest The weights manifest JSON.\n * @param filePathPrefix The path prefix for filenames given in the manifest.\n *     Defaults to the empty string.\n * @param weightNames The names of the weights to be fetched.\n */\nexport async function loadWeights(manifest, filePathPrefix = '', weightNames, requestInit) {\n    // TODO(nsthorat): Groups are currently fetched atomically. If you need a\n    // single weight from a group, the whole group will be fetched. At a future\n    // date, we should support fetching only the individual shards within a\n    // group that are needed to reconstruct the requested weight.\n    // TODO(cais): Use `decodeWeights` for implementation.\n    const fetchWeights = (fetchUrls) => loadWeightsAsArrayBuffer(fetchUrls, { requestInit });\n    const loadWeights = weightsLoaderFactory(fetchWeights);\n    return loadWeights(manifest, filePathPrefix, weightNames);\n}\n/**\n * Creates a function, which reads a weights manifest JSON configuration,\n * fetches the weight files using the specified function and returns them as\n * `Tensor`s.\n *\n * ```js\n * // example for creating a nodejs weight loader, which reads the weight files\n * // from disk using fs.readFileSync\n *\n * import * as fs from 'fs'\n *\n * const fetchWeightsFromDisk = (filePaths: string[]) =>\n *   filePaths.map(filePath => fs.readFileSync(filePath).buffer)\n *\n * const loadWeights = tf.io.weightsLoaderFactory(fetchWeightsFromDisk)\n *\n * const manifest = JSON.parse(\n *   fs.readFileSync('./my_model-weights_manifest').toString()\n * )\n * const weightMap = await loadWeights(manifest, './')\n * ```\n * @param fetchWeightsFunction The function used for fetching the weight files.\n * @returns Weight loading function.\n */\nexport function weightsLoaderFactory(fetchWeightsFunction) {\n    return async (manifest, filePathPrefix = '', weightNames) => {\n        // Collect all the groups, weights, and their relative offsets to be\n        // fetched.\n        const groupIndicesToFetchMap = manifest.map(() => false);\n        const groupWeightsToFetch = {};\n        const weightsFound = weightNames != null ? weightNames.map(() => false) : [];\n        const allManifestWeightNames = [];\n        manifest.forEach((manifestGroupConfig, groupIndex) => {\n            let groupOffset = 0;\n            manifestGroupConfig.weights.forEach(weightsEntry => {\n                const rawDtype = ('quantization' in weightsEntry) ?\n                    weightsEntry.quantization.dtype :\n                    weightsEntry.dtype;\n                const weightsBytes = DTYPE_VALUE_SIZE_MAP[rawDtype] *\n                    util.sizeFromShape(weightsEntry.shape);\n                const enqueueWeightsForFetchingFn = () => {\n                    groupIndicesToFetchMap[groupIndex] = true;\n                    if (groupWeightsToFetch[groupIndex] == null) {\n                        groupWeightsToFetch[groupIndex] = [];\n                    }\n                    groupWeightsToFetch[groupIndex].push({\n                        manifestEntry: weightsEntry,\n                        groupOffset,\n                        sizeBytes: weightsBytes\n                    });\n                };\n                if (weightNames != null) {\n                    weightNames.forEach((weightName, weightIndex) => {\n                        if (weightName === weightsEntry.name) {\n                            enqueueWeightsForFetchingFn();\n                            weightsFound[weightIndex] = true;\n                        }\n                    });\n                }\n                else {\n                    enqueueWeightsForFetchingFn();\n                }\n                allManifestWeightNames.push(weightsEntry.name);\n                groupOffset += weightsBytes;\n            });\n        });\n        if (!weightsFound.every(found => found)) {\n            const weightsNotFound = weightNames.filter((_, i) => !weightsFound[i]);\n            throw new Error(`Could not find weights in manifest with names: ` +\n                `${weightsNotFound.join(', ')}. \\n` +\n                `Manifest JSON has weights with names: ` +\n                `${allManifestWeightNames.join(', ')}.`);\n        }\n        // Convert the one-hot boolean groupId => shouldFetch map to a list of group\n        // IDs.\n        const groupIndicesToFetch = groupIndicesToFetchMap.reduce((accumulator, shouldFetch, i) => {\n            if (shouldFetch) {\n                accumulator.push(i);\n            }\n            return accumulator;\n        }, []);\n        const fetchUrls = [];\n        groupIndicesToFetch.forEach(i => {\n            manifest[i].paths.forEach(filepath => {\n                const fetchUrl = filePathPrefix +\n                    (!filePathPrefix.endsWith('/') ? '/' : '') + filepath;\n                fetchUrls.push(fetchUrl);\n            });\n        });\n        const buffers = await fetchWeightsFunction(fetchUrls);\n        const weightsTensorMap = {};\n        let bufferIndexOffset = 0;\n        groupIndicesToFetch.forEach(i => {\n            const numBuffers = manifest[i].paths.length;\n            let groupBytes = 0;\n            for (let i = 0; i < numBuffers; i++) {\n                groupBytes += buffers[bufferIndexOffset + i].byteLength;\n            }\n            // Create a buffer for the whole group.\n            const groupBuffer = new ArrayBuffer(groupBytes);\n            const groupByteBuffer = new Uint8Array(groupBuffer);\n            let groupBufferOffset = 0;\n            for (let i = 0; i < numBuffers; i++) {\n                const buffer = new Uint8Array(buffers[bufferIndexOffset + i]);\n                groupByteBuffer.set(buffer, groupBufferOffset);\n                groupBufferOffset += buffer.byteLength;\n            }\n            const weightsEntries = groupWeightsToFetch[i];\n            weightsEntries.forEach(weightsEntry => {\n                const byteBuffer = groupBuffer.slice(weightsEntry.groupOffset, weightsEntry.groupOffset + weightsEntry.sizeBytes);\n                const nameToTensorMap = decodeWeights(byteBuffer, [weightsEntry.manifestEntry]);\n                for (const name in nameToTensorMap) {\n                    weightsTensorMap[name] = nameToTensorMap[name];\n                }\n            });\n            bufferIndexOffset += numBuffers;\n        });\n        return weightsTensorMap;\n    };\n}\n//# sourceMappingURL=weights_loader.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n/**\n * IOHandler implementations based on HTTP requests in the web browser.\n *\n * Uses [`fetch`](https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API).\n */\nimport { env } from '../environment';\nimport { assert } from '../util';\nimport { concatenateArrayBuffers, getModelArtifactsInfoForJSON } from './io_utils';\nimport { IORouterRegistry } from './router_registry';\nimport { loadWeightsAsArrayBuffer } from './weights_loader';\nconst OCTET_STREAM_MIME_TYPE = 'application/octet-stream';\nconst JSON_TYPE = 'application/json';\nexport class HTTPRequest {\n    constructor(path, loadOptions) {\n        this.DEFAULT_METHOD = 'POST';\n        if (loadOptions == null) {\n            loadOptions = {};\n        }\n        this.weightPathPrefix = loadOptions.weightPathPrefix;\n        this.onProgress = loadOptions.onProgress;\n        this.weightUrlConverter = loadOptions.weightUrlConverter;\n        if (loadOptions.fetchFunc != null) {\n            assert(typeof loadOptions.fetchFunc === 'function', () => 'Must pass a function that matches the signature of ' +\n                '`fetch` (see ' +\n                'https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API)');\n            this.fetch = loadOptions.fetchFunc;\n        }\n        else {\n            this.fetch = env().platform.fetch;\n        }\n        assert(path != null && path.length > 0, () => 'URL path for http must not be null, undefined or ' +\n            'empty.');\n        if (Array.isArray(path)) {\n            assert(path.length === 2, () => 'URL paths for http must have a length of 2, ' +\n                `(actual length is ${path.length}).`);\n        }\n        this.path = path;\n        if (loadOptions.requestInit != null &&\n            loadOptions.requestInit.body != null) {\n            throw new Error('requestInit is expected to have no pre-existing body, but has one.');\n        }\n        this.requestInit = loadOptions.requestInit || {};\n    }\n    async save(modelArtifacts) {\n        if (modelArtifacts.modelTopology instanceof ArrayBuffer) {\n            throw new Error('BrowserHTTPRequest.save() does not support saving model topology ' +\n                'in binary formats yet.');\n        }\n        const init = Object.assign({ method: this.DEFAULT_METHOD }, this.requestInit);\n        init.body = new FormData();\n        const weightsManifest = [{\n                paths: ['./model.weights.bin'],\n                weights: modelArtifacts.weightSpecs,\n            }];\n        const modelTopologyAndWeightManifest = {\n            modelTopology: modelArtifacts.modelTopology,\n            format: modelArtifacts.format,\n            generatedBy: modelArtifacts.generatedBy,\n            convertedBy: modelArtifacts.convertedBy,\n            userDefinedMetadata: modelArtifacts.userDefinedMetadata,\n            weightsManifest\n        };\n        init.body.append('model.json', new Blob([JSON.stringify(modelTopologyAndWeightManifest)], { type: JSON_TYPE }), 'model.json');\n        if (modelArtifacts.weightData != null) {\n            init.body.append('model.weights.bin', new Blob([modelArtifacts.weightData], { type: OCTET_STREAM_MIME_TYPE }), 'model.weights.bin');\n        }\n        const response = await this.fetch(this.path, init);\n        if (response.ok) {\n            return {\n                modelArtifactsInfo: getModelArtifactsInfoForJSON(modelArtifacts),\n                responses: [response],\n            };\n        }\n        else {\n            throw new Error(`BrowserHTTPRequest.save() failed due to HTTP response status ` +\n                `${response.status}.`);\n        }\n    }\n    /**\n     * Load model artifacts via HTTP request(s).\n     *\n     * See the documentation to `tf.io.http` for details on the saved\n     * artifacts.\n     *\n     * @returns The loaded model artifacts (if loading succeeds).\n     */\n    async load() {\n        const modelConfigRequest = await this.fetch(this.path, this.requestInit);\n        if (!modelConfigRequest.ok) {\n            throw new Error(`Request to ${this.path} failed with status code ` +\n                `${modelConfigRequest.status}. Please verify this URL points to ` +\n                `the model JSON of the model to load.`);\n        }\n        let modelConfig;\n        try {\n            modelConfig = await modelConfigRequest.json();\n        }\n        catch (e) {\n            let message = `Failed to parse model JSON of response from ${this.path}.`;\n            // TODO(nsthorat): Remove this after some time when we're comfortable that\n            // .pb files are mostly gone.\n            if (this.path.endsWith('.pb')) {\n                message += ' Your path contains a .pb file extension. ' +\n                    'Support for .pb models have been removed in TensorFlow.js 1.0 ' +\n                    'in favor of .json models. You can re-convert your Python ' +\n                    'TensorFlow model using the TensorFlow.js 1.0 conversion scripts ' +\n                    'or you can convert your.pb models with the \\'pb2json\\'' +\n                    'NPM script in the tensorflow/tfjs-converter repository.';\n            }\n            else {\n                message += ' Please make sure the server is serving valid ' +\n                    'JSON for this request.';\n            }\n            throw new Error(message);\n        }\n        const modelTopology = modelConfig.modelTopology;\n        const weightsManifest = modelConfig.weightsManifest;\n        const generatedBy = modelConfig.generatedBy;\n        const convertedBy = modelConfig.convertedBy;\n        const format = modelConfig.format;\n        const userDefinedMetadata = modelConfig.userDefinedMetadata;\n        // We do not allow both modelTopology and weightsManifest to be missing.\n        if (modelTopology == null && weightsManifest == null) {\n            throw new Error(`The JSON from HTTP path ${this.path} contains neither model ` +\n                `topology or manifest for weights.`);\n        }\n        let weightSpecs;\n        let weightData;\n        if (weightsManifest != null) {\n            const results = await this.loadWeights(weightsManifest);\n            [weightSpecs, weightData] = results;\n        }\n        return {\n            modelTopology,\n            weightSpecs,\n            weightData,\n            userDefinedMetadata,\n            generatedBy,\n            convertedBy,\n            format\n        };\n    }\n    async loadWeights(weightsManifest) {\n        const weightPath = Array.isArray(this.path) ? this.path[1] : this.path;\n        const [prefix, suffix] = parseUrl(weightPath);\n        const pathPrefix = this.weightPathPrefix || prefix;\n        const weightSpecs = [];\n        for (const entry of weightsManifest) {\n            weightSpecs.push(...entry.weights);\n        }\n        const fetchURLs = [];\n        const urlPromises = [];\n        for (const weightsGroup of weightsManifest) {\n            for (const path of weightsGroup.paths) {\n                if (this.weightUrlConverter != null) {\n                    urlPromises.push(this.weightUrlConverter(path));\n                }\n                else {\n                    fetchURLs.push(pathPrefix + path + suffix);\n                }\n            }\n        }\n        if (this.weightUrlConverter) {\n            fetchURLs.push(...await Promise.all(urlPromises));\n        }\n        const buffers = await loadWeightsAsArrayBuffer(fetchURLs, {\n            requestInit: this.requestInit,\n            fetchFunc: this.fetch,\n            onProgress: this.onProgress\n        });\n        return [weightSpecs, concatenateArrayBuffers(buffers)];\n    }\n}\nHTTPRequest.URL_SCHEME_REGEX = /^https?:\\/\\//;\n/**\n * Extract the prefix and suffix of the url, where the prefix is the path before\n * the last file, and suffix is the search params after the last file.\n * ```\n * const url = 'http://tfhub.dev/model/1/tensorflowjs_model.pb?tfjs-format=file'\n * [prefix, suffix] = parseUrl(url)\n * // prefix = 'http://tfhub.dev/model/1/'\n * // suffix = '?tfjs-format=file'\n * ```\n * @param url the model url to be parsed.\n */\nexport function parseUrl(url) {\n    const lastSlash = url.lastIndexOf('/');\n    const lastSearchParam = url.lastIndexOf('?');\n    const prefix = url.substring(0, lastSlash);\n    const suffix = lastSearchParam > lastSlash ? url.substring(lastSearchParam) : '';\n    return [prefix + '/', suffix];\n}\nexport function isHTTPScheme(url) {\n    return url.match(HTTPRequest.URL_SCHEME_REGEX) != null;\n}\nexport const httpRouter = (url, loadOptions) => {\n    if (typeof fetch === 'undefined' &&\n        (loadOptions == null || loadOptions.fetchFunc == null)) {\n        // `http` uses `fetch` or `node-fetch`, if one wants to use it in\n        // an environment that is not the browser or node they have to setup a\n        // global fetch polyfill.\n        return null;\n    }\n    else {\n        let isHTTP = true;\n        if (Array.isArray(url)) {\n            isHTTP = url.every(urlItem => isHTTPScheme(urlItem));\n        }\n        else {\n            isHTTP = isHTTPScheme(url);\n        }\n        if (isHTTP) {\n            return http(url, loadOptions);\n        }\n    }\n    return null;\n};\nIORouterRegistry.registerSaveRouter(httpRouter);\nIORouterRegistry.registerLoadRouter(httpRouter);\n/**\n * Creates an IOHandler subtype that sends model artifacts to HTTP server.\n *\n * An HTTP request of the `multipart/form-data` mime type will be sent to the\n * `path` URL. The form data includes artifacts that represent the topology\n * and/or weights of the model. In the case of Keras-style `tf.Model`, two\n * blobs (files) exist in form-data:\n *   - A JSON file consisting of `modelTopology` and `weightsManifest`.\n *   - A binary weights file consisting of the concatenated weight values.\n * These files are in the same format as the one generated by\n * [tfjs_converter](https://js.tensorflow.org/tutorials/import-keras.html).\n *\n * The following code snippet exemplifies the client-side code that uses this\n * function:\n *\n * ```js\n * const model = tf.sequential();\n * model.add(\n *     tf.layers.dense({units: 1, inputShape: [100], activation: 'sigmoid'}));\n *\n * const saveResult = await model.save(tf.io.http(\n *     'http://model-server:5000/upload', {requestInit: {method: 'PUT'}}));\n * console.log(saveResult);\n * ```\n *\n * If the default `POST` method is to be used, without any custom parameters\n * such as headers, you can simply pass an HTTP or HTTPS URL to `model.save`:\n *\n * ```js\n * const saveResult = await model.save('http://model-server:5000/upload');\n * ```\n *\n * The following GitHub Gist\n * https://gist.github.com/dsmilkov/1b6046fd6132d7408d5257b0976f7864\n * implements a server based on [flask](https://github.com/pallets/flask) that\n * can receive the request. Upon receiving the model artifacts via the requst,\n * this particular server reconsistutes instances of [Keras\n * Models](https://keras.io/models/model/) in memory.\n *\n *\n * @param path A URL path to the model.\n *   Can be an absolute HTTP path (e.g.,\n *   'http://localhost:8000/model-upload)') or a relative path (e.g.,\n *   './model-upload').\n * @param requestInit Request configurations to be used when sending\n *    HTTP request to server using `fetch`. It can contain fields such as\n *    `method`, `credentials`, `headers`, `mode`, etc. See\n *    https://developer.mozilla.org/en-US/docs/Web/API/Request/Request\n *    for more information. `requestInit` must not have a body, because the\n * body will be set by TensorFlow.js. File blobs representing the model\n * topology (filename: 'model.json') and the weights of the model (filename:\n * 'model.weights.bin') will be appended to the body. If `requestInit` has a\n * `body`, an Error will be thrown.\n * @param loadOptions Optional configuration for the loading. It includes the\n *   following fields:\n *   - weightPathPrefix Optional, this specifies the path prefix for weight\n *     files, by default this is calculated from the path param.\n *   - fetchFunc Optional, custom `fetch` function. E.g., in Node.js,\n *     the `fetch` from node-fetch can be used here.\n *   - onProgress Optional, progress callback function, fired periodically\n *     before the load is completed.\n * @returns An instance of `IOHandler`.\n *\n * @doc {\n *   heading: 'Models',\n *   subheading: 'Loading',\n *   namespace: 'io',\n *   ignoreCI: true\n * }\n */\nexport function http(path, loadOptions) {\n    return new HTTPRequest(path, loadOptions);\n}\n/**\n * Deprecated. Use `tf.io.http`.\n * @param path\n * @param loadOptions\n */\nexport function browserHTTPRequest(path, loadOptions) {\n    return http(path, loadOptions);\n}\n//# sourceMappingURL=http.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nclass PassthroughLoader {\n    constructor(modelArtifacts) {\n        this.modelArtifacts = modelArtifacts;\n    }\n    async load() {\n        return this.modelArtifacts;\n    }\n}\nclass PassthroughSaver {\n    constructor(saveHandler) {\n        this.saveHandler = saveHandler;\n    }\n    async save(modelArtifacts) {\n        return this.saveHandler(modelArtifacts);\n    }\n}\n/**\n * Creates an IOHandler that loads model artifacts from memory.\n *\n * When used in conjunction with `tf.loadLayersModel`, an instance of\n * `tf.LayersModel` (Keras-style) can be constructed from the loaded artifacts.\n *\n * ```js\n * const model = await tf.loadLayersModel(tf.io.fromMemory(\n *     modelTopology, weightSpecs, weightData));\n * ```\n *\n * @param modelArtifacts a object containing model topology (i.e., parsed from\n *   the JSON format).\n * @param weightSpecs An array of `WeightsManifestEntry` objects describing the\n *   names, shapes, types, and quantization of the weight data.\n * @param weightData A single `ArrayBuffer` containing the weight data,\n *   concatenated in the order described by the weightSpecs.\n * @param trainingConfig Model training configuration. Optional.\n *\n * @returns A passthrough `IOHandler` that simply loads the provided data.\n */\nexport function fromMemory(modelArtifacts, weightSpecs, weightData, trainingConfig) {\n    if (arguments.length === 1) {\n        const isModelArtifacts = modelArtifacts.modelTopology != null ||\n            modelArtifacts.weightSpecs != null;\n        if (isModelArtifacts) {\n            return new PassthroughLoader(modelArtifacts);\n        }\n        else {\n            // Legacy support: with only modelTopology.\n            // TODO(cais): Remove this deprecated API.\n            console.warn('Please call tf.io.fromMemory() with only one argument. ' +\n                'The argument should be of type ModelArtifacts. ' +\n                'The multi-argument signature of tf.io.fromMemory() has been ' +\n                'deprecated and will be removed in a future release.');\n            return new PassthroughLoader({ modelTopology: modelArtifacts });\n        }\n    }\n    else {\n        // Legacy support.\n        // TODO(cais): Remove this deprecated API.\n        console.warn('Please call tf.io.fromMemory() with only one argument. ' +\n            'The argument should be of type ModelArtifacts. ' +\n            'The multi-argument signature of tf.io.fromMemory() has been ' +\n            'deprecated and will be removed in a future release.');\n        return new PassthroughLoader({\n            modelTopology: modelArtifacts,\n            weightSpecs,\n            weightData,\n            trainingConfig\n        });\n    }\n}\n/**\n * Creates an IOHandler that passes saved model artifacts to a callback.\n *\n * ```js\n * function handleSave(artifacts) {\n *   // ... do something with the artifacts ...\n *   return {modelArtifactsInfo: {...}, ...};\n * }\n *\n * const saveResult = model.save(tf.io.withSaveHandler(handleSave));\n * ```\n *\n * @param saveHandler A function that accepts a `ModelArtifacts` and returns a\n *     `SaveResult`.\n */\nexport function withSaveHandler(saveHandler) {\n    return new PassthroughSaver(saveHandler);\n}\n//# sourceMappingURL=passthrough.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { complex } from '../ops/complex';\nimport { tensor } from '../ops/tensor';\nimport { sizeFromShape } from '../util';\nimport { DTYPE_VALUE_SIZE_MAP } from './types';\n/** Number of bytes reserved for the length of the string. (32bit integer). */\nconst NUM_BYTES_STRING_LENGTH = 4;\n/**\n * Encode a map from names to weight values as an ArrayBuffer, along with an\n * `Array` of `WeightsManifestEntry` as specification of the encoded weights.\n *\n * This function does not perform sharding.\n *\n * This function is the reverse of `decodeWeights`.\n *\n * @param tensors A map (\"dict\") from names to tensors.\n * @param group Group to which the weights belong (optional).\n * @returns A `Promise` of\n *   - A flat `ArrayBuffer` with all the binary values of the `Tensor`s\n *     concatenated.\n *   - An `Array` of `WeightManifestEntry`s, carrying information including\n *     tensor names, `dtype`s and shapes.\n * @throws Error: on unsupported tensor `dtype`.\n */\nexport async function encodeWeights(tensors, group) {\n    // TODO(adarob, cais): Support quantization.\n    const specs = [];\n    const dataPromises = [];\n    const names = Array.isArray(tensors) ?\n        tensors.map(tensor => tensor.name) :\n        Object.keys(tensors);\n    for (let i = 0; i < names.length; ++i) {\n        const name = names[i];\n        const t = Array.isArray(tensors) ? tensors[i].tensor : tensors[name];\n        if (t.dtype !== 'float32' && t.dtype !== 'int32' && t.dtype !== 'bool' &&\n            t.dtype !== 'string' && t.dtype !== 'complex64') {\n            throw new Error(`Unsupported dtype in weight '${name}': ${t.dtype}`);\n        }\n        const spec = { name, shape: t.shape, dtype: t.dtype };\n        if (t.dtype === 'string') {\n            const utf8bytes = new Promise(async (resolve) => {\n                const vals = await t.bytes();\n                const totalNumBytes = vals.reduce((p, c) => p + c.length, 0) +\n                    NUM_BYTES_STRING_LENGTH * vals.length;\n                const bytes = new Uint8Array(totalNumBytes);\n                let offset = 0;\n                for (let i = 0; i < vals.length; i++) {\n                    const val = vals[i];\n                    const bytesOfLength = new Uint8Array(new Uint32Array([val.length]).buffer);\n                    bytes.set(bytesOfLength, offset);\n                    offset += NUM_BYTES_STRING_LENGTH;\n                    bytes.set(val, offset);\n                    offset += val.length;\n                }\n                resolve(bytes);\n            });\n            dataPromises.push(utf8bytes);\n        }\n        else {\n            dataPromises.push(t.data());\n        }\n        if (group != null) {\n            spec.group = group;\n        }\n        specs.push(spec);\n    }\n    const tensorValues = await Promise.all(dataPromises);\n    return { data: concatenateTypedArrays(tensorValues), specs };\n}\n/**\n * Decode flat ArrayBuffer as weights.\n *\n * This function does not handle sharding.\n *\n * This function is the reverse of `encodeWeights`.\n *\n * @param buffer A flat ArrayBuffer carrying the binary values of the tensors\n *   concatenated in the order specified in `specs`.\n * @param specs Specifications of the names, dtypes and shapes of the tensors\n *   whose value are encoded by `buffer`.\n * @return A map from tensor name to tensor value, with the names corresponding\n *   to names in `specs`.\n * @throws Error, if any of the tensors has unsupported dtype.\n */\nexport function decodeWeights(buffer, specs) {\n    // TODO(adarob, cais): Support quantization.\n    const out = {};\n    let float16Decode;\n    let offset = 0;\n    for (const spec of specs) {\n        const name = spec.name;\n        const dtype = spec.dtype;\n        const shape = spec.shape;\n        const size = sizeFromShape(shape);\n        let values;\n        if ('quantization' in spec) {\n            const quantization = spec.quantization;\n            if (quantization.dtype === 'uint8' || quantization.dtype === 'uint16') {\n                if (!('min' in quantization && 'scale' in quantization)) {\n                    throw new Error(`Weight ${spec.name} with quantization ${quantization.dtype} ` +\n                        `doesn't have corresponding metadata min and scale.`);\n                }\n            }\n            else if (quantization.dtype === 'float16') {\n                if (dtype !== 'float32') {\n                    throw new Error(`Weight ${spec.name} is quantized with ${quantization.dtype} ` +\n                        `which only supports weights of type float32 not ${dtype}.`);\n                }\n            }\n            else {\n                throw new Error(`Weight ${spec.name} has unknown ` +\n                    `quantization dtype ${quantization.dtype}. ` +\n                    `Supported quantization dtypes are: ` +\n                    `'uint8', 'uint16', and 'float16'.`);\n            }\n            const quantizationSizeFactor = DTYPE_VALUE_SIZE_MAP[quantization.dtype];\n            const byteBuffer = buffer.slice(offset, offset + size * quantizationSizeFactor);\n            const quantizedArray = (quantization.dtype === 'uint8') ?\n                new Uint8Array(byteBuffer) :\n                new Uint16Array(byteBuffer);\n            if (dtype === 'float32') {\n                if (quantization.dtype === 'uint8' || quantization.dtype === 'uint16') {\n                    values = new Float32Array(quantizedArray.length);\n                    for (let i = 0; i < quantizedArray.length; i++) {\n                        const v = quantizedArray[i];\n                        values[i] = v * quantization.scale + quantization.min;\n                    }\n                }\n                else if (quantization.dtype === 'float16') {\n                    if (float16Decode === undefined) {\n                        float16Decode = getFloat16Decoder();\n                    }\n                    values = float16Decode(quantizedArray);\n                }\n                else {\n                    throw new Error(`Unsupported quantization type ${quantization.dtype} ` +\n                        `for weight type float32.`);\n                }\n            }\n            else if (dtype === 'int32') {\n                if (quantization.dtype !== 'uint8' && quantization.dtype !== 'uint16') {\n                    throw new Error(`Unsupported quantization type ${quantization.dtype} ` +\n                        `for weight type int32.`);\n                }\n                values = new Int32Array(quantizedArray.length);\n                for (let i = 0; i < quantizedArray.length; i++) {\n                    const v = quantizedArray[i];\n                    values[i] = Math.round(v * quantization.scale + quantization.min);\n                }\n            }\n            else {\n                throw new Error(`Unsupported dtype in weight '${name}': ${dtype}`);\n            }\n            offset += size * quantizationSizeFactor;\n        }\n        else if (dtype === 'string') {\n            const size = sizeFromShape(spec.shape);\n            values = [];\n            for (let i = 0; i < size; i++) {\n                const byteLength = new Uint32Array(buffer.slice(offset, offset + NUM_BYTES_STRING_LENGTH))[0];\n                offset += NUM_BYTES_STRING_LENGTH;\n                const bytes = new Uint8Array(buffer.slice(offset, offset + byteLength));\n                values.push(bytes);\n                offset += byteLength;\n            }\n        }\n        else {\n            const dtypeFactor = DTYPE_VALUE_SIZE_MAP[dtype];\n            const byteBuffer = buffer.slice(offset, offset + size * dtypeFactor);\n            if (dtype === 'float32') {\n                values = new Float32Array(byteBuffer);\n            }\n            else if (dtype === 'int32') {\n                values = new Int32Array(byteBuffer);\n            }\n            else if (dtype === 'bool') {\n                values = new Uint8Array(byteBuffer);\n            }\n            else if (dtype === 'complex64') {\n                values = new Float32Array(byteBuffer);\n                const real = new Float32Array(values.length / 2);\n                const image = new Float32Array(values.length / 2);\n                for (let i = 0; i < real.length; i++) {\n                    real[i] = values[i * 2];\n                    image[i] = values[i * 2 + 1];\n                }\n                const realTensor = tensor(real, shape, 'float32');\n                const imageTensor = tensor(image, shape, 'float32');\n                out[name] = complex(realTensor, imageTensor);\n            }\n            else {\n                throw new Error(`Unsupported dtype in weight '${name}': ${dtype}`);\n            }\n            offset += size * dtypeFactor;\n        }\n        if (dtype !== 'complex64') {\n            out[name] = tensor(values, shape, dtype);\n        }\n    }\n    return out;\n}\n/**\n * Concatenate TypedArrays into an ArrayBuffer.\n */\nexport function concatenateTypedArrays(xs) {\n    // TODO(adarob, cais): Support quantization.\n    if (xs === null) {\n        throw new Error(`Invalid input value: ${JSON.stringify(xs)}`);\n    }\n    let totalByteLength = 0;\n    // `normalizedXs` is here for this reason: a `TypedArray`'s `buffer'\n    // can have a different byte length from that of the `TypedArray` itself,\n    // for example, when the `TypedArray` is created from an offset in an\n    // `ArrayBuffer`. `normliazedXs` holds `TypedArray`s whose `buffer`s match\n    // the `TypedArray` in byte length. If an element of `xs` does not show\n    // this property, a new `TypedArray` that satisfy this property will be\n    // constructed and pushed into `normalizedXs`.\n    const normalizedXs = [];\n    xs.forEach((x) => {\n        totalByteLength += x.byteLength;\n        // tslint:disable:no-any\n        normalizedXs.push(x.byteLength === x.buffer.byteLength ? x :\n            new x.constructor(x));\n        if (!(x instanceof Float32Array || x instanceof Int32Array ||\n            x instanceof Uint8Array)) {\n            throw new Error(`Unsupported TypedArray subtype: ${x.constructor.name}`);\n        }\n        // tslint:enable:no-any\n    });\n    const y = new Uint8Array(totalByteLength);\n    let offset = 0;\n    normalizedXs.forEach((x) => {\n        y.set(new Uint8Array(x.buffer), offset);\n        offset += x.byteLength;\n    });\n    return y.buffer;\n}\n// Use Buffer on Node.js instead of Blob/atob/btoa\nconst useNodeBuffer = typeof Buffer !== 'undefined' &&\n    (typeof Blob === 'undefined' || typeof atob === 'undefined' ||\n        typeof btoa === 'undefined');\n/**\n * Calculate the byte length of a JavaScript string.\n *\n * Note that a JavaScript string can contain wide characters, therefore the\n * length of the string is not necessarily equal to the byte length.\n *\n * @param str Input string.\n * @returns Byte length.\n */\nexport function stringByteLength(str) {\n    if (useNodeBuffer) {\n        return Buffer.byteLength(str);\n    }\n    return new Blob([str]).size;\n}\n/**\n * Encode an ArrayBuffer as a base64 encoded string.\n *\n * @param buffer `ArrayBuffer` to be converted.\n * @returns A string that base64-encodes `buffer`.\n */\nexport function arrayBufferToBase64String(buffer) {\n    if (useNodeBuffer) {\n        return Buffer.from(buffer).toString('base64');\n    }\n    const buf = new Uint8Array(buffer);\n    let s = '';\n    for (let i = 0, l = buf.length; i < l; i++) {\n        s += String.fromCharCode(buf[i]);\n    }\n    return btoa(s);\n}\n/**\n * Decode a base64 string as an ArrayBuffer.\n *\n * @param str Base64 string.\n * @returns Decoded `ArrayBuffer`.\n */\nexport function base64StringToArrayBuffer(str) {\n    if (useNodeBuffer) {\n        const buf = Buffer.from(str, 'base64');\n        return buf.buffer.slice(buf.byteOffset, buf.byteOffset + buf.byteLength);\n    }\n    const s = atob(str);\n    const buffer = new Uint8Array(s.length);\n    for (let i = 0; i < s.length; ++i) {\n        buffer.set([s.charCodeAt(i)], i);\n    }\n    return buffer.buffer;\n}\n/**\n * Concatenate a number of ArrayBuffers into one.\n *\n * @param buffers A number of array buffers to concatenate.\n * @returns Result of concatenating `buffers` in order.\n */\nexport function concatenateArrayBuffers(buffers) {\n    if (buffers.length === 1) {\n        return buffers[0];\n    }\n    let totalByteLength = 0;\n    buffers.forEach((buffer) => {\n        totalByteLength += buffer.byteLength;\n    });\n    const temp = new Uint8Array(totalByteLength);\n    let offset = 0;\n    buffers.forEach((buffer) => {\n        temp.set(new Uint8Array(buffer), offset);\n        offset += buffer.byteLength;\n    });\n    return temp.buffer;\n}\n/**\n * Get the basename of a path.\n *\n * Behaves in a way analogous to Linux's basename command.\n *\n * @param path\n */\nexport function basename(path) {\n    const SEPARATOR = '/';\n    path = path.trim();\n    while (path.endsWith(SEPARATOR)) {\n        path = path.slice(0, path.length - 1);\n    }\n    const items = path.split(SEPARATOR);\n    return items[items.length - 1];\n}\n/**\n * Populate ModelArtifactsInfo fields for a model with JSON topology.\n * @param modelArtifacts\n * @returns A ModelArtifactsInfo object.\n */\nexport function getModelArtifactsInfoForJSON(modelArtifacts) {\n    if (modelArtifacts.modelTopology instanceof ArrayBuffer) {\n        throw new Error('Expected JSON model topology, received ArrayBuffer.');\n    }\n    return {\n        dateSaved: new Date(),\n        modelTopologyType: 'JSON',\n        modelTopologyBytes: modelArtifacts.modelTopology == null ?\n            0 :\n            stringByteLength(JSON.stringify(modelArtifacts.modelTopology)),\n        weightSpecsBytes: modelArtifacts.weightSpecs == null ?\n            0 :\n            stringByteLength(JSON.stringify(modelArtifacts.weightSpecs)),\n        weightDataBytes: modelArtifacts.weightData == null ?\n            0 :\n            modelArtifacts.weightData.byteLength,\n    };\n}\n/**\n * Computes mantisa table for casting Float16 to Float32\n * See http://www.fox-toolkit.org/ftp/fasthalffloatconversion.pdf\n *\n * @returns Uint32Array, 2048 mantissa lookup values.\n */\nfunction computeFloat16MantisaTable() {\n    const convertMantissa = (i) => {\n        let m = i << 13;\n        let e = 0;\n        while ((m & 0x00800000) === 0) {\n            e -= 0x00800000;\n            m <<= 1;\n        }\n        m &= ~0x00800000;\n        e += 0x38800000;\n        return m | e;\n    };\n    const mantisaTable = new Uint32Array(2048);\n    mantisaTable[0] = 0;\n    for (let i = 1; i < 1024; i++) {\n        mantisaTable[i] = convertMantissa(i);\n    }\n    for (let i = 1024; i < 2048; i++) {\n        mantisaTable[i] = 0x38000000 + ((i - 1024) << 13);\n    }\n    return mantisaTable;\n}\n/**\n * Computes exponent table for casting Float16 to Float32\n * See http://www.fox-toolkit.org/ftp/fasthalffloatconversion.pdf\n *\n * @returns Uint32Array, 64 exponent lookup values.\n */\nfunction computeFloat16ExponentTable() {\n    const exponentTable = new Uint32Array(64);\n    exponentTable[0] = 0;\n    exponentTable[31] = 0x47800000;\n    exponentTable[32] = 0x80000000;\n    exponentTable[63] = 0xc7800000;\n    for (let i = 1; i < 31; i++) {\n        exponentTable[i] = i << 23;\n    }\n    for (let i = 33; i < 63; i++) {\n        exponentTable[i] = 0x80000000 + ((i - 32) << 23);\n    }\n    return exponentTable;\n}\n/**\n * Computes offset table for casting Float16 to Float32\n * See http://www.fox-toolkit.org/ftp/fasthalffloatconversion.pdf\n *\n * @returns Uint32Array, 6d offset values.\n */\nfunction computeFloat16OffsetTable() {\n    const offsetTable = new Uint32Array(64);\n    for (let i = 0; i < 64; i++) {\n        offsetTable[i] = 1024;\n    }\n    offsetTable[0] = offsetTable[32] = 0;\n    return offsetTable;\n}\n/**\n * Retrieve a Float16 decoder which will decode a ByteArray of Float16 values\n * to a Float32Array.\n *\n * @returns Function (buffer: Uint16Array) => Float32Array which decodes\n *          the Uint16Array of Float16 bytes to a Float32Array.\n */\nexport function getFloat16Decoder() {\n    // Algorithm is based off of\n    // http://www.fox-toolkit.org/ftp/fasthalffloatconversion.pdf\n    // Cache lookup tables\n    const mantisaTable = computeFloat16MantisaTable();\n    const exponentTable = computeFloat16ExponentTable();\n    const offsetTable = computeFloat16OffsetTable();\n    return (quantizedArray) => {\n        const buffer = new ArrayBuffer(4 * quantizedArray.length);\n        const bufferUint32View = new Uint32Array(buffer);\n        for (let index = 0; index < quantizedArray.length; index++) {\n            const float16Bits = quantizedArray[index];\n            const float32Bits = mantisaTable[offsetTable[float16Bits >> 10] + (float16Bits & 0x3ff)] +\n                exponentTable[float16Bits >> 10];\n            bufferUint32View[index] = float32Bits;\n        }\n        return new Float32Array(buffer);\n    };\n}\n//# sourceMappingURL=io_utils.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nexport class IORouterRegistry {\n    constructor() {\n        this.saveRouters = [];\n        this.loadRouters = [];\n    }\n    static getInstance() {\n        if (IORouterRegistry.instance == null) {\n            IORouterRegistry.instance = new IORouterRegistry();\n        }\n        return IORouterRegistry.instance;\n    }\n    /**\n     * Register a save-handler router.\n     *\n     * @param saveRouter A function that maps a URL-like string onto an instance\n     * of `IOHandler` with the `save` method defined or `null`.\n     */\n    static registerSaveRouter(saveRouter) {\n        IORouterRegistry.getInstance().saveRouters.push(saveRouter);\n    }\n    /**\n     * Register a load-handler router.\n     *\n     * @param loadRouter A function that maps a URL-like string onto an instance\n     * of `IOHandler` with the `load` method defined or `null`.\n     */\n    static registerLoadRouter(loadRouter) {\n        IORouterRegistry.getInstance().loadRouters.push(loadRouter);\n    }\n    /**\n     * Look up IOHandler for saving, given a URL-like string.\n     *\n     * @param url\n     * @returns If only one match is found, an instance of IOHandler with the\n     * `save` method defined. If no match is found, `null`.\n     * @throws Error, if more than one match is found.\n     */\n    static getSaveHandlers(url) {\n        return IORouterRegistry.getHandlers(url, 'save');\n    }\n    /**\n     * Look up IOHandler for loading, given a URL-like string.\n     *\n     * @param url\n     * @param loadOptions Optional, custom load options.\n     * @returns All valid handlers for `url`, given the currently registered\n     *   handler routers.\n     */\n    static getLoadHandlers(url, loadOptions) {\n        return IORouterRegistry.getHandlers(url, 'load', loadOptions);\n    }\n    static getHandlers(url, handlerType, loadOptions) {\n        const validHandlers = [];\n        const routers = handlerType === 'load' ?\n            IORouterRegistry.getInstance().loadRouters :\n            IORouterRegistry.getInstance().saveRouters;\n        routers.forEach(router => {\n            const handler = router(url, loadOptions);\n            if (handler !== null) {\n                validHandlers.push(handler);\n            }\n        });\n        return validHandlers;\n    }\n}\nexport const registerSaveRouter = (loudRouter) => IORouterRegistry.registerSaveRouter(loudRouter);\nexport const registerLoadRouter = (loudRouter) => IORouterRegistry.registerLoadRouter(loudRouter);\nexport const getSaveHandlers = (url) => IORouterRegistry.getSaveHandlers(url);\nexport const getLoadHandlers = (url, loadOptions) => IORouterRegistry.getLoadHandlers(url, loadOptions);\n//# sourceMappingURL=router_registry.js.map","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { env } from './environment';\nimport { getGlobal } from './global_util';\nconst kernelRegistry = getGlobal('kernelRegistry', () => new Map());\nconst gradRegistry = getGlobal('gradRegistry', () => new Map());\n/**\n * Returns the kernel function (code) associated with the provided names.\n *\n * @param kernelName The official name of the kernel.\n * @param backendName The official name of the backend.\n */\nexport function getKernel(kernelName, backendName) {\n    const key = makeKey(kernelName, backendName);\n    return kernelRegistry.get(key);\n}\n/**\n * Returns the registered gradient info associated with the provided kernel.\n * @param kernelName The official TF kernel name.\n */\nexport function getGradient(kernelName) {\n    return gradRegistry.get(kernelName);\n}\nexport function getKernelsForBackend(backendName) {\n    const it = kernelRegistry.entries();\n    const result = [];\n    while (true) {\n        const { done, value } = it.next();\n        if (done) {\n            break;\n        }\n        const [key, config] = value;\n        const [backend,] = key.split('_');\n        if (backend === backendName) {\n            result.push(config);\n        }\n    }\n    return result;\n}\n/**\n * Registers the function (forward pass) for the kernel in a global registry.\n *\n * @param config A config object with the following properties:\n * - `kernelName` The official name of the kernel.\n * - `backendName` The official name of the backend.\n * - `kernelFunc` The function to run during the forward pass of the kernel.\n * - `setupFunc` Optional. Gets called once, after the backend initializes.\n * - `disposeFunc` Optional. Gets called once, right before the backend is\n * disposed.\n */\nexport function registerKernel(config) {\n    const { kernelName, backendName } = config;\n    const key = makeKey(kernelName, backendName);\n    if (kernelRegistry.has(key)) {\n        console.warn(`The kernel '${kernelName}' for backend ` +\n            `'${backendName}' is already registered`);\n    }\n    kernelRegistry.set(key, config);\n}\n/**\n * Registers a gradient function for a given kernel in the global registry,\n * to be used during the back-propagation of that kernel.\n *\n * @param config An object with the following properties:\n * - `kernelName` The name of the kernel that the gradient function is for.\n * - `gradFunc` The function to run during back-propagation.\n */\nexport function registerGradient(config) {\n    const { kernelName } = config;\n    if (gradRegistry.has(kernelName)) {\n        // TODO (yassogba) after 3.0 assess whether we need to keep this gated\n        // to debug mode.\n        if (env().getBool('DEBUG')) {\n            console.warn(`Overriding the gradient for '${kernelName}'`);\n        }\n    }\n    gradRegistry.set(kernelName, config);\n}\n/**\n * Removes the kernel function from the registry.\n *\n * @param kernelName The official name of the kernel.\n * @param backendName The official name of the backend.\n *\n */\nexport function unregisterKernel(kernelName, backendName) {\n    const key = makeKey(kernelName, backendName);\n    if (!kernelRegistry.has(key)) {\n        throw new Error(`The kernel '${kernelName}' for backend ` +\n            `'${backendName}' is not registered`);\n    }\n    kernelRegistry.delete(key);\n}\n/** Removes the registered gradient from the global registry. */\nexport function unregisterGradient(kernelName) {\n    if (!gradRegistry.has(kernelName)) {\n        throw new Error(`The gradient '${kernelName}' for backend is not registered`);\n    }\n    gradRegistry.delete(kernelName);\n}\nfunction makeKey(kernelName, backendName) {\n    return `${backendName}_${kernelName}`;\n}\n//# sourceMappingURL=kernel_registry.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n/**\n * Classes and functions for model management across multiple storage mediums.\n *\n * Supported client actions:\n * - Listing models on all registered storage mediums.\n * - Remove model by URL from any registered storage mediums, by using URL\n *   string.\n * - Moving or copying model from one path to another in the same medium or from\n *   one medium to another, by using URL strings.\n */\nimport { assert } from '../util';\nimport { IORouterRegistry } from './router_registry';\nconst URL_SCHEME_SUFFIX = '://';\nexport class ModelStoreManagerRegistry {\n    constructor() {\n        this.managers = {};\n    }\n    static getInstance() {\n        if (ModelStoreManagerRegistry.instance == null) {\n            ModelStoreManagerRegistry.instance = new ModelStoreManagerRegistry();\n        }\n        return ModelStoreManagerRegistry.instance;\n    }\n    /**\n     * Register a save-handler router.\n     *\n     * @param saveRouter A function that maps a URL-like string onto an instance\n     * of `IOHandler` with the `save` method defined or `null`.\n     */\n    static registerManager(scheme, manager) {\n        assert(scheme != null, () => 'scheme must not be undefined or null.');\n        if (scheme.endsWith(URL_SCHEME_SUFFIX)) {\n            scheme = scheme.slice(0, scheme.indexOf(URL_SCHEME_SUFFIX));\n        }\n        assert(scheme.length > 0, () => 'scheme must not be an empty string.');\n        const registry = ModelStoreManagerRegistry.getInstance();\n        assert(registry.managers[scheme] == null, () => `A model store manager is already registered for scheme '${scheme}'.`);\n        registry.managers[scheme] = manager;\n    }\n    static getManager(scheme) {\n        const manager = this.getInstance().managers[scheme];\n        if (manager == null) {\n            throw new Error(`Cannot find model manager for scheme '${scheme}'`);\n        }\n        return manager;\n    }\n    static getSchemes() {\n        return Object.keys(this.getInstance().managers);\n    }\n}\n/**\n * Helper method for parsing a URL string into a scheme and a path.\n *\n * @param url E.g., 'localstorage://my-model'\n * @returns A dictionary with two fields: scheme and path.\n *   Scheme: e.g., 'localstorage' in the example above.\n *   Path: e.g., 'my-model' in the example above.\n */\nfunction parseURL(url) {\n    if (url.indexOf(URL_SCHEME_SUFFIX) === -1) {\n        throw new Error(`The url string provided does not contain a scheme. ` +\n            `Supported schemes are: ` +\n            `${ModelStoreManagerRegistry.getSchemes().join(',')}`);\n    }\n    return {\n        scheme: url.split(URL_SCHEME_SUFFIX)[0],\n        path: url.split(URL_SCHEME_SUFFIX)[1],\n    };\n}\nasync function cloneModelInternal(sourceURL, destURL, deleteSource = false) {\n    assert(sourceURL !== destURL, () => `Old path and new path are the same: '${sourceURL}'`);\n    const loadHandlers = IORouterRegistry.getLoadHandlers(sourceURL);\n    assert(loadHandlers.length > 0, () => `Copying failed because no load handler is found for source URL ${sourceURL}.`);\n    assert(loadHandlers.length < 2, () => `Copying failed because more than one (${loadHandlers.length}) ` +\n        `load handlers for source URL ${sourceURL}.`);\n    const loadHandler = loadHandlers[0];\n    const saveHandlers = IORouterRegistry.getSaveHandlers(destURL);\n    assert(saveHandlers.length > 0, () => `Copying failed because no save handler is found for destination ` +\n        `URL ${destURL}.`);\n    assert(saveHandlers.length < 2, () => `Copying failed because more than one (${loadHandlers.length}) ` +\n        `save handlers for destination URL ${destURL}.`);\n    const saveHandler = saveHandlers[0];\n    const sourceScheme = parseURL(sourceURL).scheme;\n    const sourcePath = parseURL(sourceURL).path;\n    const sameMedium = sourceScheme === parseURL(sourceURL).scheme;\n    const modelArtifacts = await loadHandler.load();\n    // If moving within the same storage medium, remove the old model as soon as\n    // the loading is done. Without doing this, it is possible that the combined\n    // size of the two models will cause the cloning to fail.\n    if (deleteSource && sameMedium) {\n        await ModelStoreManagerRegistry.getManager(sourceScheme)\n            .removeModel(sourcePath);\n    }\n    const saveResult = await saveHandler.save(modelArtifacts);\n    // If moving between mediums, the deletion is done after the save succeeds.\n    // This guards against the case in which saving to the destination medium\n    // fails.\n    if (deleteSource && !sameMedium) {\n        await ModelStoreManagerRegistry.getManager(sourceScheme)\n            .removeModel(sourcePath);\n    }\n    return saveResult.modelArtifactsInfo;\n}\n/**\n * List all models stored in registered storage mediums.\n *\n * For a web browser environment, the registered mediums are Local Storage and\n * IndexedDB.\n *\n * ```js\n * // First create and save a model.\n * const model = tf.sequential();\n * model.add(tf.layers.dense(\n *     {units: 1, inputShape: [10], activation: 'sigmoid'}));\n * await model.save('localstorage://demo/management/model1');\n *\n * // Then list existing models.\n * console.log(JSON.stringify(await tf.io.listModels()));\n *\n * // Delete the model.\n * await tf.io.removeModel('localstorage://demo/management/model1');\n *\n * // List models again.\n * console.log(JSON.stringify(await tf.io.listModels()));\n * ```\n *\n * @returns A `Promise` of a dictionary mapping URLs of existing models to\n * their model artifacts info. URLs include medium-specific schemes, e.g.,\n *   'indexeddb://my/model/1'. Model artifacts info include type of the\n * model's topology, byte sizes of the topology, weights, etc.\n *\n * @doc {\n *   heading: 'Models',\n *   subheading: 'Management',\n *   namespace: 'io',\n *   ignoreCI: true\n * }\n */\nasync function listModels() {\n    const schemes = ModelStoreManagerRegistry.getSchemes();\n    const out = {};\n    for (const scheme of schemes) {\n        const schemeOut = await ModelStoreManagerRegistry.getManager(scheme).listModels();\n        for (const path in schemeOut) {\n            const url = scheme + URL_SCHEME_SUFFIX + path;\n            out[url] = schemeOut[path];\n        }\n    }\n    return out;\n}\n/**\n * Remove a model specified by URL from a reigstered storage medium.\n *\n * ```js\n * // First create and save a model.\n * const model = tf.sequential();\n * model.add(tf.layers.dense(\n *     {units: 1, inputShape: [10], activation: 'sigmoid'}));\n * await model.save('localstorage://demo/management/model1');\n *\n * // Then list existing models.\n * console.log(JSON.stringify(await tf.io.listModels()));\n *\n * // Delete the model.\n * await tf.io.removeModel('localstorage://demo/management/model1');\n *\n * // List models again.\n * console.log(JSON.stringify(await tf.io.listModels()));\n * ```\n *\n * @param url A URL to a stored model, with a scheme prefix, e.g.,\n *   'localstorage://my-model-1', 'indexeddb://my/model/2'.\n * @returns ModelArtifactsInfo of the deleted model (if and only if deletion\n *   is successful).\n * @throws Error if deletion fails, e.g., if no model exists at `path`.\n *\n * @doc {\n *   heading: 'Models',\n *   subheading: 'Management',\n *   namespace: 'io',\n *   ignoreCI: true\n * }\n */\nasync function removeModel(url) {\n    const schemeAndPath = parseURL(url);\n    const manager = ModelStoreManagerRegistry.getManager(schemeAndPath.scheme);\n    return manager.removeModel(schemeAndPath.path);\n}\n/**\n * Copy a model from one URL to another.\n *\n * This function supports:\n *\n * 1. Copying within a storage medium, e.g.,\n *    `tf.io.copyModel('localstorage://model-1', 'localstorage://model-2')`\n * 2. Copying between two storage mediums, e.g.,\n *    `tf.io.copyModel('localstorage://model-1', 'indexeddb://model-1')`\n *\n * ```js\n * // First create and save a model.\n * const model = tf.sequential();\n * model.add(tf.layers.dense(\n *     {units: 1, inputShape: [10], activation: 'sigmoid'}));\n * await model.save('localstorage://demo/management/model1');\n *\n * // Then list existing models.\n * console.log(JSON.stringify(await tf.io.listModels()));\n *\n * // Copy the model, from Local Storage to IndexedDB.\n * await tf.io.copyModel(\n *     'localstorage://demo/management/model1',\n *     'indexeddb://demo/management/model1');\n *\n * // List models again.\n * console.log(JSON.stringify(await tf.io.listModels()));\n *\n * // Remove both models.\n * await tf.io.removeModel('localstorage://demo/management/model1');\n * await tf.io.removeModel('indexeddb://demo/management/model1');\n * ```\n *\n * @param sourceURL Source URL of copying.\n * @param destURL Destination URL of copying.\n * @returns ModelArtifactsInfo of the copied model (if and only if copying\n *   is successful).\n * @throws Error if copying fails, e.g., if no model exists at `sourceURL`, or\n *   if `oldPath` and `newPath` are identical.\n *\n * @doc {\n *   heading: 'Models',\n *   subheading: 'Management',\n *   namespace: 'io',\n *   ignoreCI: true\n * }\n */\nasync function copyModel(sourceURL, destURL) {\n    const deleteSource = false;\n    return cloneModelInternal(sourceURL, destURL, deleteSource);\n}\n/**\n * Move a model from one URL to another.\n *\n * This function supports:\n *\n * 1. Moving within a storage medium, e.g.,\n *    `tf.io.moveModel('localstorage://model-1', 'localstorage://model-2')`\n * 2. Moving between two storage mediums, e.g.,\n *    `tf.io.moveModel('localstorage://model-1', 'indexeddb://model-1')`\n *\n * ```js\n * // First create and save a model.\n * const model = tf.sequential();\n * model.add(tf.layers.dense(\n *     {units: 1, inputShape: [10], activation: 'sigmoid'}));\n * await model.save('localstorage://demo/management/model1');\n *\n * // Then list existing models.\n * console.log(JSON.stringify(await tf.io.listModels()));\n *\n * // Move the model, from Local Storage to IndexedDB.\n * await tf.io.moveModel(\n *     'localstorage://demo/management/model1',\n *     'indexeddb://demo/management/model1');\n *\n * // List models again.\n * console.log(JSON.stringify(await tf.io.listModels()));\n *\n * // Remove the moved model.\n * await tf.io.removeModel('indexeddb://demo/management/model1');\n * ```\n *\n * @param sourceURL Source URL of moving.\n * @param destURL Destination URL of moving.\n * @returns ModelArtifactsInfo of the copied model (if and only if copying\n *   is successful).\n * @throws Error if moving fails, e.g., if no model exists at `sourceURL`, or\n *   if `oldPath` and `newPath` are identical.\n *\n * @doc {\n *   heading: 'Models',\n *   subheading: 'Management',\n *   namespace: 'io',\n *   ignoreCI: true\n * }\n */\nasync function moveModel(sourceURL, destURL) {\n    const deleteSource = true;\n    return cloneModelInternal(sourceURL, destURL, deleteSource);\n}\nexport { moveModel, copyModel, removeModel, listModels };\n//# sourceMappingURL=model_management.js.map"],"sourceRoot":""}