{"version":3,"sources":["webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/cast.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/elu.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/broadcast_util.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/cumsum.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/cos.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/avg_pool.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/conv2d_backprop_input.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/conv2d_backprop_filter.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/eye.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/div.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/cosh.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/all.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/any.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/arg_max.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/arg_min.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/atan2.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/conv1d.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/conv2d_transpose.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/depth_to_space.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/dilation2d.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/div_no_nan.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/dot.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/batchnorm.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/batchnorm_util.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/depthwise_conv2d_native_backprop_input.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/depthwise_conv2d_native_backprop_filter.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/add.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/conv_util.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/concat_2d.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/browser.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/concat_util.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/array_ops_util.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/erf_util.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/log.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/acos.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/acosh.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/binary_ops.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/asin.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/asinh.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/atan.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/atanh.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/ceil.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/clip_by_value.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/compare.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/erf.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/expm1.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/concat.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/avg_pool_3d_grad.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/avg_pool_grad.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/conv3d_backprop_input.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/conv3d_backprop_filter.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/exp.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/axis_util.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/abs.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/complex.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/expand_dims.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/conv2d.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/clone.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/depthwise_conv2d.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/equal.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/buffer.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/batch_to_space_nd.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/broadcast_to.js"],"names":["cast","cast_","x","dtype","$x","Error","inputs","attrs","runKernel","elu","elu_","getBroadcastDims","inShape","outShape","inRank","length","dims","i","dim","a","unshift","getReductionAxes","result","inDim","outAxis","outDim","assertAndGetBroadcastShape","shapeA","shapeB","l","Math","max","b","cumsum","cumsum_","axis","exclusive","reverse","cos","cos_","avgPool","avgPool_","filterSize","strides","pad","dimRoundingMode","x4D","reshapedTo4D","rank","shape","res","conv2DBackpropInput","conv2DBackpropInput_","xShape","dy","filter","dataFormat","xShape4D","dy4D","inDepth","outDepth","inputShape","conv2DBackpropFilter","conv2DBackpropFilter_","filterShape","eye","eye_","numRows","numColumns","batchShape","buff","n","set","out","toTensor","div","div_","$a","$b","cosh","cosh_","all","all_","keepDims","any","any_","argMax","argMax_","argMin","argMin_","atan2","atan2_","conv1d","conv1d_","stride","dilation","$filter","x3D","reshapedTo3D","filter4D","input4D","dilations","conv2dTranspose","conv2dTranspose_","outputShape","depthToSpace","depthToSpace_","blockSize","inputHeight","inputWidth","inputDepth","dilation2d","dilation2d_","divNoNan","divNoNan_","divResult","zeros","bEqualsZero","dot","dot_","t1","t2","$t1","$t2","t1Inner","size","t2Inner","t12D","t22D","t1t2","batchNorm","batchNorm_","mean","variance","offset","scale","varianceEpsilon","$mean","$variance","$scale","$offset","reshape","xAs4D","depthwiseConv2dNativeBackpropInput","depthwiseConv2dNativeBackpropInput_","depthwiseConv2dNativeBackpropFilter","depthwiseConv2dNativeBackpropFilter_","add","add_","computeDilation2DInfo","computeConv2DInfo","convertConv2DDataFormat","computePool2DInfo","roundingMode","filterHeight","filterWidth","parseTupleParam","computePool3DInfo","filterDepth","parse3TupleParam","$dataFormat","computeConv3DInfo","depthwise","batchSize","inHeight","inWidth","inChannels","filterChannels","strideHeight","strideWidth","dilationHeight","dilationWidth","effectiveFilterHeight","getEffectiveFilterSize","effectiveFilterWidth","padInfo","outHeight","outWidth","top","bottom","left","right","type","fieldSize","zeroPad","computeDefaultPad","inputRows","inputCols","outputRows","round","outputCols","computeOutputShape2D","ceil","padAlongHeight","padAlongWidth","floor","getPadAndOutInfo","outChannels","strideDepth","dilationDepth","effectiveFilterDepth","front","back","outputDepths","computeOutputShape4D","padAlongDepth","get3DPadAndOutInfo","effectiveFieldSize","param","value","trunc","tupleValuesAreOne","dimA","dimB","dimC","eitherStridesOrDilationsAreOne","concat2d","concat2d_","tensors","fromPixels2DContext","async","toPixels","img","canvas","$img","originalImgTensor","dispose","height","width","slice","depth","data","multiplier","bytes","Uint8ClampedArray","rgba","d","j","ctx","getContext","imageData","ImageData","putImageData","fromPixels","fromPixels_","pixels","numChannels","isPixelData","isImageData","isVideo","isImage","isCanvasLike","isImageBitmap","Uint8Array","HTMLVideoElement","HTMLImageElement","ImageBitmap","constructor","name","HAVE_CURRENT_DATA_READY_STATE","readyState","backendName","videoWidth","videoHeight","vals","values","getImageData","document","createElement","drawImage","Int32Array","numPixels","channel","assertParamsConsistent","shapes","forEach","firstShape","r","computeOutShape","getReshaped","blockShape","prod","batchToSpace","reshaped","concat","push","spatialLength","getPermuted","reshapedRank","blockShapeRank","permuted","permutedBeforeBatch","permutedAfterBatch","getReshapedPermuted","reshapedPermuted","getSliceBeginCoords","crops","sliceBeginCoords","getSliceSize","uncroppedShape","sliceSize","ERF_P","ERF_A1","ERF_A2","ERF_A3","ERF_A4","ERF_A5","warn","msg","getBool","console","log","acos","acos_","acosh","acosh_","addStrict","addStrict_","divStrict","divStrict_","maximumStrict","maximumStrict_","minimumStrict","minimumStrict_","modStrict","modStrict_","mulStrict","mulStrict_","powStrict","powStrict_","base","exp","squaredDifferenceStrict","squaredDifferenceStrict_","subStrict","subStrict_","asin","asin_","asinh","asinh_","atan","atan_","atanh","atanh_","ceil_","clipByValue","clipByValue_","clipValueMin","clipValueMax","equalStrict","equalStrict_","greaterEqualStrict","greaterEqualStrict_","greaterStrict","greaterStrict_","lessEqualStrict","lessEqualStrict_","lessStrict","lessStrict_","notEqualStrict","notEqualStrict_","erf","erf_","expm1","expm1_","concat_","$tensors","tensor","attr","avgPool3dGrad","avgPool3dGrad_","input","$dy","$input","dy5D","input5D","reshapedTo5D","avgPoolGrad","avgPoolGrad_","conv3DBackpropInput","conv3DBackpropInput_","xShape5D","conv3DBackpropFilter","conv3DBackpropFilter_","x5D","exp_","axesAreInnerMostDims","axes","combineLocations","outputLoc","reduceLoc","loc","outIdx","reduceIdx","indexOf","computeOutAndReduceShapes","aShape","map","expandShapeToKeepDim","assertAxesAreInnerMostDims","getAxesPermutation","getUndoAxesPermutation","sort","getInnerMostAxes","numAxes","abs","abs_","complex","complex_","real","imag","$real","$imag","expandDims","expandDims_","conv2d","conv2d_","clone","clone_","depthwiseConv2d","depthwiseConv2d_","equal","equal_","buffer","batchToSpaceND","batchToSpaceND_","reduce","join","broadcastTo","broadcastTo_","some","newShape","reps","Array","from"],"mappings":";sJAAA,yEA+CO,MAAMA,EAAO,YAAG,CAAEC,MAdzB,SAAeC,EAAGC,GACd,MAAMC,EAAK,YAAgBF,EAAG,IAAK,QAEnC,IAAK,IAAkBC,GACnB,MAAM,IAAIE,MAAM,mCAAmCF,KAEvD,GAAc,WAAVA,GAAmC,WAAbC,EAAGD,OACf,WAAVA,GAAmC,WAAbC,EAAGD,MACzB,MAAM,IAAIE,MAAM,yCAEpB,MAAMC,EAAS,CAAEJ,EAAGE,GACdG,EAAQ,CAAEJ,SAChB,OAAO,IAAOK,UAAU,IAAMF,EAAQC,O,iCC7C1C,kEAqCO,MAAME,EAAM,YAAG,CAAEC,KALxB,SAAcR,GACV,MACMI,EAAS,CAAEJ,EADN,YAAgBA,EAAG,IAAK,QAEnC,OAAO,IAAOM,UAAU,IAAKF,O,gCCV1B,SAASK,EAAiBC,EAASC,GACtC,MAAMC,EAASF,EAAQG,OACjBC,EAAO,GACb,IAAK,IAAIC,EAAI,EAAGA,EAAIH,EAAQG,IAAK,CAC7B,MAAMC,EAAMJ,EAAS,EAAIG,EACnBE,EAAIP,EAAQM,IAAQ,GAChBL,EAASA,EAASE,OAAS,EAAIE,IAAM,GACvC,GAAW,IAANE,GACTH,EAAKI,QAAQF,GAGrB,OAAOF,EAMJ,SAASK,EAAiBT,EAASC,GACtC,MAAMS,EAAS,GACf,IAAK,IAAIL,EAAI,EAAGA,EAAIJ,EAASE,OAAQE,IAAK,CACtC,MAAMM,EAAQX,EAAQA,EAAQG,OAASE,EAAI,GACrCO,EAAUX,EAASE,OAASE,EAAI,EAChCQ,EAASZ,EAASW,IACX,MAATD,GAA4B,IAAVA,GAAeE,EAAS,IAC1CH,EAAOF,QAAQI,GAGvB,OAAOF,EAEJ,SAASI,EAA2BC,EAAQC,GAC/C,MAAMN,EAAS,GACTO,EAAIC,KAAKC,IAAIJ,EAAOZ,OAAQa,EAAOb,QACzC,IAAK,IAAIE,EAAI,EAAGA,EAAIY,EAAGZ,IAAK,CACxB,IAAIE,EAAIQ,EAAOA,EAAOZ,OAASE,EAAI,GAC1B,MAALE,IACAA,EAAI,GAER,IAAIa,EAAIJ,EAAOA,EAAOb,OAASE,EAAI,GAInC,GAHS,MAALe,IACAA,EAAI,GAEE,IAANb,EACAG,EAAOF,QAAQY,QAEd,GAAU,IAANA,EACLV,EAAOF,QAAQD,OAEd,IAAIA,IAAMa,EAAG,CAGd,MAAM3B,MADF,wDAAGsB,SAAcC,MAIrBN,EAAOF,QAAQD,IAGvB,OAAOG,EAjFX,uG,iCCAA,kEAiDO,MAAMW,EAAS,YAAG,CAAEC,QAN3B,SAAiBhC,EAAGiC,EAAO,EAAGC,GAAY,EAAOC,GAAU,GACvD,MACM/B,EAAS,CAAEJ,EADN,YAAgBA,EAAG,IAAK,WAE7BK,EAAQ,CAAE4B,OAAMC,YAAWC,WACjC,OAAO,IAAO7B,UAAU,IAAQF,EAAQC,O,iCC/C5C,kEAqCO,MAAM+B,EAAM,YAAG,CAAEC,KALxB,SAAcrC,GACV,MACMI,EAAS,CAAEJ,EADN,YAAgBA,EAAG,IAAK,QAEnC,OAAO,IAAOM,UAAU,IAAKF,O,iCCnCjC,gGAsEO,MAAMkC,EAAU,YAAG,CAAEC,SA1B5B,SAAkBvC,EAAGwC,EAAYC,EAASC,EAAKC,GAC3C,MAAMzC,EAAK,YAAgBF,EAAG,IAAK,UAAW,WAE9C,IAAY,IAAyCyC,EADnC,IACwD,IACtE,wEAAeA,wBACnB,IAAIG,EAAM1C,EACN2C,GAAe,EACH,IAAZ3C,EAAG4C,OACHD,GAAe,EACfD,EAAM,YAAQ1C,EAAI,CAAC,EAAGA,EAAG6C,MAAM,GAAI7C,EAAG6C,MAAM,GAAI7C,EAAG6C,MAAM,MAE7D,IAAyB,IAAbH,EAAIE,MAAY,IAAM,mDAAmDF,EAAIE,UAClE,MAAnBH,GACA,IAAY,IAAWD,IAAM,IACzB,wEAAmBC,iBAA+BD,OAE1D,MAAMtC,EAAS,CAAEJ,EAAG4C,GACdvC,EAAQ,CAAEmC,aAAYC,UAASC,MAAKC,mBAE1C,IAAIK,EAAM,IAAO1C,UAAU,IAASF,EAAQC,GAE5C,OADA2C,EAAM,YAAKA,EAAK9C,EAAGD,OACf4C,EACO,YAAQG,EAAK,CAACA,EAAID,MAAM,GAAIC,EAAID,MAAM,GAAIC,EAAID,MAAM,KAExDC,M,iCCpEX,yEAiFO,MAAMC,EAAsB,YAAG,CAAEC,qBApCxC,SAA8BC,EAAQC,EAAIC,EAAQZ,EAASC,EAAKY,EAAa,OAAQX,GACjF,IAAYQ,EAAOtC,SAAWuC,EAAGN,MAAM,IACnC,sBAAIK,EAAOtC,2BAA2BuC,EAAGN,qBAC7C,IAAIS,EAAWJ,EACXK,EAAOJ,EACPP,GAAe,EACH,IAAZO,EAAGN,OACHD,GAAe,EACfW,EAAO,YAAQJ,EAAI,CAAC,EAAGA,EAAGL,MAAM,GAAIK,EAAGL,MAAM,GAAIK,EAAGL,MAAM,KAC1DQ,EAAW,CAAC,EAAGJ,EAAO,GAAIA,EAAO,GAAIA,EAAO,KAEhD,IAAgC,IAApBI,EAAS1C,QAAc,IAC/B,qEAAG0C,EAAS1C,YAChB,IAA0B,IAAd2C,EAAKV,MAAY,IACzB,4DAAQU,EAAKV,SACjB,IAA4B,IAAhBO,EAAOP,MAAY,IAC3B,gEAAQO,EAAOP,SACnB,MAAMW,EAAyB,SAAfH,EAAwBC,EAAS,GAAKA,EAAS,GACzDG,EAA0B,SAAfJ,EAAwBE,EAAKT,MAAM,GAAKS,EAAKT,MAAM,GACpE,IAAYU,IAAYJ,EAAON,MAAM,IAAI,IAAM,4CAA4CU,wCACvDJ,EAAON,MAAM,QACjD,IAAYW,IAAaL,EAAON,MAAM,IAAI,IAAM,6CAA6CW,yCACxDL,EAAON,MAAM,QAC3B,MAAnBJ,GACA,IAAY,IAAWD,IAAM,IACzB,+EAAmBC,iBAA+BD,OAE1D,MAAMtC,EAAS,CAAEgD,GAAII,EAAMH,UACrBhD,EAAQ,CAAEoC,UAASC,MAAKY,aAAYX,kBAAiBgB,WAAYJ,GAEjEP,EAAM,IAAO1C,UAAU,IAAqBF,EAAQC,GAC1D,OAAIwC,EACO,YAAQG,EAAK,CAACA,EAAID,MAAM,GAAIC,EAAID,MAAM,GAAIC,EAAID,MAAM,KAExDC,M,iCC/EX,yEAuEO,MAAMY,EAAuB,YAAG,CAAEC,sBA9BzC,SAA+B7D,EAAGoD,EAAIU,EAAarB,EAASC,EAAKY,EAAa,OAAQX,GAClF,IAAIC,EAAM5C,EACK,IAAXA,EAAE8C,OACFF,EAAM,YAAQ5C,EAAG,CAAC,EAAGA,EAAE+C,MAAM,GAAI/C,EAAE+C,MAAM,GAAI/C,EAAE+C,MAAM,MAEzD,IAAIS,EAAOJ,EACO,IAAdI,EAAKV,OACLU,EAAO,YAAQJ,EAAI,CAAC,EAAGA,EAAGL,MAAM,GAAIK,EAAGL,MAAM,GAAIK,EAAGL,MAAM,MAE9D,IAAyB,IAAbH,EAAIE,MAAY,IACxB,iEAAGF,EAAIG,WACX,IAA0B,IAAdS,EAAKV,MAAY,IACzB,8DAAGU,EAAKT,WACZ,IAAmC,IAAvBe,EAAYjD,QAAc,IAClC,mEAAGiD,OACP,MAAML,EAAyB,SAAfH,EAAwBV,EAAIG,MAAM,GAAKH,EAAIG,MAAM,GAC3DW,EAA0B,SAAfJ,EAAwBE,EAAKT,MAAM,GAAKS,EAAKT,MAAM,GACpE,IAAYU,IAAYK,EAAY,IAAI,IAAM,4CAA4CL,wCACtDK,EAAY,QAChD,IAAYJ,IAAaI,EAAY,IAAI,IAAM,0CAA0CJ,0CACnDI,EAAY,SAC3B,MAAnBnB,GACA,IAAY,IAAWD,IAAM,IACzB,gFAAmBC,iBAA+BD,OAE1D,MAAMtC,EAAS,CAAEJ,EAAG4C,EAAKQ,GAAII,GACvBnD,EAAQ,CAAEoC,UAASC,MAAKY,aAAYX,kBAAiBmB,eAE3D,OAAO,IAAOxD,UAAU,IAAsBF,EAAQC,O,iCCrE1D,4EAqEO,MAAM0D,EAAM,YAAG,CAAEC,KAlCxB,SAAcC,EAASC,EAAYC,EAAYlE,EAAQ,WACjC,MAAdiE,IACAA,EAAaD,GAEjB,MAAMG,EAAO,YAAO,CAACH,EAASC,GAAajE,GACrCoE,EAAIJ,GAAWC,EAAaD,EAAUC,EAC5C,IAAK,IAAInD,EAAI,EAAGA,EAAIsD,IAAKtD,EACrBqD,EAAKE,IAAI,EAAGvD,EAAGA,GAEnB,MAAMwD,EAAM,YAAQH,EAAKI,WAAY,CAACP,EAASC,IAC/C,GAAkB,MAAdC,EACA,OAAOI,EAGP,GAA0B,IAAtBJ,EAAWtD,OACX,OAAO,YAAK,YAAW0D,EAAK,GAAI,CAACJ,EAAW,GAAI,EAAG,IAElD,GAA0B,IAAtBA,EAAWtD,OAEhB,OAAO,YAAK,YAAW,YAAW0D,EAAK,GAAI,GAAI,CAACJ,EAAW,GAAIA,EAAW,GAAI,EAAG,IAEhF,GAA0B,IAAtBA,EAAWtD,OAEhB,OAAO,YAAK,YAAW,YAAW,YAAW0D,EAAK,GAAI,GAAI,GAAI,CAC1DJ,EAAW,GAAIA,EAAW,GAAIA,EAAW,GAAI,EAAG,IAIpD,MAAM,IAAIhE,MAEN,qEAA6BgE,EAAWtD,gB,gCCjExD,mFA0DO,MAAM4D,EAAM,YAAG,CAAEC,KAZxB,SAAczD,EAAGa,GACb,IAAI6C,EAAK,YAAgB1D,EAAG,IAAK,OAC7B2D,EAAK,YAAgB9C,EAAG,IAAK,OAEjC,IADC6C,EAAIC,GAAM,YAAeD,EAAIC,GACb,UAAbD,EAAG1E,OAAkC,UAAb2E,EAAG3E,MAC3B,OAAO,YAAS0E,EAAIC,GAExB,MAAMxE,EAAS,CAAEa,EAAG0D,EAAI7C,EAAG8C,GAG3B,OAAO,IAAOtE,UAAU,KAASF,EAFnB,Q,iCCtDlB,kEAqCO,MAAMyE,EAAO,YAAG,CAAEC,MALzB,SAAe9E,GACX,MACMI,EAAS,CAAEJ,EADN,YAAgBA,EAAG,IAAK,SAEnC,OAAO,IAAOM,UAAU,IAAMF,O,iCCnClC,kEAuDO,MAAM2E,EAAM,YAAG,CAAEC,KANxB,SAAchF,EAAGiC,EAAO,KAAMgD,GAAW,GACrC,MACM7E,EAAS,CAAEJ,EADN,YAAgBA,EAAG,IAAK,MAAO,SAEpCK,EAAQ,CAAE4B,OAAMgD,YACtB,OAAO,IAAO3E,UAAU,IAAKF,EAAQC,O,iCCrDzC,kEAwDO,MAAM6E,EAAM,YAAG,CAAEC,KAPxB,SAAcnF,EAAGiC,EAAO,KAAMgD,GAAW,GACrC,MACM7E,EAAS,CAAEJ,EADN,YAAgBA,EAAG,IAAK,MAAO,SAEpCK,EAAQ,CAAE4B,OAAMgD,YACtB,OAAO,IAAO3E,UAAU,IAAKF,EAAQC,O,iCCrDzC,kEAkDO,MAAM+E,EAAS,YAAG,CAAEC,QAN3B,SAAiBrF,EAAGiC,EAAO,GACvB,MACM7B,EAAS,CAAEJ,EADN,YAAgBA,EAAG,IAAK,WAE7BK,EAAQ,CAAE4B,QAChB,OAAO,IAAO3B,UAAU,IAAQF,EAAQC,O,iCChD5C,kEAkDO,MAAMiF,EAAS,YAAG,CAAEC,QAN3B,SAAiBvF,EAAGiC,EAAO,GACvB,MACM7B,EAAS,CAAEJ,EADN,YAAgBA,EAAG,IAAK,WAE7BK,EAAQ,CAAE4B,QAChB,OAAO,IAAO3B,UAAU,IAAQF,EAAQC,O,iCChD5C,0EA4CO,MAAMmF,EAAQ,YAAG,CAAEC,OAP1B,SAAgBxE,EAAGa,GACf,IAAI6C,EAAK,YAAgB1D,EAAG,IAAK,SAC7B2D,EAAK,YAAgB9C,EAAG,IAAK,UAChC6C,EAAIC,GAAM,YAAeD,EAAIC,GAC9B,MAAMxE,EAAS,CAAEa,EAAG0D,EAAI7C,EAAG8C,GAC3B,OAAO,IAAOtE,UAAU,IAAOF,O,iCC1CnC,kFAkEO,MAAMsF,EAAS,YAAG,CAAEC,QAhC3B,SAAiB3F,EAAGqD,EAAQuC,EAAQlD,EAAKY,EAAa,MAAOuC,EAAW,EAAGlD,GACvE,MAAMzC,EAAK,YAAgBF,EAAG,IAAK,UAC7B8F,EAAU,YAAgBzC,EAAQ,SAAU,UAClD,IAAI0C,EAAM7F,EACN8F,GAAe,EACH,IAAZ9F,EAAG4C,OACHkD,GAAe,EACfD,EAAM,YAAQ7F,EAAI,CAAC,EAAGA,EAAG6C,MAAM,GAAI7C,EAAG6C,MAAM,MAEhD,IAAyB,IAAbgD,EAAIjD,MAAY,IAAM,uDAAuDiD,EAAIjD,UAC7F,IAA6B,IAAjBgD,EAAQhD,MAAY,IAC5B,wDAAGgD,EAAQhD,UACQ,MAAnBH,GACA,IAAY,IAAWD,IAAM,IACzB,uEAAmBC,iBAA+BD,OAE1D,IAAYqD,EAAIhD,MAAM,KAAO+C,EAAQ/C,MAAM,IAAI,IAAM,oCAAoCgD,EAAIhD,MAAM,yCACrE+C,EAAQ/C,MAAM,QAC5C,IAAY,IAAyC6C,EAAQC,IAAW,IACpE,oEAAcD,mBAAwBC,OAC1C,IAA2B,QAAfvC,GAAsB,IAAM,sCAAsCA,2CAC9E,MAAM2C,EAAW,YAAQH,EAAS,CAAC,EAAGA,EAAQ/C,MAAM,GAAI+C,EAAQ/C,MAAM,GAAI+C,EAAQ/C,MAAM,KAClFmD,EAAU,YAAQH,EAAK,CAACA,EAAIhD,MAAM,GAAI,EAAGgD,EAAIhD,MAAM,GAAIgD,EAAIhD,MAAM,KACjEN,EAAU,CAAC,EAAGmD,GACdO,EAAY,CAAC,EAAGN,GAEhB7C,EAAM,YAAOkD,EAASD,EAAUxD,EAASC,EADtB,OAC6CyD,EAAWxD,GACjF,OAAIqD,EACO,YAAQhD,EAAK,CAACA,EAAID,MAAM,GAAIC,EAAID,MAAM,KAE1C,YAAQC,EAAK,CAACA,EAAID,MAAM,GAAIC,EAAID,MAAM,GAAIC,EAAID,MAAM,S,iCChE/D,6DA4BO,MAAMqD,EAAkB,YAAG,CAAEC,iBALpC,SAA0BrG,EAAGqD,EAAQiD,EAAa7D,EAASC,EAAKC,GAC5D,MAAMzC,EAAK,YAAgBF,EAAG,IAAK,mBAC7B8F,EAAU,YAAgBzC,EAAQ,SAAU,mBAClD,OAAO,YAAoBiD,EAAapG,EAAI4F,EAASrD,EAASC,EAAK,OAAQC,O,iCC1B/E,yEA0EO,MAAM4D,EAAe,YAAG,CAAEC,cAhBjC,SAAuBxG,EAAGyG,EAAWnD,EAAa,QAC9C,MAAMpD,EAAK,YAAgBF,EAAG,IAAK,gBAC7B0G,EAA8B,SAAfpD,EAAyBpD,EAAG6C,MAAM,GAAK7C,EAAG6C,MAAM,GAC/D4D,EAA6B,SAAfrD,EAAyBpD,EAAG6C,MAAM,GAAK7C,EAAG6C,MAAM,GAC9D6D,EAA6B,SAAftD,EAAyBpD,EAAG6C,MAAM,GAAK7C,EAAG6C,MAAM,GACpE,IAAY2D,EAAcD,GAAa,GAAG,IAAM,oEAC9CC,SAAmBD,6CACnBvG,EAAG6C,UACL,IAAY4D,EAAaF,GAAa,GAAG,IAAM,oEAC7CE,SAAkBF,gDACdvG,EAAG6C,UACT,IAAa6D,GAAcH,EAAYA,IAAe,GAAI,IAAM,8CAA8CA,EAAYA,YAAoBG,uCAAgD1G,EAAG6C,UACjM,MAAM3C,EAAS,CAAEJ,EAAGE,GACdG,EAAQ,CAAEoG,YAAWnD,cAC3B,OAAO,IAAOhD,UAAU,IAAcF,EAAQC,O,iCCxElD,gFA6EO,MAAMwG,EAAa,YAAG,CAAEC,YAxB/B,SAAqB9G,EAAGqD,EAAQZ,EAASC,EAAKyD,EAAY,CAAC,EAAG,GAAI7C,EAAa,QAC3E,MAAMpD,EAAK,YAAgBF,EAAG,IAAK,cAC7B8F,EAAU,YAAgBzC,EAAQ,SAAU,cAClD,IAAwB,IAAZnD,EAAG4C,MAA0B,IAAZ5C,EAAG4C,MAAY,IACxC,gEAAG5C,EAAG4C,UACV,IAA6B,IAAjBgD,EAAQhD,MAAY,IAC5B,4DAAGgD,EAAQhD,UACf,IAA2B,SAAfQ,GAAuB,IAC/B,gFAAyBA,MAC7B,IAAIV,EAAM1C,EACN2C,GAAe,EACH,IAAZ3C,EAAG4C,OACHF,EAAM,YAAQ1C,EAAI,CAAC,EAAGA,EAAG6C,MAAM,GAAI7C,EAAG6C,MAAM,GAAI7C,EAAG6C,MAAM,KACzDF,GAAe,GAEnB,MAAMzC,EAAS,CAAEJ,EAAG4C,EAAKS,OAAQyC,GAC3BzF,EAAQ,CAAEoC,UAASC,MAAKyD,aAExBnD,EAAM,IAAO1C,UAAU,IAAYF,EAAQC,GACjD,OAAIwC,EACO,YAAQG,EAAK,CAACA,EAAID,MAAM,GAAIC,EAAID,MAAM,GAAIC,EAAID,MAAM,KAExDC,M,iCC3EX,4FA+DO,MAAM+D,EAAW,YAAG,CAAEC,UAV7B,SAAmB/F,EAAGa,GAElB,IAAI6C,EAAK,YAAgB1D,EAAG,IAAK,OAC7B2D,EAAK,YAAgB9C,EAAG,IAAK,QAChC6C,EAAIC,GAAM,YAAeD,EAAIC,GAC9B,MAAMqC,EAAY,YAAItC,EAAIC,GACpBsC,EAAQ,YAAUD,GAClBE,EAAc,YAAMvC,EAAIsC,GAC9B,OAAO,YAAMC,EAAaD,EAAOD,O,iCC7DrC,0EAsEO,MAAMG,EAAM,YAAG,CAAEC,KAhCxB,SAAcC,EAAIC,GACd,MAAMC,EAAM,YAAgBF,EAAI,KAAM,OAChCG,EAAM,YAAgBF,EAAI,KAAM,OACtC,MAA0B,IAAbC,EAAI1E,MAA2B,IAAb0E,EAAI1E,MAA6B,IAAb2E,EAAI3E,MAA2B,IAAb2E,EAAI3E,OAAa,IAClF,+DAAG0E,EAAI1E,YAAY2E,EAAI3E,UAC3B,MAAM4E,EAAwB,IAAbF,EAAI1E,KAAa0E,EAAIG,KAAOH,EAAIzE,MAAM,GACjD6E,EAAwB,IAAbH,EAAI3E,KAAa2E,EAAIE,KAAOF,EAAI1E,MAAM,GAGvD,GAFA,IAAY2E,IAAYE,GAAS,IAC7B,gEAAGF,SAAeE,OACL,IAAbJ,EAAI1E,MAA2B,IAAb2E,EAAI3E,KAAY,CAClC,MAAM+E,EAAO,YAAQL,EAAK,CAAC,GAAI,IACzBM,EAAO,YAAQL,EAAK,EAAE,EAAG,IACzBM,EAAO,YAAOF,EAAMC,GAC1B,OAAO,YAAQC,EAAM,IAEpB,GAAiB,IAAbP,EAAI1E,MAA2B,IAAb2E,EAAI3E,KAAY,CACvC,MAAM+E,EAAO,YAAQL,EAAK,CAAC,GAAI,IACzBM,EAAO,YAAQL,EAAK,CAACA,EAAI1E,MAAM,GAAI0E,EAAI1E,MAAM,KAC7CgF,EAAO,YAAOF,EAAMC,GAC1B,OAAO,YAAQC,EAAM,CAACA,EAAKJ,OAE1B,GAAiB,IAAbH,EAAI1E,MAA2B,IAAb2E,EAAI3E,KAAY,CACvC,MAAMgF,EAAO,YAAQL,EAAK,EAAE,EAAG,IACzBM,EAAO,YAAOP,EAAKM,GACzB,OAAO,YAAQC,EAAM,CAACA,EAAKJ,OAE1B,CACD,MAAMG,EAAO,YAAQL,EAAK,CAACA,EAAI1E,MAAM,GAAI0E,EAAI1E,MAAM,KAEnD,OADa,YAAOyE,EAAKM,Q,qHCiB1B,MAAME,EAAY,YAAG,CAAEC,WAlC9B,SAAoBjI,EAAGkI,EAAMC,EAAUC,EAAQC,EAAOC,GAC3B,MAAnBA,IACAA,EAAkB,MAEtB,MAAMpI,EAAK,YAAgBF,EAAG,IAAK,aAC7BuI,EAAQ,YAAgBL,EAAM,OAAQ,aACtCM,EAAY,YAAgBL,EAAU,WAAY,aACxD,IAAIM,EAIAC,EAHS,MAATL,IACAI,EAAS,YAAgBJ,EAAO,QAAS,cAG/B,MAAVD,IACAM,EAAU,YAAgBN,EAAQ,SAAU,cAEhD,IAAYG,EAAMzF,OAAS0F,EAAU1F,MAAM,IAAM,iFAEjD,IAAuB,MAAX4F,GAAmBH,EAAMzF,OAAS4F,EAAQ5F,MAAM,IAAM,+EAElE,IAAsB,MAAV2F,GAAkBF,EAAMzF,OAAS2F,EAAO3F,MAAM,IAAM,8EAEhE,MACM1C,EAAS,CACXJ,ECvED,SAAeA,GAClB,IAAI4C,EAaJ,OAXIA,EADW,IAAX5C,EAAE8C,MAAyB,IAAX9C,EAAE8C,KACZ,OAAA6F,EAAA,GAAQ3I,EAAG,CAAC,EAAG,EAAG,EAAGA,EAAE2H,OAEb,IAAX3H,EAAE8C,KACD,OAAA6F,EAAA,GAAQ3I,EAAG,CAAC,EAAG,EAAGA,EAAE+C,MAAM,GAAI/C,EAAE+C,MAAM,KAE5B,IAAX/C,EAAE8C,KACD,OAAA6F,EAAA,GAAQ3I,EAAG,CAAC,EAAGA,EAAE+C,MAAM,GAAI/C,EAAE+C,MAAM,GAAI/C,EAAE+C,MAAM,KAG/C/C,EAEH4C,EDuDKgG,CAAM1I,GAGdmI,MAAOI,EACPL,OAAQM,EACRR,KAAMK,EACNJ,SAAUK,GAERnI,EAAQ,CAAEiI,mBAEVtF,EAAM,IAAO1C,UAAU,KAAgBF,EAAQC,GACrD,OAAO,OAAAsI,EAAA,GAAQ3F,EAAK9C,EAAG6C,W,iCEjF3B,kEAqCO,MAAM8F,EAAqC,YAAG,CAAEC,oCAjBvD,SAA6C3F,EAAQC,EAAIC,EAAQZ,EAASC,EAAKyD,EAAY,CAAC,EAAG,GAAIxD,GAC/F,IAAIa,EAAOJ,EACPP,GAAe,EACH,IAAZO,EAAGN,OACHD,GAAe,EACfW,EAAO,YAAQJ,EAAI,CAAC,EAAGA,EAAGL,MAAM,GAAIK,EAAGL,MAAM,GAAIK,EAAGL,MAAM,MAE9D,MAAM3C,EAAS,CAAEgD,GAAII,EAAMH,UACrBhD,EAAQ,CAAEoC,UAASC,MAAKC,kBAAiBwD,YAAWxC,WAAYR,GAChEH,EAEN,IAAO1C,UAAU,IAAoCF,EAAQC,GAC7D,OAAIwC,EACO,YAAQG,EAAK,CAACA,EAAID,MAAM,GAAIC,EAAID,MAAM,GAAIC,EAAID,MAAM,KAExDC,M,iCCnCX,kEAkCO,MAAM+F,EAAsC,YAAG,CAAEC,qCAdxD,SAA8ChJ,EAAGoD,EAAIU,EAAarB,EAASC,EAAKyD,EAAY,CAAC,EAAG,GAAIxD,GAChG,IAAIC,EAAM5C,EACK,IAAXA,EAAE8C,OACFF,EAAM,YAAQ5C,EAAG,CAAC,EAAGA,EAAE+C,MAAM,GAAI/C,EAAE+C,MAAM,GAAI/C,EAAE+C,MAAM,MAEzD,IAAIS,EAAOJ,EACO,IAAdI,EAAKV,OACLU,EAAO,YAAQJ,EAAI,CAAC,EAAGA,EAAGL,MAAM,GAAIK,EAAGL,MAAM,GAAIK,EAAGL,MAAM,MAE9D,MAAM3C,EAAS,CAAEJ,EAAG4C,EAAKQ,GAAII,GACvBnD,EAAQ,CAAEoC,UAASC,MAAKC,kBAAiBwD,YAAWrC,eAE1D,OAAO,IAAOxD,UAAU,IAAqCF,EAAQC,O,gCChCzE,0EAmDO,MAAM4I,EAAM,YAAG,CAAEC,KAPxB,SAAcjI,EAAGa,GACb,IAAI6C,EAAK,YAAgB1D,EAAG,IAAK,OAC7B2D,EAAK,YAAgB9C,EAAG,IAAK,QAChC6C,EAAIC,GAAM,YAAeD,EAAIC,GAC9B,MAAMxE,EAAS,CAAEa,EAAG0D,EAAI7C,EAAG8C,GAC3B,OAAO,IAAOtE,UAAU,IAAKF,O,gCCT1B,SAAS+I,EAAsBxF,EAAYG,EAAarB,EAASC,EAAKY,EAAa,OAAQ6C,GAQ9F,OAAOiD,EAAkBzF,EAFJ,IAAIG,EADHH,EAAW,IAGkBlB,EAAS0D,EAAWzD,EAAK,KAAyB,KADjF2G,EAAwB/F,IAGzC,SAASgG,EAAkB5I,EAAS8B,EAAYC,EAAS0D,EAAWzD,EAAK6G,EAAcjG,EAAa,gBACvG,MAAOkG,EAAcC,GAAeC,EAAgBlH,GACpD,IAAIsB,EACJ,GAAmB,iBAAfR,EACAQ,EAAc,CAAC0F,EAAcC,EAAa/I,EAAQ,GAAIA,EAAQ,QAE7D,IAAmB,kBAAf4C,EAIL,MAAM,IAAInD,MAAM,sBAAsBmD,KAHtCQ,EAAc,CAAC0F,EAAcC,EAAa/I,EAAQ,GAAIA,EAAQ,IAKlE,OAAO0I,EAAkB1I,EAASoD,EAAarB,EAAS0D,EAAWzD,EAAK6G,GAAc,EAAOjG,GAK1F,SAASqG,EAAkBjJ,EAAS8B,EAAYC,EAAS0D,EAAWzD,EAAK6G,EAAcjG,EAAa,SACvG,MAAOsG,EAAaJ,EAAcC,GAAeI,EAAiBrH,GAClE,IAAIsB,EACAgG,EACJ,GAAmB,UAAfxG,EACAwG,EAAc,eACdhG,EACI,CAAC8F,EAAaJ,EAAcC,EAAa/I,EAAQ,GAAIA,EAAQ,QAEhE,IAAmB,UAAf4C,EAML,MAAM,IAAInD,MAAM,sBAAsBmD,KALtCwG,EAAc,gBACdhG,EACI,CAAC8F,EAAaJ,EAAcC,EAAa/I,EAAQ,GAAIA,EAAQ,IAKrE,OAAOqJ,EAAkBrJ,EAASoD,EAAarB,EAAS0D,EAAWzD,GAAK,EAAOoH,EAAaP,GAMzF,SAASH,EAAkB1I,EAASoD,EAAarB,EAAS0D,EAAWzD,EAAK6G,EAAcS,GAAY,EAAO1G,EAAa,gBAC3H,IAAK2G,EAAWC,EAAUC,EAASC,GAAc,EAAE,GAAI,GAAI,GAAI,GAC/D,GAAmB,iBAAf9G,GACC2G,EAAWC,EAAUC,EAASC,GAAc1J,MAE5C,IAAmB,kBAAf4C,EAIL,MAAM,IAAInD,MAAM,sBAAsBmD,MAHrC2G,EAAWG,EAAYF,EAAUC,GAAWzJ,EAKjD,MAAO8I,EAAcC,EAAa,CAAEY,GAAkBvG,GAC/CwG,EAAcC,GAAeb,EAAgBjH,IAC7C+H,EAAgBC,GAAiBf,EAAgBvD,GAClDuE,EAAwBC,EAAuBnB,EAAcgB,GAC7DI,EAAuBD,EAAuBlB,EAAagB,IAC3D,QAAEI,EAAO,UAAEC,EAAS,SAAEC,GAkJhC,SAA0BrI,EAAKwH,EAAUC,EAASG,EAAcC,EAAaf,EAAcC,EAAaF,EAAcjG,GAClH,IAAIuH,EACAC,EACAC,EACJ,GAAmB,iBAARrI,EAAkB,CAEzBmI,EAAU,CAAEG,IAAKtI,EAAKuI,OAAQvI,EAAKwI,KAAMxI,EAAKyI,MAAOzI,EAAK0I,KADjC,IAAR1I,EAAa,QAAU,UAExC,MAAM/B,EA9Dd,SAA8BD,EAAS2K,EAAWzF,EAAQ0F,EAAS/B,GAChD,MAAX+B,IACAA,EAAUC,EAAkB7K,EAAS2K,EAAWzF,IAEpD,MAAM4F,EAAY9K,EAAQ,GACpB+K,EAAY/K,EAAQ,GACpBgL,EAAaC,GAAOH,EAAYH,EAAY,EAAIC,GAAW1F,EAAS,EAAG2D,GACvEqC,EAAaD,GAAOF,EAAYJ,EAAY,EAAIC,GAAW1F,EAAS,EAAG2D,GAC7E,MAAO,CAACmC,EAAYE,GAsDCC,CAAqB,CAAC3B,EAAUC,GAAUX,EAAcc,EAAc5H,EAAK6G,GAC5FuB,EAAYnK,EAAS,GACrBoK,EAAWpK,EAAS,QAEnB,GAAY,SAAR+B,EAAgB,CACrBoI,EAAYlJ,KAAKkK,KAAK5B,EAAWI,GACjCS,EAAWnJ,KAAKkK,KAAK3B,EAAUI,GAC/B,MAAMwB,EAAiBnK,KAAKC,IAAI,GAAIiJ,EAAY,GAAKR,EAAed,EAAeU,GAC7E8B,EAAgBpK,KAAKC,IAAI,GAAIkJ,EAAW,GAAKR,EAAcd,EAAcU,GACzEa,EAAMpJ,KAAKqK,MAAMF,EAAiB,GAClCd,EAASc,EAAiBf,EAC1BE,EAAOtJ,KAAKqK,MAAMD,EAAgB,GAExCnB,EAAU,CAAEG,MAAKC,SAAQC,OAAMC,MADjBa,EAAgBd,EACQE,KAAM,aAE3C,GAAY,UAAR1I,EACLmI,EAAU,CAAEG,IAAK,EAAGC,OAAQ,EAAGC,KAAM,EAAGC,MAAO,EAAGC,KAAM,SACxDN,EAAYlJ,KAAKkK,MAAM5B,EAAWV,EAAe,GAAKc,GACtDS,EAAWnJ,KAAKkK,MAAM3B,EAAUV,EAAc,GAAKc,OAElD,IAAmB,iBAAR7H,EAaZ,MAAMvC,MAAM,8BAA8BuC,KAbZ,CAC9B,MAAMsI,EAAqB,iBAAf1H,EAAgCZ,EAAI,GAAG,GAAKA,EAAI,GAAG,GACzDuI,EAAwB,iBAAf3H,EAAgCZ,EAAI,GAAG,GAAKA,EAAI,GAAG,GAC5DwI,EAAsB,iBAAf5H,EAAgCZ,EAAI,GAAG,GAAKA,EAAI,GAAG,GAC1DyI,EAAuB,iBAAf7H,EAAgCZ,EAAI,GAAG,GAAKA,EAAI,GAAG,GAIjEmI,EAAU,CAAEG,MAAKC,SAAQC,OAAMC,QAAOC,KAHb,IAARJ,GAAwB,IAAXC,GAAyB,IAATC,GAAwB,IAAVC,EACxD,QACA,YAEJL,EAAYa,GAAOzB,EAAWV,EAAewB,EAAMC,GAAUX,EAAe,EAAGf,GAC/EwB,EAAWY,GAAOxB,EAAUV,EAAcyB,EAAOC,GAASZ,EAAc,EAAGhB,IAK/E,MAAO,CAAEsB,UAASC,YAAWC,YA5LYmB,CAAiBxJ,EAAKwH,EAAUC,EAASG,EAAcC,EAAaG,EAAuBE,EAAsBrB,EAAcjG,GAClK6I,EAAcnC,EAAYK,EAAiBD,EAAaC,EAC9D,IAAI1J,EAOJ,MANmB,kBAAf2C,EACA3C,EAAW,CAACsJ,EAAWkC,EAAarB,EAAWC,GAE3B,iBAAfzH,IACL3C,EAAW,CAACsJ,EAAWa,EAAWC,EAAUoB,IAEzC,CACHlC,YACA3G,aACA4G,WACAC,UACAC,aACAU,YACAC,WACAoB,cACAtB,UACAP,eACAC,cACAf,eACAC,cACAiB,wBACAE,uBACAJ,iBACAC,gBACA/J,UACAC,WACAmD,eAOD,SAASiG,EAAkBrJ,EAASoD,EAAarB,EAAS0D,EAAWzD,EAAKsH,GAAY,EAAO1G,EAAa,eAAgBiG,GAC7H,IAAKU,EAAWxG,EAASyG,EAAUC,EAASC,GAAc,EAAE,GAAI,GAAI,GAAI,GAAI,GAC5E,GAAmB,iBAAf9G,GACC2G,EAAWxG,EAASyG,EAAUC,EAASC,GAAc1J,MAErD,IAAmB,kBAAf4C,EAIL,MAAM,IAAInD,MAAM,sBAAsBmD,MAHrC2G,EAAWG,EAAY3G,EAASyG,EAAUC,GAAWzJ,EAK1D,MAAOkJ,EAAaJ,EAAcC,EAAa,CAAEY,GAAkBvG,GAC5DsI,EAAa9B,EAAcC,GAAeV,EAAiBpH,IAC3D4J,EAAe7B,EAAgBC,GAAiBZ,EAAiB1D,GAClEmG,EAAuB3B,EAAuBf,EAAayC,GAC3D3B,EAAwBC,EAAuBnB,EAAcgB,GAC7DI,EAAuBD,EAAuBlB,EAAagB,IAC3D,QAAEI,EAAO,SAAEnH,EAAQ,UAAEoH,EAAS,SAAEC,GAyI1C,SAA4BrI,EAAKe,EAASyG,EAAUC,EAASiC,EAAa9B,EAAcC,EAAaX,EAAaJ,EAAcC,EAAaF,GACzI,IAAIsB,EACAnH,EACAoH,EACAC,EACJ,GAAmB,iBAARrI,EAAkB,CAEzBmI,EAAU,CACNG,IAAKtI,EACLuI,OAAQvI,EACRwI,KAAMxI,EACNyI,MAAOzI,EACP6J,MAAO7J,EACP8J,KAAM9J,EACN0I,KARqB,IAAR1I,EAAa,QAAU,UAUxC,MAAM/B,EAzGd,SAA8BD,EAAS2K,EAAWc,EAAavG,EAAQ0F,EAAS/B,GAC7D,MAAX+B,IACAA,EAAUC,EAAkB7K,EAAS2K,EAAWzF,IAEpD,MAAMgB,EAAalG,EAAQ,GACrB8K,EAAY9K,EAAQ,GACpB+K,EAAY/K,EAAQ,GACpB+L,EAAed,GAAO/E,EAAayE,EAAY,EAAIC,GAAW1F,EAAS,EAAG2D,GAC1EmC,EAAaC,GAAOH,EAAYH,EAAY,EAAIC,GAAW1F,EAAS,EAAG2D,GACvEqC,EAAaD,GAAOF,EAAYJ,EAAY,EAAIC,GAAW1F,EAAS,EAAG2D,GAC7E,MAAO,CAACkD,EAAcf,EAAYE,EAAYO,GA+FzBO,CAAqB,CAACjJ,EAASyG,EAAUC,EAAS,GAAIP,EAAa,EAAGwC,EAAa1J,EAAK6G,GACzG7F,EAAW/C,EAAS,GACpBmK,EAAYnK,EAAS,GACrBoK,EAAWpK,EAAS,QAEnB,GAAY,SAAR+B,EAAgB,CACrBgB,EAAW9B,KAAKkK,KAAKrI,EAAU2I,GAC/BtB,EAAYlJ,KAAKkK,KAAK5B,EAAWI,GACjCS,EAAWnJ,KAAKkK,KAAK3B,EAAUI,GAC/B,MAAMoC,GAAiBjJ,EAAW,GAAK0I,EAAcxC,EAAcnG,EAC7DsI,GAAkBjB,EAAY,GAAKR,EAAed,EAAeU,EACjE8B,GAAiBjB,EAAW,GAAKR,EAAcd,EAAcU,EAC7DoC,EAAQ3K,KAAKqK,MAAMU,EAAgB,GACnCH,EAAOG,EAAgBJ,EACvBvB,EAAMpJ,KAAKqK,MAAMF,EAAiB,GAClCd,EAASc,EAAiBf,EAC1BE,EAAOtJ,KAAKqK,MAAMD,EAAgB,GAExCnB,EAAU,CAAEG,MAAKC,SAAQC,OAAMC,MADjBa,EAAgBd,EACQqB,QAAOC,OAAMpB,KAAM,YAExD,IAAY,UAAR1I,EAeL,MAAMvC,MAAM,8BAA8BuC,KAd1CmI,EAAU,CACNG,IAAK,EACLC,OAAQ,EACRC,KAAM,EACNC,MAAO,EACPoB,MAAO,EACPC,KAAM,EACNpB,KAAM,SAEV1H,EAAW9B,KAAKkK,MAAMrI,EAAUmG,EAAc,GAAKwC,GACnDtB,EAAYlJ,KAAKkK,MAAM5B,EAAWV,EAAe,GAAKc,GACtDS,EAAWnJ,KAAKkK,MAAM3B,EAAUV,EAAc,GAAKc,GAKvD,MAAO,CAAEM,UAASnH,WAAUoH,YAAWC,YA9LY6B,CAAmBlK,EAAKe,EAASyG,EAAUC,EAASiC,EAAa9B,EAAcC,EAAa+B,EAAsB5B,EAAuBE,EAAsBrB,GAC5M4C,EAAcnC,EAAYK,EAAiBD,EAAaC,EAC9D,IAAI1J,EAOJ,MANmB,kBAAf2C,EACA3C,EAAW,CAACsJ,EAAWkC,EAAazI,EAAUoH,EAAWC,GAErC,iBAAfzH,IACL3C,EAAW,CAACsJ,EAAWvG,EAAUoH,EAAWC,EAAUoB,IAEnD,CACHlC,YACA3G,aACAG,UACAyG,WACAC,UACAC,aACA1G,WACAoH,YACAC,WACAoB,cACAtB,UACAuB,cACA9B,eACAC,cACAX,cACAJ,eACAC,cACA6C,uBACA5B,wBACAE,uBACAyB,gBACA7B,iBACAC,gBACA/J,UACAC,WACAmD,eAyBD,SAASyH,EAAkB5H,EAAY0H,EAAWzF,EAAQC,EAAW,GACxE,MAAMgH,EAAqBlC,EAAuBU,EAAWxF,GAC7D,OAAOjE,KAAKqK,OAAOtI,EAAW,IAAMiC,EAAS,GAAKA,EAASiH,GAAsB,GAErF,SAASnD,EAAgBoD,GACrB,MAAqB,iBAAVA,EACA,CAACA,EAAOA,EAAOA,GAEL,IAAjBA,EAAMjM,OACC,CAACiM,EAAM,GAAIA,EAAM,GAAI,GAEzBA,EAEX,SAASjD,EAAiBiD,GACtB,MAAwB,iBAAVA,EAAqB,CAACA,EAAOA,EAAOA,GAASA,EAa/D,SAASnC,EAAuBnI,EAAYqD,GACxC,OAAIA,GAAY,EACLrD,EAEJA,GAAcA,EAAa,IAAMqD,EAAW,GA2GvD,SAAS8F,EAAMoB,EAAOxD,GAClB,IAAKA,EACD,OAAO3H,KAAKoL,MAAMD,GAEtB,OAAQxD,GACJ,IAAK,QAED,OAAO3H,KAAK+J,MAAMoB,GACtB,IAAK,OAED,OAAOnL,KAAKkK,KAAKiB,GACrB,IAAK,QACD,OAAOnL,KAAKqK,MAAMc,GACtB,QACI,MAAM,IAAI5M,MAAM,wBAAwBoJ,MAG7C,SAAS0D,EAAkBH,GAC9B,MAAOI,EAAMC,EAAMC,GAAQ1D,EAAgBoD,GAC3C,OAAgB,IAATI,GAAuB,IAATC,GAAuB,IAATC,EAEhC,SAASC,EAA+B5K,EAAS0D,GACpD,OAAO8G,EAAkBxK,IAAYwK,EAAkB9G,GASpD,SAASkD,EAAwB/F,GACpC,GAAmB,SAAfA,EACA,MAAO,eAEN,GAAmB,SAAfA,EACL,MAAO,gBAGP,MAAM,IAAInD,MAAM,sBAAsBmD,KA5Y9C,mT,iCCAA,qDAgCO,MAAMgK,EAAW,YAAG,CAAEC,UAH7B,SAAmBC,EAASvL,GACxB,OAAO,YAAOuL,EAASvL,O,iCC9B3B,2JAwBA,IAAIwL,EA+IGC,eAAeC,EAASC,EAAKC,GAChC,IAAIC,EAAO,YAAgBF,EAAK,MAAO,YACvC,KAAMA,aAAe,KAAS,CAE1B,MAAMG,EAAoBD,EAC1BA,EAAO,YAAKC,EAAmB,SAC/BA,EAAkBC,UAEtB,GAAkB,IAAdF,EAAKhL,MAA4B,IAAdgL,EAAKhL,KACxB,MAAM,IAAI3C,MAAM,wDAAwD2N,EAAKhL,SAEjF,MAAOmL,EAAQC,GAASJ,EAAK/K,MAAMoL,MAAM,EAAG,GACtCC,EAAsB,IAAdN,EAAKhL,KAAa,EAAIgL,EAAK/K,MAAM,GAC/C,GAAIqL,EAAQ,GAAe,IAAVA,EACb,MAAM,IAAIjO,MACN,0DAAqBiO,KAE7B,GAAmB,YAAfN,EAAK7N,OAAsC,UAAf6N,EAAK7N,MACjC,MAAM,IAAIE,MAAM,kCAAkC2N,EAAK7N,+CAG3D,MAAMoO,QAAaP,EAAKO,OAClBC,EAA4B,YAAfR,EAAK7N,MAAsB,IAAM,EAC9CsO,EAAQ,IAAIC,kBAAkBN,EAAQD,EAAS,GACrD,IAAK,IAAIlN,EAAI,EAAGA,EAAIkN,EAASC,IAASnN,EAAG,CACrC,MAAM0N,EAAO,CAAC,EAAG,EAAG,EAAG,KACvB,IAAK,IAAIC,EAAI,EAAGA,EAAIN,EAAOM,IAAK,CAC5B,MAAM3B,EAAQsB,EAAKtN,EAAIqN,EAAQM,GAC/B,GAAmB,YAAfZ,EAAK7N,OACL,GAAI8M,EAAQ,GAAKA,EAAQ,EACrB,MAAM,IAAI5M,MACN,mFAAiC4M,WAGxC,GAAmB,UAAfe,EAAK7N,QACN8M,EAAQ,GAAKA,EAAQ,KACrB,MAAM,IAAI5M,MACN,mFAAmC4M,MAGjC,IAAVqB,GACAK,EAAK,GAAK1B,EAAQuB,EAClBG,EAAK,GAAK1B,EAAQuB,EAClBG,EAAK,GAAK1B,EAAQuB,GAGlBG,EAAKC,GAAK3B,EAAQuB,EAG1B,MAAMK,EAAQ,EAAJ5N,EACVwN,EAAMI,EAAI,GAAK/M,KAAK+J,MAAM8C,EAAK,IAC/BF,EAAMI,EAAI,GAAK/M,KAAK+J,MAAM8C,EAAK,IAC/BF,EAAMI,EAAI,GAAK/M,KAAK+J,MAAM8C,EAAK,IAC/BF,EAAMI,EAAI,GAAK/M,KAAK+J,MAAM8C,EAAK,IAEnC,GAAc,MAAVZ,EAAgB,CAChBA,EAAOK,MAAQA,EACfL,EAAOI,OAASA,EAChB,MAAMW,EAAMf,EAAOgB,WAAW,MACxBC,EAAY,IAAIC,UAAUR,EAAOL,EAAOD,GAC9CW,EAAII,aAAaF,EAAW,EAAG,GAKnC,OAHIhB,IAASF,GACTE,EAAKE,UAEFO,EAEJ,MAAMU,EAAa,YAAG,CAAEC,YA1L/B,SAAqBC,EAAQC,EAAc,GAEvC,GAAIA,EAAc,EACd,MAAM,IAAIjP,MAAM,kEAEpB,GAAc,MAAVgP,EACA,MAAM,IAAIhP,MAAM,4DAEpB,IAAIkP,GAAc,EACdC,GAAc,EACdC,GAAU,EACVC,GAAU,EACVC,GAAe,EACfC,GAAgB,EACpB,GAAIP,EAAOd,gBAAgBsB,WACvBN,GAAc,OAEb,GAA2B,oBAAhB,WAA+BF,aAAkBJ,UAC7DO,GAAc,OAEb,GAAkC,oBAAvB,kBACZH,aAAkBS,iBAClBL,GAAU,OAET,GAAkC,oBAAvB,kBACZJ,aAAkBU,iBAClBL,GAAU,OAGT,GAAyB,MAArBL,EAAON,WACZY,GAAe,MAEd,MAA6B,oBAAlB,aACZN,aAAkBW,aAIlB,MAAM,IAAI3P,MAIN,qPAAWgP,EAAOY,YAAYC,QAPlCN,GAAgB,EASpB,GAAIH,EAAS,CACT,MAAMU,EAAgC,EACtC,GAAIV,GACAJ,EAAOe,WACHD,EACJ,MAAM,IAAI9P,MAAM,yGAOxB,GAAc,MADC,YAAU,KAAY,IAAOgQ,aACxB,CAChB,MAAM/P,EAAS,CAAE+O,UACX9O,EAAQ,CAAE+O,eAChB,OAAO,IAAO9O,UAAU,KAAYF,EAAQC,GAEhD,MAAO6N,EAAOD,GAAUsB,EACpB,CACIJ,EAAOiB,WACPjB,EAAOkB,aAEX,CAAClB,EAAOjB,MAAOiB,EAAOlB,QAC1B,IAAIqC,EAkBAC,EACJ,GAlBId,EACAa,EAEInB,EAAON,WAAW,MAAM2B,aAAa,EAAG,EAAGtC,EAAOD,GAAQI,KAEzDiB,GAAeD,EACpBiB,EAAOnB,EAAOd,MAETmB,GAAWD,GAAWG,KACA,MAAvBjC,IACAA,EAAsBgD,SAASC,cAAc,UAAU7B,WAAW,OAEtEpB,EAAoBI,OAAOK,MAAQA,EACnCT,EAAoBI,OAAOI,OAASA,EACpCR,EAAoBkD,UAAUxB,EAAQ,EAAG,EAAGjB,EAAOD,GACnDqC,EAAO7C,EAAoB+C,aAAa,EAAG,EAAGtC,EAAOD,GAAQI,MAG7C,IAAhBe,EACAmB,EAAS,IAAIK,WAAWN,OAEvB,CACD,MAAMO,EAAY3C,EAAQD,EAC1BsC,EAAS,IAAIK,WAAWC,EAAYzB,GACpC,IAAK,IAAIrO,EAAI,EAAGA,EAAI8P,EAAW9P,IAC3B,IAAK,IAAI+P,EAAU,EAAGA,EAAU1B,IAAe0B,EAC3CP,EAAOxP,EAAIqO,EAAc0B,GAAWR,EAAS,EAAJvP,EAAQ+P,GAI7D,MAAMnQ,EAAW,CAACsN,EAAQC,EAAOkB,GACjC,OAAO,YAASmB,EAAQ5P,EAAU,a,iCClJtC,+EAiBO,SAASoQ,EAAuBC,EAAQ/O,GAC3C,MAAMa,EAAOkO,EAAO,GAAGnQ,OACvBmQ,EAAOC,SAAQ,CAAClO,EAAOhC,KACnB,IAAYgC,EAAMlC,SAAWiC,GAAM,IAAM,kBAAkBA,uBAA0B/B,gDACrD+B,UAEpC,IAAYb,GAAQ,GAAKA,EAAOa,GAAM,IAAM,kBAAkBA,kCAAqCA,EAAO,OAC1G,MAAMoO,EAAaF,EAAO,GAC1BA,EAAOC,SAAQ,CAAClO,EAAOhC,KACnB,IAAK,IAAIoQ,EAAI,EAAGA,EAAIrO,EAAMqO,IACtB,IAAaA,IAAMlP,GAAUc,EAAMoO,KAAOD,EAAWC,IAAK,IAAM,kBAAkBrO,wBAA2B/B,OAAOgC,4CACvEmO,sCACNnQ,UAI5C,SAASqQ,EAAgBJ,EAAQ/O,GACpC,MAAMqE,EAAc0K,EAAO,GAAG7C,QAC9B,IAAK,IAAIpN,EAAI,EAAGA,EAAIiQ,EAAOnQ,OAAQE,IAC/BuF,EAAYrE,IAAS+O,EAAOjQ,GAAGkB,GAEnC,OAAOqE,I,iCCdJ,SAAS+K,EAAY1N,EAAY2N,EAAYC,EAAMC,GAAe,GACrE,IAAIC,EAAW,GACf,GAAID,EACAC,EAAWA,EAASC,OAAOJ,EAAWnD,MAAM,IAC5CsD,EAASE,KAAKhO,EAAW,GAAK4N,GAC9BE,EAAWA,EAASC,OAAO/N,EAAWwK,MAAM,QAE3C,CACDsD,EAAWA,EAASC,OAAO/N,EAAW,IACtC,MAAMiO,EAAgBN,EAAWzQ,OACjC,IAAK,IAAIE,EAAI,EAAGA,EAAI6Q,IAAiB7Q,EACjC0Q,EACIA,EAASC,OAAO,CAAC/N,EAAW5C,EAAI,GAAKuQ,EAAWvQ,GAAIuQ,EAAWvQ,KAEvE0Q,EAAWA,EAASC,OAAO/N,EAAWwK,MAAMyD,EAAgB,IAEhE,OAAOH,EAWJ,SAASI,EAAYC,EAAcC,EAAgBP,GAAe,GACrE,MAAMQ,EAAW,GACjB,GAAIR,EAAc,CACdQ,EAASL,KAAKI,GACd,IAAK,IAAIhR,EAAIgR,EAAiB,EAAGhR,EAAI+Q,IAAgB/Q,EAC7CA,GAAK,EAAIgR,GACTC,EAASL,KAAK5Q,GACdiR,EAASL,KAAK5Q,GAAKgR,EAAiB,KAGpCC,EAASL,KAAK5Q,OAIrB,CACD,MAAMkR,EAAsB,GACtBC,EAAqB,GAC3B,IAAK,IAAInR,EAAI,EAAGA,EAAI+Q,IAAgB/Q,EAC5BA,GAAsB,EAAjBgR,EAAqB,GAAKhR,EAAI,GAAM,EACzCmR,EAAmBP,KAAK5Q,GAGxBkR,EAAoBN,KAAK5Q,GAGjCiR,EAASL,QAAQM,GACjBD,EAASL,KAAK,GACdK,EAASL,QAAQO,GAErB,OAAOF,EAWJ,SAASG,EAAoBxO,EAAY2N,EAAYC,EAAMC,GAAe,GAC7E,MAAMY,EAAmB,GACrBZ,EACAY,EAAiBT,KAAKhO,EAAW,GAAK4N,GAGtCa,EAAiBT,KAAKhO,EAAW,GAAK4N,GAE1C,IAAK,IAAIxQ,EAAI,EAAGA,EAAI4C,EAAW9C,SAAUE,EACjCA,GAAKuQ,EAAWzQ,OACZ2Q,EACAY,EAAiBT,KAAKL,EAAWvQ,EAAI,GAAK4C,EAAW5C,IAGrDqR,EAAiBT,KAAKhO,EAAW5C,GAAKuQ,EAAWvQ,EAAI,IAIzDqR,EAAiBT,KAAKhO,EAAW5C,IAGzC,OAAOqR,EAMJ,SAASC,EAAoBC,EAAOhB,GACvC,MAAMiB,EAAmB,CAAC,GAC1B,IAAK,IAAIxR,EAAI,EAAGA,EAAIuQ,IAAcvQ,EAC9BwR,EAAiBZ,KAAKW,EAAMvR,GAAG,IAEnC,OAAOwR,EAaJ,SAASC,EAAaC,EAAgBH,EAAOhB,GAChD,MAAMoB,EAAYD,EAAetE,MAAM,EAAG,GAC1C,IAAK,IAAIpN,EAAI,EAAGA,EAAIuQ,IAAcvQ,EAC9B2R,EAAUf,KAAKc,EAAe1R,EAAI,GAAKuR,EAAMvR,GAAG,GAAKuR,EAAMvR,GAAG,IAElE,OAAO2R,EA7IX,2K,iCCAA,4MAgBO,MAAMC,EAAQ,SACRC,EAAS,WACTC,GAAU,WACVC,EAAS,YACTC,GAAU,YACVC,EAAS,a,iCCrBtB,gFAiBO,SAASC,KAAQC,GACf,cAAMC,QAAQ,YACfC,QAAQH,QAAQC,GAGjB,SAASG,KAAOH,GACd,cAAMC,QAAQ,YACfC,QAAQC,OAAOH,K,iCCxBvB,kEAoCO,MAAMI,EAAO,YAAG,CAAEC,MALzB,SAAevT,GACX,MACMI,EAAS,CAAEJ,EADN,YAAgBA,EAAG,IAAK,SAEnC,OAAO,IAAOM,UAAU,IAAMF,O,iCClClC,kEAsCO,MAAMoT,EAAQ,YAAG,CAAEC,OAL1B,SAAgBzT,GACZ,MACMI,EAAS,CAAEJ,EADN,YAAgBA,EAAG,IAAK,UAEnC,OAAO,IAAOM,UAAU,IAAOF,O,iCCpCnC,2ZAoLO,MAAMsT,EAAY,YAAG,CAAEC,WA9I9B,SAAoB1S,EAAGa,GACnB,YAAgB,6EAEhB,MAAM6C,EAAK,YAAgB1D,EAAG,IAAK,aAC7B2D,EAAK,YAAgB9C,EAAG,IAAK,aAEnC,OADA,IAAuB6C,EAAG5B,MAAO6B,EAAG7B,MAAO,wBACpC,YAAI4B,EAAIC,MAyINgP,EAAY,YAAG,CAAEC,WA3E9B,SAAoB5S,EAAGa,GACnB,YAAgB,6EAEhB,MAAM6C,EAAK,YAAgB1D,EAAG,IAAK,OAC7B2D,EAAK,YAAgB9C,EAAG,IAAK,OAEnC,OADA,IAAuB6C,EAAG5B,MAAO6B,EAAG7B,MAAO,2BACpC,YAAI4B,EAAIC,MAsENkP,EAAgB,YAAG,CAAEC,eA5BlC,SAAwB9S,EAAGa,GACvB,YAAgB,6EAEhB,MAAM6C,EAAK,YAAgB1D,EAAG,IAAK,iBAC7B2D,EAAK,YAAgB9C,EAAG,IAAK,iBAEnC,OADA,IAAuB6C,EAAG5B,MAAO6B,EAAG7B,MAAO,4BACpC,YAAQ4B,EAAIC,MAuBVoP,EAAgB,YAAG,CAAEC,eA7ClC,SAAwBhT,EAAGa,GACvB,YAAgB,6EAEhB,MAAM6C,EAAK,YAAgB1D,EAAG,IAAK,iBAC7B2D,EAAK,YAAgB9C,EAAG,IAAK,iBAEnC,OADA,IAAuB6C,EAAG5B,MAAO6B,EAAG7B,MAAO,4BACpC,YAAQ4B,EAAIC,MAwCVsP,EAAY,YAAG,CAAEC,WA9D9B,SAAoBlT,EAAGa,GACnB,YAAgB,6EAEhB,MAAM6C,EAAK,YAAgB1D,EAAG,IAAK,aAC7B2D,EAAK,YAAgB9C,EAAG,IAAK,aAEnC,OADA,IAAuB6C,EAAG5B,MAAO6B,EAAG7B,MAAO,wBACpC,YAAI4B,EAAIC,MAyDNwP,EAAY,YAAG,CAAEC,WA/F9B,SAAoBpT,EAAGa,GACnB,YAAgB,6EAEhB,MAAM6C,EAAK,YAAgB1D,EAAG,IAAK,OAC7B2D,EAAK,YAAgB9C,EAAG,IAAK,OAEnC,OADA,IAAuB6C,EAAG5B,MAAO6B,EAAG7B,MAAO,6BACpC,YAAI4B,EAAIC,MA0FN0P,EAAY,YAAG,CAAEC,WAhH9B,SAAoBC,EAAMC,GAItB,OAHA,YAAgB,6EAEhB,IAAuBD,EAAKzR,MAAO0R,EAAI1R,MAAO,wBACvC,YAAIyR,EAAMC,MA6GRC,EAA0B,YAAG,CAAEC,yBAf5C,SAAkC1T,EAAGa,GACjC,YAAgB,6EAEhB,MAAM6C,EAAK,YAAgB1D,EAAG,IAAK,2BAC7B2D,EAAK,YAAgB9C,EAAG,IAAK,2BAEnC,OADA,IAAuB6C,EAAG5B,MAAO6B,EAAG7B,MAAO,sCACpC,YAAkB4B,EAAIC,MAUpBgQ,EAAY,YAAG,CAAEC,WApI9B,SAAoB5T,EAAGa,GACnB,YAAgB,6EAEhB,MAAM6C,EAAK,YAAgB1D,EAAG,IAAK,aAC7B2D,EAAK,YAAgB9C,EAAG,IAAK,aAEnC,OADA,IAAuB6C,EAAG5B,MAAO6B,EAAG7B,MAAO,wBACpC,YAAI4B,EAAIC,O,iCC9DnB,kEAoCO,MAAMkQ,EAAO,YAAG,CAAEC,MALzB,SAAe/U,GACX,MACMI,EAAS,CAAEJ,EADN,YAAgBA,EAAG,IAAK,SAEnC,OAAO,IAAOM,UAAU,IAAMF,O,iCClClC,kEAsCO,MAAM4U,EAAQ,YAAG,CAAEC,OAL1B,SAAgBjV,GACZ,MACMI,EAAS,CAAEJ,EADN,YAAgBA,EAAG,IAAK,UAEnC,OAAO,IAAOM,UAAU,IAAOF,O,iCCpCnC,kEAqCO,MAAM8U,EAAO,YAAG,CAAEC,MALzB,SAAenV,GACX,MACMI,EAAS,CAAEJ,EADN,YAAgBA,EAAG,IAAK,SAEnC,OAAO,IAAOM,UAAU,IAAMF,O,iCCnClC,kEAsCO,MAAMgV,EAAQ,YAAG,CAAEC,OAL1B,SAAgBrV,GACZ,MACMI,EAAS,CAAEJ,EADN,YAAgBA,EAAG,IAAK,UAEnC,OAAO,IAAOM,UAAU,IAAOF,O,iCCpCnC,kEAqCO,MAAM0L,EAAO,YAAG,CAAEwJ,MALzB,SAAetV,GACX,MACMI,EAAS,CAAEJ,EADN,YAAgBA,EAAG,IAAK,SAEnC,OAAO,IAAOM,UAAU,IAAMF,O,iCCnClC,yEA2CO,MAAMmV,EAAc,YAAG,CAAEC,aARhC,SAAsBxV,EAAGyV,EAAcC,GACnC,MAAMxV,EAAK,YAAgBF,EAAG,IAAK,eACnC,IAAayV,GAAgBC,GAAe,IAAM,uBAAuBD,yCACvCC,QAClC,MAAMtV,EAAS,CAAEJ,EAAGE,GACdG,EAAQ,CAAEoV,eAAcC,gBAC9B,OAAO,IAAOpV,UAAU,IAAaF,EAAQC,O,iCCzCjD,6RA4FO,MAAMsV,EAAc,YAAG,CAAEC,aAhChC,SAAsB3U,EAAGa,GACrB,YAAgB,6EAEhB,MAAM6C,EAAK,YAAgB1D,EAAG,IAAK,eAC7B2D,EAAK,YAAgB9C,EAAG,IAAK,eAEnC,OADA,YAAkB6C,EAAG5B,MAAO6B,EAAG7B,MAAO,0BAC/B,YAAM4B,EAAIC,MA2BRiR,EAAqB,YAAG,CAAEC,oBATvC,SAA6B7U,EAAGa,GAC5B,YAAgB,6EAEhB,MAAM6C,EAAK,YAAgB1D,EAAG,IAAK,sBAC7B2D,EAAK,YAAgB9C,EAAG,IAAK,sBAEnC,OADA,YAAkB6C,EAAG5B,MAAO6B,EAAG7B,MAAO,iCAC/B,YAAa4B,EAAIC,MAIfmR,EAAgB,YAAG,CAAEC,eAlBlC,SAAwB/U,EAAGa,GACvB,YAAgB,6EAEhB,MAAM6C,EAAK,YAAgB1D,EAAG,IAAK,iBAC7B2D,EAAK,YAAgB9C,EAAG,IAAK,iBAEnC,OADA,YAAkB6C,EAAG5B,MAAO6B,EAAG7B,MAAO,4BAC/B,YAAQ4B,EAAIC,MAaVqR,EAAkB,YAAG,CAAEC,iBA3BpC,SAA0BjV,EAAGa,GACzB,YAAgB,6EAEhB,MAAM6C,EAAK,YAAgB1D,EAAG,IAAK,mBAC7B2D,EAAK,YAAgB9C,EAAG,IAAK,mBAEnC,OADA,YAAkB6C,EAAG5B,MAAO6B,EAAG7B,MAAO,8BAC/B,YAAU4B,EAAIC,MAsBZuR,EAAa,YAAG,CAAEC,YA5C/B,SAAqBnV,EAAGa,GACpB,YAAgB,6EAEhB,MAAM6C,EAAK,YAAgB1D,EAAG,IAAK,cAC7B2D,EAAK,YAAgB9C,EAAG,IAAK,cAEnC,OADA,YAAkB6C,EAAG5B,MAAO6B,EAAG7B,MAAO,yBAC/B,YAAK4B,EAAIC,MAuCPyR,EAAiB,YAAG,CAAEC,gBA9DnC,SAAyBrV,EAAGa,GACxB,YAAgB,6EAEhB,MAAM6C,EAAK,YAAgB1D,EAAG,IAAK,kBAC7B2D,EAAK,YAAgB9C,EAAG,IAAK,kBAEnC,OADA,YAAkB6C,EAAG5B,MAAO6B,EAAG7B,MAAO,6BAC/B,YAAS4B,EAAIC,O,iCCzCxB,iFA4CO,MAAM2R,EAAM,YAAG,CAAEC,KATxB,SAAcxW,GACV,IAAIE,EAAK,YAAgBF,EAAG,IAAK,OACjC,IAAyB,UAAbE,EAAGD,OAAkC,YAAbC,EAAGD,OAAqB,IAAM,8CACjD,UAAbC,EAAGD,QACHC,EAAK,YAAKA,EAAI,YAElB,MAAME,EAAS,CAAEJ,EAAGE,GACpB,OAAO,IAAOI,UAAU,IAAKF,O,iCC1CjC,kEAsCO,MAAMqW,EAAQ,YAAG,CAAEC,OAL1B,SAAgB1W,GACZ,MACMI,EAAS,CAAEJ,EADN,YAAgBA,EAAG,IAAK,UAEnC,OAAO,IAAOM,UAAU,KAAOF,O,gCCpCnC,iFAgFO,MAAMsR,EAAS,YAAG,CAAEiF,QAlB3B,SAAiBnJ,EAASvL,EAAO,GAC7B,YAAOuL,EAAQ3M,QAAU,GAAG,IAAM,uCAClC,MAAM+V,EAAW,YAAqBpJ,EAAS,UAAW,SAAU,qBASpE,GAR0B,cAAtBoJ,EAAS,GAAG3W,OACZ2W,EAAS3F,SAAQ4F,IACb,GAAqB,cAAjBA,EAAO5W,MACP,MAAM,IAAIE,MAAM,4EACT0W,EAAO5W,cAIF,IAApB2W,EAAS/V,OACT,OAAO,YAAM+V,EAAS,IAE1B,MAAMxW,EAASwW,EACTE,EAAO,CAAE7U,QACf,OAAO,IAAO3B,UAAU,IAAQF,EAAQ0W,O,iCC9E5C,wFAkFO,MAAMC,EAAgB,YAAG,CAAEC,eAhClC,SAAwB5T,EAAI6T,EAAOzU,EAAYC,EAAS0D,EAAY,CAAC,EAAG,EAAG,GAAIzD,EAAKC,GAChF,MAAMuU,EAAM,YAAgB9T,EAAI,KAAM,iBAChC+T,EAAS,YAAgBF,EAAO,QAAS,iBAC/C,IAAIG,EAAOF,EACPG,EAAUF,EACVG,GAAe,EACC,IAAhBH,EAAOrU,OACPwU,GAAe,EACfF,EAAO,YAAQF,EAAK,CAAC,EAAGA,EAAInU,MAAM,GAAImU,EAAInU,MAAM,GAAImU,EAAInU,MAAM,GAAImU,EAAInU,MAAM,KAC5EsU,EAAU,YAAQF,EAAQ,CACtB,EAAGA,EAAOpU,MAAM,GAAIoU,EAAOpU,MAAM,GAAIoU,EAAOpU,MAAM,GAAIoU,EAAOpU,MAAM,MAG3E,IAA0B,IAAdqU,EAAKtU,MAAY,IACzB,0DAAGsU,EAAKtU,UACZ,IAA6B,IAAjBuU,EAAQvU,MAAY,IAC5B,6DAAGuU,EAAQvU,UACf,IAAY,IAAyCL,EAAS0D,IAAY,IACtE,8EAA0B1D,oBAA0B0D,OACjC,MAAnBxD,GACA,IAAY,IAAWD,IAAM,IACzB,8EAA0BC,iBAA+BD,OAEjE,MAAMtC,EAAS,CAAEgD,GAAIgU,EAAMH,MAAOI,GAC5BhX,EAAQ,CAAEmC,aAAYC,UAAS0D,YAAWzD,MAAKC,mBAE/CK,EAAM,IAAO1C,UAAU,IAAeF,EAAQC,GACpD,OAAIiX,EACO,YAAQtU,EAAK,CAACA,EAAID,MAAM,GAAIC,EAAID,MAAM,GAAIC,EAAID,MAAM,GAAIC,EAAID,MAAM,KAEtEC,M,iCChFX,gFAgEO,MAAMuU,EAAc,YAAG,CAAEC,aA1BhC,SAAsBpU,EAAI6T,EAAOzU,EAAYC,EAASC,GAClD,MAAMwU,EAAM,YAAgB9T,EAAI,KAAM,eAChC+T,EAAS,YAAgBF,EAAO,QAAS,eAC/C,IAAYE,EAAOrU,OAASoU,EAAIpU,MAAM,IAAM,kBAAkBqU,EAAOrU,oCAAoCoU,EAAIpU,UAC7G,IAAIoD,EAAUiR,EACV3T,EAAO0T,EACPrU,GAAe,EACC,IAAhBsU,EAAOrU,OACPD,GAAe,EACfqD,EACI,YAAQiR,EAAQ,CAAC,EAAGA,EAAOpU,MAAM,GAAIoU,EAAOpU,MAAM,GAAIoU,EAAOpU,MAAM,KACvES,EAAO,YAAQ0T,EAAK,CAAC,EAAGA,EAAInU,MAAM,GAAImU,EAAInU,MAAM,GAAImU,EAAInU,MAAM,MAElE,IAA0B,IAAdS,EAAKV,MAAY,IACzB,wDAAGU,EAAKV,UACZ,IAA6B,IAAjBoD,EAAQpD,MAAY,IAC5B,2DAAGoD,EAAQpD,UACf,MAAM1C,EAAS,CAAEgD,GAAII,EAAMyT,MAAO/Q,GAC5B7F,EAAQ,CAAEmC,aAAYC,UAASC,OAE/BM,EAAM,IAAO1C,UAAU,IAAaF,EAAQC,GAClD,OAAIwC,EACO,YAAQG,EAAK,CAACA,EAAID,MAAM,GAAIC,EAAID,MAAM,GAAIC,EAAID,MAAM,KAExDC,M,iCC9DX,yEAuEO,MAAMyU,EAAsB,YAAG,CAAEC,qBAhCxC,SAA8BvU,EAAQC,EAAIC,EAAQZ,EAASC,GACvD,IAAYS,EAAOtC,SAAWuC,EAAGN,MAAM,IACnC,sBAAIK,EAAOtC,2BAA2BuC,EAAGN,qBAC7C,IAAI6U,EAAWxU,EACXiU,EAAOhU,EACPkU,GAAe,EACH,IAAZlU,EAAGN,OACHwU,GAAe,EACfF,EAAO,YAAQhU,EAAI,CAAC,EAAGA,EAAGL,MAAM,GAAIK,EAAGL,MAAM,GAAIK,EAAGL,MAAM,GAAIK,EAAGL,MAAM,KACvE4U,EAAW,CAAC,EAAGxU,EAAO,GAAIA,EAAO,GAAIA,EAAO,GAAIA,EAAO,KAE3D,MAAMM,EAAUkU,EAAS,GACnBjU,EAAW0T,EAAKrU,MAAM,GAC5B,IAAgC,IAApB4U,EAAS9W,QAAc,IAC/B,qEAAG8W,EAAS9W,YAChB,IAA0B,IAAduW,EAAKtU,MAAY,IACzB,4DAAQsU,EAAKtU,SACjB,IAA4B,IAAhBO,EAAOP,MAAY,IAC3B,gEAAQO,EAAOP,SACnB,IAAYW,IAAYJ,EAAON,MAAM,IAAI,IAAM,4CAA4CU,wCACvDJ,EAAON,MAAM,QACjD,IAAYW,IAAaL,EAAON,MAAM,IAAI,IAAM,6CAA6CW,yCACxDL,EAAON,MAAM,QAClD,MAAM3C,EAAS,CAAEgD,GAAIgU,EAAM/T,UACrBhD,EAAQ,CAAEqC,MAAKD,UAASkB,WAAYgU,GAEpC3U,EAAM,IAAO1C,UAAU,IAAuBF,EAAQC,GAC5D,OAAIiX,EACO,YAAQtU,EAAK,CAACA,EAAID,MAAM,GAAIC,EAAID,MAAM,GAAIC,EAAID,MAAM,GAAIC,EAAID,MAAM,KAEtEC,M,iCCrEX,yEA6DO,MAAM4U,EAAuB,YAAG,CAAEC,sBAxBzC,SAA+B7X,EAAGoD,EAAIU,EAAarB,EAASC,GACxD,IAAIoV,EAAM9X,EACK,IAAXA,EAAE8C,OACFgV,EAAM,YAAQ9X,EAAG,CAAC,EAAGA,EAAE+C,MAAM,GAAI/C,EAAE+C,MAAM,GAAI/C,EAAE+C,MAAM,GAAI/C,EAAE+C,MAAM,MAErE,IAAIqU,EAAOhU,EACO,IAAdgU,EAAKtU,OACLsU,EAAO,YAAQhU,EAAI,CAAC,EAAGA,EAAGL,MAAM,GAAIK,EAAGL,MAAM,GAAIK,EAAGL,MAAM,GAAIK,EAAGL,MAAM,MAE3E,IAAyB,IAAb+U,EAAIhV,MAAY,IACxB,iEAAGgV,EAAI/U,WACX,IAA0B,IAAdqU,EAAKtU,MAAY,IACzB,8DAAGsU,EAAKrU,WACZ,IAAmC,IAAvBe,EAAYjD,QAAc,IAClC,mEAAGiD,OACP,IAAYgU,EAAI/U,MAAM,KAAOe,EAAY,IAAI,IAAM,4CAA4CgU,EAAI/U,MAAM,yCACrEe,EAAY,QAChD,IAAYsT,EAAKrU,MAAM,KAAOe,EAAY,IAAI,IAAM,0CAA0CsT,EAAKrU,MAAM,2CACnEe,EAAY,SAClD,MAAM1D,EAAS,CAAEJ,EAAG8X,EAAK1U,GAAIgU,GACvB/W,EAAQ,CAAEoC,UAASC,MAAKoB,eAE9B,OAAO,IAAOxD,UAAU,IAAwBF,EAAQC,O,gCC3D5D,kEAqCO,MAAMoU,EAAM,YAAG,CAAEsD,KALxB,SAAc/X,GACV,MACMI,EAAS,CAAEJ,EADN,YAAgBA,EAAG,IAAK,QAEnC,OAAO,IAAOM,UAAU,IAAKF,O,gCCnCjC,2RAqBO,SAAS4X,EAAqBC,EAAMnV,GACvC,IAAK,IAAI/B,EAAI,EAAGA,EAAIkX,EAAKpX,SAAUE,EAC/B,GAAIkX,EAAKA,EAAKpX,OAASE,EAAI,KAAO+B,EAAO,EAAI/B,EACzC,OAAO,EAGf,OAAO,EAEJ,SAASmX,EAAiBC,EAAWC,EAAWH,GACnD,MAAMnV,EAAOqV,EAAUtX,OAASuX,EAAUvX,OACpCwX,EAAM,GACZ,IAAIC,EAAS,EACTC,EAAY,EAChB,IAAK,IAAIvX,EAAM,EAAGA,EAAM8B,EAAM9B,KACC,IAAvBiX,EAAKO,QAAQxX,GACbqX,EAAI1G,KAAKwG,EAAUG,MAGnBD,EAAI1G,KAAKyG,EAAUG,MAG3B,OAAOF,EAEJ,SAASI,EAA0BC,EAAQT,GAC9C,MAAMtX,EAAW,GACXmC,EAAO4V,EAAO7X,OACpB,IAAK,IAAIG,EAAM,EAAGA,EAAM8B,EAAM9B,KACC,IAAvBiX,EAAKO,QAAQxX,IACbL,EAASgR,KAAK+G,EAAO1X,IAI7B,MAAO,CAACL,EADYsX,EAAKU,KAAI3X,GAAO0X,EAAO1X,MAGxC,SAAS4X,EAAqB7V,EAAOkV,GAExC,OAAOC,EAAiBnV,EADDkV,EAAKU,KAAI3Y,GAAK,IACUiY,GAE5C,SAASY,EAA2B3F,EAAK+E,EAAMnV,GAClD,IAAYkV,EAAqBC,EAAMnV,IAAO,IAAM,GAAGoQ,qDACvC+E,cAAiBnV,aAO9B,SAASgW,EAAmBb,EAAMnV,GACrC,GAAIkV,EAAqBC,EAAMnV,GAC3B,OAAO,KAEX,MAAM1B,EAAS,GACf,IAAK,IAAIL,EAAI,EAAGA,EAAI+B,IAAQ/B,GACC,IAArBkX,EAAKO,QAAQzX,IACbK,EAAOuQ,KAAK5Q,GAIpB,OADAkX,EAAKhH,SAAQhP,GAAQb,EAAOuQ,KAAK1P,KAC1Bb,EAGJ,SAAS2X,EAAuBd,GACnC,OAAOA,EAAKU,KAAI,CAAC1W,EAAMlB,IAAM,CAACA,EAAGkB,KAC5B+W,MAAK,CAAC/X,EAAGa,IAAMb,EAAE,GAAKa,EAAE,KACxB6W,KAAI3Y,GAAKA,EAAE,KAEb,SAASiZ,EAAiBC,EAASpW,GACtC,MAAME,EAAM,GACZ,IAAK,IAAIjC,EAAI+B,EAAOoW,EAASnY,EAAI+B,IAAQ/B,EACrCiC,EAAI2O,KAAK5Q,GAEb,OAAOiC,I,gCC5FX,kEA2CO,MAAMmW,EAAM,YAAG,CAAEC,KAXxB,SAAcpZ,GACV,MAAME,EAAK,YAAgBF,EAAG,IAAK,OACnC,GAAiB,cAAbE,EAAGD,MAAuB,CAC1B,MAAMG,EAAS,CAAEJ,EAAGE,GACpB,OAAO,IAAOI,UAAU,IAAYF,GAEnC,CACD,MAAMA,EAAS,CAAEJ,EAAGE,GACpB,OAAO,IAAOI,UAAU,IAAKF,Q,gCCxCrC,yEAiDO,MAAMiZ,EAAU,YAAG,CAAEC,SAR5B,SAAkBC,EAAMC,GACpB,MAAMC,EAAQ,YAAgBF,EAAM,OAAQ,WACtCG,EAAQ,YAAgBF,EAAM,OAAQ,WAC5C,IAAuBC,EAAM1W,MAAO2W,EAAM3W,MAAO,yBAAyB0W,EAAM1W,aAAa2W,EAAM3W,8CAEnG,MAAM3C,EAAS,CAAEmZ,KAAME,EAAOD,KAAME,GACpC,OAAO,IAAOpZ,UAAU,IAASF,O,gCC/CrC,yEA4CO,MAAMuZ,EAAa,YAAG,CAAEC,YAP/B,SAAqB5Z,EAAGiC,EAAO,GAC3B,MAAM/B,EAAK,YAAgBF,EAAG,IAAK,aAAc,qBACjD,IAAYiC,GAAQ/B,EAAG4C,MAAM,IAAM,uCACnC,MAAM1C,EAAS,CAAE6W,MAAO/W,GAClBG,EAAQ,CAAEW,IAAKiB,GACrB,OAAO,IAAO3B,UAAU,IAAYF,EAAQC,O,gCC1ChD,wFAqFO,MAAMwZ,EAAS,YAAG,CAAEC,QA9B3B,SAAiB9Z,EAAGqD,EAAQZ,EAASC,EAAKY,EAAa,OAAQ6C,EAAY,CAAC,EAAG,GAAIxD,GAC/E,MAAMzC,EAAK,YAAgBF,EAAG,IAAK,UAC7B8F,EAAU,YAAgBzC,EAAQ,SAAU,UAClD,IAAIT,EAAM1C,EACN2C,GAAe,EACH,IAAZ3C,EAAG4C,OACHD,GAAe,EACfD,EAAM,YAAQ1C,EAAI,CAAC,EAAGA,EAAG6C,MAAM,GAAI7C,EAAG6C,MAAM,GAAI7C,EAAG6C,MAAM,MAE7D,IAAyB,IAAbH,EAAIE,MAAY,IAAM,uDAAuDF,EAAIE,UAC7F,IAA6B,IAAjBgD,EAAQhD,MAAY,IAC5B,wDAAGgD,EAAQhD,UACQ,MAAnBH,GACA,IAAY,IAAWD,IAAM,IACzB,uEAAmBC,iBAA+BD,OAE1D,MAAMe,EAAyB,SAAfH,EAAwBV,EAAIG,MAAM,GAAKH,EAAIG,MAAM,GACjE,IAAYU,IAAYqC,EAAQ/C,MAAM,IAAI,IAAM,oCAAoCU,wCACtDqC,EAAQ/C,MAAM,QAC5C,IAAY,IAAyCN,EAAS0D,IAAY,IACtE,uEAAe1D,oBAA0B0D,OAC7C,MAAM/F,EAAS,CAAEJ,EAAG4C,EAAKS,OAAQyC,GAC3BzF,EAAQ,CAAEoC,UAASC,MAAKY,aAAY6C,YAAWxD,mBAE/CK,EAAM,IAAO1C,UAAU,IAAQF,EAAQC,GAC7C,OAAIwC,EACO,YAAQG,EAAK,CAACA,EAAID,MAAM,GAAIC,EAAID,MAAM,GAAIC,EAAID,MAAM,KAExDC,M,gCCnFX,kEAyCO,MAAM+W,EAAQ,YAAG,CAAEC,OAP1B,SAAgBha,GACZ,MACMI,EAAS,CAAEJ,EADN,YAAgBA,EAAG,IAAK,QAAS,sBAI5C,OAAO,IAAOM,UAAU,KAAUF,O,gCCvCtC,gFAgGO,MAAM6Z,EAAkB,YAAG,CAAEC,iBA7BpC,SAA0Bla,EAAGqD,EAAQZ,EAASC,EAAKY,EAAa,OAAQ6C,EAAY,CAAC,EAAG,GAAIxD,GACxF,MAAMzC,EAAK,YAAgBF,EAAG,IAAK,mBAC7B8F,EAAU,YAAgBzC,EAAQ,SAAU,mBAClD,IAAIT,EAAM1C,EACN2C,GAAe,EACH,IAAZ3C,EAAG4C,OACHD,GAAe,EACfD,EAAM,YAAQ1C,EAAI,CAAC,EAAGA,EAAG6C,MAAM,GAAI7C,EAAG6C,MAAM,GAAI7C,EAAG6C,MAAM,MAE7D,IAAyB,IAAbH,EAAIE,MAAY,IACxB,gEAAQF,EAAIE,UAChB,IAA6B,IAAjBgD,EAAQhD,MAAY,IAC5B,iEAAGgD,EAAQhD,UACf,IAAYF,EAAIG,MAAM,KAAO+C,EAAQ/C,MAAM,IAAI,IAC3C,uDAAIH,EAAIG,MAAM,qDACJ+C,EAAQ/C,MAAM,QACL,MAAnBJ,GACA,IAAY,IAAWD,IAAM,IACzB,gFAAmBC,iBAA+BD,OAE1D,MAAMtC,EAAS,CAAEJ,EAAG4C,EAAKS,OAAQyC,GAC3BzF,EAAQ,CAAEoC,UAASC,MAAKY,aAAY6C,YAAWxD,mBAE/CK,EAAM,IAAO1C,UAAU,IAAuBF,EAAQC,GAC5D,OAAIwC,EACO,YAAQG,EAAK,CAACA,EAAID,MAAM,GAAIC,EAAID,MAAM,GAAIC,EAAID,MAAM,KAExDC,M,gCC9FX,kFA6CO,MAAMmX,EAAQ,YAAG,CAAEC,OAR1B,SAAgBnZ,EAAGa,GACf,IAAI6C,EAAK,YAAgB1D,EAAG,IAAK,SAC7B2D,EAAK,YAAgB9C,EAAG,IAAK,UAChC6C,EAAIC,GAAM,YAAeD,EAAIC,GAC9B,YAA2BD,EAAG5B,MAAO6B,EAAG7B,OACxC,MAAM3C,EAAS,CAAEa,EAAG0D,EAAI7C,EAAG8C,GAC3B,OAAO,IAAOtE,UAAU,IAAOF,O,gCC3CnC,oDA4CO,SAASia,EAAOtX,EAAO9C,EAAQ,UAAWsQ,GAG7C,OAFAtQ,EAAQA,GAAS,UACjB,IAAwC8C,GACjC,IAAI,IAAaA,EAAO9C,EAAOsQ,K,gCC/C1C,yEAgFO,MAAM+J,EAAiB,YAAG,CAAEC,gBAXnC,SAAyBva,EAAGsR,EAAYgB,GACpC,MAAMpS,EAAK,YAAgBF,EAAG,IAAK,kBAC7BuR,EAAOD,EAAWkJ,QAAO,CAACvZ,EAAGa,IAAMb,EAAIa,IAC7C,IAAY5B,EAAG4C,MAAQ,EAAIwO,EAAWzQ,QAAQ,IAAM,iBAAiBX,EAAG4C,+CAA+CwO,EAAWzQ,WAClI,IAAYyR,EAAMzR,SAAWyQ,EAAWzQ,QAAQ,IAAM,mBAAmByR,EAAMzR,oDAAoDyQ,EAAWzQ,WAC9I,IAAYX,EAAG6C,MAAM,GAAKwO,GAAS,GAAG,IAAM,yBAAyBrR,EAAG6C,MAAM,wEAC5CuO,EAAWmJ,KAAK,cAAclJ,MAChE,MAAMnR,EAAS,CAAEJ,EAAGE,GACdG,EAAQ,CAAEiR,aAAYgB,SAC5B,OAAO,IAAOhS,UAAU,IAAgBF,EAAQC,O,gCC9EpD,iFAuEO,MAAMqa,EAAc,YAAG,CAAEC,aAnChC,SAAsB3a,EAAG+C,GACrB,IAAIkU,EAAQ,YAAgBjX,EAAG,cAAe,KAC9C,MAAMmD,EAAS8T,EAAMlU,MACrB,GAAIA,EAAM6X,MAAKlM,KAAOA,EAAI,IAAMA,EAAI,GAAM,IACtC,MAAM,IAAIvO,MAAM,2CAA2C4C,OAE/D,GAAIA,EAAMlC,OAASoW,EAAMnU,KACrB,MAAM,IAAI3C,MAAM,+BAA+B4C,EAAMlC,uBAAuBoW,EAAMnU,SAEtF,GAAIC,EAAMlC,OAASoW,EAAMnU,KAAM,CAC3B,MAAM+X,EAAW5D,EAAMlU,MAAMoL,QAC7B,KAAO0M,EAASha,OAASkC,EAAMlC,QAC3Bga,EAAS3Z,QAAQ,GAErB+V,EAAQ,YAAQA,EAAO4D,GAE3B,MAAMlX,EAAasT,EAAMlU,MACnB+X,EAAOC,MAAMC,KAAKjY,GACxB,IAAK,IAAIhC,EAAIgC,EAAMlC,OAAS,EAAGE,GAAK,EAAGA,IACnC,GAAI4C,EAAW5C,KAAOgC,EAAMhC,GACxB+Z,EAAK/Z,GAAK,OAET,GAAuB,IAAnBkW,EAAMlU,MAAMhC,GACjB,MAAM,IAAIZ,MAAM,mBAAmBgD,8BAAmCJ,OAI9E,GAAoB,IADP+X,EAAKnC,KAAI,CAACtU,EAAGtD,IAAMsD,EAAI,EAAItD,GAAK,IAAGsC,QAAOtC,GAAKA,GAAK,IACxDF,OACL,OAAO,YAAMoW,GAGjB,MAAM7W,EAAS,CAAEJ,EAAGiX,GACd5W,EAAQ,CAAEya,QAChB,OAAO,IAAOxa,UAAU,KAAMF,EAAQC","file":"js/bundle~bundle~a1212309.cc17a678.js","sourcesContent":["/**\n * @license\n * Copyright 2020 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Cast } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport * as util from '../util';\nimport { op } from './operation';\n/**\n * Casts a `tf.Tensor` to a new dtype.\n *\n * ```js\n * const x = tf.tensor1d([1.5, 2.5, 3]);\n * tf.cast(x, 'int32').print();\n * ```\n * @param x The input tensor to be casted.\n * @param dtype The dtype to cast the input tensor to.\n *\n * @doc {heading: 'Tensors', subheading: 'Transformations'}\n */\nfunction cast_(x, dtype) {\n    const $x = convertToTensor(x, 'x', 'cast');\n    // Sanity checks.\n    if (!util.isValidDtype(dtype)) {\n        throw new Error(`Failed to cast to unknown dtype ${dtype}`);\n    }\n    if (dtype === 'string' && $x.dtype !== 'string' ||\n        dtype !== 'string' && $x.dtype === 'string') {\n        throw new Error('Only strings can be casted to strings');\n    }\n    const inputs = { x: $x };\n    const attrs = { dtype };\n    return ENGINE.runKernel(Cast, inputs, attrs);\n}\nexport const cast = op({ cast_ });\n//# sourceMappingURL=cast.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Elu } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes exponential linear element-wise: `x > 0 ? e ^ x - 1 : 0`.\n *\n * ```js\n * const x = tf.tensor1d([-1, 1, -3, 2]);\n *\n * x.elu().print();  // or tf.elu(x)\n * ```\n * @param x The input tensor.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction elu_(x) {\n    const $x = convertToTensor(x, 'x', 'elu');\n    const inputs = { x: $x };\n    return ENGINE.runKernel(Elu, inputs);\n}\nexport const elu = op({ elu_ });\n//# sourceMappingURL=elu.js.map","/**\n * @license\n * Copyright 2017 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n/**\n * Returns the dimensions in the input shape that are broadcasted to\n * produce the provided output shape.\n *\n * The returned dimensions are 0-indexed and sorted. An example:\n * inShape = [4, 1, 3]\n * outShape = [5, 4, 3, 3]\n * result = [1]. Dimension 1 (2nd dimension of input) gets broadcasted 1 => 3.\n */\nexport function getBroadcastDims(inShape, outShape) {\n    const inRank = inShape.length;\n    const dims = [];\n    for (let i = 0; i < inRank; i++) {\n        const dim = inRank - 1 - i;\n        const a = inShape[dim] || 1;\n        const b = outShape[outShape.length - 1 - i] || 1;\n        if (b > 1 && a === 1) {\n            dims.unshift(dim);\n        }\n    }\n    return dims;\n}\n/**\n * Returns the axes in the output space that should be reduced to produce\n * the input space.\n */\nexport function getReductionAxes(inShape, outShape) {\n    const result = [];\n    for (let i = 0; i < outShape.length; i++) {\n        const inDim = inShape[inShape.length - i - 1];\n        const outAxis = outShape.length - i - 1;\n        const outDim = outShape[outAxis];\n        if (inDim == null || (inDim === 1 && outDim > 1)) {\n            result.unshift(outAxis);\n        }\n    }\n    return result;\n}\nexport function assertAndGetBroadcastShape(shapeA, shapeB) {\n    const result = [];\n    const l = Math.max(shapeA.length, shapeB.length);\n    for (let i = 0; i < l; i++) {\n        let a = shapeA[shapeA.length - i - 1];\n        if (a == null) {\n            a = 1;\n        }\n        let b = shapeB[shapeB.length - i - 1];\n        if (b == null) {\n            b = 1;\n        }\n        if (a === 1) {\n            result.unshift(b);\n        }\n        else if (b === 1) {\n            result.unshift(a);\n        }\n        else if (a !== b) {\n            const errMsg = `Operands could not be broadcast together with shapes ` +\n                `${shapeA} and ${shapeB}.`;\n            throw Error(errMsg);\n        }\n        else {\n            result.unshift(a);\n        }\n    }\n    return result;\n}\n//# sourceMappingURL=broadcast_util.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Cumsum } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes the cumulative sum of a `tf.Tensor` along `axis`.\n *\n * ```js\n * const x = tf.tensor([1, 2, 3, 4]);\n * x.cumsum().print();\n * ```\n * ```js\n * const x = tf.tensor([[1, 2], [3, 4]]);\n * x.cumsum().print();\n * ```\n *\n * @param x The input tensor to be summed.\n * @param axis The axis along which to sum. Optional. Defaults to 0.\n * @param exclusive Whether to perform exclusive cumulative sum. Optional.\n *     Defaults to false. If set to true then the sum of each tensor entry\n *     does not include its own value, but only the values previous to it\n *     along the specified axis.\n * @param reverse Whether to sum in the opposite direction. Optional.\n *     Defaults to false.\n *\n * @doc {heading: 'Operations', subheading: 'Scan'}\n */\nfunction cumsum_(x, axis = 0, exclusive = false, reverse = false) {\n    const $x = convertToTensor(x, 'x', 'cumsum');\n    const inputs = { x: $x };\n    const attrs = { axis, exclusive, reverse };\n    return ENGINE.runKernel(Cumsum, inputs, attrs);\n}\nexport const cumsum = op({ cumsum_ });\n//# sourceMappingURL=cumsum.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Cos } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes cos of the input `tf.Tensor` element-wise: `cos(x)`\n *\n * ```js\n * const x = tf.tensor1d([0, Math.PI / 2, Math.PI * 3 / 4]);\n *\n * x.cos().print();  // or tf.cos(x)\n * ```\n * @param x The input tensor.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction cos_(x) {\n    const $x = convertToTensor(x, 'x', 'cos');\n    const inputs = { x: $x };\n    return ENGINE.runKernel(Cos, inputs);\n}\nexport const cos = op({ cos_ });\n//# sourceMappingURL=cos.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { AvgPool } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport * as util from '../util';\nimport { cast } from './cast';\nimport * as conv_util from './conv_util';\nimport { op } from './operation';\nimport { reshape } from './reshape';\n/**\n * Computes the 2D average pooling of an image.\n *\n * @param x The input tensor, of rank 4 or rank 3 of shape\n *     `[batch, height, width, inChannels]`. If rank 3, batch of 1 is assumed.\n * @param filterSize The filter size: `[filterHeight, filterWidth]`. If\n *     `filterSize` is a single number, then `filterHeight == filterWidth`.\n * @param strides The strides of the pooling: `[strideHeight, strideWidth]`. If\n *     `strides` is a single number, then `strideHeight == strideWidth`.\n * @param pad The type of padding algorithm:\n *    - `same` and stride 1: output will be of same size as input,\n *       regardless of filter size.\n *    - `valid`: output will be smaller than input if filter is larger\n *       than 1x1.\n *    - For more info, see this guide:\n *     [https://www.tensorflow.org/api_guides/python/nn#Convolution](\n *         https://www.tensorflow.org/api_guides/python/nn#Convolution)\n * @param dimRoundingMode A string from: 'ceil', 'round', 'floor'. If none is\n *     provided, it will default to truncate.\n */\nfunction avgPool_(x, filterSize, strides, pad, dimRoundingMode) {\n    const $x = convertToTensor(x, 'x', 'avgPool', 'float32');\n    const dilations = 1;\n    util.assert(conv_util.eitherStridesOrDilationsAreOne(strides, dilations), () => 'Error in avgPool: Either strides or dilations must be 1. ' +\n        `Got strides ${strides} and dilations '${dilations}'`);\n    let x4D = $x;\n    let reshapedTo4D = false;\n    if ($x.rank === 3) {\n        reshapedTo4D = true;\n        x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);\n    }\n    util.assert(x4D.rank === 4, () => `Error in avgPool: x must be rank 4 but got rank ${x4D.rank}.`);\n    if (dimRoundingMode != null) {\n        util.assert(util.isInt(pad), () => `Error in avgPool: pad must be an integer when using, ` +\n            `dimRoundingMode ${dimRoundingMode} but got pad ${pad}.`);\n    }\n    const inputs = { x: x4D };\n    const attrs = { filterSize, strides, pad, dimRoundingMode };\n    // tslint:disable-next-line: no-unnecessary-type-assertion\n    let res = ENGINE.runKernel(AvgPool, inputs, attrs);\n    res = cast(res, $x.dtype);\n    if (reshapedTo4D) {\n        return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);\n    }\n    return res;\n}\nexport const avgPool = op({ avgPool_ });\n//# sourceMappingURL=avg_pool.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Conv2DBackpropInput } from '../kernel_names';\nimport * as util from '../util';\nimport { op } from './operation';\nimport { reshape } from './reshape';\n/**\n * Computes the derivative of the input of a 2D convolution.\n *\n * @param xShape The shape of the input: [batch, height, width, inDepth].\n * If length of 3, batch of 1 is assumed.\n * @param dy The derivative of the output, of rank 4 or rank 3 of shape\n *   `[batch, outHeight, outWidth, outDepth]`. If rank 3, batch of 1 is\n * assumed.\n * @param filter The filter, rank 4, of shape\n *     `[filterHeight, filterWidth, inDepth, outDepth]`.\n * @param strides The strides of the convolution: `[strideHeight,\n * strideWidth]`.\n * @param pad The type of padding algorithm used:\n *    - `same` and stride 1: output will be of same size as input,\n *       regardless of filter size.\n *    - `valid`: output will be smaller than input if filter is larger\n *       than 1x1.\n * @param dataFormat: An optional string from: \"NHWC\", \"NCHW\". Defaults to\n *     \"NHWC\". Specify the data format of the input and output data. With the\n *     default format \"NHWC\", the data is stored in the order of: [batch,\n *     height, width, channels].\n * @param dimRoundingMode A string from: 'ceil', 'round', 'floor'. If none is\n *     provided, it will default to truncate.\n */\nfunction conv2DBackpropInput_(xShape, dy, filter, strides, pad, dataFormat = 'NHWC', dimRoundingMode) {\n    util.assert(xShape.length === dy.rank, () => `Length of inShape ` +\n        `(${xShape.length}) and rank of dy (${dy.rank}) must match`);\n    let xShape4D = xShape;\n    let dy4D = dy;\n    let reshapedTo4D = false;\n    if (dy.rank === 3) {\n        reshapedTo4D = true;\n        dy4D = reshape(dy, [1, dy.shape[0], dy.shape[1], dy.shape[2]]);\n        xShape4D = [1, xShape[0], xShape[1], xShape[2]];\n    }\n    util.assert(xShape4D.length === 4, () => `Error in conv2dDerInput: inShape must be length 4, but got length ` +\n        `${xShape4D.length}.`);\n    util.assert(dy4D.rank === 4, () => `Error in conv2dDerInput: dy must be rank 4, but got ` +\n        `rank ${dy4D.rank}`);\n    util.assert(filter.rank === 4, () => `Error in conv2dDerInput: filter must be rank 4, but got ` +\n        `rank ${filter.rank}`);\n    const inDepth = dataFormat === 'NHWC' ? xShape4D[3] : xShape4D[1];\n    const outDepth = dataFormat === 'NHWC' ? dy4D.shape[3] : dy4D.shape[1];\n    util.assert(inDepth === filter.shape[2], () => `Error in conv2dDerInput: depth of input (${inDepth}) must ` +\n        `match input depth for filter ${filter.shape[2]}.`);\n    util.assert(outDepth === filter.shape[3], () => `Error in conv2dDerInput: depth of output (${outDepth}) must ` +\n        `match output depth for filter ${filter.shape[3]}.`);\n    if (dimRoundingMode != null) {\n        util.assert(util.isInt(pad), () => `Error in conv2dDerInput: pad must be an integer when using, ` +\n            `dimRoundingMode ${dimRoundingMode} but got pad ${pad}.`);\n    }\n    const inputs = { dy: dy4D, filter };\n    const attrs = { strides, pad, dataFormat, dimRoundingMode, inputShape: xShape4D };\n    // tslint:disable-next-line: no-unnecessary-type-assertion\n    const res = ENGINE.runKernel(Conv2DBackpropInput, inputs, attrs);\n    if (reshapedTo4D) {\n        return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);\n    }\n    return res;\n}\nexport const conv2DBackpropInput = op({ conv2DBackpropInput_ });\n//# sourceMappingURL=conv2d_backprop_input.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Conv2DBackpropFilter } from '../kernel_names';\nimport * as util from '../util';\nimport { op } from './operation';\nimport { reshape } from './reshape';\n/**\n * Computes the derivative of the filter of a 2D convolution.\n *\n * @param x The input tensor, of rank 4 or rank 3 of shape\n *     [batch, height, width, inChannels]. If rank 3, batch of 1 is assumed.\n * @param dy The dy image, of rank 4 or rank 3, of shape\n *     [batch, height, width, outDepth]. If rank 3, batch of 1 is assumed.\n * @param filterShape The shape of the filter, length 4,\n *     [filterHeight, filterWidth, inDepth, outDepth].\n * @param strides The strides of the convolution: [strideHeight,\n * strideWidth].\n * @param pad A string from: 'same', 'valid'. The type of padding algorithm\n *     used in the forward prop of the op.\n * @param dataFormat: An optional string from: \"NHWC\", \"NCHW\". Defaults to\n *     \"NHWC\". Specify the data format of the input and output data. With the\n *     default format \"NHWC\", the data is stored in the order of: [batch,\n *     height, width, channels].\n * @param dimRoundingMode A string from: 'ceil', 'round', 'floor'. If none is\n *     provided, it will default to truncate.\n */\nfunction conv2DBackpropFilter_(x, dy, filterShape, strides, pad, dataFormat = 'NHWC', dimRoundingMode) {\n    let x4D = x;\n    if (x.rank === 3) {\n        x4D = reshape(x, [1, x.shape[0], x.shape[1], x.shape[2]]);\n    }\n    let dy4D = dy;\n    if (dy4D.rank === 3) {\n        dy4D = reshape(dy, [1, dy.shape[0], dy.shape[1], dy.shape[2]]);\n    }\n    util.assert(x4D.rank === 4, () => `Error in conv2dDerFilter: input must be rank 4, but got shape ` +\n        `${x4D.shape}.`);\n    util.assert(dy4D.rank === 4, () => `Error in conv2dDerFilter: dy must be rank 4, but got shape ` +\n        `${dy4D.shape}.`);\n    util.assert(filterShape.length === 4, () => `Error in conv2dDerFilter: filterShape must be length 4, but got ` +\n        `${filterShape}.`);\n    const inDepth = dataFormat === 'NHWC' ? x4D.shape[3] : x4D.shape[1];\n    const outDepth = dataFormat === 'NHWC' ? dy4D.shape[3] : dy4D.shape[1];\n    util.assert(inDepth === filterShape[2], () => `Error in conv2dDerFilter: depth of input ${inDepth}) must ` +\n        `match input depth in filter (${filterShape[2]}.`);\n    util.assert(outDepth === filterShape[3], () => `Error in conv2dDerFilter: depth of dy (${outDepth}) must ` +\n        `match output depth for filter (${filterShape[3]}).`);\n    if (dimRoundingMode != null) {\n        util.assert(util.isInt(pad), () => `Error in conv2dDerFilter: pad must be an integer when using, ` +\n            `dimRoundingMode ${dimRoundingMode} but got pad ${pad}.`);\n    }\n    const inputs = { x: x4D, dy: dy4D };\n    const attrs = { strides, pad, dataFormat, dimRoundingMode, filterShape };\n    // tslint:disable-next-line: no-unnecessary-type-assertion\n    return ENGINE.runKernel(Conv2DBackpropFilter, inputs, attrs);\n}\nexport const conv2DBackpropFilter = op({ conv2DBackpropFilter_ });\n//# sourceMappingURL=conv2d_backprop_filter.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { buffer } from './buffer';\nimport { expandDims } from './expand_dims';\nimport { op } from './operation';\nimport { reshape } from './reshape';\nimport { tile } from './tile';\n/**\n * Create an identity matrix.\n *\n * @param numRows Number of rows.\n * @param numColumns Number of columns. Defaults to `numRows`.\n * @param batchShape If provided, will add the batch shape to the beginning\n *   of the shape of the returned `tf.Tensor` by repeating the identity\n *   matrix.\n * @param dtype Data type.\n * @returns Identity matrix of the specified size and data type, possibly\n *   with batch repetition if `batchShape` is specified.\n *\n * @doc {heading: 'Tensors', subheading: 'Creation'}\n */\nfunction eye_(numRows, numColumns, batchShape, dtype = 'float32') {\n    if (numColumns == null) {\n        numColumns = numRows;\n    }\n    const buff = buffer([numRows, numColumns], dtype);\n    const n = numRows <= numColumns ? numRows : numColumns;\n    for (let i = 0; i < n; ++i) {\n        buff.set(1, i, i);\n    }\n    const out = reshape(buff.toTensor(), [numRows, numColumns]);\n    if (batchShape == null) {\n        return out;\n    }\n    else {\n        if (batchShape.length === 1) {\n            return tile(expandDims(out, 0), [batchShape[0], 1, 1]);\n        }\n        else if (batchShape.length === 2) {\n            // tslint:disable-next-line:no-unnecessary-type-assertion\n            return tile(expandDims(expandDims(out, 0), 0), [batchShape[0], batchShape[1], 1, 1]);\n        }\n        else if (batchShape.length === 3) {\n            // tslint:disable-next-line:no-unnecessary-type-assertion\n            return tile(expandDims(expandDims(expandDims(out, 0), 0), 0), [\n                batchShape[0], batchShape[1], batchShape[2], 1, 1\n            ]);\n        }\n        else {\n            throw new Error(`eye() currently supports only 1D and 2D ` +\n                // tslint:disable-next-line:no-any\n                `batchShapes, but received ${batchShape.length}D.`);\n        }\n    }\n}\nexport const eye = op({ eye_ });\n//# sourceMappingURL=eye.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { RealDiv } from '../kernel_names';\nimport { makeTypesMatch } from '../tensor_util';\nimport { convertToTensor } from '../tensor_util_env';\nimport { floorDiv } from './floorDiv';\nimport { op } from './operation';\n/**\n * Divides two `tf.Tensor`s element-wise, A / B. Supports broadcasting.\n *\n * ```js\n * const a = tf.tensor1d([1, 4, 9, 16]);\n * const b = tf.tensor1d([1, 2, 3, 4]);\n *\n * a.div(b).print();  // or tf.div(a, b)\n * ```\n *\n * ```js\n * // Broadcast div a with b.\n * const a = tf.tensor1d([2, 4, 6, 8]);\n * const b = tf.scalar(2);\n *\n * a.div(b).print();  // or tf.div(a, b)\n * ```\n *\n * @param a The first tensor as the numerator.\n * @param b The second tensor as the denominator. Must have the same dtype as\n * `a`.\n *\n * @doc {heading: 'Operations', subheading: 'Arithmetic'}\n */\nfunction div_(a, b) {\n    let $a = convertToTensor(a, 'a', 'div');\n    let $b = convertToTensor(b, 'b', 'div');\n    [$a, $b] = makeTypesMatch($a, $b);\n    if ($a.dtype === 'int32' && $b.dtype === 'int32') {\n        return floorDiv($a, $b);\n    }\n    const inputs = { a: $a, b: $b };\n    const attrs = {};\n    // tslint:disable-next-line: no-unnecessary-type-assertion\n    return ENGINE.runKernel(RealDiv, inputs, attrs);\n}\nexport const div = op({ div_ });\n//# sourceMappingURL=div.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Cosh } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes hyperbolic cos of the input `tf.Tensor` element-wise: `cosh(x)`\n *\n * ```js\n * const x = tf.tensor1d([0, 1, -1, .7]);\n *\n * x.cosh().print();  // or tf.cosh(x)\n * ```\n * @param x The input tensor.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction cosh_(x) {\n    const $x = convertToTensor(x, 'x', 'cosh');\n    const inputs = { x: $x };\n    return ENGINE.runKernel(Cosh, inputs);\n}\nexport const cosh = op({ cosh_ });\n//# sourceMappingURL=cosh.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { All } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes the logical and of elements across dimensions of a `tf.Tensor`.\n *\n * Reduces the input along the dimensions given in `axes`. Unless `keepDims`\n * is true, the rank of the `tf.Tensor` is reduced by 1 for each entry in\n * `axes`. If `keepDims` is true, the reduced dimensions are retained with\n * length 1. If `axes` has no entries, all dimensions are reduced, and an\n * `tf.Tensor` with a single element is returned.\n *\n * ```js\n * const x = tf.tensor1d([1, 1, 1], 'bool');\n *\n * x.all().print();  // or tf.all(x)\n * ```\n *\n * ```js\n * const x = tf.tensor2d([1, 1, 0, 0], [2, 2], 'bool');\n *\n * const axis = 1;\n * x.all(axis).print();  // or tf.all(x, axis)\n * ```\n *\n * @param x The input tensor. Must be of dtype bool.\n * @param axis The dimension(s) to reduce. By default it reduces\n *     all dimensions.\n * @param keepDims If true, retains reduced dimensions with size 1.\n *\n * @doc {heading: 'Operations', subheading: 'Reduction'}\n */\nfunction all_(x, axis = null, keepDims = false) {\n    const $x = convertToTensor(x, 'x', 'all', 'bool');\n    const inputs = { x: $x };\n    const attrs = { axis, keepDims };\n    return ENGINE.runKernel(All, inputs, attrs);\n}\nexport const all = op({ all_ });\n//# sourceMappingURL=all.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Any } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes the logical or of elements across dimensions of a `tf.Tensor`.\n *\n * Reduces the input along the dimensions given in `axes`. Unless `keepDims`\n * is true, the rank of the `tf.Tensor` is reduced by 1 for each entry in\n * `axes`. If `keepDims` is true, the reduced dimensions are retained with\n * length 1. If `axes` has no entries, all dimensions are reduced, and an\n * `tf.Tensor` with a single element is returned.\n *\n * ```js\n * const x = tf.tensor1d([1, 1, 1], 'bool');\n *\n * x.any().print();  // or tf.any(x)\n * ```\n *\n * ```js\n * const x = tf.tensor2d([1, 1, 0, 0], [2, 2], 'bool');\n *\n * const axis = 1;\n * x.any(axis).print();  // or tf.any(x, axis)\n * ```\n *\n * @param x The input tensor. Must be of dtype bool.\n * @param axis The dimension(s) to reduce. By default it reduces\n *     all dimensions.\n * @param keepDims If true, retains reduced dimensions with size 1.\n *\n * @doc {heading: 'Operations', subheading: 'Reduction'}\n */\nfunction any_(x, axis = null, keepDims = false) {\n    const $x = convertToTensor(x, 'x', 'any', 'bool');\n    const inputs = { x: $x };\n    const attrs = { axis, keepDims };\n    return ENGINE.runKernel(Any, inputs, attrs);\n}\n// tslint:disable-next-line:variable-name\nexport const any = op({ any_ });\n//# sourceMappingURL=any.js.map","/**\n * @license\n * Copyright 2020 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { ArgMax } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Returns the indices of the maximum values along an `axis`.\n *\n * The result has the same shape as `input` with the dimension along `axis`\n * removed.\n *\n * ```js\n * const x = tf.tensor1d([1, 2, 3]);\n *\n * x.argMax().print();  // or tf.argMax(x)\n * ```\n *\n * ```js\n * const x = tf.tensor2d([1, 2, 4, 3], [2, 2]);\n *\n * const axis = 1;\n * x.argMax(axis).print();  // or tf.argMax(x, axis)\n * ```\n *\n * @param x The input tensor.\n * @param axis The dimension to reduce. Defaults to 0 (outer-most dimension).\n *\n * @doc {heading: 'Operations', subheading: 'Reduction'}\n */\nfunction argMax_(x, axis = 0) {\n    const $x = convertToTensor(x, 'x', 'argMax');\n    const inputs = { x: $x };\n    const attrs = { axis };\n    return ENGINE.runKernel(ArgMax, inputs, attrs);\n}\nexport const argMax = op({ argMax_ });\n//# sourceMappingURL=arg_max.js.map","/**\n * @license\n * Copyright 2020 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { ArgMin } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Returns the indices of the minimum values along an `axis`.\n *\n * The result has the same shape as `input` with the dimension along `axis`\n * removed.\n *\n * ```js\n * const x = tf.tensor1d([1, 2, 3]);\n *\n * x.argMin().print();  // or tf.argMin(x)\n * ```\n *\n * ```js\n * const x = tf.tensor2d([1, 2, 4, 3], [2, 2]);\n *\n * const axis = 1;\n * x.argMin(axis).print();  // or tf.argMin(x, axis)\n * ```\n *\n * @param x The input tensor.\n * @param axis The dimension to reduce. Defaults to 0 (outer-most dimension).\n *\n * @doc {heading: 'Operations', subheading: 'Reduction'}\n */\nfunction argMin_(x, axis = 0) {\n    const $x = convertToTensor(x, 'x', 'argMin');\n    const inputs = { x: $x };\n    const attrs = { axis };\n    return ENGINE.runKernel(ArgMin, inputs, attrs);\n}\nexport const argMin = op({ argMin_ });\n//# sourceMappingURL=arg_min.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Atan2 } from '../kernel_names';\nimport { makeTypesMatch } from '../tensor_util';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes arctangent of `tf.Tensor`s a / b element-wise: `atan2(a, b)`.\n * Supports broadcasting.\n *\n * ```js\n * const a = tf.tensor1d([1.0, 1.0, -1.0, .7]);\n * const b = tf.tensor1d([2.0, 13.0, 3.5, .21]);\n *\n * tf.atan2(a, b).print()\n * ```\n *\n * @param a The first tensor.\n * @param b The second tensor. Must have the same dtype as `a`.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction atan2_(a, b) {\n    let $a = convertToTensor(a, 'a', 'atan2');\n    let $b = convertToTensor(b, 'b', 'atan2');\n    [$a, $b] = makeTypesMatch($a, $b);\n    const inputs = { a: $a, b: $b };\n    return ENGINE.runKernel(Atan2, inputs);\n}\nexport const atan2 = op({ atan2_ });\n//# sourceMappingURL=atan2.js.map","import { convertToTensor } from '../tensor_util_env';\nimport * as util from '../util';\nimport { conv2d } from './conv2d';\nimport * as conv_util from './conv_util';\nimport { op } from './operation';\nimport { reshape } from './reshape';\n/**\n * Computes a 1D convolution over the input x.\n *\n * @param x The input tensor, of rank 3 or rank 2, of shape\n *     `[batch, width, inChannels]`. If rank 2, batch of 1 is assumed.\n * @param filter The filter, rank 3, of shape\n *     `[filterWidth, inDepth, outDepth]`.\n * @param stride The number of entries by which the filter is moved right at\n *     each step.\n * @param pad The type of padding algorithm.\n *    - `same` and stride 1: output will be of same size as input,\n *       regardless of filter size.\n *    - `valid`: output will be smaller than input if filter is larger\n *       than 1x1.\n *   - For more info, see this guide:\n *     [https://www.tensorflow.org/api_guides/python/nn#Convolution](\n *          https://www.tensorflow.org/api_guides/python/nn#Convolution)\n * @param dataFormat An optional string from \"NWC\", \"NCW\". Defaults to \"NWC\",\n *     the data is stored in the order of [batch, in_width, in_channels]. Only\n *     \"NWC\" is currently supported.\n * @param dilation The dilation rate in which we sample input values in\n *     atrous convolution. Defaults to `1`. If it is greater than 1, then\n *     stride must be `1`.\n * @param dimRoundingMode A string from: 'ceil', 'round', 'floor'. If none is\n *     provided, it will default to truncate.\n *\n * @doc {heading: 'Operations', subheading: 'Convolution'}\n */\nfunction conv1d_(x, filter, stride, pad, dataFormat = 'NWC', dilation = 1, dimRoundingMode) {\n    const $x = convertToTensor(x, 'x', 'conv1d');\n    const $filter = convertToTensor(filter, 'filter', 'conv1d');\n    let x3D = $x;\n    let reshapedTo3D = false;\n    if ($x.rank === 2) {\n        reshapedTo3D = true;\n        x3D = reshape($x, [1, $x.shape[0], $x.shape[1]]);\n    }\n    util.assert(x3D.rank === 3, () => `Error in conv1d: input must be rank 3, but got rank ${x3D.rank}.`);\n    util.assert($filter.rank === 3, () => `Error in conv1d: filter must be rank 3, but got rank ` +\n        `${$filter.rank}.`);\n    if (dimRoundingMode != null) {\n        util.assert(util.isInt(pad), () => `Error in conv1d: pad must be an integer when using, ` +\n            `dimRoundingMode ${dimRoundingMode} but got pad ${pad}.`);\n    }\n    util.assert(x3D.shape[2] === $filter.shape[1], () => `Error in conv1d: depth of input (${x3D.shape[2]}) must match ` +\n        `input depth for filter ${$filter.shape[1]}.`);\n    util.assert(conv_util.eitherStridesOrDilationsAreOne(stride, dilation), () => 'Error in conv1D: Either stride or dilation must be 1. ' +\n        `Got stride ${stride} and dilation '${dilation}'`);\n    util.assert(dataFormat === 'NWC', () => `Error in conv1d: got dataFormat of ${dataFormat} but only NWC is currently supported.`);\n    const filter4D = reshape($filter, [1, $filter.shape[0], $filter.shape[1], $filter.shape[2]]);\n    const input4D = reshape(x3D, [x3D.shape[0], 1, x3D.shape[1], x3D.shape[2]]);\n    const strides = [1, stride];\n    const dilations = [1, dilation];\n    const conv2dDataFormat = 'NHWC';\n    const res = conv2d(input4D, filter4D, strides, pad, conv2dDataFormat, dilations, dimRoundingMode);\n    if (reshapedTo3D) {\n        return reshape(res, [res.shape[2], res.shape[3]]);\n    }\n    return reshape(res, [res.shape[0], res.shape[2], res.shape[3]]);\n}\nexport const conv1d = op({ conv1d_ });\n//# sourceMappingURL=conv1d.js.map","import { convertToTensor } from '../tensor_util_env';\nimport { conv2DBackpropInput } from './conv2d_backprop_input';\nimport { op } from './operation';\n/**\n * Computes the transposed 2D convolution of an image, also known as a\n * deconvolution.\n *\n * @param x The input image, of rank 4 or rank 3, of shape\n *   `[batch, height, width, inDepth]`. If rank 3, batch of 1 is assumed.\n * @param filter The filter, rank 4, of shape\n *     `[filterHeight, filterWidth, outDepth, inDepth]`.\n *     `inDepth` must match `inDepth` in `x`.\n * @param outputShape Output shape, of rank 4 or rank 3:\n *     `[batch, height, width, outDepth]`. If rank 3, batch of 1 is assumed.\n * @param strides The strides of the original convolution:\n *     `[strideHeight, strideWidth]`.\n * @param pad  The type of padding algorithm used in the non-transpose version\n *    of the op.\n * @param dimRoundingMode A string from: 'ceil', 'round', 'floor'. If none is\n *     provided, it will default to truncate.\n *\n * @doc {heading: 'Operations', subheading: 'Convolution'}\n */\nfunction conv2dTranspose_(x, filter, outputShape, strides, pad, dimRoundingMode) {\n    const $x = convertToTensor(x, 'x', 'conv2dTranspose');\n    const $filter = convertToTensor(filter, 'filter', 'conv2dTranspose');\n    return conv2DBackpropInput(outputShape, $x, $filter, strides, pad, 'NHWC', dimRoundingMode);\n}\nexport const conv2dTranspose = op({ conv2dTranspose_ });\n//# sourceMappingURL=conv2d_transpose.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { DepthToSpace } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport * as util from '../util';\nimport { op } from './operation';\n/**\n * Rearranges data from depth into blocks of spatial data. More specifically,\n * this op outputs a copy of the input tensor where values from the `depth`\n * dimension are moved in spatial blocks to the `height` and `width` dimensions.\n * The attr `blockSize` indicates the input block size and how the data is\n * moved.\n *\n *  - Chunks of data of size `blockSize * blockSize` from depth are rearranged\n * into non-overlapping blocks of size `blockSize x blockSize`\n *\n *  - The width the output tensor is `inputWidth * blockSize`, whereas the\n * height is `inputHeight * blockSize`\n *\n *  - The Y, X coordinates within each block of the output image are determined\n * by the high order component of the input channel index\n *\n *  - The depth of the input tensor must be divisible by `blockSize *\n * blockSize`\n *\n * The `dataFormat` attr specifies the layout of the input and output tensors\n * with the following options: \"NHWC\": [ `batch, height, width, channels` ]\n * \"NCHW\": [ `batch, channels, height, width` ]\n *\n * ```js\n * const x = tf.tensor4d([1, 2, 3, 4], [1, 1, 1, 4]);\n * const blockSize = 2;\n * const dataFormat = \"NHWC\";\n *\n * tf.depthToSpace(x, blockSize, dataFormat).print();\n * ```\n *\n * @param x The input tensor of rank 4\n * @param blockSIze  An `int` that is `>= 2`. The size of the spatial block\n * @param dataFormat An optional string from: \"NHWC\", \"NCHW\". Defaults to \"NHWC\"\n *\n * @doc {heading: 'Tensors', subheading: 'Transformations'}\n */\nfunction depthToSpace_(x, blockSize, dataFormat = 'NHWC') {\n    const $x = convertToTensor(x, 'x', 'depthToSpace');\n    const inputHeight = (dataFormat === 'NHWC') ? $x.shape[1] : $x.shape[2];\n    const inputWidth = (dataFormat === 'NHWC') ? $x.shape[2] : $x.shape[3];\n    const inputDepth = (dataFormat === 'NHWC') ? $x.shape[3] : $x.shape[1];\n    util.assert(inputHeight * blockSize >= 0, () => `Negative dimension size caused by overflow when multiplying\n    ${inputHeight} and ${blockSize}  for depthToSpace with input shape\n    ${$x.shape}`);\n    util.assert(inputWidth * blockSize >= 0, () => `Negative dimension size caused by overflow when multiplying\n    ${inputWidth} and ${blockSize} for depthToSpace with input shape\n        ${$x.shape}`);\n    util.assert((inputDepth % (blockSize * blockSize) === 0), () => `Dimension size must be evenly divisible by ${blockSize * blockSize} but is ${inputDepth} for depthToSpace with input shape ${$x.shape}`);\n    const inputs = { x: $x };\n    const attrs = { blockSize, dataFormat };\n    return ENGINE.runKernel(DepthToSpace, inputs, attrs);\n}\nexport const depthToSpace = op({ depthToSpace_ });\n//# sourceMappingURL=depth_to_space.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Dilation2D } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport * as util from '../util';\nimport { op } from './operation';\nimport { reshape } from './reshape';\n/**\n * Computes the grayscale dilation over the input `x`.\n *\n * @param x The input tensor, rank 3 or rank 4 of shape\n *     `[batch, height, width, inChannels]`. If rank 3, batch of 1 is assumed.\n * @param filter The filter tensor, rank 3, of shape\n *     `[filterHeight, filterWidth, depth]`.\n * @param strides The strides of the sliding window for each dimension of the\n *     input tensor: `[strideHeight, strideWidth]`.\n *     If `strides` is a single number,\n *     then `strideHeight == strideWidth`.\n * @param pad The type of padding algorithm.\n *    - `same` and stride 1: output will be of same size as input,\n *       regardless of filter size.\n *    - `valid`: output will be smaller than input if filter is larger\n *       than 1*1x1.\n *    - For more info, see this guide:\n *     [https://www.tensorflow.org/api_guides/python/nn#Convolution](\n *          https://www.tensorflow.org/api_guides/python/nn#Convolution)\n * @param dataFormat Specify the data format of the input and output data.\n *      Defaults to 'NHWC'. Only 'NHWC' is currently supported. With the\n *      default format \"NHWC\", the data is stored in the order of: [batch,\n *      height, width, channels].\n * @param dilations The dilation rates: `[dilationHeight, dilationWidth]`\n *     in which we sample input values across the height and width dimensions\n *     for atrous morphological dilation. Defaults to `[1, 1]`. If `dilations`\n *     is a single number, then `dilationHeight == dilationWidth`. If it is\n *     greater than 1, then all values of `strides` must be 1.\n *\n * @doc {heading: 'Operations', subheading: 'Convolution'}\n */\nfunction dilation2d_(x, filter, strides, pad, dilations = [1, 1], dataFormat = 'NHWC') {\n    const $x = convertToTensor(x, 'x', 'dilation2d');\n    const $filter = convertToTensor(filter, 'filter', 'dilation2d');\n    util.assert($x.rank === 3 || $x.rank === 4, () => `Error in dilation2d: input must be rank 3 or 4, but got rank ` +\n        `${$x.rank}.`);\n    util.assert($filter.rank === 3, () => `Error in dilation2d: filter must be rank 3, but got rank ` +\n        `${$filter.rank}.`);\n    util.assert(dataFormat === 'NHWC', () => `Error in dilation2d: Only NHWC is currently supported, ` +\n        `but got dataFormat of ${dataFormat}`);\n    let x4D = $x;\n    let reshapedTo4D = false;\n    if ($x.rank === 3) {\n        x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);\n        reshapedTo4D = true;\n    }\n    const inputs = { x: x4D, filter: $filter };\n    const attrs = { strides, pad, dilations };\n    // tslint:disable-next-line: no-unnecessary-type-assertion\n    const res = ENGINE.runKernel(Dilation2D, inputs, attrs);\n    if (reshapedTo4D) {\n        return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);\n    }\n    return res;\n}\nexport const dilation2d = op({ dilation2d_ });\n//# sourceMappingURL=dilation2d.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { makeTypesMatch } from '../tensor_util';\nimport { convertToTensor } from '../tensor_util_env';\nimport { div } from './div';\nimport { equal } from './equal';\nimport { op } from './operation';\nimport { where } from './where';\nimport { zerosLike } from './zeros_like';\n/**\n * Divides two `tf.Tensor`s element-wise, A / B. Supports broadcasting. Return 0\n * if denominator is 0.\n *\n *\n * ```js\n * const a = tf.tensor1d([1, 4, 9, 16]);\n * const b = tf.tensor1d([1, 2, 3, 4]);\n * const c = tf.tensor1d([0, 0, 0, 0]);\n *\n * a.divNoNan(b).print();  // or tf.divNoNan(a, b)\n * a.divNoNan(c).print();  // or tf.divNoNan(a, c)\n * ```\n *\n * ```js\n * // Broadcast div a with b.\n * const a = tf.tensor1d([2, 4, 6, 8]);\n * const b = tf.scalar(2);\n * const c = tf.scalar(0);\n *\n * a.divNoNan(b).print();  // or tf.divNoNan(a, b)\n * a.divNoNan(c).print();  // or tf.divNoNan(a, c)\n * ```\n *\n * @param a The first tensor as the numerator.\n * @param b The second tensor as the denominator. Must have the same dtype as\n * `a`.\n *\n * @doc {heading: 'Operations', subheading: 'Arithmetic'}\n */\nfunction divNoNan_(a, b) {\n    // TODO: Make this into its own kernel.\n    let $a = convertToTensor(a, 'a', 'div');\n    let $b = convertToTensor(b, 'b', 'div');\n    [$a, $b] = makeTypesMatch($a, $b);\n    const divResult = div($a, $b);\n    const zeros = zerosLike(divResult);\n    const bEqualsZero = equal($b, zeros);\n    return where(bEqualsZero, zeros, divResult);\n}\nexport const divNoNan = op({ divNoNan_ });\n//# sourceMappingURL=div_no_nan.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { convertToTensor } from '../tensor_util_env';\nimport * as util from '../util';\nimport { matMul } from './mat_mul';\nimport { op } from './operation';\nimport { reshape } from './reshape';\n/**\n * Computes the dot product of two matrices and/or vectors, `t1` and `t2`.\n *\n * ```js\n * const a = tf.tensor1d([1, 2]);\n * const b = tf.tensor2d([[1, 2], [3, 4]]);\n * const c = tf.tensor2d([[1, 2, 3], [4, 5, 6]]);\n *\n * a.dot(b).print();  // or tf.dot(a, b)\n * b.dot(a).print();\n * b.dot(c).print();\n * ```\n * @param t1 The first tensor in the dot operation.\n * @param t2 The second tensor in the dot operation.\n *\n * @doc {heading: 'Operations', subheading: 'Matrices'}\n */\nfunction dot_(t1, t2) {\n    const $t1 = convertToTensor(t1, 't1', 'dot');\n    const $t2 = convertToTensor(t2, 't2', 'dot');\n    util.assert(($t1.rank === 1 || $t1.rank === 2) && ($t2.rank === 1 || $t2.rank === 2), () => `Error in dot: inputs must all be rank 1 or 2, but got ranks ` +\n        `${$t1.rank} and ${$t2.rank}.`);\n    const t1Inner = ($t1.rank === 1 ? $t1.size : $t1.shape[1]);\n    const t2Inner = ($t2.rank === 1 ? $t2.size : $t2.shape[0]);\n    util.assert(t1Inner === t2Inner, () => `Error in dot: inner dimensions of inputs must match, but got ` +\n        `${t1Inner} and ${t2Inner}.`);\n    if ($t1.rank === 1 && $t2.rank === 1) {\n        const t12D = reshape($t1, [1, -1]);\n        const t22D = reshape($t2, [-1, 1]);\n        const t1t2 = matMul(t12D, t22D);\n        return reshape(t1t2, []);\n    }\n    else if ($t1.rank === 1 && $t2.rank === 2) {\n        const t12D = reshape($t1, [1, -1]);\n        const t22D = reshape($t2, [$t2.shape[0], $t2.shape[1]]);\n        const t1t2 = matMul(t12D, t22D);\n        return reshape(t1t2, [t1t2.size]);\n    }\n    else if ($t1.rank === 2 && $t2.rank === 1) {\n        const t22D = reshape($t2, [-1, 1]);\n        const t1t2 = matMul($t1, t22D);\n        return reshape(t1t2, [t1t2.size]);\n    }\n    else {\n        const t22D = reshape($t2, [$t2.shape[0], $t2.shape[1]]);\n        const t1t2 = matMul($t1, t22D);\n        return t1t2;\n    }\n}\nexport const dot = op({ dot_ });\n//# sourceMappingURL=dot.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { FusedBatchNorm } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport * as util from '../util';\nimport { xAs4D } from './batchnorm_util';\nimport { op } from './operation';\nimport { reshape } from './reshape';\n/**\n * Batch normalization.\n *\n * As described in\n * [http://arxiv.org/abs/1502.03167](http://arxiv.org/abs/1502.03167).\n *\n * Mean, variance, scale, and offset can be of two shapes:\n *   - The same shape as the input.\n *   - In the common case, the depth dimension is the last dimension of x, so\n *     the values would be an `tf.Tensor1D` of shape [depth].\n *\n * Also available are stricter rank-specific methods with the same signature\n * as this method that assert that parameters passed are of given rank\n *   - `tf.batchNorm2d`\n *   - `tf.batchNorm3d`\n *   - `tf.batchNorm4d`\n *\n * @param x The input Tensor.\n * @param mean A mean Tensor.\n * @param variance A variance Tensor.\n * @param offset An offset Tensor.\n * @param scale A scale Tensor.\n * @param varianceEpsilon A small float number to avoid dividing by 0.\n *\n * @doc {heading: 'Operations', subheading: 'Normalization'}\n */\nfunction batchNorm_(x, mean, variance, offset, scale, varianceEpsilon) {\n    if (varianceEpsilon == null) {\n        varianceEpsilon = 0.001;\n    }\n    const $x = convertToTensor(x, 'x', 'batchNorm');\n    const $mean = convertToTensor(mean, 'mean', 'batchNorm');\n    const $variance = convertToTensor(variance, 'variance', 'batchNorm');\n    let $scale;\n    if (scale != null) {\n        $scale = convertToTensor(scale, 'scale', 'batchNorm');\n    }\n    let $offset;\n    if (offset != null) {\n        $offset = convertToTensor(offset, 'offset', 'batchNorm');\n    }\n    util.assert($mean.rank === $variance.rank, () => 'Batch normalization gradient requires mean and variance to have ' +\n        'equal ranks.');\n    util.assert($offset == null || $mean.rank === $offset.rank, () => 'Batch normalization gradient requires mean and offset to have ' +\n        'equal ranks.');\n    util.assert($scale == null || $mean.rank === $scale.rank, () => 'Batch normalization gradient requires mean and scale to have ' +\n        'equal ranks.');\n    const x4D = xAs4D($x);\n    const inputs = {\n        x: x4D,\n        scale: $scale,\n        offset: $offset,\n        mean: $mean,\n        variance: $variance\n    };\n    const attrs = { varianceEpsilon };\n    // tslint:disable-next-line: no-unnecessary-type-assertion\n    const res = ENGINE.runKernel(FusedBatchNorm, inputs, attrs);\n    return reshape(res, $x.shape);\n}\nexport const batchNorm = op({ batchNorm_ });\n//# sourceMappingURL=batchnorm.js.map","import { reshape } from './reshape';\nexport function xAs4D(x) {\n    let x4D;\n    if (x.rank === 0 || x.rank === 1) {\n        x4D = reshape(x, [1, 1, 1, x.size]);\n    }\n    else if (x.rank === 2) {\n        x4D = reshape(x, [1, 1, x.shape[0], x.shape[1]]);\n    }\n    else if (x.rank === 3) {\n        x4D = reshape(x, [1, x.shape[0], x.shape[1], x.shape[2]]);\n    }\n    else {\n        x4D = x;\n    }\n    return x4D;\n}\n//# sourceMappingURL=batchnorm_util.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { DepthwiseConv2dNativeBackpropInput } from '../kernel_names';\nimport { op } from './operation';\nimport { reshape } from './reshape';\nfunction depthwiseConv2dNativeBackpropInput_(xShape, dy, filter, strides, pad, dilations = [1, 1], dimRoundingMode) {\n    let dy4D = dy;\n    let reshapedTo4D = false;\n    if (dy.rank === 3) {\n        reshapedTo4D = true;\n        dy4D = reshape(dy, [1, dy.shape[0], dy.shape[1], dy.shape[2]]);\n    }\n    const inputs = { dy: dy4D, filter };\n    const attrs = { strides, pad, dimRoundingMode, dilations, inputShape: xShape };\n    const res = \n    // tslint:disable-next-line: no-unnecessary-type-assertion\n    ENGINE.runKernel(DepthwiseConv2dNativeBackpropInput, inputs, attrs);\n    if (reshapedTo4D) {\n        return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);\n    }\n    return res;\n}\nexport const depthwiseConv2dNativeBackpropInput = op({ depthwiseConv2dNativeBackpropInput_ });\n//# sourceMappingURL=depthwise_conv2d_native_backprop_input.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { DepthwiseConv2dNativeBackpropFilter } from '../kernel_names';\nimport { op } from './operation';\nimport { reshape } from './reshape';\nfunction depthwiseConv2dNativeBackpropFilter_(x, dy, filterShape, strides, pad, dilations = [1, 1], dimRoundingMode) {\n    let x4D = x;\n    if (x.rank === 3) {\n        x4D = reshape(x, [1, x.shape[0], x.shape[1], x.shape[2]]);\n    }\n    let dy4D = dy;\n    if (dy4D.rank === 3) {\n        dy4D = reshape(dy, [1, dy.shape[0], dy.shape[1], dy.shape[2]]);\n    }\n    const inputs = { x: x4D, dy: dy4D };\n    const attrs = { strides, pad, dimRoundingMode, dilations, filterShape };\n    // tslint:disable-next-line: no-unnecessary-type-assertion\n    return ENGINE.runKernel(DepthwiseConv2dNativeBackpropFilter, inputs, attrs);\n}\nexport const depthwiseConv2dNativeBackpropFilter = op({ depthwiseConv2dNativeBackpropFilter_ });\n//# sourceMappingURL=depthwise_conv2d_native_backprop_filter.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Add } from '../kernel_names';\nimport { makeTypesMatch } from '../tensor_util';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Adds two `tf.Tensor`s element-wise, A + B. Supports broadcasting.\n *\n *\n * ```js\n * const a = tf.tensor1d([1, 2, 3, 4]);\n * const b = tf.tensor1d([10, 20, 30, 40]);\n *\n * a.add(b).print();  // or tf.add(a, b)\n * ```\n *\n * ```js\n * // Broadcast add a with b.\n * const a = tf.scalar(5);\n * const b = tf.tensor1d([10, 20, 30, 40]);\n *\n * a.add(b).print();  // or tf.add(a, b)\n * ```\n * @param a The first `tf.Tensor` to add.\n * @param b The second `tf.Tensor` to add. Must have the same type as `a`.\n *\n * @doc {heading: 'Operations', subheading: 'Arithmetic'}\n */\nfunction add_(a, b) {\n    let $a = convertToTensor(a, 'a', 'add');\n    let $b = convertToTensor(b, 'b', 'add');\n    [$a, $b] = makeTypesMatch($a, $b);\n    const inputs = { a: $a, b: $b };\n    return ENGINE.runKernel(Add, inputs);\n}\nexport const add = op({ add_ });\n//# sourceMappingURL=add.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n/**\n *\n * @param inputShape Input tensor shape is of the following dimensions:\n *     `[batch, height, width, inChannels]`.\n * @param filterShape The filter shape is of the following dimensions:\n *     `[filterHeight, filterWidth, depth]`.\n * @param strides The strides of the sliding window for each dimension of the\n *     input tensor: `[strideHeight, strideWidth]`.\n *     If `strides` is a single number,\n *     then `strideHeight == strideWidth`.\n * @param pad The type of padding algorithm.\n *    - `same` and stride 1: output will be of same size as input,\n *       regardless of filter size.\n *    - `valid`: output will be smaller than input if filter is larger\n *       than 1*1x1.\n *    - For more info, see this guide:\n *     [https://www.tensorflow.org/api_guides/python/nn#Convolution](\n *          https://www.tensorflow.org/api_guides/python/nn#Convolution)\n * @param dataFormat The data format of the input and output data.\n *     Defaults to 'NHWC'.\n * @param dilations The dilation rates: `[dilationHeight, dilationWidth]`.\n *     Defaults to `[1, 1]`. If `dilations` is a single number, then\n *     `dilationHeight == dilationWidth`.\n */\nexport function computeDilation2DInfo(inputShape, filterShape, strides, pad, dataFormat = 'NHWC', dilations) {\n    // `computerConv2DInfo` require filterShape to be in the dimension of:\n    // `[filterHeight, filterWidth, depth, outDepth]`, dilation2d doesn't have\n    // outDepth, it should have the same depth as the input.\n    // Input shape: [batch, height, width, inChannels]\n    const inputChannels = inputShape[3];\n    const $filterShape = [...filterShape, inputChannels];\n    const $dataFormat = convertConv2DDataFormat(dataFormat);\n    return computeConv2DInfo(inputShape, $filterShape, strides, dilations, pad, null /* roundingMode */, null /* depthWise */, $dataFormat);\n}\nexport function computePool2DInfo(inShape, filterSize, strides, dilations, pad, roundingMode, dataFormat = 'channelsLast') {\n    const [filterHeight, filterWidth] = parseTupleParam(filterSize);\n    let filterShape;\n    if (dataFormat === 'channelsLast') {\n        filterShape = [filterHeight, filterWidth, inShape[3], inShape[3]];\n    }\n    else if (dataFormat === 'channelsFirst') {\n        filterShape = [filterHeight, filterWidth, inShape[1], inShape[1]];\n    }\n    else {\n        throw new Error(`Unknown dataFormat ${dataFormat}`);\n    }\n    return computeConv2DInfo(inShape, filterShape, strides, dilations, pad, roundingMode, false, dataFormat);\n}\n/**\n * Computes the information for a forward pass of a pooling3D operation.\n */\nexport function computePool3DInfo(inShape, filterSize, strides, dilations, pad, roundingMode, dataFormat = 'NDHWC') {\n    const [filterDepth, filterHeight, filterWidth] = parse3TupleParam(filterSize);\n    let filterShape;\n    let $dataFormat;\n    if (dataFormat === 'NDHWC') {\n        $dataFormat = 'channelsLast';\n        filterShape =\n            [filterDepth, filterHeight, filterWidth, inShape[4], inShape[4]];\n    }\n    else if (dataFormat === 'NCDHW') {\n        $dataFormat = 'channelsFirst';\n        filterShape =\n            [filterDepth, filterHeight, filterWidth, inShape[1], inShape[1]];\n    }\n    else {\n        throw new Error(`Unknown dataFormat ${dataFormat}`);\n    }\n    return computeConv3DInfo(inShape, filterShape, strides, dilations, pad, false, $dataFormat, roundingMode);\n}\n/**\n * Computes the information for a forward pass of a convolution/pooling\n * operation.\n */\nexport function computeConv2DInfo(inShape, filterShape, strides, dilations, pad, roundingMode, depthwise = false, dataFormat = 'channelsLast') {\n    let [batchSize, inHeight, inWidth, inChannels] = [-1, -1, -1, -1];\n    if (dataFormat === 'channelsLast') {\n        [batchSize, inHeight, inWidth, inChannels] = inShape;\n    }\n    else if (dataFormat === 'channelsFirst') {\n        [batchSize, inChannels, inHeight, inWidth] = inShape;\n    }\n    else {\n        throw new Error(`Unknown dataFormat ${dataFormat}`);\n    }\n    const [filterHeight, filterWidth, , filterChannels] = filterShape;\n    const [strideHeight, strideWidth] = parseTupleParam(strides);\n    const [dilationHeight, dilationWidth] = parseTupleParam(dilations);\n    const effectiveFilterHeight = getEffectiveFilterSize(filterHeight, dilationHeight);\n    const effectiveFilterWidth = getEffectiveFilterSize(filterWidth, dilationWidth);\n    const { padInfo, outHeight, outWidth } = getPadAndOutInfo(pad, inHeight, inWidth, strideHeight, strideWidth, effectiveFilterHeight, effectiveFilterWidth, roundingMode, dataFormat);\n    const outChannels = depthwise ? filterChannels * inChannels : filterChannels;\n    let outShape;\n    if (dataFormat === 'channelsFirst') {\n        outShape = [batchSize, outChannels, outHeight, outWidth];\n    }\n    else if (dataFormat === 'channelsLast') {\n        outShape = [batchSize, outHeight, outWidth, outChannels];\n    }\n    return {\n        batchSize,\n        dataFormat,\n        inHeight,\n        inWidth,\n        inChannels,\n        outHeight,\n        outWidth,\n        outChannels,\n        padInfo,\n        strideHeight,\n        strideWidth,\n        filterHeight,\n        filterWidth,\n        effectiveFilterHeight,\n        effectiveFilterWidth,\n        dilationHeight,\n        dilationWidth,\n        inShape,\n        outShape,\n        filterShape\n    };\n}\n/**\n * Computes the information for a forward pass of a 3D convolution/pooling\n * operation.\n */\nexport function computeConv3DInfo(inShape, filterShape, strides, dilations, pad, depthwise = false, dataFormat = 'channelsLast', roundingMode) {\n    let [batchSize, inDepth, inHeight, inWidth, inChannels] = [-1, -1, -1, -1, -1];\n    if (dataFormat === 'channelsLast') {\n        [batchSize, inDepth, inHeight, inWidth, inChannels] = inShape;\n    }\n    else if (dataFormat === 'channelsFirst') {\n        [batchSize, inChannels, inDepth, inHeight, inWidth] = inShape;\n    }\n    else {\n        throw new Error(`Unknown dataFormat ${dataFormat}`);\n    }\n    const [filterDepth, filterHeight, filterWidth, , filterChannels] = filterShape;\n    const [strideDepth, strideHeight, strideWidth] = parse3TupleParam(strides);\n    const [dilationDepth, dilationHeight, dilationWidth] = parse3TupleParam(dilations);\n    const effectiveFilterDepth = getEffectiveFilterSize(filterDepth, dilationDepth);\n    const effectiveFilterHeight = getEffectiveFilterSize(filterHeight, dilationHeight);\n    const effectiveFilterWidth = getEffectiveFilterSize(filterWidth, dilationWidth);\n    const { padInfo, outDepth, outHeight, outWidth } = get3DPadAndOutInfo(pad, inDepth, inHeight, inWidth, strideDepth, strideHeight, strideWidth, effectiveFilterDepth, effectiveFilterHeight, effectiveFilterWidth, roundingMode);\n    const outChannels = depthwise ? filterChannels * inChannels : filterChannels;\n    let outShape;\n    if (dataFormat === 'channelsFirst') {\n        outShape = [batchSize, outChannels, outDepth, outHeight, outWidth];\n    }\n    else if (dataFormat === 'channelsLast') {\n        outShape = [batchSize, outDepth, outHeight, outWidth, outChannels];\n    }\n    return {\n        batchSize,\n        dataFormat,\n        inDepth,\n        inHeight,\n        inWidth,\n        inChannels,\n        outDepth,\n        outHeight,\n        outWidth,\n        outChannels,\n        padInfo,\n        strideDepth,\n        strideHeight,\n        strideWidth,\n        filterDepth,\n        filterHeight,\n        filterWidth,\n        effectiveFilterDepth,\n        effectiveFilterHeight,\n        effectiveFilterWidth,\n        dilationDepth,\n        dilationHeight,\n        dilationWidth,\n        inShape,\n        outShape,\n        filterShape\n    };\n}\nfunction computeOutputShape2D(inShape, fieldSize, stride, zeroPad, roundingMode) {\n    if (zeroPad == null) {\n        zeroPad = computeDefaultPad(inShape, fieldSize, stride);\n    }\n    const inputRows = inShape[0];\n    const inputCols = inShape[1];\n    const outputRows = round((inputRows - fieldSize + 2 * zeroPad) / stride + 1, roundingMode);\n    const outputCols = round((inputCols - fieldSize + 2 * zeroPad) / stride + 1, roundingMode);\n    return [outputRows, outputCols];\n}\nfunction computeOutputShape4D(inShape, fieldSize, outChannels, stride, zeroPad, roundingMode) {\n    if (zeroPad == null) {\n        zeroPad = computeDefaultPad(inShape, fieldSize, stride);\n    }\n    const inputDepth = inShape[0];\n    const inputRows = inShape[1];\n    const inputCols = inShape[2];\n    const outputDepths = round((inputDepth - fieldSize + 2 * zeroPad) / stride + 1, roundingMode);\n    const outputRows = round((inputRows - fieldSize + 2 * zeroPad) / stride + 1, roundingMode);\n    const outputCols = round((inputCols - fieldSize + 2 * zeroPad) / stride + 1, roundingMode);\n    return [outputDepths, outputRows, outputCols, outChannels];\n}\nexport function computeDefaultPad(inputShape, fieldSize, stride, dilation = 1) {\n    const effectiveFieldSize = getEffectiveFilterSize(fieldSize, dilation);\n    return Math.floor((inputShape[0] * (stride - 1) - stride + effectiveFieldSize) / 2);\n}\nfunction parseTupleParam(param) {\n    if (typeof param === 'number') {\n        return [param, param, param];\n    }\n    if (param.length === 2) {\n        return [param[0], param[1], 1];\n    }\n    return param;\n}\nfunction parse3TupleParam(param) {\n    return typeof param === 'number' ? [param, param, param] : param;\n}\n/* See https://www.tensorflow.org/api_docs/python/tf/nn/atrous_conv2d\n * Atrous convolution is equivalent to standard convolution with upsampled\n * filters with effective_filter_height =\n * filter_height + (filter_height - 1) * (dilation - 1)\n * and effective_filter_width =\n * filter_width + (filter_width - 1) * (dilation - 1),\n * produced by inserting dilation - 1 zeros along consecutive elements across\n * the filters' spatial dimensions.\n * When there is a dilation, this converts a filter dimension to the\n * effective filter dimension, so it can be used in a standard convolution.\n */\nfunction getEffectiveFilterSize(filterSize, dilation) {\n    if (dilation <= 1) {\n        return filterSize;\n    }\n    return filterSize + (filterSize - 1) * (dilation - 1);\n}\nfunction getPadAndOutInfo(pad, inHeight, inWidth, strideHeight, strideWidth, filterHeight, filterWidth, roundingMode, dataFormat) {\n    let padInfo;\n    let outHeight;\n    let outWidth;\n    if (typeof pad === 'number') {\n        const padType = (pad === 0) ? 'VALID' : 'NUMBER';\n        padInfo = { top: pad, bottom: pad, left: pad, right: pad, type: padType };\n        const outShape = computeOutputShape2D([inHeight, inWidth], filterHeight, strideHeight, pad, roundingMode);\n        outHeight = outShape[0];\n        outWidth = outShape[1];\n    }\n    else if (pad === 'same') {\n        outHeight = Math.ceil(inHeight / strideHeight);\n        outWidth = Math.ceil(inWidth / strideWidth);\n        const padAlongHeight = Math.max(0, (outHeight - 1) * strideHeight + filterHeight - inHeight);\n        const padAlongWidth = Math.max(0, (outWidth - 1) * strideWidth + filterWidth - inWidth);\n        const top = Math.floor(padAlongHeight / 2);\n        const bottom = padAlongHeight - top;\n        const left = Math.floor(padAlongWidth / 2);\n        const right = padAlongWidth - left;\n        padInfo = { top, bottom, left, right, type: 'SAME' };\n    }\n    else if (pad === 'valid') {\n        padInfo = { top: 0, bottom: 0, left: 0, right: 0, type: 'VALID' };\n        outHeight = Math.ceil((inHeight - filterHeight + 1) / strideHeight);\n        outWidth = Math.ceil((inWidth - filterWidth + 1) / strideWidth);\n    }\n    else if (typeof pad === 'object') {\n        const top = dataFormat === 'channelsLast' ? pad[1][0] : pad[2][0];\n        const bottom = dataFormat === 'channelsLast' ? pad[1][1] : pad[2][1];\n        const left = dataFormat === 'channelsLast' ? pad[2][0] : pad[3][0];\n        const right = dataFormat === 'channelsLast' ? pad[2][1] : pad[3][1];\n        const padType = (top === 0 && bottom === 0 && left === 0 && right === 0) ?\n            'VALID' :\n            'EXPLICIT';\n        padInfo = { top, bottom, left, right, type: padType };\n        outHeight = round((inHeight - filterHeight + top + bottom) / strideHeight + 1, roundingMode);\n        outWidth = round((inWidth - filterWidth + left + right) / strideWidth + 1, roundingMode);\n    }\n    else {\n        throw Error(`Unknown padding parameter: ${pad}`);\n    }\n    return { padInfo, outHeight, outWidth };\n}\nfunction get3DPadAndOutInfo(pad, inDepth, inHeight, inWidth, strideDepth, strideHeight, strideWidth, filterDepth, filterHeight, filterWidth, roundingMode) {\n    let padInfo;\n    let outDepth;\n    let outHeight;\n    let outWidth;\n    if (typeof pad === 'number') {\n        const padType = (pad === 0) ? 'VALID' : 'NUMBER';\n        padInfo = {\n            top: pad,\n            bottom: pad,\n            left: pad,\n            right: pad,\n            front: pad,\n            back: pad,\n            type: padType\n        };\n        const outShape = computeOutputShape4D([inDepth, inHeight, inWidth, 1], filterDepth, 1, strideDepth, pad, roundingMode);\n        outDepth = outShape[0];\n        outHeight = outShape[1];\n        outWidth = outShape[2];\n    }\n    else if (pad === 'same') {\n        outDepth = Math.ceil(inDepth / strideDepth);\n        outHeight = Math.ceil(inHeight / strideHeight);\n        outWidth = Math.ceil(inWidth / strideWidth);\n        const padAlongDepth = (outDepth - 1) * strideDepth + filterDepth - inDepth;\n        const padAlongHeight = (outHeight - 1) * strideHeight + filterHeight - inHeight;\n        const padAlongWidth = (outWidth - 1) * strideWidth + filterWidth - inWidth;\n        const front = Math.floor(padAlongDepth / 2);\n        const back = padAlongDepth - front;\n        const top = Math.floor(padAlongHeight / 2);\n        const bottom = padAlongHeight - top;\n        const left = Math.floor(padAlongWidth / 2);\n        const right = padAlongWidth - left;\n        padInfo = { top, bottom, left, right, front, back, type: 'SAME' };\n    }\n    else if (pad === 'valid') {\n        padInfo = {\n            top: 0,\n            bottom: 0,\n            left: 0,\n            right: 0,\n            front: 0,\n            back: 0,\n            type: 'VALID'\n        };\n        outDepth = Math.ceil((inDepth - filterDepth + 1) / strideDepth);\n        outHeight = Math.ceil((inHeight - filterHeight + 1) / strideHeight);\n        outWidth = Math.ceil((inWidth - filterWidth + 1) / strideWidth);\n    }\n    else {\n        throw Error(`Unknown padding parameter: ${pad}`);\n    }\n    return { padInfo, outDepth, outHeight, outWidth };\n}\n/**\n * Rounds a value depending on the rounding mode\n * @param value\n * @param roundingMode A string from: 'ceil', 'round', 'floor'. If none is\n *     provided, it will default to truncate.\n */\nfunction round(value, roundingMode) {\n    if (!roundingMode) {\n        return Math.trunc(value);\n    }\n    switch (roundingMode) {\n        case 'round':\n            // used for Caffe Conv\n            return Math.round(value);\n        case 'ceil':\n            // used for Caffe Pool\n            return Math.ceil(value);\n        case 'floor':\n            return Math.floor(value);\n        default:\n            throw new Error(`Unknown roundingMode ${roundingMode}`);\n    }\n}\nexport function tupleValuesAreOne(param) {\n    const [dimA, dimB, dimC] = parseTupleParam(param);\n    return dimA === 1 && dimB === 1 && dimC === 1;\n}\nexport function eitherStridesOrDilationsAreOne(strides, dilations) {\n    return tupleValuesAreOne(strides) || tupleValuesAreOne(dilations);\n}\n/**\n * Convert Conv2D dataFormat from 'NHWC'|'NCHW' to\n *    'channelsLast'|'channelsFirst'\n * @param dataFormat in 'NHWC'|'NCHW' mode\n * @return dataFormat in 'channelsLast'|'channelsFirst' mode\n * @throws unknown dataFormat\n */\nexport function convertConv2DDataFormat(dataFormat) {\n    if (dataFormat === 'NHWC') {\n        return 'channelsLast';\n    }\n    else if (dataFormat === 'NCHW') {\n        return 'channelsFirst';\n    }\n    else {\n        throw new Error(`Unknown dataFormat ${dataFormat}`);\n    }\n}\n//# sourceMappingURL=conv_util.js.map","import { concat } from './concat';\nimport { op } from './operation';\n/**\n * Concatenates a list of`tf.Tensor2D`s along an axis. See `concat` for details.\n *\n * For example, if:\n * A: shape(2, 3) = | r1, g1, b1 |\n *                  | r2, g2, b2 |\n *\n * B: shape(2, 3) = | r3, g3, b3 |\n *                  | r4, g4, b4 |\n *\n * C = tf.concat2d([A, B], axis)\n *\n * if axis = 0:\n * C: shape(4, 3) = | r1, g1, b1 |\n *                  | r2, g2, b2 |\n *                  | r3, g3, b3 |\n *                  | r4, g4, b4 |\n *\n * if axis = 1:\n * C = shape(2, 6) = | r1, g1, b1, r3, g3, b3 |\n *                   | r2, g2, b2, r4, g4, b4 |\n *\n *\n * @param tensors A list of `tf.Tensor`s to concatenate.\n * @param axis The axis to concatenate along.\n * @return The concatenated array.\n */\nfunction concat2d_(tensors, axis) {\n    return concat(tensors, axis);\n}\nexport const concat2d = op({ concat2d_ });\n//# sourceMappingURL=concat_2d.js.map","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { FromPixels } from '../kernel_names';\nimport { getKernel } from '../kernel_registry';\nimport { Tensor } from '../tensor';\nimport { convertToTensor } from '../tensor_util_env';\nimport { cast } from './cast';\nimport { op } from './operation';\nimport { tensor3d } from './tensor3d';\nlet fromPixels2DContext;\n/**\n * Creates a `tf.Tensor` from an image.\n *\n * ```js\n * const image = new ImageData(1, 1);\n * image.data[0] = 100;\n * image.data[1] = 150;\n * image.data[2] = 200;\n * image.data[3] = 255;\n *\n * tf.browser.fromPixels(image).print();\n * ```\n *\n * @param pixels The input image to construct the tensor from. The\n * supported image types are all 4-channel. You can also pass in an image\n * object with following attributes:\n * `{data: Uint8Array; width: number; height: number}`\n * @param numChannels The number of channels of the output tensor. A\n * numChannels value less than 4 allows you to ignore channels. Defaults to\n * 3 (ignores alpha channel of input image).\n *\n * @doc {heading: 'Browser', namespace: 'browser', ignoreCI: true}\n */\nfunction fromPixels_(pixels, numChannels = 3) {\n    // Sanity checks.\n    if (numChannels > 4) {\n        throw new Error('Cannot construct Tensor with more than 4 channels from pixels.');\n    }\n    if (pixels == null) {\n        throw new Error('pixels passed to tf.browser.fromPixels() can not be null');\n    }\n    let isPixelData = false;\n    let isImageData = false;\n    let isVideo = false;\n    let isImage = false;\n    let isCanvasLike = false;\n    let isImageBitmap = false;\n    if (pixels.data instanceof Uint8Array) {\n        isPixelData = true;\n    }\n    else if (typeof (ImageData) !== 'undefined' && pixels instanceof ImageData) {\n        isImageData = true;\n    }\n    else if (typeof (HTMLVideoElement) !== 'undefined' &&\n        pixels instanceof HTMLVideoElement) {\n        isVideo = true;\n    }\n    else if (typeof (HTMLImageElement) !== 'undefined' &&\n        pixels instanceof HTMLImageElement) {\n        isImage = true;\n        // tslint:disable-next-line: no-any\n    }\n    else if (pixels.getContext != null) {\n        isCanvasLike = true;\n    }\n    else if (typeof (ImageBitmap) !== 'undefined' &&\n        pixels instanceof ImageBitmap) {\n        isImageBitmap = true;\n    }\n    else {\n        throw new Error('pixels passed to tf.browser.fromPixels() must be either an ' +\n            `HTMLVideoElement, HTMLImageElement, HTMLCanvasElement, ImageData ` +\n            `in browser, or OffscreenCanvas, ImageData in webworker` +\n            ` or {data: Uint32Array, width: number, height: number}, ` +\n            `but was ${pixels.constructor.name}`);\n    }\n    if (isVideo) {\n        const HAVE_CURRENT_DATA_READY_STATE = 2;\n        if (isVideo &&\n            pixels.readyState <\n                HAVE_CURRENT_DATA_READY_STATE) {\n            throw new Error('The video element has not loaded data yet. Please wait for ' +\n                '`loadeddata` event on the <video> element.');\n        }\n    }\n    // If the current backend has 'FromPixels' registered, it has a more\n    // efficient way of handling pixel uploads, so we call that.\n    const kernel = getKernel(FromPixels, ENGINE.backendName);\n    if (kernel != null) {\n        const inputs = { pixels };\n        const attrs = { numChannels };\n        return ENGINE.runKernel(FromPixels, inputs, attrs);\n    }\n    const [width, height] = isVideo ?\n        [\n            pixels.videoWidth,\n            pixels.videoHeight\n        ] :\n        [pixels.width, pixels.height];\n    let vals;\n    if (isCanvasLike) {\n        vals =\n            // tslint:disable-next-line:no-any\n            pixels.getContext('2d').getImageData(0, 0, width, height).data;\n    }\n    else if (isImageData || isPixelData) {\n        vals = pixels.data;\n    }\n    else if (isImage || isVideo || isImageBitmap) {\n        if (fromPixels2DContext == null) {\n            fromPixels2DContext = document.createElement('canvas').getContext('2d');\n        }\n        fromPixels2DContext.canvas.width = width;\n        fromPixels2DContext.canvas.height = height;\n        fromPixels2DContext.drawImage(pixels, 0, 0, width, height);\n        vals = fromPixels2DContext.getImageData(0, 0, width, height).data;\n    }\n    let values;\n    if (numChannels === 4) {\n        values = new Int32Array(vals);\n    }\n    else {\n        const numPixels = width * height;\n        values = new Int32Array(numPixels * numChannels);\n        for (let i = 0; i < numPixels; i++) {\n            for (let channel = 0; channel < numChannels; ++channel) {\n                values[i * numChannels + channel] = vals[i * 4 + channel];\n            }\n        }\n    }\n    const outShape = [height, width, numChannels];\n    return tensor3d(values, outShape, 'int32');\n}\n/**\n * Draws a `tf.Tensor` of pixel values to a byte array or optionally a\n * canvas.\n *\n * When the dtype of the input is 'float32', we assume values in the range\n * [0-1]. Otherwise, when input is 'int32', we assume values in the range\n * [0-255].\n *\n * Returns a promise that resolves when the canvas has been drawn to.\n *\n * @param img A rank-2 or rank-3 tensor. If rank-2, draws grayscale. If\n *     rank-3, must have depth of 1, 3 or 4. When depth of 1, draws\n * grayscale. When depth of 3, we draw with the first three components of\n * the depth dimension corresponding to r, g, b and alpha = 1. When depth of\n * 4, all four components of the depth dimension correspond to r, g, b, a.\n * @param canvas The canvas to draw to.\n *\n * @doc {heading: 'Browser', namespace: 'browser'}\n */\nexport async function toPixels(img, canvas) {\n    let $img = convertToTensor(img, 'img', 'toPixels');\n    if (!(img instanceof Tensor)) {\n        // Assume int32 if user passed a native array.\n        const originalImgTensor = $img;\n        $img = cast(originalImgTensor, 'int32');\n        originalImgTensor.dispose();\n    }\n    if ($img.rank !== 2 && $img.rank !== 3) {\n        throw new Error(`toPixels only supports rank 2 or 3 tensors, got rank ${$img.rank}.`);\n    }\n    const [height, width] = $img.shape.slice(0, 2);\n    const depth = $img.rank === 2 ? 1 : $img.shape[2];\n    if (depth > 4 || depth === 2) {\n        throw new Error(`toPixels only supports depth of size ` +\n            `1, 3 or 4 but got ${depth}`);\n    }\n    if ($img.dtype !== 'float32' && $img.dtype !== 'int32') {\n        throw new Error(`Unsupported type for toPixels: ${$img.dtype}.` +\n            ` Please use float32 or int32 tensors.`);\n    }\n    const data = await $img.data();\n    const multiplier = $img.dtype === 'float32' ? 255 : 1;\n    const bytes = new Uint8ClampedArray(width * height * 4);\n    for (let i = 0; i < height * width; ++i) {\n        const rgba = [0, 0, 0, 255];\n        for (let d = 0; d < depth; d++) {\n            const value = data[i * depth + d];\n            if ($img.dtype === 'float32') {\n                if (value < 0 || value > 1) {\n                    throw new Error(`Tensor values for a float32 Tensor must be in the ` +\n                        `range [0 - 1] but encountered ${value}.`);\n                }\n            }\n            else if ($img.dtype === 'int32') {\n                if (value < 0 || value > 255) {\n                    throw new Error(`Tensor values for a int32 Tensor must be in the ` +\n                        `range [0 - 255] but encountered ${value}.`);\n                }\n            }\n            if (depth === 1) {\n                rgba[0] = value * multiplier;\n                rgba[1] = value * multiplier;\n                rgba[2] = value * multiplier;\n            }\n            else {\n                rgba[d] = value * multiplier;\n            }\n        }\n        const j = i * 4;\n        bytes[j + 0] = Math.round(rgba[0]);\n        bytes[j + 1] = Math.round(rgba[1]);\n        bytes[j + 2] = Math.round(rgba[2]);\n        bytes[j + 3] = Math.round(rgba[3]);\n    }\n    if (canvas != null) {\n        canvas.width = width;\n        canvas.height = height;\n        const ctx = canvas.getContext('2d');\n        const imageData = new ImageData(bytes, width, height);\n        ctx.putImageData(imageData, 0, 0);\n    }\n    if ($img !== img) {\n        $img.dispose();\n    }\n    return bytes;\n}\nexport const fromPixels = op({ fromPixels_ });\n//# sourceMappingURL=browser.js.map","/**\n * @license\n * Copyright 2017 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport * as util from '../util';\nexport function assertParamsConsistent(shapes, axis) {\n    const rank = shapes[0].length;\n    shapes.forEach((shape, i) => {\n        util.assert(shape.length === rank, () => `Error in concat${rank}D: rank of tensors[${i}] must be the same ` +\n            `as the rank of the rest (${rank})`);\n    });\n    util.assert(axis >= 0 && axis < rank, () => `Error in concat${rank}D: axis must be between 0 and ${rank - 1}.`);\n    const firstShape = shapes[0];\n    shapes.forEach((shape, i) => {\n        for (let r = 0; r < rank; r++) {\n            util.assert((r === axis) || (shape[r] === firstShape[r]), () => `Error in concat${rank}D: Shape of tensors[${i}] (${shape}) ` +\n                `does not match the shape of the rest (${firstShape}) ` +\n                `along the non-concatenated axis ${i}.`);\n        }\n    });\n}\nexport function computeOutShape(shapes, axis) {\n    const outputShape = shapes[0].slice();\n    for (let i = 1; i < shapes.length; i++) {\n        outputShape[axis] += shapes[i][axis];\n    }\n    return outputShape;\n}\n//# sourceMappingURL=concat_util.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n/**\n * Gets the new shape of the input Tensor after it's been reshaped\n * to:\n * [blockShape[0], ..., blockShape[M-1], batch / prod(blockShape),\n * inputShape[1], ..., inputShape[N-1]]\n *\n * See step 1: https://www.tensorflow.org/api_docs/python/tf/batch_to_space_nd\n */\nexport function getReshaped(inputShape, blockShape, prod, batchToSpace = true) {\n    let reshaped = [];\n    if (batchToSpace) {\n        reshaped = reshaped.concat(blockShape.slice(0));\n        reshaped.push(inputShape[0] / prod);\n        reshaped = reshaped.concat(inputShape.slice(1));\n    }\n    else {\n        reshaped = reshaped.concat(inputShape[0]);\n        const spatialLength = blockShape.length;\n        for (let i = 0; i < spatialLength; ++i) {\n            reshaped =\n                reshaped.concat([inputShape[i + 1] / blockShape[i], blockShape[i]]);\n        }\n        reshaped = reshaped.concat(inputShape.slice(spatialLength + 1));\n    }\n    return reshaped;\n}\n/**\n * Gets the permutation that will transpose the dimensions of the\n * reshaped tensor to shape:\n *\n * [batch / prod(block_shape),inputShape[1], blockShape[0], ...,\n * inputShape[M], blockShape[M-1],inputShape[M+1], ..., inputShape[N-1]]\n *\n * see step 2: https://www.tensorflow.org/api_docs/python/tf/batch_to_space_nd\n */\nexport function getPermuted(reshapedRank, blockShapeRank, batchToSpace = true) {\n    const permuted = [];\n    if (batchToSpace) {\n        permuted.push(blockShapeRank);\n        for (let i = blockShapeRank + 1; i < reshapedRank; ++i) {\n            if (i <= 2 * blockShapeRank) {\n                permuted.push(i);\n                permuted.push(i - (blockShapeRank + 1));\n            }\n            else {\n                permuted.push(i);\n            }\n        }\n    }\n    else {\n        const permutedBeforeBatch = [];\n        const permutedAfterBatch = [];\n        for (let i = 1; i < reshapedRank; ++i) {\n            if (i >= blockShapeRank * 2 + 1 || i % 2 === 1) {\n                permutedAfterBatch.push(i);\n            }\n            else {\n                permutedBeforeBatch.push(i);\n            }\n        }\n        permuted.push(...permutedBeforeBatch);\n        permuted.push(0);\n        permuted.push(...permutedAfterBatch);\n    }\n    return permuted;\n}\n/**\n * Gets the shape of the reshaped and permuted input Tensor before any cropping\n * is applied.  The new shape will be:\n *\n * [batch / prod(blockShape),inputShape[1] * blockShape[0], ...,\n * inputShape[M] * blockShape[M-1],inputShape[M+1], ..., inputShape[N-1]]\n *\n * See step 3: https://www.tensorflow.org/api_docs/python/tf/batch_to_space_nd\n */\nexport function getReshapedPermuted(inputShape, blockShape, prod, batchToSpace = true) {\n    const reshapedPermuted = [];\n    if (batchToSpace) {\n        reshapedPermuted.push(inputShape[0] / prod);\n    }\n    else {\n        reshapedPermuted.push(inputShape[0] * prod);\n    }\n    for (let i = 1; i < inputShape.length; ++i) {\n        if (i <= blockShape.length) {\n            if (batchToSpace) {\n                reshapedPermuted.push(blockShape[i - 1] * inputShape[i]);\n            }\n            else {\n                reshapedPermuted.push(inputShape[i] / blockShape[i - 1]);\n            }\n        }\n        else {\n            reshapedPermuted.push(inputShape[i]);\n        }\n    }\n    return reshapedPermuted;\n}\n/**\n * Converts the crops argument into the beginning coordinates of a slice\n * operation.\n */\nexport function getSliceBeginCoords(crops, blockShape) {\n    const sliceBeginCoords = [0];\n    for (let i = 0; i < blockShape; ++i) {\n        sliceBeginCoords.push(crops[i][0]);\n    }\n    return sliceBeginCoords;\n}\n/**\n * Converts the crops argument into the size of a slice operation.  When\n * combined with getSliceBeginCoords this function allows the reshaped and\n * permuted Tensor to be cropped to its final output shape of:\n *\n * inputShape[1] * blockShape[0] - crops[0,0] - crops[0,1], ...,\n * inputShape[M] * blockShape[M-1] -crops[M-1,0] -\n * crops[M-1,1],inputShape[M+1], ..., inputShape[N-1]]\n *\n * See step 4: https://www.tensorflow.org/api_docs/python/tf/batch_to_space_nd\n */\nexport function getSliceSize(uncroppedShape, crops, blockShape) {\n    const sliceSize = uncroppedShape.slice(0, 1);\n    for (let i = 0; i < blockShape; ++i) {\n        sliceSize.push(uncroppedShape[i + 1] - crops[i][0] - crops[i][1]);\n    }\n    return sliceSize;\n}\n//# sourceMappingURL=array_ops_util.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nexport const ERF_P = 0.3275911;\nexport const ERF_A1 = 0.254829592;\nexport const ERF_A2 = -0.284496736;\nexport const ERF_A3 = 1.421413741;\nexport const ERF_A4 = -1.453152027;\nexport const ERF_A5 = 1.061405429;\n//# sourceMappingURL=erf_util.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { env } from './environment';\nexport function warn(...msg) {\n    if (!env().getBool('IS_TEST')) {\n        console.warn(...msg);\n    }\n}\nexport function log(...msg) {\n    if (!env().getBool('IS_TEST')) {\n        console.log(...msg);\n    }\n}\n//# sourceMappingURL=log.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Acos } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes acos of the input `tf.Tensor` element-wise: `acos(x)`\n *\n * ```js\n * const x = tf.tensor1d([0, 1, -1, .7]);\n *\n * x.acos().print();  // or tf.acos(x)\n * ```\n * @param x The input tensor.\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction acos_(x) {\n    const $x = convertToTensor(x, 'x', 'acos');\n    const inputs = { x: $x };\n    return ENGINE.runKernel(Acos, inputs);\n}\nexport const acos = op({ acos_ });\n//# sourceMappingURL=acos.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Acosh } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes the inverse hyperbolic cos of the input `tf.Tensor` element-wise:\n * `acosh(x)`\n *\n * ```js\n * const x = tf.tensor1d([10, 1, 3, 5.7]);\n *\n * x.acosh().print();  // or tf.acosh(x)\n * ```\n * @param x The input tensor.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction acosh_(x) {\n    const $x = convertToTensor(x, 'x', 'acosh');\n    const inputs = { x: $x };\n    return ENGINE.runKernel(Acosh, inputs);\n}\nexport const acosh = op({ acosh_ });\n//# sourceMappingURL=acosh.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { deprecationWarn } from '../globals';\nimport { convertToTensor } from '../tensor_util_env';\nimport * as util from '../util';\nimport { add } from './add';\nimport { div } from './div';\nimport { maximum } from './maximum';\nimport { minimum } from './minimum';\nimport { mod } from './mod';\nimport { mul } from './mul';\nimport { op } from './operation';\nimport { pow } from './pow';\nimport { squaredDifference } from './squared_difference';\nimport { sub } from './sub';\n/**\n * @deprecated\n * Adds two `tf.Tensor`s element-wise, A + B.\n *\n * Inputs must be the same shape. For broadcasting support, use add() instead.\n *\n * @param a The first Tensor to add element-wise.\n * @param b The second Tensor to add element-wise.\n */\nfunction addStrict_(a, b) {\n    deprecationWarn('strict variants of ops have been deprecated ' +\n        'and will be removed in future');\n    const $a = convertToTensor(a, 'a', 'addStrict');\n    const $b = convertToTensor(b, 'b', 'addStrict');\n    util.assertShapesMatch($a.shape, $b.shape, 'Error in addStrict: ');\n    return add($a, $b);\n}\n/**\n * @deprecated\n * Subtracts two `tf.Tensor`s element-wise, A - B. Inputs must\n * be the same shape.\n *\n * For broadcasting support, use `tf.sub` instead.\n *\n * @param a The first Tensor to subtract element-wise.\n * @param b The second Tensor to subtract element-wise.\n */\nfunction subStrict_(a, b) {\n    deprecationWarn('strict variants of ops have been deprecated ' +\n        'and will be removed in future');\n    const $a = convertToTensor(a, 'a', 'subStrict');\n    const $b = convertToTensor(b, 'b', 'subStrict');\n    util.assertShapesMatch($a.shape, $b.shape, 'Error in subStrict: ');\n    return sub($a, $b);\n}\n/**\n * @deprecated\n * Computes the power of one `tf.Tensor` to another. Inputs must\n * be the same shape.\n *\n * For broadcasting support, use `tf.pow` instead.\n *\n * @param base The base tensor to pow element-wise.\n * @param exp The exponent tensor to pow element-wise.\n */\nfunction powStrict_(base, exp) {\n    deprecationWarn('strict variants of ops have been deprecated ' +\n        'and will be removed in future');\n    util.assertShapesMatch(base.shape, exp.shape, 'Error in powStrict: ');\n    return pow(base, exp);\n}\n/**\n * @deprecated\n * Multiplies two `tf.Tensor`s element-wise, A * B.\n *\n * Inputs must be the same shape. For broadcasting support, use `tf.mul`.\n *\n * @param a The first tensor to multiply.\n * @param b The first tensor to multiply. Must have the same\n *    dtype as `a`.\n */\nfunction mulStrict_(a, b) {\n    deprecationWarn('strict variants of ops have been deprecated ' +\n        'and will be removed in future');\n    const $a = convertToTensor(a, 'a', 'mul');\n    const $b = convertToTensor(b, 'b', 'mul');\n    util.assertShapesMatch($a.shape, $b.shape, 'Error in multiplyStrict: ');\n    return mul($a, $b);\n}\n/**\n * @deprecated\n * Divides two `tf.Tensor`s element-wise, A / B. Inputs must\n * be the same shape.\n *\n * @param a The first tensor as the numerator for element-wise division.\n * @param b The second tensor as the denominator for element-wise division.\n */\nfunction divStrict_(a, b) {\n    deprecationWarn('strict variants of ops have been deprecated ' +\n        'and will be removed in future');\n    const $a = convertToTensor(a, 'a', 'div');\n    const $b = convertToTensor(b, 'b', 'div');\n    util.assertShapesMatch($a.shape, $b.shape, 'Error in divideStrict: ');\n    return div($a, $b);\n}\n/**\n * @deprecated\n * Returns the mod of a and b (`a < b ? a : b`) element-wise. Inputs must\n * be the same shape. For broadcasting support, use mod().\n *\n * @param a The first tensor.\n * @param b The second tensor. Must have the same dtype as `a`.\n */\nfunction modStrict_(a, b) {\n    deprecationWarn('strict variants of ops have been deprecated ' +\n        'and will be removed in future');\n    const $a = convertToTensor(a, 'a', 'modStrict');\n    const $b = convertToTensor(b, 'b', 'modStrict');\n    util.assertShapesMatch($a.shape, $b.shape, 'Error in modStrict: ');\n    return mod($a, $b);\n}\n/**\n * @deprecated\n * Returns the min of a and b (`a < b ? a : b`) element-wise. Inputs must\n * be the same shape. For broadcasting support, use minimum().\n *\n * @param a The first tensor.\n * @param b The second tensor. Must have the same dtype as `a`.\n */\nfunction minimumStrict_(a, b) {\n    deprecationWarn('strict variants of ops have been deprecated ' +\n        'and will be removed in future');\n    const $a = convertToTensor(a, 'a', 'minimumStrict');\n    const $b = convertToTensor(b, 'b', 'minimumStrict');\n    util.assertShapesMatch($a.shape, $b.shape, 'Error in minimumStrict: ');\n    return minimum($a, $b);\n}\n/**\n * @deprecated\n * Returns the max of a and b (`a > b ? a : b`) element-wise. Inputs must\n * be the same shape. For broadcasting support, use maximum().\n *\n * @param a The first tensor.\n * @param b The second tensor. Must have the same dtype as `a`.\n */\nfunction maximumStrict_(a, b) {\n    deprecationWarn('strict variants of ops have been deprecated ' +\n        'and will be removed in future');\n    const $a = convertToTensor(a, 'a', 'maximumStrict');\n    const $b = convertToTensor(b, 'b', 'maximumStrict');\n    util.assertShapesMatch($a.shape, $b.shape, 'Error in maximumStrict: ');\n    return maximum($a, $b);\n}\n/**\n * @deprecated\n * Returns (a - b) * (a - b) element-wise.\n *\n * Inputs must be the same shape. For broadcasting support, use\n * `tf.squaredDifference` instead.\n *\n * @param a The first tensor.\n * @param b The second tensor. Must have the same type as `a`.\n */\nfunction squaredDifferenceStrict_(a, b) {\n    deprecationWarn('strict variants of ops have been deprecated ' +\n        'and will be removed in future');\n    const $a = convertToTensor(a, 'a', 'squaredDifferenceStrict');\n    const $b = convertToTensor(b, 'b', 'squaredDifferenceStrict');\n    util.assertShapesMatch($a.shape, $b.shape, 'Error in squaredDifferenceStrict: ');\n    return squaredDifference($a, $b);\n}\nexport const addStrict = op({ addStrict_ });\nexport const divStrict = op({ divStrict_ });\nexport const maximumStrict = op({ maximumStrict_ });\nexport const minimumStrict = op({ minimumStrict_ });\nexport const modStrict = op({ modStrict_ });\nexport const mulStrict = op({ mulStrict_ });\nexport const powStrict = op({ powStrict_ });\nexport const squaredDifferenceStrict = op({ squaredDifferenceStrict_ });\nexport const subStrict = op({ subStrict_ });\n//# sourceMappingURL=binary_ops.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Asin } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes asin of the input `tf.Tensor` element-wise: `asin(x)`\n *\n * ```js\n * const x = tf.tensor1d([0, 1, -1, .7]);\n *\n * x.asin().print();  // or tf.asin(x)\n * ```\n * @param x The input tensor.\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction asin_(x) {\n    const $x = convertToTensor(x, 'x', 'asin');\n    const inputs = { x: $x };\n    return ENGINE.runKernel(Asin, inputs);\n}\nexport const asin = op({ asin_ });\n//# sourceMappingURL=asin.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Asinh } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes inverse hyperbolic sin of the input `tf.Tensor` element-wise:\n * `asinh(x)`\n *\n * ```js\n * const x = tf.tensor1d([0, 1, -1, .7]);\n *\n * x.asinh().print();  // or tf.asinh(x)\n * ```\n * @param x The input tensor.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction asinh_(x) {\n    const $x = convertToTensor(x, 'x', 'asinh');\n    const inputs = { x: $x };\n    return ENGINE.runKernel(Asinh, inputs);\n}\nexport const asinh = op({ asinh_ });\n//# sourceMappingURL=asinh.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Atan } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes atan of the input `tf.Tensor` element-wise: `atan(x)`\n *\n * ```js\n * const x = tf.tensor1d([0, 1, -1, .7]);\n *\n * x.atan().print();  // or tf.atan(x)\n * ```\n * @param x The input tensor.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction atan_(x) {\n    const $x = convertToTensor(x, 'x', 'atan');\n    const inputs = { x: $x };\n    return ENGINE.runKernel(Atan, inputs);\n}\nexport const atan = op({ atan_ });\n//# sourceMappingURL=atan.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Atanh } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes inverse hyperbolic tan of the input `tf.Tensor` element-wise:\n * `atanh(x)`\n *\n * ```js\n * const x = tf.tensor1d([0, .1, -.1, .7]);\n *\n * x.atanh().print();  // or tf.atanh(x)\n * ```\n * @param x The input tensor.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction atanh_(x) {\n    const $x = convertToTensor(x, 'x', 'atanh');\n    const inputs = { x: $x };\n    return ENGINE.runKernel(Atanh, inputs);\n}\nexport const atanh = op({ atanh_ });\n//# sourceMappingURL=atanh.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Ceil } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes ceiling of input `tf.Tensor` element-wise: `ceil(x)`\n *\n * ```js\n * const x = tf.tensor1d([.6, 1.1, -3.3]);\n *\n * x.ceil().print();  // or tf.ceil(x)\n * ```\n * @param x The input Tensor.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction ceil_(x) {\n    const $x = convertToTensor(x, 'x', 'ceil');\n    const inputs = { x: $x };\n    return ENGINE.runKernel(Ceil, inputs);\n}\nexport const ceil = op({ ceil_ });\n//# sourceMappingURL=ceil.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { ClipByValue } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport * as util from '../util';\nimport { op } from './operation';\n/**\n * Clips values element-wise. `max(min(x, clipValueMax), clipValueMin)`\n *\n * ```js\n * const x = tf.tensor1d([-1, 2, -3, 4]);\n *\n * x.clipByValue(-2, 3).print();  // or tf.clipByValue(x, -2, 3)\n * ```\n * @param x The input tensor.\n * @param clipValueMin Lower-bound of range to be clipped to.\n * @param clipValueMax Upper-bound of range to be clipped to.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction clipByValue_(x, clipValueMin, clipValueMax) {\n    const $x = convertToTensor(x, 'x', 'clipByValue');\n    util.assert((clipValueMin <= clipValueMax), () => `Error in clip: min (${clipValueMin}) must be ` +\n        `less than or equal to max (${clipValueMax}).`);\n    const inputs = { x: $x };\n    const attrs = { clipValueMin, clipValueMax };\n    return ENGINE.runKernel(ClipByValue, inputs, attrs);\n}\nexport const clipByValue = op({ clipByValue_ });\n//# sourceMappingURL=clip_by_value.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { deprecationWarn } from '../globals';\nimport { convertToTensor } from '../tensor_util_env';\nimport { assertShapesMatch } from '../util';\nimport { equal } from './equal';\nimport { greater } from './greater';\nimport { greaterEqual } from './greater_equal';\nimport { less } from './less';\nimport { lessEqual } from './less_equal';\nimport { notEqual } from './not_equal';\nimport { op } from './operation';\n/**\n * @deprecated\n * Strict version of `tf.notEqual` that forces `a` and `b` to be of the same\n * shape.\n *\n * @param a The first input tensor.\n * @param b The second input tensor. Must have the same shape and dtype as\n *     `a`.\n */\nfunction notEqualStrict_(a, b) {\n    deprecationWarn('strict variants of ops have been deprecated ' +\n        'and will be removed in future');\n    const $a = convertToTensor(a, 'a', 'notEqualStrict');\n    const $b = convertToTensor(b, 'b', 'notEqualStrict');\n    assertShapesMatch($a.shape, $b.shape, 'Error in notEqualStrict: ');\n    return notEqual($a, $b);\n}\n/**\n * @deprecated\n * Strict version of `tf.less` that forces `a` and `b` to be of the same\n * shape.\n *\n * @param a The first input tensor.\n * @param b The second input tensor. Must have the same shape and dtype as\n *     `a`.\n */\nfunction lessStrict_(a, b) {\n    deprecationWarn('strict variants of ops have been deprecated ' +\n        'and will be removed in future');\n    const $a = convertToTensor(a, 'a', 'lessStrict');\n    const $b = convertToTensor(b, 'b', 'lessStrict');\n    assertShapesMatch($a.shape, $b.shape, 'Error in lessStrict: ');\n    return less($a, $b);\n}\nfunction equalStrict_(a, b) {\n    deprecationWarn('strict variants of ops have been deprecated ' +\n        'and will be removed in future');\n    const $a = convertToTensor(a, 'a', 'equalStrict');\n    const $b = convertToTensor(b, 'b', 'equalStrict');\n    assertShapesMatch($a.shape, $b.shape, 'Error in equalStrict: ');\n    return equal($a, $b);\n}\nfunction lessEqualStrict_(a, b) {\n    deprecationWarn('strict variants of ops have been deprecated ' +\n        'and will be removed in future');\n    const $a = convertToTensor(a, 'a', 'lessEqualStrict');\n    const $b = convertToTensor(b, 'b', 'lessEqualStrict');\n    assertShapesMatch($a.shape, $b.shape, 'Error in lessEqualStrict: ');\n    return lessEqual($a, $b);\n}\nfunction greaterStrict_(a, b) {\n    deprecationWarn('strict variants of ops have been deprecated ' +\n        'and will be removed in future');\n    const $a = convertToTensor(a, 'a', 'greaterStrict');\n    const $b = convertToTensor(b, 'b', 'greaterStrict');\n    assertShapesMatch($a.shape, $b.shape, 'Error in greaterStrict: ');\n    return greater($a, $b);\n}\nfunction greaterEqualStrict_(a, b) {\n    deprecationWarn('strict variants of ops have been deprecated ' +\n        'and will be removed in future');\n    const $a = convertToTensor(a, 'a', 'greaterEqualStrict');\n    const $b = convertToTensor(b, 'b', 'greaterEqualStrict');\n    assertShapesMatch($a.shape, $b.shape, 'Error in greaterEqualStrict: ');\n    return greaterEqual($a, $b);\n}\nexport const equalStrict = op({ equalStrict_ });\nexport const greaterEqualStrict = op({ greaterEqualStrict_ });\nexport const greaterStrict = op({ greaterStrict_ });\nexport const lessEqualStrict = op({ lessEqualStrict_ });\nexport const lessStrict = op({ lessStrict_ });\nexport const notEqualStrict = op({ notEqualStrict_ });\n//# sourceMappingURL=compare.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Erf } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport * as util from '../util';\nimport { cast } from './cast';\nimport { op } from './operation';\n/**\n * Computes gause error function of the input `tf.Tensor` element-wise:\n * `erf(x)`\n *\n * ```js\n * const x = tf.tensor1d([0, .1, -.1, .7]);\n *\n * x.erf().print(); // or tf.erf(x);\n * ```\n * @param x The input tensor.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction erf_(x) {\n    let $x = convertToTensor(x, 'x', 'erf');\n    util.assert($x.dtype === 'int32' || $x.dtype === 'float32', () => 'Input dtype must be `int32` or `float32`.');\n    if ($x.dtype === 'int32') {\n        $x = cast($x, 'float32');\n    }\n    const inputs = { x: $x };\n    return ENGINE.runKernel(Erf, inputs);\n}\nexport const erf = op({ erf_ });\n//# sourceMappingURL=erf.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Expm1 } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes exponential of the input `tf.Tensor` minus one element-wise.\n * `e ^ x - 1`\n *\n * ```js\n * const x = tf.tensor1d([1, 2, -3]);\n *\n * x.expm1().print();  // or tf.expm1(x)\n * ```\n * @param x The input tensor.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction expm1_(x) {\n    const $x = convertToTensor(x, 'x', 'expm1');\n    const inputs = { x: $x };\n    return ENGINE.runKernel(Expm1, inputs);\n}\nexport const expm1 = op({ expm1_ });\n//# sourceMappingURL=expm1.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Concat } from '../kernel_names';\nimport { convertToTensorArray } from '../tensor_util_env';\nimport { assert } from '../util';\nimport { clone } from './clone';\nimport { op } from './operation';\n/**\n * Concatenates a list of `tf.Tensor`s along a given axis.\n *\n * The tensors ranks and types must match, and their sizes must match in all\n * dimensions except `axis`.\n *\n * Also available are stricter rank-specific methods that assert that\n * `tensors` are of the given rank:\n *   - `tf.concat1d`\n *   - `tf.concat2d`\n *   - `tf.concat3d`\n *   - `tf.concat4d`\n *\n * Except `tf.concat1d` (which does not have axis param), all methods have\n * same signature as this method.\n *\n * ```js\n * const a = tf.tensor1d([1, 2]);\n * const b = tf.tensor1d([3, 4]);\n * a.concat(b).print();  // or a.concat(b)\n * ```\n *\n * ```js\n * const a = tf.tensor1d([1, 2]);\n * const b = tf.tensor1d([3, 4]);\n * const c = tf.tensor1d([5, 6]);\n * tf.concat([a, b, c]).print();\n * ```\n *\n * ```js\n * const a = tf.tensor2d([[1, 2], [10, 20]]);\n * const b = tf.tensor2d([[3, 4], [30, 40]]);\n * const axis = 1;\n * tf.concat([a, b], axis).print();\n * ```\n * @param tensors A list of tensors to concatenate.\n * @param axis The axis to concate along. Defaults to 0 (the first dim).\n *\n * @doc {heading: 'Tensors', subheading: 'Slicing and Joining'}\n */\nfunction concat_(tensors, axis = 0) {\n    assert(tensors.length >= 1, () => 'Pass at least one tensor to concat');\n    const $tensors = convertToTensorArray(tensors, 'tensors', 'concat', 'string_or_numeric');\n    if ($tensors[0].dtype === 'complex64') {\n        $tensors.forEach(tensor => {\n            if (tensor.dtype !== 'complex64') {\n                throw new Error(`Cannot concatenate complex64 tensors with a tensor\n          with dtype ${tensor.dtype}. `);\n            }\n        });\n    }\n    if ($tensors.length === 1) {\n        return clone($tensors[0]);\n    }\n    const inputs = $tensors;\n    const attr = { axis };\n    return ENGINE.runKernel(Concat, inputs, attr);\n}\nexport const concat = op({ concat_ });\n//# sourceMappingURL=concat.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { AvgPool3DGrad } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport * as util from '../util';\nimport * as conv_util from './conv_util';\nimport { op } from './operation';\nimport { reshape } from './reshape';\n/**\n * Computes the backprop of a 3d avg pool.\n *\n * @param dy The dy error, of rank 5 of shape\n *     [batchSize, depth, height, width, channels].\n * assumed.\n * @param input The original input image, of rank 5 or rank4 of shape\n *     [batchSize, depth, height, width, channels].\n * @param filterSize The filter size:\n *     `[filterDepth, filterHeight, filterWidth]`.\n *     `filterSize` is a single number,\n *     then `filterDepth == filterHeight == filterWidth`.\n * @param strides The strides of the pooling:\n *     `[strideDepth, strideHeight, strideWidth]`. If\n *     `strides` is a single number, then `strideHeight == strideWidth`.\n * @param dilations Deprecated, this field will be gone in v3.0.0. The dilation\n *     rates: `[dilationDepth, dilationHeight, dilationWidth]`\n *     in which we sample input values across the depth, height and width\n *     dimensions in dilated pooling.\n *     Defaults to `[1, 1, 1]`. If `dilations` is a single number,\n *     then `dilationDepth == dilationHeight == dilationWidth`.\n *     If it is greater than 1, then all values of `strides` must be 1.\n * @param pad A string from: 'same', 'valid'. The type of padding algorithm\n *     used in the forward prop of the op.\n * @param dimRoundingMode A string from: 'ceil', 'round', 'floor'. If none is\n *     provided, it will default to truncate.\n */\nfunction avgPool3dGrad_(dy, input, filterSize, strides, dilations = [1, 1, 1], pad, dimRoundingMode) {\n    const $dy = convertToTensor(dy, 'dy', 'avgPool3dGrad');\n    const $input = convertToTensor(input, 'input', 'avgPool3dGrad');\n    let dy5D = $dy;\n    let input5D = $input;\n    let reshapedTo5D = false;\n    if ($input.rank === 4) {\n        reshapedTo5D = true;\n        dy5D = reshape($dy, [1, $dy.shape[0], $dy.shape[1], $dy.shape[2], $dy.shape[3]]);\n        input5D = reshape($input, [\n            1, $input.shape[0], $input.shape[1], $input.shape[2], $input.shape[3]\n        ]);\n    }\n    util.assert(dy5D.rank === 5, () => `Error in avgPool3dGrad: dy must be rank 5 but got rank ` +\n        `${dy5D.rank}.`);\n    util.assert(input5D.rank === 5, () => `Error in avgPool3dGrad: input must be rank 5 but got rank ` +\n        `${input5D.rank}.`);\n    util.assert(conv_util.eitherStridesOrDilationsAreOne(strides, dilations), () => 'Error in avgPool3dGrad: Either strides or dilations ' +\n        `must be 1. Got strides ${strides} and dilations '${dilations}'`);\n    if (dimRoundingMode != null) {\n        util.assert(util.isInt(pad), () => `Error in avgPool3dGrad: pad must be an integer when ` +\n            `using, dimRoundingMode ${dimRoundingMode} but got pad ${pad}.`);\n    }\n    const inputs = { dy: dy5D, input: input5D };\n    const attrs = { filterSize, strides, dilations, pad, dimRoundingMode };\n    // tslint:disable-next-line: no-unnecessary-type-assertion\n    const res = ENGINE.runKernel(AvgPool3DGrad, inputs, attrs);\n    if (reshapedTo5D) {\n        return reshape(res, [res.shape[1], res.shape[2], res.shape[3], res.shape[4]]);\n    }\n    return res;\n}\nexport const avgPool3dGrad = op({ avgPool3dGrad_ });\n//# sourceMappingURL=avg_pool_3d_grad.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { AvgPoolGrad } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport * as util from '../util';\nimport { op } from './operation';\nimport { reshape } from './reshape';\n/**\n * Computes the backprop of an 2D avg pool.\n *\n * @param dy The dy error, of rank 4 or rank 3 of shape\n *     [batchSize, height, width, channels]. If rank 3, batch of 1 is\n * assumed.\n * @param input The input image, of rank 4 or rank 3 of shape\n *     [batchSize, height, width, channels]. If rank 3, batch of 1 is\n * assumed.\n * @param filterSize The filter size: `[filterHeight, filterWidth]`. If\n *     `filterSize` is a single number, then `filterHeight == filterWidth`.\n * @param strides The strides of the pooling: `[strideHeight, strideWidth]`. If\n *     `strides` is a single number, then `strideHeight == strideWidth`.\n * @param pad A string from: 'same', 'valid'. The type of padding algorithm\n *     used in the forward prop of the op.\n */\nfunction avgPoolGrad_(dy, input, filterSize, strides, pad) {\n    const $dy = convertToTensor(dy, 'dy', 'avgPoolGrad');\n    const $input = convertToTensor(input, 'input', 'avgPoolGrad');\n    util.assert($input.rank === $dy.rank, () => `Rank of input (${$input.rank}) does not match rank of dy (${$dy.rank})`);\n    let input4D = $input;\n    let dy4D = $dy;\n    let reshapedTo4D = false;\n    if ($input.rank === 3) {\n        reshapedTo4D = true;\n        input4D =\n            reshape($input, [1, $input.shape[0], $input.shape[1], $input.shape[2]]);\n        dy4D = reshape($dy, [1, $dy.shape[0], $dy.shape[1], $dy.shape[2]]);\n    }\n    util.assert(dy4D.rank === 4, () => `Error in avgPoolGrad: dy must be rank 4 but got rank ` +\n        `${dy4D.rank}.`);\n    util.assert(input4D.rank === 4, () => `Error in avgPoolGrad: input must be rank 4 but got rank ` +\n        `${input4D.rank}.`);\n    const inputs = { dy: dy4D, input: input4D };\n    const attrs = { filterSize, strides, pad };\n    // tslint:disable-next-line: no-unnecessary-type-assertion\n    const res = ENGINE.runKernel(AvgPoolGrad, inputs, attrs);\n    if (reshapedTo4D) {\n        return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);\n    }\n    return res;\n}\nexport const avgPoolGrad = op({ avgPoolGrad_ });\n//# sourceMappingURL=avg_pool_grad.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Conv3DBackpropInputV2 } from '../kernel_names';\nimport * as util from '../util';\nimport { op } from './operation';\nimport { reshape } from './reshape';\n/**\n * Computes the derivative of the input of a 3D convolution.\n *\n * @param xShape The shape of the input: [batch, depth, height, width,\n * in_channels]. If length of 4, batch of 1 is assumed.\n * @param dy The derivative of the output, of rank 5 or rank 4 of shape\n *   `[batch, outDepth, outHeight, outWidth, in_channels]`.\n * If rank 4, batch of 1 is assumed.\n * @param filter The filter, rank 5, of shape\n *     `[filterDepth, filterHeight, filterWidth, inDepth, outDepth]`.\n * @param strides The strides of the convolution: `[strideDepth, strideHeight,\n * strideWidth]`.\n * @param pad The type of padding algorithm used:\n *    - `same` and stride 1: output will be of same size as input,\n *       regardless of filter size.\n *    - `valid`: output will be smaller than input if filter is larger\n *       than 1x1.\n */\nfunction conv3DBackpropInput_(xShape, dy, filter, strides, pad) {\n    util.assert(xShape.length === dy.rank, () => `Length of inShape ` +\n        `(${xShape.length}) and rank of dy (${dy.rank}) must match`);\n    let xShape5D = xShape;\n    let dy5D = dy;\n    let reshapedTo5D = false;\n    if (dy.rank === 4) {\n        reshapedTo5D = true;\n        dy5D = reshape(dy, [1, dy.shape[0], dy.shape[1], dy.shape[2], dy.shape[3]]);\n        xShape5D = [1, xShape[0], xShape[1], xShape[2], xShape[3]];\n    }\n    const inDepth = xShape5D[4];\n    const outDepth = dy5D.shape[4];\n    util.assert(xShape5D.length === 5, () => `Error in conv3dDerInput: inShape must be length 5, but got length ` +\n        `${xShape5D.length}.`);\n    util.assert(dy5D.rank === 5, () => `Error in conv3dDerInput: dy must be rank 5, but got ` +\n        `rank ${dy5D.rank}`);\n    util.assert(filter.rank === 5, () => `Error in conv3dDerInput: filter must be rank 5, but got ` +\n        `rank ${filter.rank}`);\n    util.assert(inDepth === filter.shape[3], () => `Error in conv3dDerInput: depth of input (${inDepth}) must ` +\n        `match input depth for filter ${filter.shape[3]}.`);\n    util.assert(outDepth === filter.shape[4], () => `Error in conv3dDerInput: depth of output (${outDepth}) must ` +\n        `match output depth for filter ${filter.shape[4]}.`);\n    const inputs = { dy: dy5D, filter };\n    const attrs = { pad, strides, inputShape: xShape5D };\n    // tslint:disable-next-line: no-unnecessary-type-assertion\n    const res = ENGINE.runKernel(Conv3DBackpropInputV2, inputs, attrs);\n    if (reshapedTo5D) {\n        return reshape(res, [res.shape[1], res.shape[2], res.shape[3], res.shape[4]]);\n    }\n    return res;\n}\nexport const conv3DBackpropInput = op({ conv3DBackpropInput_ });\n//# sourceMappingURL=conv3d_backprop_input.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Conv3DBackpropFilterV2 } from '../kernel_names';\nimport * as util from '../util';\nimport { op } from './operation';\nimport { reshape } from './reshape';\n/**\n * Computes the derivative of the filter of a 3D convolution.\n *\n * @param x The input tensor, of rank 5 or rank 4 of shape\n *     [batch, depth, height, width, inChannels]. If rank 4, batch of 1 is\n *     assumed.\n * @param dy The dy image, of rank 5 or rank 4, of shape\n *     [batch, depth, height, width, outDepth]. If rank 4, batch of 1 is\n *     assumed.\n * @param filterShape The shape of the filter, length 5,\n *     [filterDepth, filterHeight, filterWidth, inDepth, outDepth].\n * @param strides The strides of the convolution: [strideDepth, strideHeight,\n * strideWidth].\n * @param pad A string from: 'same', 'valid'. The type of padding algorithm\n *     used in the forward prop of the op.\n */\nfunction conv3DBackpropFilter_(x, dy, filterShape, strides, pad) {\n    let x5D = x;\n    if (x.rank === 4) {\n        x5D = reshape(x, [1, x.shape[0], x.shape[1], x.shape[2], x.shape[3]]);\n    }\n    let dy5D = dy;\n    if (dy5D.rank === 4) {\n        dy5D = reshape(dy, [1, dy.shape[0], dy.shape[1], dy.shape[2], dy.shape[3]]);\n    }\n    util.assert(x5D.rank === 5, () => `Error in conv3dDerFilter: input must be rank 5, but got shape ` +\n        `${x5D.shape}.`);\n    util.assert(dy5D.rank === 5, () => `Error in conv3dDerFilter: dy must be rank 5, but got shape ` +\n        `${dy5D.shape}.`);\n    util.assert(filterShape.length === 5, () => `Error in conv3dDerFilter: filterShape must be length 5, but got ` +\n        `${filterShape}.`);\n    util.assert(x5D.shape[4] === filterShape[3], () => `Error in conv3dDerFilter: depth of input ${x5D.shape[4]}) must ` +\n        `match input depth in filter (${filterShape[3]}.`);\n    util.assert(dy5D.shape[4] === filterShape[4], () => `Error in conv3dDerFilter: depth of dy (${dy5D.shape[4]}) must ` +\n        `match output depth for filter (${filterShape[4]}).`);\n    const inputs = { x: x5D, dy: dy5D };\n    const attrs = { strides, pad, filterShape };\n    // tslint:disable-next-line: no-unnecessary-type-assertion\n    return ENGINE.runKernel(Conv3DBackpropFilterV2, inputs, attrs);\n}\nexport const conv3DBackpropFilter = op({ conv3DBackpropFilter_ });\n//# sourceMappingURL=conv3d_backprop_filter.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Exp } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes exponential of the input `tf.Tensor` element-wise. `e ^ x`\n *\n * ```js\n * const x = tf.tensor1d([1, 2, -3]);\n *\n * x.exp().print();  // or tf.exp(x)\n * ```\n * @param x The input tensor.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction exp_(x) {\n    const $x = convertToTensor(x, 'x', 'exp');\n    const inputs = { x: $x };\n    return ENGINE.runKernel(Exp, inputs);\n}\nexport const exp = op({ exp_ });\n//# sourceMappingURL=exp.js.map","/**\n * @license\n * Copyright 2017 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport * as util from '../util';\n/**\n * Returns true if the axis specifies the inner most dimensions of the\n * array.\n */\nexport function axesAreInnerMostDims(axes, rank) {\n    for (let i = 0; i < axes.length; ++i) {\n        if (axes[axes.length - i - 1] !== rank - 1 - i) {\n            return false;\n        }\n    }\n    return true;\n}\nexport function combineLocations(outputLoc, reduceLoc, axes) {\n    const rank = outputLoc.length + reduceLoc.length;\n    const loc = [];\n    let outIdx = 0;\n    let reduceIdx = 0;\n    for (let dim = 0; dim < rank; dim++) {\n        if (axes.indexOf(dim) === -1) {\n            loc.push(outputLoc[outIdx++]);\n        }\n        else {\n            loc.push(reduceLoc[reduceIdx++]);\n        }\n    }\n    return loc;\n}\nexport function computeOutAndReduceShapes(aShape, axes) {\n    const outShape = [];\n    const rank = aShape.length;\n    for (let dim = 0; dim < rank; dim++) {\n        if (axes.indexOf(dim) === -1) {\n            outShape.push(aShape[dim]);\n        }\n    }\n    const reduceShape = axes.map(dim => aShape[dim]);\n    return [outShape, reduceShape];\n}\nexport function expandShapeToKeepDim(shape, axes) {\n    const reduceSubShape = axes.map(x => 1);\n    return combineLocations(shape, reduceSubShape, axes);\n}\nexport function assertAxesAreInnerMostDims(msg, axes, rank) {\n    util.assert(axesAreInnerMostDims(axes, rank), () => `${msg} supports only inner-most axes for now. ` +\n        `Got axes ${axes} and rank-${rank} input.`);\n}\n/**\n * Returns the axes permutation to be used with `tf.transpose`, if such\n * permutation is necessary. Otherwise it returns null. This method is used by\n * operations that operate only on inner-most axes.\n */\nexport function getAxesPermutation(axes, rank) {\n    if (axesAreInnerMostDims(axes, rank)) {\n        return null;\n    }\n    const result = [];\n    for (let i = 0; i < rank; ++i) {\n        if (axes.indexOf(i) === -1) {\n            result.push(i);\n        }\n    }\n    axes.forEach(axis => result.push(axis));\n    return result;\n}\n/** Returns the axes permutation that undoes the original permutation. */\nexport function getUndoAxesPermutation(axes) {\n    return axes.map((axis, i) => [i, axis])\n        .sort((a, b) => a[1] - b[1])\n        .map(x => x[0]);\n}\nexport function getInnerMostAxes(numAxes, rank) {\n    const res = [];\n    for (let i = rank - numAxes; i < rank; ++i) {\n        res.push(i);\n    }\n    return res;\n}\n//# sourceMappingURL=axis_util.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Abs, ComplexAbs } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes absolute value element-wise: `abs(x)`\n *\n * ```js\n * const x = tf.tensor1d([-1, 2, -3, 4]);\n *\n * x.abs().print();  // or tf.abs(x)\n * ```\n * @param x The input `tf.Tensor`.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction abs_(x) {\n    const $x = convertToTensor(x, 'x', 'abs');\n    if ($x.dtype === 'complex64') {\n        const inputs = { x: $x };\n        return ENGINE.runKernel(ComplexAbs, inputs);\n    }\n    else {\n        const inputs = { x: $x };\n        return ENGINE.runKernel(Abs, inputs);\n    }\n}\nexport const abs = op({ abs_ });\n//# sourceMappingURL=abs.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Complex } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport * as util from '../util';\nimport { op } from './operation';\n/**\n * Converts two real numbers to a complex number.\n *\n * Given a tensor `real` representing the real part of a complex number, and a\n * tensor `imag` representing the imaginary part of a complex number, this\n * operation returns complex numbers elementwise of the form [r0, i0, r1, i1],\n * where r represents the real part and i represents the imag part.\n *\n * The input tensors real and imag must have the same shape.\n *\n * ```js\n * const real = tf.tensor1d([2.25, 3.25]);\n * const imag = tf.tensor1d([4.75, 5.75]);\n * const complex = tf.complex(real, imag);\n *\n * complex.print();\n * ```\n *\n * @doc {heading: 'Tensors', subheading: 'Creation'}\n */\nfunction complex_(real, imag) {\n    const $real = convertToTensor(real, 'real', 'complex');\n    const $imag = convertToTensor(imag, 'imag', 'complex');\n    util.assertShapesMatch($real.shape, $imag.shape, `real and imag shapes, ${$real.shape} and ${$imag.shape}, ` +\n        `must match in call to tf.complex().`);\n    const inputs = { real: $real, imag: $imag };\n    return ENGINE.runKernel(Complex, inputs);\n}\nexport const complex = op({ complex_ });\n//# sourceMappingURL=complex.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { ExpandDims } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport * as util from '../util';\nimport { op } from './operation';\n/**\n * Returns a `tf.Tensor` that has expanded rank, by inserting a dimension\n * into the tensor's shape.\n *\n * ```js\n * const x = tf.tensor1d([1, 2, 3, 4]);\n * const axis = 1;\n * x.expandDims(axis).print();\n * ```\n *\n * @param x The input tensor whose dimensions to be expanded.\n * @param axis The dimension index at which to insert shape of `1`. Defaults\n *     to 0 (the first dimension).\n *\n * @doc {heading: 'Tensors', subheading: 'Transformations'}\n */\nfunction expandDims_(x, axis = 0) {\n    const $x = convertToTensor(x, 'x', 'expandDims', 'string_or_numeric');\n    util.assert(axis <= $x.rank, () => 'Axis must be <= rank of the tensor');\n    const inputs = { input: $x };\n    const attrs = { dim: axis };\n    return ENGINE.runKernel(ExpandDims, inputs, attrs);\n}\nexport const expandDims = op({ expandDims_ });\n//# sourceMappingURL=expand_dims.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Conv2D } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport * as util from '../util';\nimport * as conv_util from './conv_util';\nimport { op } from './operation';\nimport { reshape } from './reshape';\n/**\n * Computes a 2D convolution over the input x.\n *\n * @param x The input tensor, of rank 4 or rank 3, of shape\n *     `[batch, height, width, inChannels]`. If rank 3, batch of 1 is\n * assumed.\n * @param filter The filter, rank 4, of shape\n *     `[filterHeight, filterWidth, inDepth, outDepth]`.\n * @param strides The strides of the convolution: `[strideHeight,\n * strideWidth]`.\n * @param pad The type of padding algorithm.\n *    - `same` and stride 1: output will be of same size as input,\n *       regardless of filter size.\n *    - `valid`: output will be smaller than input if filter is larger\n *       than 1x1.\n *   - For more info, see this guide:\n *     [https://www.tensorflow.org/api_guides/python/nn#Convolution](\n *          https://www.tensorflow.org/api_guides/python/nn#Convolution)\n * @param dataFormat: An optional string from: \"NHWC\", \"NCHW\". Defaults to\n *     \"NHWC\". Specify the data format of the input and output data. With the\n *     default format \"NHWC\", the data is stored in the order of: [batch,\n *     height, width, channels].\n * @param dilations The dilation rates: `[dilationHeight, dilationWidth]`\n *     in which we sample input values across the height and width dimensions\n *     in atrous convolution. Defaults to `[1, 1]`. If `dilations` is a single\n *     number, then `dilationHeight == dilationWidth`. If it is greater than\n *     1, then all values of `strides` must be 1.\n * @param dimRoundingMode A string from: 'ceil', 'round', 'floor'. If none is\n *     provided, it will default to truncate.\n *\n * @doc {heading: 'Operations', subheading: 'Convolution'}\n */\nfunction conv2d_(x, filter, strides, pad, dataFormat = 'NHWC', dilations = [1, 1], dimRoundingMode) {\n    const $x = convertToTensor(x, 'x', 'conv2d');\n    const $filter = convertToTensor(filter, 'filter', 'conv2d');\n    let x4D = $x;\n    let reshapedTo4D = false;\n    if ($x.rank === 3) {\n        reshapedTo4D = true;\n        x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);\n    }\n    util.assert(x4D.rank === 4, () => `Error in conv2d: input must be rank 4, but got rank ${x4D.rank}.`);\n    util.assert($filter.rank === 4, () => `Error in conv2d: filter must be rank 4, but got rank ` +\n        `${$filter.rank}.`);\n    if (dimRoundingMode != null) {\n        util.assert(util.isInt(pad), () => `Error in conv2d: pad must be an integer when using, ` +\n            `dimRoundingMode ${dimRoundingMode} but got pad ${pad}.`);\n    }\n    const inDepth = dataFormat === 'NHWC' ? x4D.shape[3] : x4D.shape[1];\n    util.assert(inDepth === $filter.shape[2], () => `Error in conv2d: depth of input (${inDepth}) must match ` +\n        `input depth for filter ${$filter.shape[2]}.`);\n    util.assert(conv_util.eitherStridesOrDilationsAreOne(strides, dilations), () => 'Error in conv2D: Either strides or dilations must be 1. ' +\n        `Got strides ${strides} and dilations '${dilations}'`);\n    const inputs = { x: x4D, filter: $filter };\n    const attrs = { strides, pad, dataFormat, dilations, dimRoundingMode };\n    // tslint:disable-next-line: no-unnecessary-type-assertion\n    const res = ENGINE.runKernel(Conv2D, inputs, attrs);\n    if (reshapedTo4D) {\n        return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);\n    }\n    return res;\n}\nexport const conv2d = op({ conv2d_ });\n//# sourceMappingURL=conv2d.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Identity } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Creates a new tensor with the same values and shape as the specified\n * tensor.\n *\n * ```js\n * const x = tf.tensor([1, 2]);\n *\n * x.clone().print();\n * ```\n *\n * @param x The tensor to clone.\n *\n * @doc {heading: 'Tensors', subheading: 'Creation'}\n */\nfunction clone_(x) {\n    const $x = convertToTensor(x, 'x', 'clone', 'string_or_numeric');\n    const inputs = { x: $x };\n    // Note this op is called tf.identity in python. Hence the kernel name used\n    // here.\n    return ENGINE.runKernel(Identity, inputs);\n}\nexport const clone = op({ clone_ });\n//# sourceMappingURL=clone.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { DepthwiseConv2dNative } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport * as util from '../util';\nimport { op } from './operation';\nimport { reshape } from './reshape';\n/**\n * Depthwise 2D convolution.\n *\n * Given a 4D `input` array and a `filter` array of shape\n * `[filterHeight, filterWidth, inChannels, channelMultiplier]` containing\n * `inChannels` convolutional filters of depth 1, this op applies a\n * different filter to each input channel (expanding from 1 channel to\n * `channelMultiplier` channels for each), then concatenates the results\n * together. The output has `inChannels * channelMultiplier` channels.\n *\n * See\n * [https://www.tensorflow.org/api_docs/python/tf/nn/depthwise_conv2d](\n *     https://www.tensorflow.org/api_docs/python/tf/nn/depthwise_conv2d)\n * for more details.\n *\n * @param x The input tensor, of rank 4 or rank 3, of shape\n *     `[batch, height, width, inChannels]`. If rank 3, batch of 1 is\n * assumed.\n * @param filter The filter tensor, rank 4, of shape\n *     `[filterHeight, filterWidth, inChannels, channelMultiplier]`.\n * @param strides The strides of the convolution: `[strideHeight,\n * strideWidth]`. If strides is a single number, then `strideHeight ==\n * strideWidth`.\n * @param pad The type of padding algorithm.\n *   - `same` and stride 1: output will be of same size as input,\n *       regardless of filter size.\n *   - `valid`: output will be smaller than input if filter is larger\n *       than 1x1.\n *   - For more info, see this guide:\n *     [https://www.tensorflow.org/api_guides/python/nn#Convolution](\n *          https://www.tensorflow.org/api_guides/python/nn#Convolution)\n * @param dilations The dilation rates: `[dilationHeight, dilationWidth]`\n *     in which we sample input values across the height and width dimensions\n *     in atrous convolution. Defaults to `[1, 1]`. If `rate` is a single\n *     number, then `dilationHeight == dilationWidth`. If it is greater than\n *     1, then all values of `strides` must be 1.\n * @param dataFormat: An optional string from: \"NHWC\", \"NCHW\". Defaults to\n *     \"NHWC\". Specify the data format of the input and output data. With the\n *     default format \"NHWC\", the data is stored in the order of: [batch,\n *     height, width, channels]. Only \"NHWC\" is currently supported.\n * @param dimRoundingMode A string from: 'ceil', 'round', 'floor'. If none is\n *     provided, it will default to truncate.\n *\n * @doc {heading: 'Operations', subheading: 'Convolution'}\n */\nfunction depthwiseConv2d_(x, filter, strides, pad, dataFormat = 'NHWC', dilations = [1, 1], dimRoundingMode) {\n    const $x = convertToTensor(x, 'x', 'depthwiseConv2d');\n    const $filter = convertToTensor(filter, 'filter', 'depthwiseConv2d');\n    let x4D = $x;\n    let reshapedTo4D = false;\n    if ($x.rank === 3) {\n        reshapedTo4D = true;\n        x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);\n    }\n    util.assert(x4D.rank === 4, () => `Error in depthwiseConv2d: input must be rank 4, but got ` +\n        `rank ${x4D.rank}.`);\n    util.assert($filter.rank === 4, () => `Error in depthwiseConv2d: filter must be rank 4, but got rank ` +\n        `${$filter.rank}.`);\n    util.assert(x4D.shape[3] === $filter.shape[2], () => `Error in depthwiseConv2d: number of input channels ` +\n        `(${x4D.shape[3]}) must match the inChannels dimension in ` +\n        `filter ${$filter.shape[2]}.`);\n    if (dimRoundingMode != null) {\n        util.assert(util.isInt(pad), () => `Error in depthwiseConv2d: pad must be an integer when using, ` +\n            `dimRoundingMode ${dimRoundingMode} but got pad ${pad}.`);\n    }\n    const inputs = { x: x4D, filter: $filter };\n    const attrs = { strides, pad, dataFormat, dilations, dimRoundingMode };\n    // tslint:disable-next-line: no-unnecessary-type-assertion\n    const res = ENGINE.runKernel(DepthwiseConv2dNative, inputs, attrs);\n    if (reshapedTo4D) {\n        return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);\n    }\n    return res;\n}\nexport const depthwiseConv2d = op({ depthwiseConv2d_ });\n//# sourceMappingURL=depthwise_conv2d.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Equal } from '../kernel_names';\nimport { makeTypesMatch } from '../tensor_util';\nimport { convertToTensor } from '../tensor_util_env';\nimport { assertAndGetBroadcastShape } from './broadcast_util';\nimport { op } from './operation';\n/**\n * Returns the truth value of (a == b) element-wise. Supports broadcasting.\n *\n * ```js\n * const a = tf.tensor1d([1, 2, 3]);\n * const b = tf.tensor1d([2, 2, 2]);\n *\n * a.equal(b).print();\n * ```\n *\n * @param a The first input tensor.\n * @param b The second input tensor. Must have the same dtype as `a`.\n *\n * @doc {heading: 'Operations', subheading: 'Logical'}\n */\nfunction equal_(a, b) {\n    let $a = convertToTensor(a, 'a', 'equal');\n    let $b = convertToTensor(b, 'b', 'equal');\n    [$a, $b] = makeTypesMatch($a, $b);\n    assertAndGetBroadcastShape($a.shape, $b.shape);\n    const inputs = { a: $a, b: $b };\n    return ENGINE.runKernel(Equal, inputs);\n}\nexport const equal = op({ equal_ });\n//# sourceMappingURL=equal.js.map","/**\n * @license\n * Copyright 2020 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { TensorBuffer } from '../tensor';\nimport * as util from '../util';\n/**\n * Creates an empty `tf.TensorBuffer` with the specified `shape` and `dtype`.\n *\n * The values are stored in CPU as `TypedArray`. Fill the buffer using\n * `buffer.set()`, or by modifying directly `buffer.values`.\n *\n * When done, call `buffer.toTensor()` to get an immutable `tf.Tensor` with\n * those values.\n *\n * ```js\n * // Create a buffer and set values at particular indices.\n * const buffer = tf.buffer([2, 2]);\n * buffer.set(3, 0, 0);\n * buffer.set(5, 1, 0);\n *\n * // Convert the buffer back to a tensor.\n * buffer.toTensor().print();\n * ```\n *\n * @param shape An array of integers defining the output tensor shape.\n * @param dtype The dtype of the buffer. Defaults to 'float32'.\n * @param values The values of the buffer as `TypedArray`. Defaults to\n * zeros.\n *\n * @doc {heading: 'Tensors', subheading: 'Creation'}\n */\nexport function buffer(shape, dtype = 'float32', values) {\n    dtype = dtype || 'float32';\n    util.assertNonNegativeIntegerDimensions(shape);\n    return new TensorBuffer(shape, dtype, values);\n}\n//# sourceMappingURL=buffer.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { BatchToSpaceND } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport * as util from '../util';\nimport { op } from './operation';\n/**\n * This operation reshapes the \"batch\" dimension 0 into `M + 1` dimensions of\n * shape `blockShape + [batch]`, interleaves these blocks back into the grid\n * defined by the spatial dimensions `[1, ..., M]`, to obtain a result with\n * the same rank as the input. The spatial dimensions of this intermediate\n * result are then optionally cropped according to `crops` to produce the\n * output. This is the reverse of `tf.spaceToBatchND`. See below for a precise\n * description.\n *\n * ```js\n * const x = tf.tensor4d([1, 2, 3, 4], [4, 1, 1, 1]);\n * const blockShape = [2, 2];\n * const crops = [[0, 0], [0, 0]];\n *\n * x.batchToSpaceND(blockShape, crops).print();\n * ```\n *\n * @param x A `tf.Tensor`. N-D with `x.shape` = `[batch] + spatialShape +\n * remainingShape`, where spatialShape has `M` dimensions.\n * @param blockShape A 1-D array. Must have shape `[M]`, all values must\n * be >= 1.\n * @param crops A 2-D array.  Must have shape `[M, 2]`, all values must be >= 0.\n * `crops[i] = [cropStart, cropEnd]` specifies the amount to crop from input\n * dimension `i + 1`, which corresponds to spatial dimension `i`. It is required\n * that `cropStart[i] + cropEnd[i] <= blockShape[i] * inputShape[i + 1]`\n *\n * This operation is equivalent to the following steps:\n *\n * 1. Reshape `x` to `reshaped` of shape: `[blockShape[0], ...,\n * blockShape[M-1], batch / prod(blockShape), x.shape[1], ...,\n * x.shape[N-1]]`\n *\n * 2. Permute dimensions of `reshaped`to produce `permuted` of shape `[batch /\n * prod(blockShape),x.shape[1], blockShape[0], ..., x.shape[M],\n * blockShape[M-1],x.shape[M+1], ..., x.shape[N-1]]`\n *\n * 3. Reshape `permuted` to produce `reshapedPermuted` of shape `[batch /\n * prod(blockShape),x.shape[1] * blockShape[0], ..., x.shape[M] *\n * blockShape[M-1],x.shape[M+1], ..., x.shape[N-1]]`\n *\n * 4. Crop the start and end of dimensions `[1, ..., M]` of `reshapedPermuted`\n * according to `crops` to produce the output of shape: `[batch /\n * prod(blockShape),x.shape[1] * blockShape[0] - crops[0,0] - crops[0,1],\n * ..., x.shape[M] * blockShape[M-1] - crops[M-1,0] -\n * crops[M-1,1],x.shape[M+1], ..., x.shape[N-1]]`\n *\n * @doc {heading: 'Tensors', subheading: 'Transformations'}\n */\nfunction batchToSpaceND_(x, blockShape, crops) {\n    const $x = convertToTensor(x, 'x', 'batchToSpaceND');\n    const prod = blockShape.reduce((a, b) => a * b);\n    util.assert($x.rank >= 1 + blockShape.length, () => `input rank is ${$x.rank} but should be > than blockShape.length ${blockShape.length}`);\n    util.assert(crops.length === blockShape.length, () => `crops.length is ${crops.length} but should be equal to blockShape.length  ${blockShape.length}`);\n    util.assert($x.shape[0] % prod === 0, () => `input tensor batch is ${$x.shape[0]} but is not divisible by the product of ` +\n        `the elements of blockShape ${blockShape.join(' * ')} === ${prod}`);\n    const inputs = { x: $x };\n    const attrs = { blockShape, crops };\n    return ENGINE.runKernel(BatchToSpaceND, inputs, attrs);\n}\nexport const batchToSpaceND = op({ batchToSpaceND_ });\n//# sourceMappingURL=batch_to_space_nd.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Tile } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { clone } from './clone';\nimport { op } from './operation';\nimport { reshape } from './reshape';\n/**\n * Broadcast an array to a compatible shape NumPy-style.\n *\n * The tensor's shape is compared to the broadcast shape from end to beginning.\n * Ones are prepended to the tensor's shape until is has the same length as\n * the broadcast shape. If input.shape[i]==shape[i], the (i+1)-th axis is\n * already broadcast-compatible. If input.shape[i]==1 and shape[i]==N, then\n * the input tensor is tiled N times along that axis (using tf.tile).\n *\n * @param input The tensor that is to be broadcasted.\n * @param shape The input is to be broadcast to this shape.\n *\n * @doc {heading: 'Tensors', subheading: 'Transformations'}\n */\nfunction broadcastTo_(x, shape) {\n    let input = convertToTensor(x, 'broadcastTo', 'x');\n    const xShape = input.shape;\n    if (shape.some(d => !(d > 0) || d % 1 !== 0)) {\n        throw new Error(`broadcastTo(): Invalid broadcast shape [${shape}].`);\n    }\n    if (shape.length < input.rank) {\n        throw new Error(`broadcastTo(): shape.length=${shape.length} < input.rank=${input.rank}.`);\n    }\n    if (shape.length > input.rank) {\n        const newShape = input.shape.slice();\n        while (newShape.length < shape.length) {\n            newShape.unshift(1);\n        }\n        input = reshape(input, newShape);\n    }\n    const inputShape = input.shape;\n    const reps = Array.from(shape);\n    for (let i = shape.length - 1; i >= 0; i--) {\n        if (inputShape[i] === shape[i]) {\n            reps[i] = 1;\n        }\n        else if (input.shape[i] !== 1) {\n            throw new Error(`broadcastTo(): [${xShape}] cannot be broadcast to [${shape}].`);\n        }\n    }\n    const axes = reps.map((n, i) => n > 1 ? i : -1).filter(i => i >= 0);\n    if (axes.length === 0) {\n        return clone(input);\n    }\n    // TODO call broadcastTo kernel directly once backends implement broadcstTo\n    const inputs = { x: input };\n    const attrs = { reps };\n    return ENGINE.runKernel(Tile, inputs, attrs);\n}\nexport const broadcastTo = op({ broadcastTo_ });\n//# sourceMappingURL=broadcast_to.js.map"],"sourceRoot":""}