{"version":3,"sources":["webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/sigmoid.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/spectral/fft.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/spectral/rfft.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/squeeze.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/norm.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/relu6.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/sum.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/prelu.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/unsorted_segment_sum.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/pad.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/signal_ops_util.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/signal/hamming_window.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/signal/hann_window.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/signal/frame.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/signal/stft.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/ops.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/scalar.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/scatter_nd_util.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/range.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/selu_util.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/sub.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/print.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/split_util.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/spectral/irfft.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/tensor3d.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/reduce_util.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/segment_util.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/sin.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/sinh.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/rsqrt.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/softplus.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/one_hot.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/pool.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/prod.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/selu.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/separable_conv2d.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/topk.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/zeros_like.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/transpose.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/square.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/rotate_util.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/slice.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/ones_like.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/reciprocal.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/round.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/sign.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/softmax.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/strided_slice.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/tan.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/tanh.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/where.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/operation.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/sqrt.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/slice_util.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/zeros.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/platforms/platform_browser.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/platforms/platform_node.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/stack.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/pow.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/nonmax_util.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/tensor1d.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/split.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/reshape.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/ones.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/relu.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/step.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/tensor_ops_util.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/tile.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/real.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/reverse.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/unstack.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/not_equal.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/squared_difference.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/space_to_batch_nd.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/tensor.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/tensor2d.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/spectral/ifft.js"],"names":["sigmoid","sigmoid_","x","$x","inputs","runKernelFunc","backend","save","res","fft","fft_","input","dtype","innerDimensionSize","shape","length","batch","size","input2D","as2D","reshape","rfft","rfft_","fftLength","adjustedInput","begin","map","v","zerosShape","zerosInput","complexInput","ret","half","Math","floor","realValues","imagValues","realComplexConjugate","imagComplexConjugate","outputShape","slice","squeeze","squeeze_","axis","newShape","normImpl","p","rank","Array","isArray","Infinity","Error","norm","norm_","ord","keepDims","keepDimsShape","axes","relu6","relu6_","sum","sum_","attrs","permutation","reductionAxes","permutedX","value","prelu","prelu_","alpha","$alpha","unsortedSegmentSum","unsortedSegmentSum_","segmentIds","numSegments","$segmentIds","pad","pad_","paddings","constantValue","cosineWindow","windowLength","a","b","even","newValues","Float32Array","i","cosArg","PI","cos","tensor1d","hammingWindow_","hannWindow","hannWindow_","frame_","signal","frameLength","frameStep","padEnd","padValue","start","output","push","padLen","concat","fill","tensor2d","stft_","windowFn","pow","ceil","log","framedSignal","windowedSignal","mul","ifft","irfft","flipLeftRight","resizeNearestNeighbor","resizeBilinear","rotateWithOffset","cropAndResize","nonMaxSuppression","nonMaxSuppressionAsync","nonMaxSuppressionWithScore","nonMaxSuppressionWithScoreAsync","nonMaxSuppressionPadded","nonMaxSuppressionPaddedAsync","qr","scalar","Uint8Array","validateUpdateShape","indices","updates","sliceDim","batchDim","shapeError","d","validateInput","calculateShapes","indicesRank","sliceRank","totalNd","sliceSize","safeSliceDim","numUpdates","strides","outputSize","range","stop","step","numElements","abs","values","SELU_SCALEALPHA","SELU_SCALE","sub","sub_","$a","$b","subtract","print","verbose","console","toString","prepareSplitSize","numOrSizeSplits","splitSizes","numOfNegs","reduce","count","negIndex","indexOf","total","irfft_","realInput","imagInput","realConjugate","imagConjugate","r","temp","dispose","tensor3d","inferredShape","PARALLELIZE_THRESHOLD","computeOptimalWindowSize","inSize","sqrt","segOpComputeOptimalWindowSize","done","computeOutShape","aShape","outShape","dim","collectGatherOpShapeInfo","dimSize","batchSize","sin","sin_","sinh","sinh_","rsqrt","rsqrt_","softplus","softplus_","oneHot","oneHot_","depth","onValue","offValue","$indices","pool","pool_","windowShape","poolingType","dilations","x4D","reshapedTo4D","convInfo","dilation","dilationHeight","dilationWidth","basePadding","filterShape","padExtraShape","s","padExtraStart","padExtraEnd","_","withSpaceToBatchBasePaddings","filterHeight","filterWidth","isDilationOne","adjustedPadding","adjustedCrops","inputShape","blockShape","padStart","origPadEnd","fullInputShape","padEndExtra","crops","requiredSpaceToBatchPaddings","inHeight","inWidth","convertedPad","convertedX","y","prod","prod_","selu","selu_","separableConv2d","separableConv2d_","depthwiseFilter","pointwiseFilter","dataFormat","$depthwiseFilter","$pointwiseFilter","inChannels","channelMultiplier","depthwise","topk","topk_","k","sorted","lastDim","zerosLike","zerosLike_","transpose","transpose_","perm","reverse","forEach","clone","square","square_","inputsToSave","getImageCenter","center","imageHeight","imageWidth","slice_","begin_","size_","onesLike","onesLike_","reciprocal","reciprocal_","round","round_","sign","sign_","softmax","softmax_","logits","$logits","stridedSlice","stridedSlice_","end","beginMask","endMask","ellipsisMask","newAxisMask","shrinkAxisMask","ellipsisAxes","numInterpolatedAxes","expandAxes","splice","normalizedBegin","normalizedEnd","normalizedStrides","shrinkAxes","filter","every","tan","tan_","tanh","tanh_","where","where_","condition","$condition","broadcastShape","$broadcastedA","$broadcastedB","t","e","select","op","f","keys","Object","opName","fn","endsWith","substring","f2","args","startScope","result","Promise","error","endScope","ex","defineProperty","configurable","sqrt_","assertParamsValid","maskToAxes","mask","stridesWithElidedDims","ellipsisInsertionIndex","numElidedAxes","newStrides","pop","unnormalizeAxis","normalizedAxis","getElidedAxes","elidedAxes","getNormalizedAxes","inputRank","fullIndex","startIndicesWithElidedDims","stopIndicesWithElidedDims","startForAxis","stopForAxis","stridesForAxis","originalBegin","newIndices","originalAxis","originalValue","originalEnd","Number","MAX_SAFE_INTEGER","axisSize","stride","startIndices","MIN_SAFE_INTEGER","stopIndices","isSliceContinous","firstNonOneAxis","computeFlatOffset","flatOffset","parseSliceParams","zeros","real","imag","makeTensor","PlatformBrowser","path","init","fetch","performance","now","text","encoding","this","textEncoder","TextEncoder","encode","bytes","TextDecoder","decode","get","setPlatform","registerManager","URL_SCHEME","err","getNodeFetch","systemFetch","PlatformNode","util","requestInits","global","time","process","hrtime","stack","stack_","tensors","$tensors","expandedTensors","pow_","base","exp","$base","$exp","nonMaxSuppSanityCheck","boxes","scores","maxOutputSize","iouThreshold","scoreThreshold","softNmsSigma","NEGATIVE_INFINITY","numBoxes","min","split","split_","attr","$axis","reshape_","ones","relu","relu_","step_","providedSize","inferredSize","inferred","flatDimsDontMatch","tile","tile_","reps","real_","$input","reverse_","dims","unstack","unstack_","notEqual","notEqual_","squaredDifference","squaredDifference_","spaceToBatchND","spaceToBatchND_","tensor","ifft_"],"mappings":";sJAAA,kEAyCO,MAAMA,EAAU,YAAG,CAAEC,SAT5B,SAAkBC,GACd,MAAMC,EAAK,YAAgBD,EAAG,IAAK,WAC7BE,EAAS,CAAEF,EAAGC,GACpB,OAAO,IAAOE,eAAc,CAACC,EAASC,KAClC,MAAMC,EAAMF,EAAQN,QAAQG,GAE5B,OADAI,EAAK,CAACC,IACCA,IACRJ,EAAQ,KAAiB,U,iCCvChC,kEAkDO,MAAMK,EAAM,YAAG,CAAEC,KAbxB,SAAcC,GACV,iBAAuB,cAAhBA,EAAMC,OAAuB,IAChC,6DAAWD,EAAMC,WACrB,MAAMR,EAAS,CAAEO,SACjB,OAAO,IAAON,eAAcC,IAExB,MAAMO,EAAqBF,EAAMG,MAAMH,EAAMG,MAAMC,OAAS,GACtDC,EAAQL,EAAMM,KAAOJ,EACrBK,EAAUP,EAAMQ,KAAKH,EAAOH,GAElC,OADeP,EAAQG,IAAIS,GACbE,QAAQT,EAAMG,SAC7BV,EAAQ,KAAqB,S,iCChDpC,oIAgFO,MAAMiB,EAAO,YAAG,CAAEC,MArCzB,SAAeX,EAAOY,GAClB,iBAAuB,YAAhBZ,EAAMC,OAAqB,IAAM,mDAAmDD,EAAMC,UACjG,IAAIC,EAAqBF,EAAMG,MAAMH,EAAMG,MAAMC,OAAS,GAC1D,MAAMC,EAAQL,EAAMM,KAAOJ,EAC3B,IAAIW,EACJ,GAAiB,MAAbD,GAAqBA,EAAYV,EAAoB,CAErD,MAAMY,EAAQd,EAAMG,MAAMY,KAAIC,GAAK,IAC7BV,EAAON,EAAMG,MAAMY,KAAIC,GAAKA,IAClCV,EAAKN,EAAMG,MAAMC,OAAS,GAAKQ,EAC/BC,EAAgB,YAAMb,EAAOc,EAAOR,GACpCJ,EAAqBU,OAEpB,GAAiB,MAAbA,GAAqBA,EAAYV,EAAoB,CAE1D,MAAMe,EAAajB,EAAMG,MAAMY,KAAIC,GAAKA,IACxCC,EAAWjB,EAAMG,MAAMC,OAAS,GAAKQ,EAAYV,EACjDW,EAAgB,YAAO,CAACb,EAAO,YAAMiB,IAAcjB,EAAMG,MAAMC,OAAS,GACxEF,EAAqBU,OAGrBC,EAAgBb,EAGpB,MAAMkB,EAAa,YAAUL,GACvBM,EAAe,YAAQ,YAAQN,EAAeK,GAAa,CAACb,EAAOH,IACnEkB,EAAM,YAAID,GAEVE,EAAOC,KAAKC,MAAMrB,EAAqB,GAAK,EAC5CsB,EAAa,YAAKJ,GAClBK,EAAa,YAAKL,GAClBM,EAAuB,YAAMF,EAAY,CAACH,EAAMnB,EAAqBmB,GAAOG,EAAWrB,MAAMC,OAAS,GACtGuB,EAAuB,YAAMF,EAAY,CAACJ,EAAMnB,EAAqBmB,GAAOI,EAAWtB,MAAMC,OAAS,GACtGwB,EAAcf,EAAcV,MAAM0B,QAExC,OADAD,EAAYf,EAAcV,MAAMC,OAAS,GAAKiB,EACvC,YAAQ,YAAQK,EAAqB,GAAIC,EAAqB,IAAKC,O,iCC9E9E,kEAuCO,MAAME,EAAU,YAAG,CAAEC,SAJ5B,SAAkBxC,EAAGyC,GACjB,MAAMxC,EAAK,YAAgBD,EAAG,IAAK,WACnC,OAAO,YAAQC,EAAI,uBAAaA,EAAGW,MAAO6B,GAAMC,c,iCCrCpD,2IA6EA,SAASC,EAAS3C,EAAG4C,EAAGH,EAAO,MAC3B,GAAe,IAAXzC,EAAE6C,KACF,OAAO,YAAI7C,GAGf,GAAe,IAAXA,EAAE6C,MAAuB,OAATJ,EAChB,OAAOE,EAAS,YAAQ3C,EAAG,EAAE,IAAK4C,EAAGH,GAGzC,GAAe,IAAXzC,EAAE6C,MAA8B,iBAATJ,GACvBK,MAAMC,QAAQN,IAAyB,IAAhBA,EAAK5B,OAAc,CAC1C,GAAU,IAAN+B,EACA,OAAO,YAAI,YAAI5C,GAAIyC,GAEvB,GAAIG,IAAMI,IACN,OAAO,YAAI,YAAIhD,GAAIyC,GAEvB,GAAIG,KAAOI,IACP,OAAO,YAAI,YAAIhD,GAAIyC,GAEvB,GAAU,cAANG,GAA2B,IAANA,EAErB,OAAO,YAAK,YAAI,YAAI,YAAI5C,GAAI,YAAO,EAAG,UAAWyC,IAErD,MAAM,IAAIQ,MAAM,qCAAqCL,KAGzD,GAAIE,MAAMC,QAAQN,IAAyB,IAAhBA,EAAK5B,OAAc,CAC1C,GAAU,IAAN+B,EACA,OAAO,YAAI,YAAI,YAAI5C,GAAIyC,EAAK,IAAKA,EAAK,GAAK,GAE/C,GAAIG,IAAMI,IACN,OAAO,YAAI,YAAI,YAAIhD,GAAIyC,EAAK,IAAKA,EAAK,IAE1C,GAAIG,KAAOI,IACP,OAAO,YAAI,YAAI,YAAIhD,GAAIyC,EAAK,IAAKA,EAAK,IAE1C,GAAU,QAANG,GAAqB,cAANA,EAEf,OAAO,YAAK,YAAI,YAAO5C,GAAIyC,IAE/B,MAAM,IAAIQ,MAAM,qCAAqCL,KAEzD,MAAM,IAAIK,MAAM,gCAAgCR,KAE7C,MAAMS,EAAO,YAAG,CAAEC,MAvDzB,SAAenD,EAAGoD,EAAM,YAAaX,EAAO,KAAMY,GAAW,GAEzD,MAAMH,EAAOP,EADb3C,EAAI,YAAgBA,EAAG,IAAK,QACHoD,EAAKX,GAC9B,IAAIa,EAAgBJ,EAAKtC,MACzB,GAAIyC,EAAU,CACV,MAAME,EAAO,yBAAed,EAAMzC,EAAEY,OACpC0C,EAAgB,IAA+BJ,EAAKtC,MAAO2C,GAE/D,OAAO,YAAQL,EAAMI,O,iCC3EzB,0EA8CO,MAAME,EAAQ,YAAG,CAAEC,OAZ1B,SAAgBzD,GACZ,MAAMC,EAAK,YAAgBD,EAAG,IAAK,SAQ7BE,EAAS,CAAEF,EAAGC,GACpB,OAAO,IAAOE,eARE,CAACC,EAASC,KACtBA,EAAK,CAACJ,IACW,SAAbA,EAAGS,MACI,YAAKT,EAAI,SAEbG,EAAQoD,MAAMvD,KAGYC,EAAQ,KAAiB,U,gCC5ClE,wGAiFO,MAAMwD,EAAM,YAAG,CAAEC,KA1BxB,SAAc3D,EAAGyC,EAAO,KAAMY,GAAW,GACrC,IAAIpD,EAAK,YAAgBD,EAAG,IAAK,OAChB,SAAbC,EAAGS,QACHT,EAAK,YAAKA,EAAI,UAElB,MAiBMC,EAAS,CAAEF,EAAGC,GACd2D,EAAQ,CAAEnB,OAAMY,YACtB,OAAO,IAAOlD,eAnBE,CAACC,EAASC,KACtBA,EAAK,CAACJ,IACN,MAAMsD,EAAO,yBAAed,EAAMxC,EAAGW,OAC/BiD,EAAc,YAAmBN,EAAMtD,EAAG4C,MAChD,IAAIiB,EAAgBP,EAChBQ,EAAY9D,EACG,MAAf4D,IACAE,EAAY,YAAU9D,EAAI4D,GAC1BC,EAAgB,YAAiBA,EAAcjD,OAAQZ,EAAG4C,OAE9D,IAAImB,EAAQ5D,EAAQsD,IAAIK,EAAWD,GACnC,GAAIT,EAAU,CACV,MAAMX,EAAW,YAAqBsB,EAAMpD,MAAO2C,GACnDS,EAAQ,YAAQA,EAAOtB,GAE3B,OAAOsB,IAI0B9D,EAAQ,KAAiB,KAAK0D,O,iCC/EvE,kEA+CO,MAAMK,EAAQ,YAAG,CAAEC,OAX1B,SAAgBlE,EAAGmE,GACf,MAAMlE,EAAK,YAAgBD,EAAG,IAAK,SAC7BoE,EAAS,YAAgBD,EAAO,QAAS,SAMzCjE,EAAS,CAAEF,EAAGC,EAAIkE,MAAOC,GAC/B,OAAO,IAAOjE,eANE,CAACC,EAASC,KACtB,MAAMC,EAAMF,EAAQ6D,MAAMhE,EAAImE,GAE9B,OADA/D,EAAK,CAACJ,EAAImE,IACH9D,IAG0BJ,EAAQ,KAAiB,U,iCC7ClE,yEAoDO,MAAMmE,EAAqB,YAAG,CAAEC,oBAbvC,SAA6BtE,EAAGuE,EAAYC,GACxC,MAAMvE,EAAK,YAAgBD,EAAG,IAAK,sBAC7ByE,EAAc,YAAgBF,EAAY,aAAc,qBAAsB,SACpF,iBAAO,gBAAMC,IAAc,IAAM,qCACjC,MAAMtE,EAAS,CAAEF,EAAGC,EAAIsE,WAAYE,GAC9Bb,EAAQ,CAAEY,eAMhB,OAAO,IAAOrE,eALE,CAACC,EAASC,KACtB,MAAMC,EAAMF,EAAQiE,mBAAmBpE,EAAIwE,EAAaD,GAExD,OADAnE,EAAK,CAACoE,IACCnE,IAE0BJ,EAAQ,KAAiB,KAAoB0D,O,iCClDtF,kEAyDO,MAAMc,EAAM,YAAG,CAAEC,KAbxB,SAAc3E,EAAG4E,EAAUC,EAAgB,GACvC,MAAM5E,EAAK,YAAgBD,EAAG,IAAK,OACnC,GAAgB,IAAZC,EAAG4C,KACH,MAAM,IAAII,MAAM,sDAEpB,MAIMW,EAAQ,CAAEgB,WAAUC,iBACpB3E,EAAS,CAAEF,EAAGC,GACpB,OAAO,IAAOE,eANE,CAACC,EAASC,KACtBA,EAAK,CAACJ,IACCG,EAAQsE,IAAIzE,EAAI2E,EAAUC,KAIA3E,EAAQ,KAAiB,KAAO0D,O,u4BClClE,SAASkB,EAAaC,EAAcC,EAAGC,GAC1C,MAAMC,EAAO,EAAIH,EAAe,EAC1BI,EAAY,IAAIC,aAAaL,GACnC,IAAK,IAAIM,EAAI,EAAGA,EAAIN,IAAgBM,EAAG,CACnC,MAAMC,EAAU,EAAMvD,KAAKwD,GAAKF,GAAMN,EAAeG,EAAO,GAC5DC,EAAUE,GAAKL,EAAIC,EAAIlD,KAAKyD,IAAIF,GAEpC,OAAO,OAAAG,EAAA,GAASN,EAAW,WCKF,YAAG,CAAEO,eAHlC,SAAwBX,GACpB,OAAOD,EAAaC,EAAc,IAAM,QCErC,MAAMY,EAAa,YAAG,CAAEC,YAH/B,SAAqBb,GACjB,OAAOD,EAAaC,EAAc,GAAK,O,aC6BpC,MAAM,EAAQ,YAAG,CAAEc,OAtB1B,SAAgBC,EAAQC,EAAaC,EAAWC,GAAS,EAAOC,EAAW,GACvE,IAAIC,EAAQ,EACZ,MAAMC,EAAS,GACf,KAAOD,EAAQJ,GAAeD,EAAO/E,MACjCqF,EAAOC,KAAK,OAAA/D,EAAA,GAAMwD,EAAQK,EAAOJ,IACjCI,GAASH,EAEb,GAAIC,EACA,KAAOE,EAAQL,EAAO/E,MAAM,CACxB,MAAMuF,EAAUH,EAAQJ,EAAeD,EAAO/E,KACxC2D,EAAM,OAAA6B,EAAA,GAAO,CACf,OAAAjE,EAAA,GAAMwD,EAAQK,EAAOJ,EAAcO,GAAS,OAAAE,EAAA,GAAK,CAACF,GAASJ,KAE/DE,EAAOC,KAAK3B,GACZyB,GAASH,EAGjB,OAAsB,IAAlBI,EAAOvF,OACA,OAAA4F,EAAA,GAAS,GAAI,CAAC,EAAGV,IAErB,OAAA7E,EAAA,GAAQ,OAAAqF,EAAA,GAAOH,GAAS,CAACA,EAAOvF,OAAQkF,OCN/B,YAAG,CAAEW,MAZzB,SAAeZ,EAAQC,EAAaC,EAAW3E,EAAWsF,EAAWhB,GJvB9D,IAA6B3B,EIwBf,MAAb3C,IJxB4B2C,EIyBI+B,EAAhC1E,EJvBGU,KAAKC,MAAMD,KAAK6E,IAAI,EAAG7E,KAAK8E,KAAK9E,KAAK+E,IAAI9C,GAASjC,KAAK+E,IAAI,OIyBnE,MAAMC,EAAe,EAAMjB,EAAQC,EAAaC,GAC1CgB,EAAiB,OAAAC,EAAA,GAAIF,EAAcJ,EAASZ,IAC5CK,EAAS,GACf,IAAK,IAAIf,EAAI,EAAGA,EAAI0B,EAAanG,MAAM,GAAIyE,IACvCe,EAAOC,KAAK,OAAAlF,EAAA,GAAK,OAAAmB,EAAA,GAAM0E,EAAgB,CAAC3B,EAAG,GAAI,CAAC,EAAGU,IAAe1E,IAEtE,OAAO,OAAAkF,EAAA,GAAOH,M,kNCiKd7F,EAAA,EACA2G,EAAA,EACA/F,EAAA,EACAgG,EAAA,EAJJ,MA6BM,EAAQ,CACVC,cAAA,IACAC,sBAAA,IACAC,eAAA,IACAC,iBAAA,IACAC,cAAA,IACAC,kBAAA,IACAC,uBAAA,IACAC,2BAAA,IACAC,gCAAA,IACAC,wBAAA,IACAC,6BAAA,KAOA,IACA,IACAC,EAAA,EAaA,IACA,IACA,IACA,IACA,IACA,IACA,IACA,IACA,K,gCCxRJ,qDAiCO,SAASC,EAAOhE,EAAOtD,GAC1B,IAAM,uBAAasD,IAAoB,WAAVtD,GAAuBoC,MAAMC,QAAQiB,KACpD,cAAVtD,EACA,MAAM,IAAIuC,MAAM,kFAGpB,GAAc,WAAVvC,GAAsB,uBAAasD,MACjCA,aAAiBiE,YACnB,MAAM,IAAIhF,MAAM,6EAKpB,OAAO,YAAWe,EAFJ,GACQ,GACyBtD,K,iCC9CnD,oKAOO,SAASwH,EAAoBtH,EAAOuH,EAASC,GAChD,MAAMC,EAAYF,EAAQtF,KAAO,EAAKsF,EAAQvH,MAAMuH,EAAQtF,KAAO,GAAK,EAClEyF,EAAYH,EAAQtF,KAAO,EAAKsF,EAAQtF,KAAO,EAAI,EACnD0F,EACF,6FAAwCH,EAAQxH,yBAC5BuH,EAAQvH,iBAAiBA,gBAC9ByH,oBAA2BC,KAC9C,GAAIF,EAAQvF,KAAOyF,EACf,MAAM,IAAIrF,MAAMsF,EAAa,kBAAkBD,OAEnD,GAAI1H,EAAMC,OAASwH,GAAYD,EAAQvF,KAAOyF,GAC1C,MAAM,IAAIrF,MAAMsF,EACZ,0BAA0BF,GAAYD,EAAQvF,KAAOyF,MAE7D,GAAIF,EAAQvF,OAASyF,EAAW1H,EAAMC,OAASwH,EAC3C,MAAM,IAAIpF,MAAMsF,EAAa,oBAAmBD,EAAW1H,EAAMC,OAASwH,IAE9E,IAAK,IAAIG,EAAI,EAAGA,EAAIF,IAAYE,EAC5B,GAAIJ,EAAQxH,MAAM4H,KAAOL,EAAQvH,MAAM4H,GACnC,MAAM,IAAIvF,MAAMsF,EACZ,kBAAkBC,OAAOJ,EAAQxH,MAAM4H,wBAAwBA,OAAOL,EAAQvH,MAAM4H,QAGhG,IAAK,IAAIA,EAAI,EAAGA,EAAIJ,EAAQvF,KAAOyF,IAAYE,EAC3C,GAAIJ,EAAQxH,MAAM4H,EAAIF,KAAc1H,EAAM4H,EAAIH,GAC1C,MAAM,IAAIpF,MAAMsF,EACZ,kBAAkBC,EAAIF,OAAcF,EAAQxH,MAAM4H,EAAIF,gBAAuBE,EAAIF,OAAc1H,EAAM4H,EAAIF,OAWlH,SAASG,EAAcL,EAASD,EAASvH,GAC5C,GAAIuH,EAAQtF,KAAO,EACf,MAAM,IAAII,MACN,+EAAqBkF,EAAQtF,SAErC,GAAIuF,EAAQvF,KAAO,EACf,MAAM,IAAII,MACN,+EAAqBmF,EAAQvF,SAErC,GAAsB,UAAlBsF,EAAQzH,MACR,MAAM,IAAIuC,MAAM,0DAA0DkF,EAAQzH,SAEtF,GAAIE,EAAMC,OAAS,EACf,MAAM,IAAIoC,MAAM,6DAA6DrC,KAEjF,GAAqB,IAAjBA,EAAMC,OAAc,CACpB,GAAqB,IAAjBsH,EAAQpH,KACR,MAAM,IAAIkC,MAAM,sDAAsDkF,EAAQvH,SAElF,GAAqB,IAAjBwH,EAAQrH,KACR,MAAM,IAAIkC,MAAM,sDAAsDmF,EAAQxH,SAGtFsH,EAAoBtH,EAAOuH,EAASC,GAWjC,SAASM,EAAgBN,EAASD,EAASvH,GAE9C,MAAM+H,EAAcR,EAAQvH,MAAMC,OAC5B+H,EAAaD,EAAc,EAAKR,EAAQvH,MAAM+H,EAAc,GAAK,EAIjEE,EAAUjI,EAAMC,OACtB,IAAIiI,EAAY,EAChB,IAAK,IAAIzD,EAAIuD,EAAWvD,EAAIwD,IAAWxD,EACnCyD,GAAalI,EAAMyE,GAEvB,MAAM0D,EAAgBH,EAAY,EAAK,EAAIA,EAI3C,MAAO,CAAEA,YAAWI,WAHD,wBAAcb,EAAQvH,OAASmI,EAGlBD,YAAWG,QAF3B,IAAI,yBAAerI,EAAM0B,MAAM,EAAGsG,IAAa,GAEXM,WADjC,wBAActI,M,iCC7FrC,2EAwCO,SAASuI,EAAMhD,EAAOiD,EAAMC,EAAO,EAAG3I,EAAQ,WACjD,GAAa,IAAT2I,EACA,MAAM,IAAIpG,MAAM,8BAEpB,MAqBMW,EAAQ,CAAEuC,QAAOiD,OAAMC,OAAM3I,SACnC,OAAO,IAAOP,eAtBE,KAIZ,GAHsBgG,IAAUiD,GACIjD,EAAQiD,GAAQC,EAAO,GACvBD,EAAOjD,GAASkD,EAAO,EAGvD,OAAO,YAAM,CAAC,GAAI3I,GAEtB,MAAM4I,EAAcvH,KAAKwH,IAAIxH,KAAK8E,MAAMuC,EAAOjD,GAASkD,IAClDG,EAAS,8BAAoBF,EAAa5I,GAC5C0I,EAAOjD,GAAkB,IAATkD,IAGhBA,GAAQ,GAEZG,EAAO,GAAKrD,EACZ,IAAK,IAAId,EAAI,EAAGA,EAAImE,EAAO3I,OAAQwE,IAC/BmE,EAAOnE,GAAKmE,EAAOnE,EAAI,GAAKgE,EAEhC,OAAO,YAASG,EAAQ9I,KAGS,GAAiB,KAAiB,KAAOkD,K,iCClElF,oEAgBO,MAAM6F,EAAkB,mBAClBC,EAAa,oB,gCCjB1B,0EAwDO,MAAMC,EAAM,YAAG,CAAEC,KAZxB,SAAc5E,EAAGC,GACb,IAAI4E,EAAK,YAAgB7E,EAAG,IAAK,OAC7B8E,EAAK,YAAgB7E,EAAG,IAAK,QAChC4E,EAAIC,GAAM,YAAeD,EAAIC,GAC9B,MAKM5J,EAAS,CAAE8E,EAAG6E,EAAI5E,EAAG6E,GAC3B,OAAO,IAAO3J,eANE,CAACC,EAASC,KACtB,MAAMC,EAAMF,EAAQ2J,SAASF,EAAIC,GAEjC,OADAzJ,EAAK,CAACwJ,EAAIC,IACHxJ,IAG0BJ,EAAQ,KAAiB,U,iCCzB3D,SAAS8J,EAAMhK,EAAGiK,GAAU,GAC/BC,QAAQpD,IAAI9G,EAAEmK,SAASF,IA9B3B,mC,iCCAA,6CAMO,SAASG,EAAiBpK,EAAGqK,EAAiB5H,EAAO,GACxD,IAAI6H,EAAa,GACjB,GAAiC,iBAAtB,EACP,iBAAOtK,EAAEY,MAAM6B,GAAQ4H,GAAoB,GAAG,IAAM,kDACpDC,EACI,IAAIxH,MAAMuH,GAAiB7D,KAAKxG,EAAEY,MAAM6B,GAAQ4H,OAEnD,CACD,MAAME,EAAYF,EAAgBG,QAAO,CAACC,EAAOzG,MAC9B,IAAXA,IACAyG,GAAS,GAENA,IACR,GACH,iBAAOF,GAAa,GAAG,IAAM,4DAC7B,MAAMG,EAAWL,EAAgBM,SAAS,GAG1C,IAAkB,IAAdD,EAAiB,CACjB,MAAME,EAAQP,EAAgBG,QAAO,CAACxF,EAAGC,IAAMA,EAAI,EAAID,EAAIC,EAAID,IAC/DqF,EAAgBK,GAAY1K,EAAEY,MAAM6B,GAAQmI,EAEhD,iBAAO5K,EAAEY,MAAM6B,KAAU4H,EAAgBG,QAAO,CAACxF,EAAGC,IAAMD,EAAIC,KAAI,IAAM,gEACxEqF,EAAaD,EAEjB,OAAOC,I,iCC/BX,2HA2EO,MAAMnD,EAAQ,YAAG,CAAE0D,OA/B1B,SAAgBpK,GACZ,MAAME,EAAqBF,EAAMG,MAAMH,EAAMG,MAAMC,OAAS,GACtDC,EAAQL,EAAMM,KAAOJ,EAC3B,IAAIkB,EACJ,GAAIlB,GAAsB,EAAG,CACzB,MAAMiB,EAAe,YAAQnB,EAAO,CAACK,EAAOH,IAC5CkB,EAAM,YAAKD,OAEV,CAGD,MAAMS,EAAc,CAACvB,EAAO,GAAKH,EAAqB,IAChDmK,EAAY,YAAQ,YAAKrK,GAAQ,CAACK,EAAOH,IACzCoK,EAAY,YAAQ,YAAKtK,GAAQ,CAACK,EAAOH,IACzCqK,EAAgB,YAAQ,YAAMF,EAAW,CAAC,EAAG,GAAI,CAAChK,EAAOH,EAAqB,IAAK,GACnFsK,EAAgB,YAAI,YAAQ,YAAMF,EAAW,CAAC,EAAG,GAAI,CAACjK,EAAOH,EAAqB,IAAK,GAAI,aAAQ,IACnGuK,EAAI,YAAO,CAACJ,EAAWE,GAAgB,GACvC3F,EAAI,YAAO,CAAC0F,EAAWE,GAAgB,GACvCrJ,EAAe,YAAQ,YAAQsJ,EAAG7F,GAAI,CAAChD,EAAY,GAAIA,EAAY,KACzER,EAAM,YAAKD,GAIf,GAFAC,EAAM,YAAKA,GAEQ,IAAfpB,EAAMoC,MAAiC,IAAnBpC,EAAMG,MAAM,GAAU,CAC1C,MAAMuK,EAAOtJ,EACPf,EAAQL,EAAMG,MAAM,GAC1BiB,EAAM,YAAQA,EAAK,CAACf,EAAOe,EAAIjB,MAAM,GAAKE,EAAOe,EAAIjB,MAAM,KAC3DuK,EAAKC,UAET,OAAOvJ,M,iCCzEX,4DA0CO,SAASwJ,EAAS7B,EAAQ5I,EAAOF,GAEpC,GADA,wBAAc8I,GACD,MAAT5I,GAAkC,IAAjBA,EAAMC,OACvB,MAAM,IAAIoC,MAAM,mDAEpB,MAAMqI,EAAgB,YAAW9B,EAAQ9I,GACzC,GAA6B,IAAzB4K,EAAczK,QAAyC,IAAzByK,EAAczK,OAC5C,MAAM,IAAIoC,MAAM,oEAEpB,GAA6B,IAAzBqI,EAAczK,QAAyB,MAATD,EAC9B,MAAM,IAAIqC,MAAM,2EAGpB,OAAO,YAAWuG,EAAQ5I,EAAO0K,EAAe5K,K,iCCvDpD,+EAqBO,MAAM6K,EAAwB,GAC9B,SAASC,EAAyBC,GACrC,OAAIA,GAAUF,EACHE,EAEJ,yBAAeA,EAAQ1J,KAAKC,MAAMD,KAAK2J,KAAKD,O,iCC1BvD,kMAkBO,SAASE,EAA8BF,EAAQjH,GAClD,IACIlE,EADAsL,GAAO,EASX,IAPIH,GAAU,KACVnL,EAAMmL,EACNG,GAAO,GAGPtL,EAAM,yBAAemL,EAAQ1J,KAAKC,MAAMD,KAAK2J,KAAKD,MAE9CG,GACAtL,EAAMkE,GAAelE,IAAQmL,EAC7BG,GAAO,EAGPtL,EAAM,yBAAemL,EAAQnL,EAAM,GAG3C,OAAOA,EAEJ,SAASuL,EAAgBC,EAAQrJ,EAAM+B,GAC1C,MAAMuH,EAAW,GACXlJ,EAAOiJ,EAAOjL,OACpB,IAAK,IAAImL,EAAM,EAAGA,EAAMnJ,EAAMmJ,IACtBA,IAAQvJ,EACRsJ,EAAS1F,KAAKyF,EAAOE,IAGrBD,EAAS1F,KAAK7B,GAGtB,OAAOuH,EAEJ,SAASE,EAAyBjM,EAAGmI,EAAS1F,GACjD,MAAMyJ,EAAUlM,EAAEY,MAAM6B,GAClBJ,EAAc,GACpB,IAAI8J,EAAY,EACZrD,EAAY,EAChB,IAAK,IAAIzD,EAAI,EAAGA,EAAI5C,EAAM4C,IACtBhD,EAAYgE,KAAKrG,EAAEY,MAAMyE,IACzB8G,GAAanM,EAAEY,MAAMyE,GAEzB,IAAK,IAAIA,EAAI,EAAGA,EAAI8C,EAAQtF,KAAMwC,IAC9BhD,EAAYgE,KAAK8B,EAAQvH,MAAMyE,IAEnC,IAAK,IAAIA,EAAI5C,EAAO,EAAG4C,EAAIrF,EAAE6C,KAAMwC,IAC/BhD,EAAYgE,KAAKrG,EAAEY,MAAMyE,IACzByD,GAAa9I,EAAEY,MAAMyE,GAEzB,MAAO,CAAE8G,YAAWrD,YAAWoD,UAAS7J,iB,iCCnE5C,kEAyCO,MAAM+J,EAAM,YAAG,CAAEC,KATxB,SAAcrM,GACV,MAAMC,EAAK,YAAgBD,EAAG,IAAK,OAC7BE,EAAS,CAAEF,EAAGC,GACpB,OAAO,IAAOE,eAAc,CAACC,EAASC,KAClC,MAAMC,EAAMF,EAAQgM,IAAInM,GAExB,OADAI,EAAK,CAACJ,IACCK,IACRJ,EAAQ,KAAiB,U,iCCvChC,kEAyCO,MAAMoM,EAAO,YAAG,CAAEC,MATzB,SAAevM,GACX,MAAMC,EAAK,YAAgBD,EAAG,IAAK,QAC7BE,EAAS,CAAEF,EAAGC,GACpB,OAAO,IAAOE,eAAc,CAACC,EAASC,KAClC,MAAMC,EAAMF,EAAQkM,KAAKrM,GAEzB,OADAI,EAAK,CAACJ,IACCK,IACRJ,EAAQ,KAAiB,U,iCCvChC,kEA0CO,MAAMsM,EAAQ,YAAG,CAAEC,OAT1B,SAAgBzM,GACZ,MAAMC,EAAK,YAAgBD,EAAG,IAAK,SAC7BE,EAAS,CAAEF,EAAGC,GACpB,OAAO,IAAOE,eAAc,CAACC,EAASC,KAClC,MAAMC,EAAMF,EAAQoM,MAAMvM,GAE1B,OADAI,EAAK,CAACJ,IACCK,IACRJ,EAAQ,KAAiB,U,iCCxChC,kEAyCO,MAAMwM,EAAW,YAAG,CAAEC,UAT7B,SAAmB3M,GACf,MAAMC,EAAK,YAAgBD,EAAG,IAAK,YAC7BE,EAAS,CAAEF,EAAGC,GACpB,OAAO,IAAOE,eAAc,CAACC,EAASC,KAClC,MAAMC,EAAMF,EAAQsM,SAASzM,GAE7B,OADAI,EAAK,CAACJ,IACCK,IACRJ,EAAQ,KAAiB,U,iCCvChC,yEAsDO,MAAM0M,EAAS,YAAG,CAAEC,QAd3B,SAAiB1E,EAAS2E,EAAOC,EAAU,EAAGC,EAAW,GACrD,GAAIF,EAAQ,EACR,MAAM,IAAI7J,MAAM,iDAAiD6J,KAErE,MAAMG,EAAW,YAAgB9E,EAAS,UAAW,SAAU,SACzD4D,EAAW,IAAIkB,EAASrM,MAAOkM,GAK/B5M,EAAS,CAAEiI,QAAS8E,GACpBrJ,EAAQ,CAAEkJ,QAAOC,UAASC,YAChC,OAAO,IAAO7M,eANE,CAACC,EAASC,KACtBA,EAAK,CAAC4M,IACC,YAAQ7M,EAAQwM,OAAO,YAAQK,EAAU,CAACA,EAASlM,OAAQ+L,EAAOC,EAASC,GAAWjB,KAI5D7L,EAAQ,KAAiB,KAAQ0D,O,iCCpD1E,4GAgIO,MAAMsJ,EAAO,YAAG,CAAEC,MA7EzB,SAAe1M,EAAO2M,EAAaC,EAAa3I,EAAK4I,EAAWrE,GAC3C,MAAbqE,IACAA,EAAY,CAAC,EAAG,IAEL,MAAXrE,IACAA,EAAU,GAEF,IAARvE,IACAA,EAAM,SAEV,MAAMzE,EAAK,YAAgBQ,EAAO,IAAK,WACvC,IAAI8M,EAAMtN,EACNuN,GAAe,EACH,IAAZvN,EAAG4C,OACH2K,GAAe,EACfD,EAAM,YAAQtN,EAAI,CAAC,EAAGA,EAAGW,MAAM,GAAIX,EAAGW,MAAM,GAAIX,EAAGW,MAAM,MAE7D,SAAY,IAAyCqI,EAASqE,IAAY,IACtE,qEAAerE,oBAA0BqE,OAC7C,MAAMG,EAAW,IAA4BF,EAAI3M,MAAOwM,EAAanE,EAASqE,EAAW5I,GACnFgJ,EAAW,CAACD,EAASE,eAAgBF,EAASG,eAKpD,IAAIC,EAEAA,EADQ,SAARnJ,EAoCR,SAAsCoJ,EAAaJ,GAG/C,MAGMK,EAHqBD,EAAYtM,KAAI,CAACwM,EAAG3I,IACpC2I,GAAKA,EAAI,IAAMN,EAASrI,GAAK,KAEC7D,KAAIwM,GAAKA,EAAI,IAGhDC,EAAgBF,EAAcvM,KAAIwM,GAAKjM,KAAKC,MAAMgM,EAAI,KACtDE,EAAcH,EAAcvM,KAAI,CAACwM,EAAG3I,IAAM2I,EAAIC,EAAc5I,KAClE,OAAO0I,EAAcvM,KAAI,CAAC2M,EAAG9I,IAClB,CAAC4I,EAAc5I,GAAI6I,EAAY7I,MA/CxB+I,CAA6B,CAACX,EAASY,aAAcZ,EAASa,aAAcZ,GAG5E,CAAC,CAAC,EAAG,GAAI,CAAC,EAAG,IAE/B,MAAMa,EAAgC,IAAhBb,EAAS,IAA4B,IAAhBA,EAAS,IAC7Cc,EAAiBC,GAgB5B,SAAsCC,EAAYC,EAAYd,GAC1D,MAAMe,EAAWf,EAAYrM,KAAIyD,GAAKA,EAAE,KAClC4J,EAAahB,EAAYrM,KAAIyD,GAAKA,EAAE,KACpC6J,EAAiBJ,EAAWnI,OAAOqI,EAAUC,GAC7CE,EAAcJ,EAAWnN,KAAI,CAACyD,EAAGI,KAAOJ,EAAI6J,EAAezJ,GAAKJ,GAAKA,IACrEgB,EAAS4I,EAAWrN,KAAI,CAACwM,EAAG3I,IAAM2I,EAAIe,EAAY1J,KAClDT,EAAW+J,EAAWnN,KAAI,CAAC2M,EAAG9I,IAAM,CAACuJ,EAASvJ,GAAIY,EAAOZ,MACzD2J,EAAQL,EAAWnN,KAAI,CAAC2M,EAAG9I,IAAM,CAAC,EAAG0J,EAAY1J,MACvD,MAAO,CAACT,EAAUoK,GAxBuBC,CAA6B,CAACxB,EAASyB,SAAUzB,EAAS0B,SAAUzB,EAAUG,GACjHuB,EAAeb,EAAgB7J,EAAM,QACrC2K,EAAad,EAAgBhB,EAAM,YAAeA,EAAKG,EAAUc,GAIjEc,GAH4B,QAAhBjC,EACd,IAAM,YAAQgC,EAAYjC,EAAanE,EAASmG,GAChD,IAAM,YAAQC,EAAYjC,EAAanE,EAASmG,MAE9C9O,EAAMiO,EAAgBe,EAAI,YAAeA,EAAG5B,EAAUe,GAC5D,OAAIjB,EACO,YAAQlN,EAAK,CAACA,EAAIM,MAAM,GAAIN,EAAIM,MAAM,GAAIN,EAAIM,MAAM,KAExDN,M,iCC/FX,wGAgFO,MAAMiP,EAAO,YAAG,CAAEC,MAzBzB,SAAexP,EAAGyC,EAAO,KAAMY,GAAW,GACtC,IAAIpD,EAAK,YAAgBD,EAAG,IAAK,QACjC,MAmBME,EAAS,CAAEF,EAAGC,GACd2D,EAAQ,CAAEnB,OAAMY,YACtB,OAAO,IAAOlD,eArBGC,IACI,SAAbH,EAAGS,QACHT,EAAK,YAAKA,EAAI,UAElB,MAAMsD,EAAO,yBAAed,EAAMxC,EAAGW,OAC/BiD,EAAc,YAAmBN,EAAMtD,EAAG4C,MAChD,IAAIiB,EAAgBP,EAChBQ,EAAY9D,EACG,MAAf4D,IACAE,EAAY,YAAU9D,EAAI4D,GAC1BC,EAAgB,YAAiBA,EAAcjD,OAAQZ,EAAG4C,OAE9D,IAAImB,EAAQ5D,EAAQmP,KAAKxL,EAAWD,GACpC,GAAIT,EAAU,CACV,MAAMX,EAAW,YAAqBsB,EAAMpD,MAAO2C,GACnDS,EAAQ,YAAQA,EAAOtB,GAE3B,OAAOsB,IAI0B9D,EAAQ,KAAiB,KAAM0D,O,iCC9ExE,kEA4CO,MAAM6L,EAAO,YAAG,CAAEC,MAVzB,SAAe1P,GACX,MAAMC,EAAK,YAAgBD,EAAG,IAAK,QAM7BE,EAAS,CAAEF,EAAGC,GACpB,OAAO,IAAOE,eANE,CAACC,EAASC,KACtB,MAAMC,EAAMF,EAAQqP,KAAKxP,GAEzB,OADAI,EAAK,CAACJ,IACCK,IAG0BJ,EAAQ,KAAiB,U,iCC1ClE,kFAwFO,MAAMyP,EAAkB,YAAG,CAAEC,iBArCpC,SAA0B5P,EAAG6P,EAAiBC,EAAiB7G,EAASvE,EAAKgJ,EAAW,CAAC,EAAG,GAAIqC,EAAa,QACzG,MAAM9P,EAAK,YAAgBD,EAAG,IAAK,mBAC7BgQ,EAAmB,YAAgBH,EAAiB,kBAAmB,mBACvEI,EAAmB,YAAgBH,EAAiB,kBAAmB,mBAC7E,IAAIvC,EAAMtN,EACNuN,GAAe,EAKnB,GAJgB,IAAZvN,EAAG4C,OACH2K,GAAe,EACfD,EAAM,YAAQtN,EAAI,CAAC,EAAGA,EAAGW,MAAM,GAAIX,EAAGW,MAAM,GAAIX,EAAGW,MAAM,MAE1C,SAAfmP,EACA,MAAM,IAAI9M,MAAM,sFAGpB,SAAyB,IAAbsK,EAAI1K,MAAY,IACxB,gEAAQ0K,EAAI1K,UAChB,SAAsC,IAA1BmN,EAAiBnN,MAAY,IACrC,2EAAYmN,EAAiBnN,UACjC,SAAsC,IAA1BoN,EAAiBpN,MAAY,IACrC,2EAAYmN,EAAiBnN,UACjC,SAA0C,IAA9BoN,EAAiBrP,MAAM,IAAU,IACzC,yFAAuBqP,EAAiBrP,MAAM,QAClD,SAA0C,IAA9BqP,EAAiBrP,MAAM,IAAU,IACzC,yFAA6BqP,EAAiBrP,MAAM,QACxD,MAAMsP,EAAaF,EAAiBpP,MAAM,GACpCuP,EAAoBH,EAAiBpP,MAAM,GACjD,SAAYqP,EAAiBrP,MAAM,KAAOsP,EAAaC,GAAmB,IACtE,6EAAWD,EAAaC,cACbF,EAAiBrP,MAAM,QACtC,MAAMwP,EAAY,YAAgB7C,EAAKyC,EAAkB/G,EAASvE,EAAKqL,EAAYrC,GAE7EpN,EAAM,YAAO8P,EAAWH,EADN,EACyC,QAASF,GAC1E,OAAIvC,EACO,YAAQlN,EAAK,CAACA,EAAIM,MAAM,GAAIN,EAAIM,MAAM,GAAIN,EAAIM,MAAM,KAExDN,M,iCCtFX,kEA2DO,MAAM+P,EAAO,YAAG,CAAEC,MAfzB,SAAetQ,EAAGuQ,EAAI,EAAGC,GAAS,GAC9B,MAAMvQ,EAAK,YAAgBD,EAAG,IAAK,QACnC,GAAgB,IAAZC,EAAG4C,KACH,MAAM,IAAII,MAAM,sDAEpB,MAAMwN,EAAUxQ,EAAGW,MAAMX,EAAGW,MAAMC,OAAS,GAC3C,GAAI0P,EAAIE,EACJ,MAAM,IAAIxN,MAAM,uDAAuDwN,cACxDF,KAEnB,MAAMrQ,EAAS,CAAEF,EAAGC,GACd2D,EAAQ,CAAE2M,IAAGC,WACZhH,EAAQrB,GAAW,IAAOhI,eAAc8E,GAAKA,EAAEoL,KAAKpQ,EAAIsQ,EAAGC,IAAStQ,EAAQ,KAAiB,KAAM0D,GAC1G,MAAO,CAAE4F,SAAQrB,e,gCCzDrB,kEAsCO,MAAMuI,EAAY,YAAG,CAAEC,WAL9B,SAAoB3Q,GAChB,MAAMC,EAAK,YAAgBD,EAAG,IAAK,aAC7BE,EAAS,CAAEF,EAAGC,GACpB,OAAO,IAAOE,eAAcC,GAAWA,EAAQsQ,UAAUzQ,IAAKC,EAAQ,KAAiB,U,gCCpC3F,yEA0DO,MAAM0Q,EAAY,YAAG,CAAEC,WAlB9B,SAAoB7Q,EAAG8Q,GACnB,MAAM7Q,EAAK,YAAgBD,EAAG,IAAK,aAUnC,GATY,MAAR8Q,IACAA,EAAO7Q,EAAGW,MAAMY,KAAI,CAACwM,EAAG3I,IAAMA,IAAG0L,WAErC,SAAY9Q,EAAG4C,OAASiO,EAAKjQ,QAAQ,IAAM,qCAAqCZ,EAAG4C,kCAClDiO,OACjCA,EAAKE,SAAQvO,IACT,SAAYA,GAAQ,GAAKA,EAAOxC,EAAG4C,MAAM,IAAM,gDAA+C5C,EAAG4C,KAAO,GACpG,YAAYiO,SAEhB7Q,EAAG4C,MAAQ,EACX,OAAO5C,EAAGgR,QAEd,MAAM/Q,EAAS,CAAEF,EAAGC,GACd2D,EAAQ,CAAEkN,QAChB,OAAO,IAAO3Q,eAAcC,GAAWA,EAAQwQ,UAAU3Q,EAAI6Q,IAAO5Q,EAAQ,KAAqB,KAAW0D,O,gCCxDhH,2DAyCO,MAAMsN,EAAS,YAAG,CAAEC,QAV3B,SAAiBnR,GACb,MAAMC,EAAK,YAAgBD,EAAG,IAAK,UAE7BoR,EAAe,CAACnR,GAEtB,OAAO,IAAOE,eAAc,CAACC,EAASC,KAClCA,EAAK,CAACJ,IACCG,EAAQ8Q,OAAOjR,KACvB,CAAED,EAAGC,GAAM,KAAiB,SANjB,GAMkCmR,EAJ1B,Q,iCClBnB,SAASC,EAAeC,EAAQC,EAAaC,GAGhD,MAAO,CAFSA,GAAgC,iBAAXF,EAAsBA,EAASA,EAAO,IAC3DC,GAAiC,iBAAXD,EAAsBA,EAASA,EAAO,KAnBhF,mC,gCCAA,0EAsEO,MAAMhP,EAAQ,YAAG,CAAEmP,OAf1B,SAAgBzR,EAAGuB,EAAOR,GACtB,MAAMd,EAAK,YAAgBD,EAAG,IAAK,SACnC,GAAgB,IAAZC,EAAG4C,KACH,MAAM,IAAII,MAAM,kCAEpB,MAAOyO,EAAQC,GAAS,mBAA4B1R,EAAIsB,EAAOR,GAC/D,oBAA6Bd,EAAIyR,EAAQC,GACzC,MAIMzR,EAAS,CAAEF,EAAGC,GACd2D,EAAQ,CAAErC,QAAOR,QACvB,OAAO,IAAOZ,eANE,CAACC,EAASC,KACtBA,EAAK,CAACJ,IACCG,EAAQkC,MAAMrC,EAAIyR,EAAQC,KAIAzR,EAAQ,KAAiB,KAAO0D,O,iCCpEzE,kGAiDO,MAAMgO,EAAW,YAAG,CAAEC,UAb7B,SAAmB7R,GACf,MAAMC,EAAK,YAAgBD,EAAG,IAAK,YAS7BE,EAAS,CAAEF,EAAGC,GACpB,OAAO,IAAOE,eATE,CAACC,EAASC,KACtB,GAAiB,cAAbJ,EAAGS,MAAuB,CAC1B,MAAMwK,EAAI0G,EAAS,YAAK3R,IAClBoF,EAAI,YAAU,YAAKpF,IACzB,OAAO,YAAQiL,EAAG7F,GAEtB,OAAOjF,EAAQwR,SAAS3R,KAGSC,EAAQ,KAAiB,U,iCC/ClE,kEAyCO,MAAM4R,EAAa,YAAG,CAAEC,YAT/B,SAAqB/R,GACjB,MAAMC,EAAK,YAAgBD,EAAG,IAAK,cAC7BE,EAAS,CAAEF,EAAGC,GACpB,OAAO,IAAOE,eAAc,CAACC,EAASC,KAClC,MAAMC,EAAMF,EAAQ0R,WAAW7R,GAE/B,OADAI,EAAK,CAACJ,IACCK,IACRJ,EAAQ,KAAiB,U,iCCvChC,kEAsCO,MAAM8R,EAAQ,YAAG,CAAEC,OAL1B,SAAgBjS,GACZ,MAAMC,EAAK,YAAgBD,EAAG,IAAK,SAC7BE,EAAS,CAAEF,EAAGC,GACpB,OAAO,IAAOE,eAAeC,GAAYA,EAAQ4R,MAAM/R,IAAKC,EAAQ,KAAiB,U,iCCpCzF,kEAqCO,MAAMgS,EAAO,YAAG,CAAEC,MALzB,SAAenS,GACX,MAAMC,EAAK,YAAgBD,EAAG,IAAK,QAC7BE,EAAS,CAAEF,EAAGC,GACpB,OAAO,IAAOE,eAAcC,GAAWA,EAAQ8R,KAAKjS,IAAKC,EAAQ,KAAiB,U,iCCnCtF,kEA0DO,MAAMkS,EAAU,YAAG,CAAEC,SAjB5B,SAAkBC,EAAQtG,GAAM,GAC5B,MAAMuG,EAAU,YAAgBD,EAAQ,SAAU,UAAW,WAI7D,IAHa,IAATtG,IACAA,EAAMuG,EAAQ1P,KAAO,GAErBmJ,IAAQuG,EAAQ1P,KAAO,EACvB,MAAMI,MACF,4EAAmBsP,EAAQ1P,oBAAoBmJ,KAEvD,MAAM9L,EAAS,CAAEoS,OAAQC,GACnB3O,EAAQ,CAAEoI,OAChB,OAAO,IAAO7L,eAAc,CAACC,EAASC,KAClC,MAAMiP,EAAIlP,EAAQgS,QAAQG,EAASvG,GAEnC,OADA3L,EAAK,CAACiP,IACCA,IACRpP,EAAQ,KAAiB,KAAS0D,O,iCCxDzC,yFAoHO,MAAM4O,EAAe,YAAG,CAAEC,cA5DjC,SAAuBzS,EAAGuB,EAAOmR,EAAKzJ,EAAS0J,EAAY,EAAGC,EAAU,EAAGC,EAAe,EAAGC,EAAc,EAAGC,EAAiB,GAC3H,IAAI9S,EAAK,YAAgBD,EAAG,IAAK,gBACjC,MA6CME,EAAS,CAAEF,EAAGC,GACd2D,EAAQ,CACVrC,QACAmR,MACAzJ,UACA0J,YACAC,UACAC,eACAC,cACAC,kBAEJ,OAAO,IAAO5S,eAxDGC,IACE,MAAX6I,IACAA,EAAU,IAAInG,MAAMvB,EAAMV,SAE9B,MAAMmS,EAAe,qBAAWH,GAChC,GAAIG,EAAanS,OAAS,EACtB,MAAM,IAAIoC,MAAM,8CAEpB,GAAqB,IAAjB4P,GAAsC,IAAhBC,EACtB,MAAM,IAAI7P,MAAM,iEAEpB,GAAqB,IAAjB4P,GAAyC,IAAnBE,EACtB,MAAM,IAAI9P,MAAM,oEAEpB,MAAMgQ,EAAsBhT,EAAG4C,KAAOtB,EAAMV,OAEtCqS,EAAa,qBAAWJ,GACxBpQ,EAAWzC,EAAGW,MAAM0B,QAC1B4Q,EAAWlC,SAAQvO,IACflB,EAAMkB,GAAQ,EACdiQ,EAAIjQ,GAAQ,EACZC,EAASyQ,OAAO1Q,EAAM,EAAG,MAE7BxC,EAAK,YAAQA,EAAIyC,GACjB,MAAQnB,MAAO6R,EAAiBV,IAAKW,EAAepK,QAASqK,GAAsB,4BAAkBrT,EAAGW,MAAOoS,EAAcC,EAAqB1R,EAAOmR,EAAKzJ,EAAS0J,EAAWC,EAASC,GAC3LtR,EAAQ6R,EACRV,EAAMW,EACNpK,EAAUqK,EACV,MAAMC,EAAa,qBAAWR,GAE9BQ,EAAWvC,SAAQvO,IACfiQ,EAAIjQ,GAAQlB,EAAMkB,GAAQ,EAC1BwG,EAAQxG,GAAQ,KAGpB,MAAM1B,EAAO,0BAAgBQ,EAAOmR,EAAKzJ,GAEnC8C,EAAWhL,EAAKyS,QAAO,CAACrF,EAAG1L,KAAuC,IAA9B8Q,EAAW5I,QAAQlI,KAE7D,GADmBwG,EAAQwK,OAAMhS,GAAW,IAANA,IAElC,OAAO,YAAQ,YAAMxB,EAAIsB,EAAOR,GAAOgL,GAE3C,MAAMzL,EAAMF,EAAQoS,aAAavS,EAAIsB,EAAOmR,EAAKzJ,GACjD,OAAO,YAAQ3I,EAAKyL,KAaa7L,EAAQ,KAAiB,KAAc0D,O,iCClHhF,kEAyCO,MAAM8P,EAAM,YAAG,CAAEC,KATxB,SAAc3T,GACV,MAAMC,EAAK,YAAgBD,EAAG,IAAK,OAC7BE,EAAS,CAAEF,EAAGC,GACpB,OAAO,IAAOE,eAAc,CAACC,EAASC,KAClC,MAAMC,EAAMF,EAAQsT,IAAIzT,GAExB,OADAI,EAAK,CAACJ,IACCK,IACRJ,EAAQ,KAAiB,U,iCCvChC,kEAyCO,MAAM0T,EAAO,YAAG,CAAEC,MATzB,SAAe7T,GACX,MAAMC,EAAK,YAAgBD,EAAG,IAAK,QAC7BE,EAAS,CAAEF,EAAGC,GACpB,OAAO,IAAOE,eAAc,CAACC,EAASC,KAClC,MAAMiP,EAAIlP,EAAQwT,KAAK3T,GAEvB,OADAI,EAAK,CAACiP,IACCA,IACRpP,EAAQ,KAAiB,U,gCCvChC,0FA6EO,MAAM4T,EAAQ,YAAG,CAAEC,OA/B1B,SAAgBC,EAAWhP,EAAGC,GAC1B,MAAM4E,EAAK,YAAgB7E,EAAG,IAAK,SAC7B8E,EAAK,YAAgB7E,EAAG,IAAK,SAC7BgP,EAAa,YAAgBD,EAAW,YAAa,QAAS,QAI9DE,EAAiB,YAA2BrK,EAAGjJ,MAAOkJ,EAAGlJ,OACzDuT,EAAgB,YAAYtK,EAAIqK,GAChCE,EAAgB,YAAYtK,EAAIoK,GACd,IAApBD,EAAWpR,MAGX,iBAAOoR,EAAWrT,MAAM,KAAOiJ,EAAGjJ,MAAM,IAAI,IAAM,mEAE9B,IAApBqT,EAAWpR,MAEX,4BAAkBoR,EAAWrT,MAAOwT,EAAcxT,MAAO,oBAE7D,MAKMV,EAAS,CACX8T,UAAWC,EACXI,EAAGF,EACHG,EAAGF,GAEP,OAAO,IAAOjU,eAVE,CAACC,EAASC,KACtB,MAAMC,EAAMF,EAAQmU,OAAON,EAAYE,EAAeC,GAEtD,OADA/T,EAAK,CAAC4T,IACC3T,IAO0BJ,EAAQ,KAAqB,U,+BC3EtE,6CAuBO,SAASsU,EAAGC,GACf,MAAMC,EAAOC,OAAOD,KAAKD,GACzB,GAAoB,IAAhBC,EAAK7T,OACL,MAAM,IAAIoC,MAEN,yGAAGyR,EAAK7T,gBAEhB,IAAI+T,EAASF,EAAK,GAClB,MAAMG,EAAKJ,EAAEG,GAETA,EAAOE,SAAS,OAChBF,EAASA,EAAOG,UAAU,EAAGH,EAAO/T,OAAS,IAGjD+T,GApB2B,OAsB3B,MAAMI,EAAK,IAAIC,KACX,IAAOC,WAAWN,GAClB,IACI,MAAMO,EAASN,KAAMI,GAKrB,OAJIE,aAAkBC,SAClBlL,QAAQmL,MAAM,2CAElB,IAAOC,SAASH,GACTA,EAEX,MAAOI,GAEH,MADA,IAAOD,SAAS,MACVC,IAKd,OAFAZ,OAAOa,eAAeR,EAAI,OAAQ,CAAEhR,MAAO4Q,EAAQa,cAAc,IAE1DT,I,gCCxDX,kEAyCO,MAAMtJ,EAAO,YAAG,CAAEgK,MATzB,SAAe1V,GACX,MAAMC,EAAK,YAAgBD,EAAG,IAAK,QAC7BE,EAAS,CAAEF,EAAGC,GACpB,OAAO,IAAOE,eAAc,CAACC,EAASC,KAClC,MAAMC,EAAMF,EAAQsL,KAAKzL,GAEzB,OADAI,EAAK,CAACJ,IACCK,IACRJ,EAAQ,KAAiB,U,gCCvChC,wpBAiBO,SAASyV,EAAkBlV,EAAOc,EAAOR,GAC5C,SAAYN,EAAMoC,OAAStB,EAAMV,QAAQ,IAAM,iBAAiBJ,EAAMoC,0BAA0BtB,uCAC5Dd,EAAMoC,WAC1C,SAAYpC,EAAMoC,OAAS9B,EAAKF,QAAQ,IAAM,iBAAiBJ,EAAMoC,yBAAyB9B,uCAC1DN,EAAMoC,WAC1C,IAAK,IAAIwC,EAAI,EAAGA,EAAI5E,EAAMoC,OAAQwC,EAC9B,SAAY9D,EAAM8D,GAAKtE,EAAKsE,IAAM5E,EAAMG,MAAMyE,IAAI,IAAM,iBAAiB5E,EAAMoC,gBAAgBwC,aAAaA,OACpG9D,EAAM8D,GAAKtE,EAAKsE,kCAAkCA,OAAO5E,EAAMG,MAAMyE,QAI9E,SAASuQ,EAAWC,GACvB,MAAMtS,EAAO,GACb,IAAId,EAAO,EACX,KAAOoT,EAAO,GACC,EAAPA,GACAtS,EAAK8C,KAAK5D,GAEdoT,GAAQ,EACRpT,IAEJ,OAAOc,EAGJ,SAASsI,EAAgBtK,EAAOmR,EAAKzJ,GACxC,MAAMlI,EAAO,GACb,IAAK,IAAI0B,EAAO,EAAGA,EAAOlB,EAAMV,OAAQ4B,IACpC1B,EAAK0B,GAAQV,KAAK8E,MAAM6L,EAAIjQ,GAAQlB,EAAMkB,IAASwG,EAAQxG,IAE/D,OAAO1B,EAIJ,SAAS+U,EAAsB7M,EAAS8M,EAAwBC,EAAetH,GAClF,MAAMuH,EAAa,IAAIhN,GACvB,IAAK,IAAI5D,EAAI4Q,EAAWpV,OAAQwE,EAAIqJ,EAAW7N,OAAQwE,IACnD4Q,EAAW5P,KAAK,GAEpB,IAAK,IAAIhB,EAAI,EAAGA,EAAI2Q,EAAe3Q,IACrB,IAANA,EACA4Q,EAAWF,GAA0B,GAGrCE,EAAW9C,OAAO4C,EAAwB,EAAgC,GAC1EE,EAAWC,OAGnB,OAAOD,EAEX,SAASE,EAAgBJ,EAAwBC,EAAeI,GAC5D,OAAIA,GAAkBL,EACXK,EAEJA,GAAkBJ,EAAgB,GAE7C,SAASK,EAAcL,EAAeD,GAClC,MAAMO,EAAa,GACnB,IAAK,IAAIjR,EAAI,EAAGA,EAAI2Q,EAAe3Q,IAC/BiR,EAAWjQ,KAAK0P,EAAyB1Q,GAE7C,OAAOiR,EAGJ,SAASC,EAAkB7H,EAAYsE,EAAcC,EAAqB1R,EAAOmR,EAAKzJ,EAAS0J,EAAWC,EAASC,GACtH,MAAM2D,EAAY9H,EAAW7N,OAC7B,IAAIuS,EAAkB,IAAItQ,MAAM0T,GAAYnD,EAAgB,IAAIvQ,MAAM0T,GAAYlD,EAAoB,IAAIxQ,MAAM0T,GAChH,GAAIxD,EAAanS,QAAUoS,EAAsB,EAAG,CAChD,MAAMwD,EAAYzD,EAAa,GAGzBgD,EAAgB/C,EAAsB,EAC5CG,EAAkBsD,EAA2B/D,EAAW8D,EAAWT,EAAezU,EAAOmN,GACzF2E,EAAgBsD,EAA0B/D,EAAS6D,EAAWT,EAAetD,EAAKhE,GAClF4E,EACIwC,EAAsB7M,EAASwN,EAAWT,EAAetH,QAG7D,IAAK,IAAIjM,EAAO,EAAGA,EAAO+T,EAAW/T,IACjC2Q,EAAgB3Q,GAAQmU,EAAajE,EAAWpR,EAAO0H,EAASyF,EAAYjM,EAAMoQ,GAClFQ,EAAc5Q,GACVoU,EAAYjE,EAASF,EAAKzJ,EAASyF,EAAYjM,EAAMoQ,GACzDS,EAAkB7Q,GAAQqU,EAAe7N,EAASxG,EAAMoQ,GAGhE,MAAO,CACHtR,MAAO6R,EACPV,IAAKW,EACLpK,QAASqK,GAKV,SAASoD,EAA2B/D,EAAWoD,EAAwBC,EAAee,EAAerI,GACxG,MAAMsI,EAAa,IAAItI,GACjB4H,EAAaD,EAAcL,EAAeD,GAChD,IAAK,IAAItT,EAAO,EAAGA,EAAOuU,EAAWnW,OAAQ4B,IACzC,GAAI6T,EAAW3L,QAAQlI,IAAS,EAC5BuU,EAAWvU,GAAQ,MAElB,CACD,MAAMwU,EAAed,EAAgBJ,EAAwBC,EAAevT,GAC5E,IAAIyU,EAAgBH,EAAcE,GAC9BtE,EAAY,GAAKsE,IACjBC,EAAgB,GAEpBF,EAAWvU,GAAQyU,EAG3B,OAAOF,EAIJ,SAASL,EAA0B/D,EAASmD,EAAwBC,EAAemB,EAAazI,GACnG,MAAMsI,EAAa,IAAItI,GACjB4H,EAAaD,EAAcL,EAAeD,GAChD,IAAK,IAAItT,EAAO,EAAGA,EAAOuU,EAAWnW,OAAQ4B,IACzC,GAAI6T,EAAW3L,QAAQlI,IAAS,EAC5BuU,EAAWvU,GAAQ2U,OAAOC,qBAEzB,CACD,MAAMJ,EAAed,EAAgBJ,EAAwBC,EAAevT,GAC5E,IAAIyU,EAAgBC,EAAYF,GAC5BrE,EAAU,GAAKqE,IACfC,EAAgBE,OAAOC,kBAE3BL,EAAWvU,GAAQyU,EAG3B,IAAK,IAAI7R,EAAI,EAAGA,EAAI2R,EAAWnW,OAAQwE,IAAK,CAExC,MAAMiS,EAAW5I,EAAWrJ,GACxB2R,EAAW3R,GAAK,IAChB2R,EAAW3R,IAAMiS,GAErBN,EAAW3R,GAAK,QAAW,EAAG2R,EAAW3R,GAAIqJ,EAAWrJ,IAE5D,OAAO2R,EAEJ,SAASF,EAAe7N,EAASxG,EAAMoQ,GAC1C,IAAI0E,EAAStO,EAAQxG,GAIrB,OAHIoQ,EAAgB,GAAKpQ,GAAmB,MAAV8U,KAC9BA,EAAS,GAENA,EAEJ,SAASX,EAAajE,EAAW6E,EAAcvO,EAASyF,EAAYjM,EAAMoQ,GAE7E,IAAI1M,EAAQqR,EAAa/U,GACzB,MAAM8U,EAAStO,EAAQxG,IAAS,GAG5BkQ,EAAY,GAAKlQ,GAAQoQ,EAAe,GAAKpQ,GAAiB,MAAT0D,KAKjDA,EAJAoR,EAAS,EAIDH,OAAOK,iBAIPL,OAAOC,kBAIvB,MAAMC,EAAW5I,EAAWjM,GAM5B,OALI0D,EAAQ,IACRA,GAASmR,GAGbnR,EAAQ,QAAW,EAAGA,EAAOmR,EAAW,GACjCnR,EAEJ,SAAS0Q,EAAYjE,EAAS8E,EAAazO,EAASyF,EAAYjM,EAAMoQ,GAEzE,IAAIzJ,EAAOsO,EAAYjV,GACvB,MAAM8U,EAAStO,EAAQxG,IAAS,GAG5BmQ,EAAW,GAAKnQ,GAASoQ,EAAgB,GAAKpQ,GAAiB,MAAR2G,KAInDA,EAHAmO,EAAS,EAGFH,OAAOC,iBAIPD,OAAOK,kBAItB,MAAMH,EAAW5I,EAAWjM,GAe5B,OAdI2G,EAAO,IACPA,GAAQkO,GAORlO,EAFAmO,EAAS,EAEF,QAAW,EAAGnO,EAAMkO,GAIpB,SAAY,EAAGlO,EAAMkO,EAAW,GAEpClO,EAMJ,SAASuO,EAAiB/W,EAAOW,EAAOR,GAE3C,IAAI6W,EAAkB7W,EAAKF,OAC3B,IAAK,IAAIwE,EAAI,EAAGA,EAAItE,EAAKF,OAAQwE,IAC7B,GAAItE,EAAKsE,GAAK,EAAG,CACbuS,EAAkBvS,EAClB,MAGR,IAAK,IAAIA,EAAIuS,EAAkB,EAAGvS,EAAItE,EAAKF,OAAQwE,IAC/C,GAAI9D,EAAM8D,GAAK,GAAKtE,EAAKsE,KAAOzE,EAAMyE,GAClC,OAAO,EAGf,OAAO,EAEJ,SAASwS,EAAkBtW,EAAO0H,GACrC,IAAI6O,EAAavW,EAAMV,OAAS,EAAIU,EAAMA,EAAMV,OAAS,GAAK,EAC9D,IAAK,IAAIwE,EAAI,EAAGA,EAAI9D,EAAMV,OAAS,EAAGwE,IAClCyS,GAAcvW,EAAM8D,GAAK4D,EAAQ5D,GAErC,OAAOyS,EAEJ,SAASC,EAAiB/X,EAAGuB,EAAOR,GAEvC,IAAI2Q,EAaAC,EAuBJ,OAlCID,EADiB,iBAAVnQ,EACE,CAACA,KAAU,IAAIuB,MAAM9C,EAAE6C,KAAO,GAAG2D,KAAK,IAE1CjF,EAAMV,OAASb,EAAE6C,KACbtB,EAAMgF,OAAO,IAAIzD,MAAM9C,EAAE6C,KAAOtB,EAAMV,QAAQ2F,KAAK,IAGnDjF,EAAMe,QAEnBoP,EAAOV,SAAQxI,IACX,UAAmB,IAAPA,GAAU,IAAM,yDAI5BmJ,EADQ,MAAR5Q,EACQ,IAAI+B,MAAM9C,EAAE6C,MAAM2D,MAAM,GAEX,iBAATzF,EACJ,CAACA,KAAS,IAAI+B,MAAM9C,EAAE6C,KAAO,GAAG2D,MAAM,IAEzCzF,EAAKF,OAASb,EAAE6C,KACb9B,EAAKwF,OAAO,IAAIzD,MAAM9C,EAAE6C,KAAO9B,EAAKF,QAAQ2F,MAAM,IAGlDzF,EAEZ4Q,EAAQA,EAAMnQ,KAAI,CAACgH,EAAGnD,IACdmD,GAAK,EACEA,GAGP,UAAmB,IAAPA,GAAU,IAClB,qDAAGA,mCAAmCnD,OACnCrF,EAAEY,MAAMyE,GAAKqM,EAAOrM,MAG5B,CAACqM,EAAQC,K,gCCjSpB,4DAgCO,SAASqG,EAAMpX,EAAOF,EAAQ,WACjC,GAAc,cAAVA,EAAuB,CACvB,MAAMuX,EAAOD,EAAMpX,EAAO,WACpBsX,EAAOF,EAAMpX,EAAO,WAC1B,OAAO,YAAQqX,EAAMC,GAEzB,MAAM1O,EAAS,8BAAoB,wBAAc5I,GAAQF,GACzD,OAAO,IAAOyX,WAAW3O,EAAQ5I,EAAOF,K,iCCvC5C,6CAqBO,MAAM0X,EACT,MAAMC,EAAMC,GACR,OAAOC,MAAMF,EAAMC,GAEvB,MACI,OAAOE,YAAYC,MAEvB,OAAOC,EAAMC,GACT,GAAiB,UAAbA,GAAqC,SAAbA,EACxB,MAAM,IAAI1V,MAAM,kDAAkD0V,KAKtE,OAHwB,MAApBC,KAAKC,cACLD,KAAKC,YAAc,IAAIC,aAEpBF,KAAKC,YAAYE,OAAOL,GAEnC,OAAOM,EAAOL,GACV,OAAO,IAAIM,YAAYN,GAAUO,OAAOF,IAGhD,GAAI,cAAMG,IAAI,cAAe,CACzB,cAAMC,YAAY,UAAW,IAAIhB,GAEjC,IACI,IAA0BiB,gBAAgB,IAAoBC,WAAY,IAAI,KAElF,MAAOC,IAGP,IACI,IAA0BF,gBAAgB,IAAiBC,WAAY,IAAI,KAE/E,MAAOC,O,kCCrDX,wBAkBO,MAAMC,EAEI,IAAM,EAAQ,KAE/B,IAAIC,EAYG,MAAMC,EACT,cAEId,KAAKe,KAAO,EAAQ,KAGpBf,KAAKC,YAAc,IAAID,KAAKe,KAAKb,YAErC,MAAMT,EAAMuB,GACR,OAA0B,MAAtB,cAAMC,OAAOtB,MACN,cAAMsB,OAAOtB,MAAMF,EAAMuB,IAEjB,MAAfH,IACAA,EAAcD,KAEXC,EAAYpB,EAAMuB,IAE7B,MACI,MAAME,EAAOC,EAAQC,SACrB,OAAiB,IAAVF,EAAK,GAAYA,EAAK,GAAK,IAEtC,OAAOpB,EAAMC,GACT,GAAiB,UAAbA,GAAqC,SAAbA,EACxB,MAAM,IAAI1V,MAAM,sDAAsD0V,KAE1E,OAAOC,KAAKC,YAAYE,OAAOL,GAEnC,OAAOM,EAAOL,GACV,OAAqB,IAAjBK,EAAMnY,OACC,GAEJ,IAAI+X,KAAKe,KAAKV,YAAYN,GAAUO,OAAOF,IAGtD,cAAMG,IAAI,YACV,cAAMC,YAAY,OAAQ,IAAIM,K,mDCrElC,2EA2DO,MAAMO,EAAQ,YAAG,CAAEC,OAvB1B,SAAgBC,EAAS1X,EAAO,GAC5B,MAAM2X,EAAW,YAAqBD,EAAS,UAAW,SAE1D,GADA,SAAYC,EAASvZ,QAAU,GAAG,IAAM,yCAChB,IAApBuZ,EAASvZ,OACT,OAAO,YAAWuZ,EAAS,GAAI3X,GAEnC,MAAMI,EAAOuX,EAAS,GAAGvX,KACnBjC,EAAQwZ,EAAS,GAAGxZ,MACpBF,EAAQ0Z,EAAS,GAAG1Z,MAC1B,SAAY+B,GAAQI,GAAM,IAAM,uCAChCuX,EAASpJ,SAAQqD,IACb,oBAAuBzT,EAAOyT,EAAEzT,MAAO,yDACvC,SAAYF,IAAU2T,EAAE3T,OAAO,IAAM,6DAEzC,MAAM2Z,EAAkBD,EAAS5Y,KAAI6S,GAAK,YAAWA,EAAG5R,KAOxD,OAAO,YAAO4X,EAAiB5X,O,gCCzDnC,0EA6DO,MAAMmE,EAAM,YAAG,CAAE0T,KAZxB,SAAcC,EAAMC,GAChB,IAAIC,EAAQ,YAAgBF,EAAM,OAAQ,OACtCG,EAAO,YAAgBF,EAAK,MAAO,QACtCC,EAAOC,GAAQ,YAAeD,EAAOC,GACtC,MAAMxa,EAAS,CAAE8E,EAAGyV,EAAOxV,EAAGyV,GAM9B,OAAO,IAAOva,eALE,CAACC,EAASC,KACtB,MAAMiP,EAAIlP,EAAQwG,IAAI6T,EAAOC,GAE7B,OADAra,EAAK,CAACoa,EAAOC,EAAMpL,IACZA,IAE0BpP,EAAQ,KAAqB,U,gCC3DtE,6CAiBA,SAASya,EAAsBC,EAAOC,EAAQC,EAAeC,EAAcC,EAAgBC,GACnE,MAAhBF,IACAA,EAAe,IAEG,MAAlBC,IACAA,EAAiB5D,OAAO8D,mBAER,MAAhBD,IACAA,EAAe,GAEnB,MAAME,EAAWP,EAAMha,MAAM,GAS7B,OARAka,EAAgB/Y,KAAKqZ,IAAIN,EAAeK,GACxC,SAAY,GAAKJ,GAAgBA,GAAgB,GAAG,IAAM,4CAA4CA,OACtG,SAA2B,IAAfH,EAAM/X,MAAY,IAAM,+CAA+C+X,EAAM/X,UACzF,SAA+B,IAAnB+X,EAAMha,MAAM,IAAU,IAAM,oDAAoDga,EAAMha,MAAM,OACxG,SAA4B,IAAhBia,EAAOhY,MAAY,IAAM,+BACrC,SAAYgY,EAAOja,MAAM,KAAOua,GAAU,IAAM,sDAAsDA,cACvFN,EAAOja,MAAM,OAC5B,SAAY,GAAKqa,GAAgBA,GAAgB,GAAG,IAAM,4CAA4CA,OAC/F,CAAEH,gBAAeC,eAAcC,iBAAgBC,kB,gCCpC1D,4DAmCO,SAASxV,EAAS+D,EAAQ9I,GAC7B,wBAAc8I,GACd,MAAM8B,EAAgB,YAAW9B,EAAQ9I,GACzC,GAA6B,IAAzB4K,EAAczK,OACd,MAAM,IAAIoC,MAAM,sDAGpB,OAAO,YAAWuG,EADJ,KACmB8B,EAAe5K,K,gCC1CpD,kFAoEO,MAAM2a,EAAQ,YAAG,CAAEC,OAX1B,SAAgBtb,EAAGqK,EAAiB5H,EAAO,GACvC,MAAMxC,EAAK,YAAgBD,EAAG,IAAK,SAM7BE,EAAS,CAAEF,EAAGC,GACdsb,EAAO,CAAElR,kBAAiB5H,QAChC,OAAO,IAAOtC,eAPE,CAACC,EAAS+N,KACtB,MAAMqN,EAAQ,yBAAe/Y,EAAMxC,EAAGW,OAAO,GACvC0J,EAAa,YAAiBrK,EAAIoK,EAAiBmR,GACzD,OAAOpb,EAAQib,MAAMpb,EAAIqK,EAAYkR,KAIJtb,EAAQ,KAAiB,KAAQqb,O,+BClE1E,yEA2DO,MAAMra,EAAU,YAAG,CAAEua,SAZ5B,SAAkBzb,EAAGY,GACjB,MAAMX,EAAK,YAAgBD,EAAG,IAAK,UAAW,MAC9CY,EAAQ,yBAA4BA,EAAOX,EAAGc,MAC9C,SAAYd,EAAGc,OAAS,gBAAmBH,IAAQ,IAAM,mEACzD,MAAMV,EAAS,CAAEF,EAAGC,GACd2D,EAAQ,CAAEhD,SAKhB,OAAO,IAAOT,eAJE,CAACC,EAASC,KACtBA,EAAK,CAACJ,IACCG,EAAQc,QAAQjB,EAAIW,KAEMV,EAAQ,KAAiB,KAAS0D,O,gCCzD3E,oEAiCO,SAAS8X,EAAK9a,EAAOF,EAAQ,WAChC,GAAc,cAAVA,EAAuB,CACvB,MAAMuX,EAAOyD,EAAK9a,EAAO,WACnBsX,EAAO,YAAMtX,EAAO,WAC1B,OAAO,YAAQqX,EAAMC,GAEzB,MAAM1O,EAAS,6BAAmB,wBAAc5I,GAAQF,GACxD,OAAO,IAAOyX,WAAW3O,EAAQ5I,EAAOF,K,gCCxC5C,0EA8CO,MAAMib,EAAO,YAAG,CAAEC,MAZzB,SAAe5b,GACX,MAAMC,EAAK,YAAgBD,EAAG,IAAK,QAQ7BE,EAAS,CAAEF,EAAGC,GACpB,OAAO,IAAOE,eARE,CAACC,EAASC,KACtBA,EAAK,CAACJ,IACW,SAAbA,EAAGS,MACI,YAAKT,EAAI,SAEbG,EAAQub,KAAK1b,KAGaC,EAAQ,KAAiB,U,gCC5ClE,kEAuCO,MAAMmJ,EAAO,YAAG,CAAEwS,MANzB,SAAe7b,EAAGmE,EAAQ,GACtB,MAAMlE,EAAK,YAAgBD,EAAG,IAAK,QAC7BE,EAAS,CAAEF,EAAGC,GACd2D,EAAQ,CAAEO,SAChB,OAAO,IAAOhE,eAAcC,GAAWA,EAAQiJ,KAAKpJ,EAAIkE,IAAQjE,EAAQ,KAAiB,KAAM0D,O,gCCrCnG,oDAmBO,SAASuU,EAAW3O,EAAQ5I,EAAO0K,EAAe5K,GAIrD,GAHa,MAATA,IACAA,EAAQ,qBAAW8I,IAET,cAAV9I,EACA,MAAM,IAAIuC,MAAM,oFAGpB,IAAK,uBAAauG,KAAY1G,MAAMC,QAAQyG,IACtB,iBAAXA,GAAyC,kBAAXA,GACnB,iBAAXA,EACP,MAAM,IAAIvG,MAAM,4HAGpB,GAAa,MAATrC,EAAe,CACf,6CAAmCA,GACnC,MAAMkb,EAAe,wBAAclb,GAC7Bmb,EAAe,wBAAczQ,GACnC,iBAAOwQ,IAAiBC,GAAc,IAAM,iCAAiCnb,8BACtEkb,oBAA+BC,MACtC,IAAK,IAAI1W,EAAI,EAAGA,EAAIiG,EAAczK,SAAUwE,EAAG,CAC3C,MAAM2W,EAAW1Q,EAAcjG,GACzB4W,EAAoB5W,IAAMiG,EAAczK,OAAS,GACnDmb,IAAa,wBAAcpb,EAAM0B,MAAM+C,IAE3C,iBAAOiG,EAAcjG,KAAOzE,EAAMyE,KAAO4W,GAAmB,IACxD,gDAAI3Q,yCACM1K,UAUtB,OAPK,uBAAa4I,IAAY1G,MAAMC,QAAQyG,KACxCA,EAAS,CAACA,IAEd5I,EAAQA,GAAS0K,EACjB9B,EAAmB,WAAV9I,EACL,uBAAa8I,EAAQ9I,GACrB,kBAAQ8I,EAAQ,IAAI,GACjB,IAAO2O,WAAW3O,EAAQ5I,EAAOF,K,gCCxD5C,yEA6DO,MAAMwb,EAAO,YAAG,CAAEC,MAfzB,SAAenc,EAAGoc,GACd,MACMnc,EAAK,YAAgBD,EAAG,IAAK,OADnB,MAEhB,SAAYC,EAAG4C,OAASuZ,EAAKvb,QAAQ,IAAM,qCAAqCZ,EAAG4C,kCAClDuZ,OACjC,MAKMhL,EAAe,CAACnR,GAChBC,EAAS,CAAEF,EAAGC,GACd2D,EAAQ,CAAEwY,QAChB,OAAO,IAAOjc,eARE,CAACC,EAASC,KACtB,MAAMC,EAAMF,EAAQ8b,KAAKjc,EAAImc,GAE7B,OADA/b,EAAK,CAACJ,IACCK,IAK0BJ,EAAQ,KAAiB,KAAM0D,EAAOwN,O,gCC3D/E,kEA2CO,MAAM6G,EAAO,YAAG,CAAEoE,MARzB,SAAe5b,GACX,MAAM6b,EAAS,YAAgB7b,EAAO,QAAS,QAIzCP,EAAS,CAAEO,MAAO6b,GACxB,OAAO,IAAOnc,eAJGC,GACNA,EAAQ6X,KAAKqE,IAGapc,EAAQ,KAAqB,U,gCCzCtE,wFAoEO,MAAM6Q,EAAU,YAAG,CAAEwL,SAd5B,SAAkBvc,EAAGyC,GACjB,MAAMxC,EAAK,YAAgBD,EAAG,IAAK,WAS7BE,EAAS,CAAEF,EAAGC,GACd2D,EAAQ,CAAE4Y,KAAM/Z,GACtB,OAAO,IAAOtC,eAVGC,IACb,MAAMmD,EAAO,yBAAed,EAAMxC,EAAGW,OACrC,GAAgB,IAAZX,EAAG4C,KACH,OAAO,YAAM5C,GAEjB,MAAMK,EAAMF,EAAQ2Q,QAAQ9Q,EAAIsD,GAChC,OAAO,YAAQjD,EAAKL,EAAGW,SAIUV,EAAQ,KAAqB,KAAS0D,O,gCClE/E,yEA8CO,MAAM6Y,EAAU,YAAG,CAAEC,SAX5B,SAAkB1c,EAAGyC,EAAO,GACxB,MAAMxC,EAAK,YAAgBD,EAAG,IAAK,WACnC,SAAYyC,IAASxC,EAAGW,MAAMC,QAAU4B,EAAOxC,EAAGW,MAAMC,QAAQ,IAAM,UAAU4B,iBAAoBxC,EAAGW,MAAMC,WAAWZ,EAAGW,MAAMC,YAC7H4B,EAAO,IACPA,GAAQxC,EAAGW,MAAMC,QAErB,MAAMX,EAAS,CAAE8D,MAAO/D,GAClB2D,EAAQ,CAAEnB,QAEhB,OAAO,IAAOtC,eADGC,GAAYA,EAAQqc,QAAQxc,EAAIwC,IACZvC,EAAQ,KAAiB,KAAQ0D,O,gCC5C1E,kFA6CO,MAAM+Y,EAAW,YAAG,CAAEC,UAT7B,SAAmB5X,EAAGC,GAClB,IAAI4E,EAAK,YAAgB7E,EAAG,IAAK,YAC7B8E,EAAK,YAAgB7E,EAAG,IAAK,aAChC4E,EAAIC,GAAM,YAAeD,EAAIC,GAC9B,YAA2BD,EAAGjJ,MAAOkJ,EAAGlJ,OACxC,MACMV,EAAS,CAAE8E,EAAG6E,EAAI5E,EAAG6E,GAC3B,OAAO,IAAO3J,eAFGC,GAAYA,EAAQuc,SAAS9S,EAAIC,IAEb5J,EAAQ,KAAiB,U,gCC3ClE,kFA4DO,MAAM2c,EAAoB,YAAG,CAAEC,mBAdtC,SAA4B9X,EAAGC,GAC3B,IAAI4E,EAAK,YAAgB7E,EAAG,IAAK,qBAC7B8E,EAAK,YAAgB7E,EAAG,IAAK,sBAChC4E,EAAIC,GAAM,YAAeD,EAAIC,GAC9B,YAA2BD,EAAGjJ,MAAOkJ,EAAGlJ,OACxC,MAKMV,EAAS,CAAE8E,EAAG6E,EAAI5E,EAAG6E,GAE3B,OAAO,IAAO3J,eAPE,CAACC,EAASC,KACtB,MAAMC,EAAMF,EAAQyc,kBAAkBhT,EAAIC,GAE1C,OADAzJ,EAAK,CAACwJ,EAAIC,IACHxJ,IAI0BJ,EAAQ,KAAiB,KADhD,Q,gCCzDlB,yEAuFO,MAAM6c,EAAiB,YAAG,CAAEC,gBAlBnC,SAAyBhd,EAAG2O,EAAY/J,GACpC,MAAM3E,EAAK,YAAgBD,EAAG,IAAK,kBACnC,SAAYC,EAAG4C,MAAQ,EAAI8L,EAAW9N,QAAQ,IAAM,cAAcZ,EAAG4C,sCAAsC8L,EAAW9N,WACtH,SAAY+D,EAAS/D,SAAW8N,EAAW9N,QAAQ,IAAM,qBAAqB+D,EAAS/D,wCAAwC8N,EAAW9N,WAC1I,SAAYZ,EAAGW,MAAM4J,QAAO,CAACxF,EAAGC,EAAGI,IAC3BA,EAAI,GAAKA,GAAKsJ,EAAW9N,OAClBmE,IACDC,EAAIL,EAASS,EAAI,GAAG,GAAKT,EAASS,EAAI,GAAG,IACvCsJ,EAAWtJ,EAAI,IACf,EAELL,IACR,IAAO,IAAM,4BAA4B/E,EAAGW,MAAM0B,MAAM,oBAAoBsC,EAASuF,+CAA+CwE,EAAWxE,eAClJ,MACMjK,EAAS,CAAEF,EAAGC,GACd2D,EAAQ,CAAE+K,aAAY/J,YAC5B,OAAO,IAAOzE,eAHEC,GAAWA,EAAQ2c,eAAe9c,EAAI0O,EAAY/J,IAG7B1E,EAAQ,KAAqB,KAAgB0D,O,gCCrFtF,qDA8CO,SAASqZ,EAAOzT,EAAQ5I,EAAOF,GAClC,MAAM4K,EAAgB,YAAW9B,EAAQ9I,GACzC,OAAO,YAAW8I,EAAQ5I,EAAO0K,EAAe5K,K,gCChDpD,4DA0CO,SAAS+F,EAAS+C,EAAQ5I,EAAOF,GAEpC,GADA,wBAAc8I,GACD,MAAT5I,GAAkC,IAAjBA,EAAMC,OACvB,MAAM,IAAIoC,MAAM,iDAEpB,MAAMqI,EAAgB,YAAW9B,EAAQ9I,GACzC,GAA6B,IAAzB4K,EAAczK,QAAyC,IAAzByK,EAAczK,OAC5C,MAAM,IAAIoC,MAAM,kEAEpB,GAA6B,IAAzBqI,EAAczK,QAAyB,MAATD,EAC9B,MAAM,IAAIqC,MAAM,gFAGpB,OAAO,YAAWuG,EAAQ5I,EAAO0K,EAAe5K,K,gCCvDpD,yEAmDO,MAAMwG,EAAO,YAAG,CAAEgW,MAbzB,SAAezc,GACX,iBAAuB,cAAhBA,EAAMC,OAAuB,IAChC,8DAAWD,EAAMC,WACrB,MAAMR,EAAS,CAAEO,SACjB,OAAO,IAAON,eAAcC,IAExB,MAAMO,EAAqBF,EAAMG,MAAMH,EAAMG,MAAMC,OAAS,GACtDC,EAAQL,EAAMM,KAAOJ,EACrBK,EAAU,YAAQP,EAAO,CAACK,EAAOH,IACjCwU,EAAS/U,EAAQ8G,KAAKlG,GAC5B,OAAO,YAAQmU,EAAQ1U,EAAMG,SAC9BV,EAAQ,KAAqB","file":"js/bundle~bundle~58c2b9c4.cd373b42.js","sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Sigmoid } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes sigmoid element-wise, `1 / (1 + exp(-x))`\n *\n * ```js\n * const x = tf.tensor1d([0, -1, 2, -3]);\n *\n * x.sigmoid().print();  // or tf.sigmoid(x)\n * ```\n * @param x The input tensor.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction sigmoid_(x) {\n    const $x = convertToTensor(x, 'x', 'sigmoid');\n    const inputs = { x: $x };\n    return ENGINE.runKernelFunc((backend, save) => {\n        const res = backend.sigmoid($x);\n        save([res]);\n        return res;\n    }, inputs, null /* grad */, Sigmoid);\n}\nexport const sigmoid = op({ sigmoid_ });\n//# sourceMappingURL=sigmoid.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../../engine';\nimport { FFT } from '../../kernel_names';\nimport { assert } from '../../util';\nimport { op } from '../operation';\n/**\n * Fast Fourier transform.\n *\n * Computes the 1-dimensional discrete Fourier transform over the inner-most\n * dimension of input.\n *\n * ```js\n * const real = tf.tensor1d([1, 2, 3]);\n * const imag = tf.tensor1d([1, 2, 3]);\n * const x = tf.complex(real, imag);\n *\n * x.fft().print();  // tf.spectral.fft(x).print();\n * ```\n * @param input The complex input to compute an fft over.\n *\n * @doc {heading: 'Operations', subheading: 'Spectral', namespace: 'spectral'}\n */\nfunction fft_(input) {\n    assert(input.dtype === 'complex64', () => `The dtype for tf.spectral.fft() must be complex64 ` +\n        `but got ${input.dtype}.`);\n    const inputs = { input };\n    return ENGINE.runKernelFunc(backend => {\n        // Collapse all outer dimensions to a single batch dimension.\n        const innerDimensionSize = input.shape[input.shape.length - 1];\n        const batch = input.size / innerDimensionSize;\n        const input2D = input.as2D(batch, innerDimensionSize);\n        const result = backend.fft(input2D);\n        return result.reshape(input.shape);\n    }, inputs, null /* gradient */, FFT);\n}\nexport const fft = op({ fft_ });\n//# sourceMappingURL=fft.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { assert } from '../../util';\nimport { complex } from '../complex';\nimport { concat } from '../concat';\nimport { imag } from '../imag';\nimport { op } from '../operation';\nimport { real } from '../real';\nimport { reshape } from '../reshape';\nimport { slice } from '../slice';\nimport { split } from '../split';\nimport { zeros } from '../zeros';\nimport { zerosLike } from '../zeros_like';\nimport { fft } from './fft';\n/**\n * Real value input fast Fourier transform.\n *\n * Computes the 1-dimensional discrete Fourier transform over the\n * inner-most dimension of the real input.\n *\n * ```js\n * const real = tf.tensor1d([1, 2, 3]);\n *\n * real.rfft().print();\n * ```\n * @param input The real value input to compute an rfft over.\n *\n * @doc {heading: 'Operations', subheading: 'Spectral', namespace: 'spectral'}\n */\nfunction rfft_(input, fftLength) {\n    assert(input.dtype === 'float32', () => `The dtype for rfft() must be real value but got ${input.dtype}`);\n    let innerDimensionSize = input.shape[input.shape.length - 1];\n    const batch = input.size / innerDimensionSize;\n    let adjustedInput;\n    if (fftLength != null && fftLength < innerDimensionSize) {\n        // Need to crop\n        const begin = input.shape.map(v => 0);\n        const size = input.shape.map(v => v);\n        size[input.shape.length - 1] = fftLength;\n        adjustedInput = slice(input, begin, size);\n        innerDimensionSize = fftLength;\n    }\n    else if (fftLength != null && fftLength > innerDimensionSize) {\n        // Need to pad with zeros\n        const zerosShape = input.shape.map(v => v);\n        zerosShape[input.shape.length - 1] = fftLength - innerDimensionSize;\n        adjustedInput = concat([input, zeros(zerosShape)], input.shape.length - 1);\n        innerDimensionSize = fftLength;\n    }\n    else {\n        adjustedInput = input;\n    }\n    // Complement the input with zero imaginary numbers.\n    const zerosInput = zerosLike(adjustedInput);\n    const complexInput = reshape(complex(adjustedInput, zerosInput), [batch, innerDimensionSize]);\n    const ret = fft(complexInput);\n    // Exclude complex conjugations. These conjugations are put symmetrically.\n    const half = Math.floor(innerDimensionSize / 2) + 1;\n    const realValues = real(ret);\n    const imagValues = imag(ret);\n    const realComplexConjugate = split(realValues, [half, innerDimensionSize - half], realValues.shape.length - 1);\n    const imagComplexConjugate = split(imagValues, [half, innerDimensionSize - half], imagValues.shape.length - 1);\n    const outputShape = adjustedInput.shape.slice();\n    outputShape[adjustedInput.shape.length - 1] = half;\n    return reshape(complex(realComplexConjugate[0], imagComplexConjugate[0]), outputShape);\n}\nexport const rfft = op({ rfft_ });\n//# sourceMappingURL=rfft.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { convertToTensor } from '../tensor_util_env';\nimport { squeezeShape } from '../util';\nimport { op } from './operation';\nimport { reshape } from './reshape';\n/**\n * Removes dimensions of size 1 from the shape of a `tf.Tensor`.\n *\n * ```js\n * const x = tf.tensor([1, 2, 3, 4], [1, 1, 4]);\n * x.squeeze().print();\n * ```\n *\n * @param x The input tensor to be squeezed.\n * @param axis An optional list of numbers. If specified, only\n *     squeezes the dimensions listed. The dimension index starts at 0. It\n * is an error to squeeze a dimension that is not 1.\n *\n * @doc {heading: 'Tensors', subheading: 'Transformations'}\n */\nfunction squeeze_(x, axis) {\n    const $x = convertToTensor(x, 'x', 'squeeze');\n    return reshape($x, squeezeShape($x.shape, axis).newShape);\n}\nexport const squeeze = op({ squeeze_ });\n//# sourceMappingURL=squeeze.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { convertToTensor } from '../tensor_util_env';\nimport { parseAxisParam } from '../util';\nimport { abs } from './abs';\nimport * as axis_util from './axis_util';\nimport { max } from './max';\nimport { min } from './min';\nimport { op } from './operation';\nimport { pow } from './pow';\nimport { reshape } from './reshape';\nimport { scalar } from './scalar';\nimport { sqrt } from './sqrt';\nimport { square } from './square';\nimport { sum } from './sum';\n/**\n * Computes the norm of scalar, vectors, and matrices.\n * This function can compute several different vector norms (the 1-norm, the\n * Euclidean or 2-norm, the inf-norm, and in general the p-norm for p > 0)\n * and matrix norms (Frobenius, 1-norm, and inf-norm).\n *\n * ```js\n * const x = tf.tensor1d([1, 2, 3, 4]);\n *\n * x.norm().print();  // or tf.norm(x)\n * ```\n *\n * @param x The input array.\n * @param ord Optional. Order of the norm. Supported norm types are\n * following:\n *\n *  | ord        | norm for matrices         | norm for vectors\n *  |------------|---------------------------|---------------------\n *  |'euclidean' |Frobenius norm             |2-norm\n *  |'fro'       |Frobenius norm\t           |\n *  |Infinity    |max(sum(abs(x), axis=1))   |max(abs(x))\n *  |-Infinity   |min(sum(abs(x), axis=1))   |min(abs(x))\n *  |1           |max(sum(abs(x), axis=0))   |sum(abs(x))\n *  |2           |                           |sum(abs(x)^2)^1/2*\n *\n * @param axis Optional. If axis is null (the default), the input is\n * considered a vector and a single vector norm is computed over the entire\n * set of values in the Tensor, i.e. norm(x, ord) is equivalent\n * to norm(x.reshape([-1]), ord). If axis is a integer, the input\n * is considered a batch of vectors, and axis determines the axis in x\n * over which to compute vector norms. If axis is a 2-tuple of integer it is\n * considered a batch of matrices and axis determines the axes in NDArray\n * over which to compute a matrix norm.\n * @param keepDims Optional. If true, the norm have the same dimensionality\n * as the input.\n *\n * @doc {heading: 'Operations', subheading: 'Matrices'}\n */\nfunction norm_(x, ord = 'euclidean', axis = null, keepDims = false) {\n    x = convertToTensor(x, 'x', 'norm');\n    const norm = normImpl(x, ord, axis);\n    let keepDimsShape = norm.shape;\n    if (keepDims) {\n        const axes = parseAxisParam(axis, x.shape);\n        keepDimsShape = axis_util.expandShapeToKeepDim(norm.shape, axes);\n    }\n    return reshape(norm, keepDimsShape);\n}\nfunction normImpl(x, p, axis = null) {\n    if (x.rank === 0) {\n        return abs(x);\n    }\n    // consider vector when no axis is specified\n    if (x.rank !== 1 && axis === null) {\n        return normImpl(reshape(x, [-1]), p, axis);\n    }\n    // vector\n    if (x.rank === 1 || typeof axis === 'number' ||\n        Array.isArray(axis) && axis.length === 1) {\n        if (p === 1) {\n            return sum(abs(x), axis);\n        }\n        if (p === Infinity) {\n            return max(abs(x), axis);\n        }\n        if (p === -Infinity) {\n            return min(abs(x), axis);\n        }\n        if (p === 'euclidean' || p === 2) {\n            // norm(x, 2) = sum(abs(xi) ^ 2) ^ 1/2\n            return sqrt(sum(pow(abs(x), scalar(2, 'int32')), axis));\n        }\n        throw new Error(`Error in norm: invalid ord value: ${p}`);\n    }\n    // matrix (assumption axis[0] < axis[1])\n    if (Array.isArray(axis) && axis.length === 2) {\n        if (p === 1) {\n            return max(sum(abs(x), axis[0]), axis[1] - 1);\n        }\n        if (p === Infinity) {\n            return max(sum(abs(x), axis[1]), axis[0]);\n        }\n        if (p === -Infinity) {\n            return min(sum(abs(x), axis[1]), axis[0]);\n        }\n        if (p === 'fro' || p === 'euclidean') {\n            // norm(x) = sqrt(sum(pow(x, 2)))\n            return sqrt(sum(square(x), axis));\n        }\n        throw new Error(`Error in norm: invalid ord value: ${p}`);\n    }\n    throw new Error(`Error in norm: invalid axis: ${axis}`);\n}\nexport const norm = op({ norm_ });\n//# sourceMappingURL=norm.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Relu6 } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { cast } from './cast';\nimport { op } from './operation';\n/**\n * Computes rectified linear 6 element-wise: `min(max(x, 0), 6)`.\n *\n * ```js\n * const x = tf.tensor1d([-1, 2, -3, 8]);\n *\n * x.relu6().print();  // or tf.relu6(x)\n * ```\n * @param x The input tensor. If the dtype is `bool`, the output dtype will be\n *     `int32'.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction relu6_(x) {\n    const $x = convertToTensor(x, 'x', 'relu6');\n    const forward = (backend, save) => {\n        save([$x]);\n        if ($x.dtype === 'bool') {\n            return cast($x, 'int32');\n        }\n        return backend.relu6($x);\n    };\n    const inputs = { x: $x };\n    return ENGINE.runKernelFunc(forward, inputs, null /* grad */, Relu6);\n}\nexport const relu6 = op({ relu6_ });\n//# sourceMappingURL=relu6.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Sum } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { parseAxisParam } from '../util';\nimport { expandShapeToKeepDim, getAxesPermutation, getInnerMostAxes } from './axis_util';\nimport { cast } from './cast';\nimport { op } from './operation';\nimport { reshape } from './reshape';\nimport { transpose } from './transpose';\n/**\n * Computes the sum of elements across dimensions of a `tf.Tensor`.\n *\n * Reduces the input along the dimensions given in `axes`. Unless `keepDims`\n * is true, the rank of the `tf.Tensor` is reduced by 1 for each entry in\n * `axes`. If `keepDims` is true, the reduced dimensions are retained with\n * length 1. If axes has no entries, all dimensions are reduced, and a\n * `tf.Tensor` with a single element is returned.\n *\n * ```js\n * const x = tf.tensor1d([1, 2, 3]);\n *\n * x.sum().print();  // or tf.sum(x)\n * ```\n *\n * ```js\n * const x = tf.tensor2d([1, 2, 3, 4], [2, 2]);\n *\n * const axis = 1;\n * x.sum(axis).print();  // or tf.sum(x, axis)\n * ```\n *\n * @param x The input tensor to compute the sum over. If the dtype is `bool`\n *   it will be converted to `int32` and the output dtype will be `int32`.\n * @param axis The dimension(s) to reduce. By default it reduces\n *     all dimensions.\n * @param keepDims If true, retains reduced dimensions with size 1.\n *\n * @doc {heading: 'Operations', subheading: 'Reduction'}\n */\nfunction sum_(x, axis = null, keepDims = false) {\n    let $x = convertToTensor(x, 'x', 'sum');\n    if ($x.dtype === 'bool') {\n        $x = cast($x, 'int32');\n    }\n    const forward = (backend, save) => {\n        save([$x]);\n        const axes = parseAxisParam(axis, $x.shape);\n        const permutation = getAxesPermutation(axes, $x.rank);\n        let reductionAxes = axes;\n        let permutedX = $x;\n        if (permutation != null) {\n            permutedX = transpose($x, permutation);\n            reductionAxes = getInnerMostAxes(reductionAxes.length, $x.rank);\n        }\n        let value = backend.sum(permutedX, reductionAxes);\n        if (keepDims) {\n            const newShape = expandShapeToKeepDim(value.shape, axes);\n            value = reshape(value, newShape);\n        }\n        return value;\n    };\n    const inputs = { x: $x };\n    const attrs = { axis, keepDims };\n    return ENGINE.runKernelFunc(forward, inputs, null /* grad */, Sum, attrs);\n}\nexport const sum = op({ sum_ });\n//# sourceMappingURL=sum.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Prelu } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes leaky rectified linear element-wise with parametric alphas.\n *\n * `x < 0 ? alpha * x : f(x) = x`\n *\n * ```js\n * const x = tf.tensor1d([-1, 2, -3, 4]);\n * const alpha = tf.scalar(0.1);\n *\n * x.prelu(alpha).print();  // or tf.prelu(x, alpha)\n * ```\n * @param x The input tensor.\n * @param alpha Scaling factor for negative values.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction prelu_(x, alpha) {\n    const $x = convertToTensor(x, 'x', 'prelu');\n    const $alpha = convertToTensor(alpha, 'alpha', 'prelu');\n    const forward = (backend, save) => {\n        const res = backend.prelu($x, $alpha);\n        save([$x, $alpha]);\n        return res;\n    };\n    const inputs = { x: $x, alpha: $alpha };\n    return ENGINE.runKernelFunc(forward, inputs, null /* grad */, Prelu);\n}\nexport const prelu = op({ prelu_ });\n//# sourceMappingURL=prelu.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { UnsortedSegmentSum } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { assert, isInt } from '../util';\nimport { op } from './operation';\n/**\n * Computes the sum along segments of a `tf.Tensor`.\n *\n * ```js\n * const x = tf.tensor1d([1, 2, 3, 4]);\n * const segmentIds = tf.tensor1d([1, 2, 0, 1], 'int32');\n * const numSegments = 3;\n *\n * x.unsortedSegmentSum(segmentIds, numSegments).print()\n * //or tf.unsortedSegmentSum(x, segmentIds, numSegments)\n * ```\n * @param x The `tf.Tensor` that will be summed along its segments.\n * @param segmentIds A `tf.Tensor1D` whose rank is equal to the rank of `x`'s\n * dimension along the `axis`.  Maps each element of `x` to a segment.\n * @param numSegments The number of distinct `segmentIds`.\n *\n * @doc {heading: 'Operations', subheading: 'Segment'}\n */\nfunction unsortedSegmentSum_(x, segmentIds, numSegments) {\n    const $x = convertToTensor(x, 'x', 'unsortedSegmentSum');\n    const $segmentIds = convertToTensor(segmentIds, 'segmentIds', 'unsortedSegmentSum', 'int32');\n    assert(isInt(numSegments), () => 'numSegments must be of dtype int');\n    const inputs = { x: $x, segmentIds: $segmentIds };\n    const attrs = { numSegments };\n    const forward = (backend, save) => {\n        const res = backend.unsortedSegmentSum($x, $segmentIds, numSegments);\n        save([$segmentIds]);\n        return res;\n    };\n    return ENGINE.runKernelFunc(forward, inputs, null /* grad */, UnsortedSegmentSum, attrs);\n}\nexport const unsortedSegmentSum = op({ unsortedSegmentSum_ });\n//# sourceMappingURL=unsorted_segment_sum.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { PadV2 } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Pads a `tf.Tensor` with a given value and paddings.\n *\n * This operation currently only implements the `CONSTANT` mode.\n *\n * Also available are stricter rank-specific methods with the same signature\n * as this method that assert that `paddings` is of given length.\n *   - `tf.pad1d`\n *   - `tf.pad2d`\n *   - `tf.pad3d`\n *   - `tf.pad4d`\n *\n * ```js\n * const x = tf.tensor1d([1, 2, 3, 4]);\n * x.pad([[1, 2]]).print();\n * ```\n * @param x The tensor to pad.\n * @param paddings An array of length `R` (the rank of the tensor), where\n * each element is a length-2 tuple of ints `[padBefore, padAfter]`,\n * specifying how much to pad along each dimension of the tensor.\n * @param constantValue The pad value to use. Defaults to 0.\n *\n * @doc {heading: 'Tensors', subheading: 'Transformations'}\n */\nfunction pad_(x, paddings, constantValue = 0) {\n    const $x = convertToTensor(x, 'x', 'pad');\n    if ($x.rank === 0) {\n        throw new Error('pad(scalar) is not defined. Pass non-scalar to pad');\n    }\n    const forward = (backend, save) => {\n        save([$x]);\n        return backend.pad($x, paddings, constantValue);\n    };\n    const attrs = { paddings, constantValue };\n    const inputs = { x: $x };\n    return ENGINE.runKernelFunc(forward, inputs, null /* grad */, PadV2, attrs);\n}\nexport const pad = op({ pad_ });\n//# sourceMappingURL=pad.js.map","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { tensor1d } from './tensor1d';\nexport function enclosingPowerOfTwo(value) {\n    // Return 2**N for integer N such that 2**N >= value.\n    return Math.floor(Math.pow(2, Math.ceil(Math.log(value) / Math.log(2.0))));\n}\nexport function cosineWindow(windowLength, a, b) {\n    const even = 1 - windowLength % 2;\n    const newValues = new Float32Array(windowLength);\n    for (let i = 0; i < windowLength; ++i) {\n        const cosArg = (2.0 * Math.PI * i) / (windowLength + even - 1);\n        newValues[i] = a - b * Math.cos(cosArg);\n    }\n    return tensor1d(newValues, 'float32');\n}\n//# sourceMappingURL=signal_ops_util.js.map","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { op } from '../operation';\nimport { cosineWindow } from '../signal_ops_util';\n/**\n * Generate a hamming window.\n *\n * See: https://en.wikipedia.org/wiki/Window_function#Hann_and_Hamming_windows\n *\n * ```js\n * tf.signal.hammingWindow(10).print();\n * ```\n * @param The length of window\n *\n * @doc {heading: 'Operations', subheading: 'Signal', namespace: 'signal'}\n */\nfunction hammingWindow_(windowLength) {\n    return cosineWindow(windowLength, 0.54, 0.46);\n}\nexport const hammingWindow = op({ hammingWindow_ });\n//# sourceMappingURL=hamming_window.js.map","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { op } from '../operation';\nimport { cosineWindow } from '../signal_ops_util';\n/**\n * Generate a Hann window.\n *\n * See: https://en.wikipedia.org/wiki/Window_function#Hann_and_Hamming_windows\n *\n * ```js\n * tf.signal.hannWindow(10).print();\n * ```\n * @param The length of window\n *\n * @doc {heading: 'Operations', subheading: 'Signal', namespace: 'signal'}\n */\nfunction hannWindow_(windowLength) {\n    return cosineWindow(windowLength, 0.5, 0.5);\n}\nexport const hannWindow = op({ hannWindow_ });\n//# sourceMappingURL=hann_window.js.map","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { concat } from '../concat';\nimport { fill } from '../fill';\nimport { op } from '../operation';\nimport { reshape } from '../reshape';\nimport { slice } from '../slice';\nimport { tensor2d } from '../tensor2d';\n/**\n * Expands input into frames of frameLength.\n * Slides a window size with frameStep.\n *\n * ```js\n * tf.signal.frame([1, 2, 3], 2, 1).print();\n * ```\n * @param signal The input tensor to be expanded\n * @param frameLength Length of each frame\n * @param frameStep The frame hop size in samples.\n * @param padEnd Whether to pad the end of signal with padValue.\n * @param padValue An number to use where the input signal does\n *     not exist when padEnd is True.\n *\n * @doc {heading: 'Operations', subheading: 'Signal', namespace: 'signal'}\n */\nfunction frame_(signal, frameLength, frameStep, padEnd = false, padValue = 0) {\n    let start = 0;\n    const output = [];\n    while (start + frameLength <= signal.size) {\n        output.push(slice(signal, start, frameLength));\n        start += frameStep;\n    }\n    if (padEnd) {\n        while (start < signal.size) {\n            const padLen = (start + frameLength) - signal.size;\n            const pad = concat([\n                slice(signal, start, frameLength - padLen), fill([padLen], padValue)\n            ]);\n            output.push(pad);\n            start += frameStep;\n        }\n    }\n    if (output.length === 0) {\n        return tensor2d([], [0, frameLength]);\n    }\n    return reshape(concat(output), [output.length, frameLength]);\n}\nexport const frame = op({ frame_ });\n//# sourceMappingURL=frame.js.map","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { concat } from '../concat';\nimport { mul } from '../mul';\nimport { op } from '../operation';\nimport { enclosingPowerOfTwo } from '../signal_ops_util';\nimport { slice } from '../slice';\nimport { rfft } from '../spectral/rfft';\nimport { frame } from './frame';\nimport { hannWindow } from './hann_window';\n/**\n * Computes the Short-time Fourier Transform of signals\n * See: https://en.wikipedia.org/wiki/Short-time_Fourier_transform\n *\n * ```js\n * const input = tf.tensor1d([1, 1, 1, 1, 1])\n * tf.signal.stft(input, 3, 1).print();\n * ```\n * @param signal 1-dimensional real value tensor.\n * @param frameLength The window length of samples.\n * @param frameStep The number of samples to step.\n * @param fftLength The size of the FFT to apply.\n * @param windowFn A callable that takes a window length and returns 1-d tensor.\n *\n * @doc {heading: 'Operations', subheading: 'Signal', namespace: 'signal'}\n */\nfunction stft_(signal, frameLength, frameStep, fftLength, windowFn = hannWindow) {\n    if (fftLength == null) {\n        fftLength = enclosingPowerOfTwo(frameLength);\n    }\n    const framedSignal = frame(signal, frameLength, frameStep);\n    const windowedSignal = mul(framedSignal, windowFn(frameLength));\n    const output = [];\n    for (let i = 0; i < framedSignal.shape[0]; i++) {\n        output.push(rfft(slice(windowedSignal, [i, 0], [1, frameLength]), fftLength));\n    }\n    return concat(output);\n}\nexport const stft = op({ stft_ });\n//# sourceMappingURL=stft.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n// Modularized ops.\nexport { abs } from './abs';\nexport { acos } from './acos';\nexport { acosh } from './acosh';\nexport { add } from './add';\nexport { addN } from './add_n';\nexport { all } from './all';\nexport { any } from './any';\nexport { argMax } from './arg_max';\nexport { argMin } from './arg_min';\nexport { asin } from './asin';\nexport { asinh } from './asinh';\nexport { atan } from './atan';\nexport { atan2 } from './atan2';\nexport { atanh } from './atanh';\nexport { avgPool } from './avg_pool';\nexport { avgPool3d } from './avg_pool_3d';\nexport { basicLSTMCell } from './basic_lstm_cell';\nexport { batchToSpaceND } from './batch_to_space_nd';\nexport { batchNorm } from './batchnorm';\nexport { batchNorm2d } from './batchnorm2d';\nexport { batchNorm3d } from './batchnorm3d';\nexport { batchNorm4d } from './batchnorm4d';\nexport { broadcastTo } from './broadcast_to';\nexport { buffer } from './buffer';\nexport { cast } from './cast';\nexport { ceil } from './ceil';\nexport { clipByValue } from './clip_by_value';\nexport { clone } from './clone';\nexport { complex } from './complex';\nexport { concat } from './concat';\nexport { concat1d } from './concat_1d';\nexport { concat2d } from './concat_2d';\nexport { concat3d } from './concat_3d';\nexport { concat4d } from './concat_4d';\nexport { conv1d } from './conv1d';\nexport { conv2d } from './conv2d';\nexport { conv2dTranspose } from './conv2d_transpose';\nexport { conv3d } from './conv3d';\nexport { conv3dTranspose } from './conv3d_transpose';\nexport { cos } from './cos';\nexport { cosh } from './cosh';\nexport { cumsum } from './cumsum';\nexport { depthToSpace } from './depth_to_space';\nexport { depthwiseConv2d } from './depthwise_conv2d';\nexport { diag } from './diag';\nexport { dilation2d } from './dilation2d';\nexport { div } from './div';\nexport { divNoNan } from './div_no_nan';\nexport { dot } from './dot';\nexport { elu } from './elu';\nexport { equal } from './equal';\nexport { erf } from './erf';\nexport { exp } from './exp';\nexport { expandDims } from './expand_dims';\nexport { expm1 } from './expm1';\nexport { eye } from './eye';\nexport { fill } from './fill';\nexport { floor } from './floor';\nexport { floorDiv } from './floorDiv';\nexport { gather } from './gather';\nexport { greater } from './greater';\nexport { greaterEqual } from './greater_equal';\nexport { imag } from './imag';\nexport { isFinite } from './is_finite';\nexport { isInf } from './is_inf';\nexport { isNaN } from './is_nan';\nexport { leakyRelu } from './leaky_relu';\nexport { less } from './less';\nexport { lessEqual } from './less_equal';\nexport { linspace } from './linspace';\nexport { localResponseNormalization } from './local_response_normalization';\nexport { log } from './log';\nexport { log1p } from './log1p';\nexport { logSigmoid } from './log_sigmoid';\nexport { logSoftmax } from './log_softmax';\nexport { logSumExp } from './log_sum_exp';\nexport { logicalAnd } from './logical_and';\nexport { logicalNot } from './logical_not';\nexport { logicalOr } from './logical_or';\nexport { logicalXor } from './logical_xor';\nexport { matMul } from './mat_mul';\nexport { max } from './max';\nexport { maxPool } from './max_pool';\nexport { maxPool3d } from './max_pool_3d';\nexport { maxPoolWithArgmax } from './max_pool_with_argmax';\nexport { maximum } from './maximum';\nexport { mean } from './mean';\nexport { min } from './min';\nexport { minimum } from './minimum';\nexport { mod } from './mod';\nexport { moments } from './moments';\nexport { mul } from './mul';\nexport { multiRNNCell } from './multi_rnn_cell';\nexport { multinomial } from './multinomial';\nexport { neg } from './neg';\nexport { notEqual } from './not_equal';\nexport { oneHot } from './one_hot';\nexport { ones } from './ones';\nexport { onesLike } from './ones_like';\nexport { outerProduct } from './outer_product';\nexport { pad } from './pad';\nexport { pad1d } from './pad1d';\nexport { pad2d } from './pad2d';\nexport { pad3d } from './pad3d';\nexport { pad4d } from './pad4d';\nexport { pool } from './pool';\nexport { pow } from './pow';\nexport { prelu } from './prelu';\nexport { print } from './print';\nexport { prod } from './prod';\nexport { rand } from './rand';\nexport { randomGamma } from './random_gamma';\nexport { randomNormal } from './random_normal';\nexport { randomUniform } from './random_uniform';\nexport { range } from './range';\nexport { real } from './real';\nexport { reciprocal } from './reciprocal';\nexport { relu } from './relu';\nexport { relu6 } from './relu6';\nexport { reshape } from './reshape';\nexport { reverse } from './reverse';\nexport { reverse1d } from './reverse_1d';\nexport { reverse2d } from './reverse_2d';\nexport { reverse3d } from './reverse_3d';\nexport { reverse4d } from './reverse_4d';\nexport { round } from './round';\nexport { rsqrt } from './rsqrt';\nexport { scalar } from './scalar';\nexport { selu } from './selu';\nexport { separableConv2d } from './separable_conv2d';\nexport { setdiff1dAsync } from './setdiff1d_async';\nexport { sigmoid } from './sigmoid';\nexport { sign } from './sign';\nexport { sin } from './sin';\nexport { sinh } from './sinh';\nexport { slice } from './slice';\nexport { slice1d } from './slice1d';\nexport { slice2d } from './slice2d';\nexport { slice3d } from './slice3d';\nexport { slice4d } from './slice4d';\nexport { softmax } from './softmax';\nexport { softplus } from './softplus';\nexport { spaceToBatchND } from './space_to_batch_nd';\nexport { fft } from './spectral/fft';\nexport { ifft } from './spectral/ifft';\nexport { irfft } from './spectral/irfft';\nexport { rfft } from './spectral/rfft';\nexport { split } from './split';\nexport { sqrt } from './sqrt';\nexport { square } from './square';\nexport { squaredDifference } from './squared_difference';\nexport { squeeze } from './squeeze';\nexport { stack } from './stack';\nexport { step } from './step';\nexport { stridedSlice } from './strided_slice';\nexport { sub } from './sub';\nexport { sum } from './sum';\nexport { tan } from './tan';\nexport { tanh } from './tanh';\nexport { tensor } from './tensor';\nexport { tensor1d } from './tensor1d';\nexport { tensor2d } from './tensor2d';\nexport { tensor3d } from './tensor3d';\nexport { tensor4d } from './tensor4d';\nexport { tensor5d } from './tensor5d';\nexport { tensor6d } from './tensor6d';\nexport { tile } from './tile';\nexport { topk } from './topk';\nexport { truncatedNormal } from './truncated_normal';\nexport { unsortedSegmentSum } from './unsorted_segment_sum';\nexport { unstack } from './unstack';\nexport { variable } from './variable';\nexport { where } from './where';\nexport { whereAsync } from './where_async';\nexport { zeros } from './zeros';\nexport { zerosLike } from './zeros_like';\nexport * from './boolean_mask';\nexport * from './compare';\nexport * from './binary_ops';\nexport * from './transpose';\nexport * from './norm';\nexport * from './moving_average';\nexport * from './scatter_nd';\nexport * from './sparse_to_dense';\nexport * from './gather_nd';\nexport * from './dropout';\nexport * from './signal_ops_util';\nexport * from './in_top_k';\nexport { op, OP_SCOPE_SUFFIX } from './operation';\nimport { rfft } from './spectral/rfft';\nimport { fft } from './spectral/fft';\nimport { ifft } from './spectral/ifft';\nimport { irfft } from './spectral/irfft';\nconst spectral = {\n    fft,\n    ifft,\n    rfft,\n    irfft\n};\nimport * as fused from './fused_ops';\nimport { hammingWindow } from './signal/hamming_window';\nimport { hannWindow } from './signal/hann_window';\nimport { frame } from './signal/frame';\nimport { stft } from './signal/stft';\nconst signal = {\n    hammingWindow,\n    hannWindow,\n    frame,\n    stft,\n};\n// Image Ops namespace\nimport { cropAndResize } from './image/crop_and_resize';\nimport { flipLeftRight } from './image/flip_left_right';\nimport { rotateWithOffset } from './image/rotate_with_offset';\nimport { nonMaxSuppression } from './image/non_max_suppression';\nimport { nonMaxSuppressionAsync } from './image/non_max_suppression_async';\nimport { nonMaxSuppressionWithScore } from './image/non_max_suppression_with_score';\nimport { nonMaxSuppressionWithScoreAsync } from './image/non_max_suppression_with_score_async';\nimport { nonMaxSuppressionPadded } from './image/non_max_suppression_padded';\nimport { nonMaxSuppressionPaddedAsync } from './image/non_max_suppression_padded_async';\nimport { resizeBilinear } from './image/resize_bilinear';\nimport { resizeNearestNeighbor } from './image/resize_nearest_neighbor';\nconst image = {\n    flipLeftRight,\n    resizeNearestNeighbor,\n    resizeBilinear,\n    rotateWithOffset,\n    cropAndResize,\n    nonMaxSuppression,\n    nonMaxSuppressionAsync,\n    nonMaxSuppressionWithScore,\n    nonMaxSuppressionWithScoreAsync,\n    nonMaxSuppressionPadded,\n    nonMaxSuppressionPaddedAsync\n};\n// linalg namespace\nimport { bandPart } from './linalg/band_part';\nimport { gramSchmidt } from './linalg/gram_schmidt';\nimport { qr } from './linalg/qr';\nconst linalg = {\n    bandPart,\n    gramSchmidt,\n    qr\n};\n// losses namespace;\nimport { absoluteDifference } from './losses/absolute_difference';\nimport { computeWeightedLoss } from './losses/compute_weighted_loss';\nimport { cosineDistance } from './losses/cosine_distance';\nimport { hingeLoss } from './losses/hinge_loss';\nimport { huberLoss } from './losses/huber_loss';\nimport { logLoss } from './losses/log_loss';\nimport { meanSquaredError } from './losses/mean_squared_error';\nimport { sigmoidCrossEntropy } from './losses/sigmoid_cross_entropy';\nimport { softmaxCrossEntropy } from './losses/softmax_cross_entropy';\nconst losses = {\n    absoluteDifference,\n    computeWeightedLoss,\n    cosineDistance,\n    hingeLoss,\n    huberLoss,\n    logLoss,\n    meanSquaredError,\n    sigmoidCrossEntropy,\n    softmaxCrossEntropy\n};\n// Second level exports.\nexport { image, linalg, losses, spectral, fused, signal };\n//# sourceMappingURL=ops.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { isTypedArray } from '../util';\nimport { makeTensor } from './tensor_ops_util';\n/**\n * Creates rank-0 `tf.Tensor` (scalar) with the provided value and dtype.\n *\n * The same functionality can be achieved with `tf.tensor`, but in general\n * we recommend using `tf.scalar` as it makes the code more readable.\n *\n * ```js\n * tf.scalar(3.14).print();\n * ```\n *\n * @param value The value of the scalar.\n * @param dtype The data type.\n *\n * @doc {heading: 'Tensors', subheading: 'Creation'}\n */\nexport function scalar(value, dtype) {\n    if (((isTypedArray(value) && dtype !== 'string') || Array.isArray(value)) &&\n        dtype !== 'complex64') {\n        throw new Error('Error creating a new Scalar: value must be a primitive ' +\n            '(number|boolean|string)');\n    }\n    if (dtype === 'string' && isTypedArray(value) &&\n        !(value instanceof Uint8Array)) {\n        throw new Error('When making a scalar from encoded string, ' +\n            'the value must be `Uint8Array`.');\n    }\n    const shape = [];\n    const inferredShape = [];\n    return makeTensor(value, shape, inferredShape, dtype);\n}\n//# sourceMappingURL=scalar.js.map","import { computeStrides, sizeFromShape } from '../util';\n/**\n * Check whether updates.shape = indices.shape[:batchDim] +\n * shape[sliceDim:]\n *\n * @param x The input tensor.\n */\nexport function validateUpdateShape(shape, indices, updates) {\n    const sliceDim = (indices.rank > 1) ? indices.shape[indices.rank - 1] : 1;\n    const batchDim = (indices.rank > 1) ? indices.rank - 1 : 1;\n    const shapeError = 'Must have updates.shape = indices.shape[:batchDim] + ' +\n        `shape[sliceDim:], got updates.shape: ${updates.shape}` +\n        `, indices.shape: ${indices.shape}, shape: ${shape}` +\n        `, sliceDim: ${sliceDim}, and batchDim: ${batchDim}.`;\n    if (updates.rank < batchDim) {\n        throw new Error(shapeError + ` update.rank < ${batchDim}. `);\n    }\n    if (shape.length < sliceDim + (updates.rank - batchDim)) {\n        throw new Error(shapeError +\n            ` Output shape length < ${sliceDim + (updates.rank - batchDim)}`);\n    }\n    if (updates.rank !== batchDim + shape.length - sliceDim) {\n        throw new Error(shapeError + ` update.rank != ${batchDim + shape.length - sliceDim}`);\n    }\n    for (let d = 0; d < batchDim; ++d) {\n        if (updates.shape[d] !== indices.shape[d]) {\n            throw new Error(shapeError +\n                ` updates.shape[${d}] (${updates.shape[d]}) != indices.shape[${d}] (${indices.shape[d]}).`);\n        }\n    }\n    for (let d = 0; d < updates.rank - batchDim; ++d) {\n        if (updates.shape[d + batchDim] !== shape[d + sliceDim]) {\n            throw new Error(shapeError +\n                ` updates.shape[${d + batchDim}] (${updates.shape[d + batchDim]}) != shape[${d + batchDim}] (${shape[d + batchDim]})`);\n        }\n    }\n}\n/**\n * Validate scatter nd inputs.\n *\n * @param update The tensor contains the update values.\n * @param indices The tensor contains the indices for the update values.\n * @param shape The shape of the output tensor.\n */\nexport function validateInput(updates, indices, shape) {\n    if (indices.rank < 1) {\n        throw new Error('tf.scatterND() expects the indices to be rank 1 or higher,' +\n            ` but the rank was ${indices.rank}.`);\n    }\n    if (updates.rank < 1) {\n        throw new Error('tf.scatterND() expects the updates to be rank 1 or higher,' +\n            ` but the rank was ${updates.rank}.`);\n    }\n    if (indices.dtype !== 'int32') {\n        throw new Error(`The dtype of 'indices' should be int32, but got dtype: ${indices.dtype}`);\n    }\n    if (shape.length < 1) {\n        throw new Error(`Output rank must be greater or equal to 1, but got shape: ${shape}`);\n    }\n    if (shape.length === 0) {\n        if (indices.size === 0) {\n            throw new Error(`Indices specified for empty output. indices shape: ${indices.shape}`);\n        }\n        if (updates.size === 0) {\n            throw new Error(`Updates specified for empty output. updates shape: ${updates.shape}`);\n        }\n    }\n    validateUpdateShape(shape, indices, updates);\n}\n/**\n * Calculate the shape information for the output.\n *\n * @param update The tensor contains the update values.\n * @param indices The tensor contains the indices for the update values.\n * @param shape The shape of the output tensor.\n *\n * @returns ScatterShapeInfo\n */\nexport function calculateShapes(updates, indices, shape) {\n    // Calculate the number of dimensions in indices\n    const indicesRank = indices.shape.length;\n    const sliceRank = (indicesRank > 1) ? indices.shape[indicesRank - 1] : 1;\n    // Calculate the number of elements that make up each slice of our updated\n    // tensor. This allows us to work with flattened tensors and copy over whole\n    // slices at a time.\n    const totalNd = shape.length;\n    let sliceSize = 1;\n    for (let i = sliceRank; i < totalNd; ++i) {\n        sliceSize *= shape[i];\n    }\n    const safeSliceDim = (sliceRank < 1) ? 1 : sliceRank;\n    const numUpdates = sizeFromShape(indices.shape) / safeSliceDim;\n    const strides = [...computeStrides(shape.slice(0, sliceRank)), 1];\n    const outputSize = sizeFromShape(shape);\n    return { sliceRank, numUpdates, sliceSize, strides, outputSize };\n}\n//# sourceMappingURL=scatter_nd_util.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Range } from '../kernel_names';\nimport { makeZerosTypedArray } from '../util';\nimport { tensor1d } from './tensor1d';\nimport { zeros } from './zeros';\n/**\n * Creates a new `tf.Tensor1D` filled with the numbers in the range provided.\n *\n * The tensor is a is half-open interval meaning it includes start, but\n * excludes stop. Decrementing ranges and negative step values are also\n * supported.sv\n *\n *\n * ```js\n * tf.range(0, 9, 2).print();\n * ```\n *\n * @param start An integer start value\n * @param stop An integer stop value\n * @param step An integer increment (will default to 1 or -1)\n * @param dtype The data type of the output tensor. Defaults to 'float32'.\n *\n * @doc {heading: 'Tensors', subheading: 'Creation'}\n */\nexport function range(start, stop, step = 1, dtype = 'float32') {\n    if (step === 0) {\n        throw new Error('Cannot have a step of zero');\n    }\n    const forward = () => {\n        const sameStartStop = start === stop;\n        const increasingRangeNegativeStep = start < stop && step < 0;\n        const decreasingRangePositiveStep = stop < start && step > 1;\n        if (sameStartStop || increasingRangeNegativeStep ||\n            decreasingRangePositiveStep) {\n            return zeros([0], dtype);\n        }\n        const numElements = Math.abs(Math.ceil((stop - start) / step));\n        const values = makeZerosTypedArray(numElements, dtype);\n        if (stop < start && step === 1) {\n            // Auto adjust the step's sign if it hasn't been set\n            // (or was set to 1)\n            step = -1;\n        }\n        values[0] = start;\n        for (let i = 1; i < values.length; i++) {\n            values[i] = values[i - 1] + step;\n        }\n        return tensor1d(values, dtype);\n    };\n    const attrs = { start, stop, step, dtype };\n    return ENGINE.runKernelFunc(forward, {} /* inputs */, null /* grad */, Range, attrs);\n}\n//# sourceMappingURL=range.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nexport const SELU_SCALEALPHA = 1.7580993408473768599402175208123;\nexport const SELU_SCALE = 1.0507009873554804934193349852946;\n//# sourceMappingURL=selu_util.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Sub } from '../kernel_names';\nimport { makeTypesMatch } from '../tensor_util';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Subtracts two `tf.Tensor`s element-wise, A - B. Supports broadcasting.\n *\n * ```js\n * const a = tf.tensor1d([10, 20, 30, 40]);\n * const b = tf.tensor1d([1, 2, 3, 4]);\n *\n * a.sub(b).print();  // or tf.sub(a, b)\n * ```\n *\n * ```js\n * // Broadcast subtract a with b.\n * const a = tf.tensor1d([10, 20, 30, 40]);\n * const b = tf.scalar(5);\n *\n * a.sub(b).print();  // or tf.sub(a, b)\n * ```\n * @param a The first `tf.Tensor` to subtract from.\n * @param b The second `tf.Tensor` to be subtracted. Must have the same dtype as\n * `a`.\n *\n * @doc {heading: 'Operations', subheading: 'Arithmetic'}\n */\nfunction sub_(a, b) {\n    let $a = convertToTensor(a, 'a', 'sub');\n    let $b = convertToTensor(b, 'b', 'sub');\n    [$a, $b] = makeTypesMatch($a, $b);\n    const forward = (backend, save) => {\n        const res = backend.subtract($a, $b);\n        save([$a, $b]);\n        return res;\n    };\n    const inputs = { a: $a, b: $b };\n    return ENGINE.runKernelFunc(forward, inputs, null /* grad */, Sub);\n}\nexport const sub = op({ sub_ });\n//# sourceMappingURL=sub.js.map","/**\n * @license\n * Copyright 2020 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n/**\n * Prints information about the `tf.Tensor` including its data.\n *\n * ```js\n * const verbose = true;\n * tf.tensor2d([1, 2, 3, 4], [2, 2]).print(verbose);\n * ```\n * @param x The tensor to be printed.\n * @param verbose Whether to print verbose information about the ` Tensor`,\n * including dtype and size.\n *\n * @doc {heading: 'Tensors', subheading: 'Creation'}\n */\nexport function print(x, verbose = false) {\n    console.log(x.toString(verbose));\n}\n//# sourceMappingURL=print.js.map","import { assert } from '../util';\n/**\n * Prepare the split size array. When the input is a number, the axis is evenly\n * divided among the split size. When the input contains the negative value, the\n * rest of the axis is allocated toward that.\n */\nexport function prepareSplitSize(x, numOrSizeSplits, axis = 0) {\n    let splitSizes = [];\n    if (typeof (numOrSizeSplits) === 'number') {\n        assert(x.shape[axis] % numOrSizeSplits === 0, () => 'Number of splits must evenly divide the axis.');\n        splitSizes =\n            new Array(numOrSizeSplits).fill(x.shape[axis] / numOrSizeSplits);\n    }\n    else {\n        const numOfNegs = numOrSizeSplits.reduce((count, value) => {\n            if (value === -1) {\n                count += 1;\n            }\n            return count;\n        }, 0);\n        assert(numOfNegs <= 1, () => 'There should be only one negative value in split array.');\n        const negIndex = numOrSizeSplits.indexOf(-1);\n        // Allow the number of split array to be -1, which indicates the rest\n        // of dimension is allocated to that split.\n        if (negIndex !== -1) {\n            const total = numOrSizeSplits.reduce((a, b) => b > 0 ? a + b : a);\n            numOrSizeSplits[negIndex] = x.shape[axis] - total;\n        }\n        assert(x.shape[axis] === numOrSizeSplits.reduce((a, b) => a + b), () => 'The sum of sizes must match the size of the axis dimension.');\n        splitSizes = numOrSizeSplits;\n    }\n    return splitSizes;\n}\n//# sourceMappingURL=split_util.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { complex } from '../complex';\nimport { concat } from '../concat';\nimport { imag } from '../imag';\nimport { mul } from '../mul';\nimport { op } from '../operation';\nimport { real } from '../real';\nimport { reshape } from '../reshape';\nimport { reverse } from '../reverse';\nimport { scalar } from '../scalar';\nimport { slice } from '../slice';\nimport { ifft } from './ifft';\n/**\n * Inversed real value input fast Fourier transform.\n *\n * Computes the 1-dimensional inversed discrete Fourier transform over the\n * inner-most dimension of the real input.\n *\n * ```js\n * const real = tf.tensor1d([1, 2, 3]);\n * const imag = tf.tensor1d([0, 0, 0]);\n * const x = tf.complex(real, imag);\n *\n * x.irfft().print();\n * ```\n * @param input The real value input to compute an irfft over.\n *\n * @doc {heading: 'Operations', subheading: 'Spectral', namespace: 'spectral'}\n */\nfunction irfft_(input) {\n    const innerDimensionSize = input.shape[input.shape.length - 1];\n    const batch = input.size / innerDimensionSize;\n    let ret;\n    if (innerDimensionSize <= 2) {\n        const complexInput = reshape(input, [batch, innerDimensionSize]);\n        ret = ifft(complexInput);\n    }\n    else {\n        // The length of unique components of the DFT of a real-valued signal\n        // is 2 * (input_len - 1)\n        const outputShape = [batch, 2 * (innerDimensionSize - 1)];\n        const realInput = reshape(real(input), [batch, innerDimensionSize]);\n        const imagInput = reshape(imag(input), [batch, innerDimensionSize]);\n        const realConjugate = reverse(slice(realInput, [0, 1], [batch, innerDimensionSize - 2]), 1);\n        const imagConjugate = mul(reverse(slice(imagInput, [0, 1], [batch, innerDimensionSize - 2]), 1), scalar(-1));\n        const r = concat([realInput, realConjugate], 1);\n        const i = concat([imagInput, imagConjugate], 1);\n        const complexInput = reshape(complex(r, i), [outputShape[0], outputShape[1]]);\n        ret = ifft(complexInput);\n    }\n    ret = real(ret);\n    // reshape the result if the input is 3D tensor.\n    if (input.rank === 3 && input.shape[0] !== 0) {\n        const temp = ret;\n        const batch = input.shape[0];\n        ret = reshape(ret, [batch, ret.shape[0] / batch, ret.shape[1]]);\n        temp.dispose();\n    }\n    return ret;\n}\nexport const irfft = op({ irfft_ });\n//# sourceMappingURL=irfft.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { inferShape } from '../tensor_util_env';\nimport { assertNonNull } from '../util';\nimport { makeTensor } from './tensor_ops_util';\n/**\n * Creates rank-3 `tf.Tensor` with the provided values, shape and dtype.\n *\n * The same functionality can be achieved with `tf.tensor`, but in general\n * we recommend using `tf.tensor3d` as it makes the code more readable.\n *\n *  ```js\n * // Pass a nested array.\n * tf.tensor3d([[[1], [2]], [[3], [4]]]).print();\n * ```\n * ```js\n * // Pass a flat array and specify a shape.\n * tf.tensor3d([1, 2, 3, 4], [2, 2, 1]).print();\n * ```\n *\n * @param values The values of the tensor. Can be nested array of numbers,\n *     or a flat array, or a `TypedArray`.\n * @param shape The shape of the tensor. If not provided,  it is inferred from\n *     `values`.\n * @param dtype The data type.\n *\n * @doc {heading: 'Tensors', subheading: 'Creation'}\n */\nexport function tensor3d(values, shape, dtype) {\n    assertNonNull(values);\n    if (shape != null && shape.length !== 3) {\n        throw new Error('tensor3d() requires shape to have three numbers');\n    }\n    const inferredShape = inferShape(values, dtype);\n    if (inferredShape.length !== 3 && inferredShape.length !== 1) {\n        throw new Error('tensor3d() requires values to be number[][][] or flat/TypedArray');\n    }\n    if (inferredShape.length === 1 && shape == null) {\n        throw new Error('tensor3d() requires shape to be provided when `values` ' +\n            'are a flat array');\n    }\n    return makeTensor(values, shape, inferredShape, dtype);\n}\n//# sourceMappingURL=tensor3d.js.map","/**\n * @license\n * Copyright 2017 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n/**\n * Inputs of size above this threshold will be parallelized by calling multiple\n * shader programs.\n */\nimport { nearestDivisor } from '../util';\nexport const PARALLELIZE_THRESHOLD = 30;\nexport function computeOptimalWindowSize(inSize) {\n    if (inSize <= PARALLELIZE_THRESHOLD) {\n        return inSize;\n    }\n    return nearestDivisor(inSize, Math.floor(Math.sqrt(inSize)));\n}\n//# sourceMappingURL=reduce_util.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { nearestDivisor } from '../util';\nimport { PARALLELIZE_THRESHOLD } from './reduce_util';\nexport function segOpComputeOptimalWindowSize(inSize, numSegments) {\n    let done = false;\n    let res;\n    if (inSize <= PARALLELIZE_THRESHOLD) {\n        res = inSize;\n        done = true;\n    }\n    else {\n        res = nearestDivisor(inSize, Math.floor(Math.sqrt(inSize)));\n    }\n    while (!done) {\n        if (res > numSegments || res === inSize) {\n            done = true;\n        }\n        else {\n            res = nearestDivisor(inSize, res + 1);\n        }\n    }\n    return res;\n}\nexport function computeOutShape(aShape, axis, numSegments) {\n    const outShape = [];\n    const rank = aShape.length;\n    for (let dim = 0; dim < rank; dim++) {\n        if (dim !== axis) {\n            outShape.push(aShape[dim]);\n        }\n        else {\n            outShape.push(numSegments);\n        }\n    }\n    return outShape;\n}\nexport function collectGatherOpShapeInfo(x, indices, axis) {\n    const dimSize = x.shape[axis];\n    const outputShape = [];\n    let batchSize = 1;\n    let sliceSize = 1;\n    for (let i = 0; i < axis; i++) {\n        outputShape.push(x.shape[i]);\n        batchSize *= x.shape[i];\n    }\n    for (let i = 0; i < indices.rank; i++) {\n        outputShape.push(indices.shape[i]);\n    }\n    for (let i = axis + 1; i < x.rank; i++) {\n        outputShape.push(x.shape[i]);\n        sliceSize *= x.shape[i];\n    }\n    return { batchSize, sliceSize, dimSize, outputShape };\n}\n//# sourceMappingURL=segment_util.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Sin } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes sin of the input Tensor element-wise: `sin(x)`\n *\n * ```js\n * const x = tf.tensor1d([0, Math.PI / 2, Math.PI * 3 / 4]);\n *\n * x.sin().print();  // or tf.sin(x)\n * ```\n * @param x The input tensor.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction sin_(x) {\n    const $x = convertToTensor(x, 'x', 'sin');\n    const inputs = { x: $x };\n    return ENGINE.runKernelFunc((backend, save) => {\n        const res = backend.sin($x);\n        save([$x]);\n        return res;\n    }, inputs, null /* grad */, Sin);\n}\nexport const sin = op({ sin_ });\n//# sourceMappingURL=sin.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Sinh } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes hyperbolic sin of the input `tf.Tensor` element-wise: `sinh(x)`\n *\n * ```js\n * const x = tf.tensor1d([0, 1, -1, .7]);\n *\n * x.sinh().print();  // or tf.sinh(x)\n * ```\n * @param x The input tensor.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction sinh_(x) {\n    const $x = convertToTensor(x, 'x', 'sinh');\n    const inputs = { x: $x };\n    return ENGINE.runKernelFunc((backend, save) => {\n        const res = backend.sinh($x);\n        save([$x]);\n        return res;\n    }, inputs, null /* grad */, Sinh);\n}\nexport const sinh = op({ sinh_ });\n//# sourceMappingURL=sinh.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Rsqrt } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes reciprocal of square root of the input `tf.Tensor` element-wise:\n * `y = 1 / sqrt(x)`\n *\n * ```js\n * const x = tf.tensor1d([1, 2, 4, -1]);\n *\n * x.rsqrt().print();  // or tf.rsqrt(x)\n * ```\n * @param x The input tensor.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction rsqrt_(x) {\n    const $x = convertToTensor(x, 'x', 'rsqrt');\n    const inputs = { x: $x };\n    return ENGINE.runKernelFunc((backend, save) => {\n        const res = backend.rsqrt($x);\n        save([$x]);\n        return res;\n    }, inputs, null /* grad */, Rsqrt);\n}\nexport const rsqrt = op({ rsqrt_ });\n//# sourceMappingURL=rsqrt.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Softplus } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes softplus of the input `tf.Tensor` element-wise: `log(exp(x) + 1)`\n *\n * ```js\n * const x = tf.tensor1d([0, 1, -1, .7]);\n *\n * x.softplus().print();  // or tf.softplus(x)\n * ```\n * @param x The input tensor.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction softplus_(x) {\n    const $x = convertToTensor(x, 'x', 'softplus');\n    const inputs = { x: $x };\n    return ENGINE.runKernelFunc((backend, save) => {\n        const res = backend.softplus($x);\n        save([$x]);\n        return res;\n    }, inputs, null /* grad */, Softplus);\n}\nexport const softplus = op({ softplus_ });\n//# sourceMappingURL=softplus.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { OneHot } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\nimport { reshape } from './reshape';\n/**\n * Creates a one-hot `tf.Tensor`. The locations represented by `indices` take\n * value `onValue` (defaults to 1), while all other locations take value\n * `offValue` (defaults to 0). If `indices` is rank `R`, the output has rank\n * `R+1` with the last axis of size `depth`.\n *\n * ```js\n * tf.oneHot(tf.tensor1d([0, 1], 'int32'), 3).print();\n * ```\n *\n * @param indices `tf.Tensor` of indices with dtype `int32`.\n * @param depth The depth of the one hot dimension.\n * @param onValue A number used to fill in the output when the index matches\n * the location.\n * @param offValue A number used to fill in the output when the index does\n *     not match the location.\n *\n * @doc {heading: 'Tensors', subheading: 'Creation'}\n */\nfunction oneHot_(indices, depth, onValue = 1, offValue = 0) {\n    if (depth < 2) {\n        throw new Error(`Error in oneHot: depth must be >=2, but it is ${depth}`);\n    }\n    const $indices = convertToTensor(indices, 'indices', 'oneHot', 'int32');\n    const outShape = [...$indices.shape, depth];\n    const forward = (backend, save) => {\n        save([$indices]);\n        return reshape(backend.oneHot(reshape($indices, [$indices.size]), depth, onValue, offValue), outShape);\n    };\n    const inputs = { indices: $indices };\n    const attrs = { depth, onValue, offValue };\n    return ENGINE.runKernelFunc(forward, inputs, null /* grad */, OneHot, attrs);\n}\nexport const oneHot = op({ oneHot_ });\n//# sourceMappingURL=one_hot.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { convertToTensor } from '../tensor_util_env';\nimport * as util from '../util';\nimport { avgPool } from './avg_pool';\nimport { batchToSpaceND } from './batch_to_space_nd';\nimport * as conv_util from './conv_util';\nimport { maxPool } from './max_pool';\nimport { op } from './operation';\nimport { reshape } from './reshape';\nimport { spaceToBatchND } from './space_to_batch_nd';\n/**\n * Performs an N-D pooling operation\n *\n * @param input The input tensor, of rank 4 or rank 3 of shape\n *     `[batch, height, width, inChannels]`. If rank 3, batch of 1 is assumed.\n * @param windowShape The filter size: `[filterHeight, filterWidth]`. If\n *     `filterSize` is a single number, then `filterHeight == filterWidth`.\n * @param poolingType The type of pooling, either 'max' or 'avg'.\n * @param pad The type of padding algorithm:\n *    - `same` and stride 1: output will be of same size as input,\n *       regardless of filter size.\n *    - `valid`: output will be smaller than input if filter is larger\n *       than 1x1.\n *    - For more info, see this guide:\n *     [https://www.tensorflow.org/api_guides/python/nn#Convolution](\n *         https://www.tensorflow.org/api_guides/python/nn#Convolution)\n * @param dilations The dilation rates: `[dilationHeight, dilationWidth]`\n *     in which we sample input values across the height and width dimensions\n *     in dilated pooling. Defaults to `[1, 1]`. If `dilationRate` is a single\n *     number, then `dilationHeight == dilationWidth`. If it is greater than\n *     1, then all values of `strides` must be 1.\n * @param strides The strides of the pooling: `[strideHeight, strideWidth]`. If\n *     `strides` is a single number, then `strideHeight == strideWidth`.\n *\n * @doc {heading: 'Operations', subheading: 'Convolution'}\n */\nfunction pool_(input, windowShape, poolingType, pad, dilations, strides) {\n    if (dilations == null) {\n        dilations = [1, 1];\n    }\n    if (strides == null) {\n        strides = 1;\n    }\n    if (pad === 0) {\n        pad = 'valid';\n    }\n    const $x = convertToTensor(input, 'x', 'maxPool');\n    let x4D = $x;\n    let reshapedTo4D = false;\n    if ($x.rank === 3) {\n        reshapedTo4D = true;\n        x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);\n    }\n    util.assert(conv_util.eitherStridesOrDilationsAreOne(strides, dilations), () => 'Error in pool: Either strides or dilations must be 1. ' +\n        `Got strides ${strides} and dilations '${dilations}'`);\n    const convInfo = conv_util.computePool2DInfo(x4D.shape, windowShape, strides, dilations, pad);\n    const dilation = [convInfo.dilationHeight, convInfo.dilationWidth];\n    // The following implementation does batchToSpace(pool(spaceToBatch(x)))\n    // whenever dilation > 1 since the TF kernels do not support dilation > 1.\n    // tslint:disable-next-line:max-line-length\n    // https://github.com/tensorflow/tensorflow/blob/50f6bb67dc98c9b74630b6047aae7a4f8a40fd02/tensorflow/python/ops/nn_ops.py#L1037\n    let basePadding;\n    if (pad === 'same') {\n        basePadding = withSpaceToBatchBasePaddings([convInfo.filterHeight, convInfo.filterWidth], dilation);\n    }\n    else {\n        basePadding = [[0, 0], [0, 0]];\n    }\n    const isDilationOne = dilation[0] === 1 && dilation[1] === 1;\n    const [adjustedPadding, adjustedCrops] = requiredSpaceToBatchPaddings([convInfo.inHeight, convInfo.inWidth], dilation, basePadding);\n    const convertedPad = isDilationOne ? pad : 'valid';\n    const convertedX = isDilationOne ? x4D : spaceToBatchND(x4D, dilation, adjustedPadding);\n    const forwardOp = poolingType === 'avg' ?\n        () => avgPool(convertedX, windowShape, strides, convertedPad) :\n        () => maxPool(convertedX, windowShape, strides, convertedPad);\n    const y = forwardOp();\n    const res = isDilationOne ? y : batchToSpaceND(y, dilation, adjustedCrops);\n    if (reshapedTo4D) {\n        return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);\n    }\n    return res;\n}\n// Helper function to compute crops and paddings for pool with dilation > 1.\n// tslint:disable-next-line:max-line-length\n// https://github.com/tensorflow/tensorflow/blob/50f6bb67dc98c9b74630b6047aae7a4f8a40fd02/tensorflow/python/ops/array_ops.py#L2184\nfunction requiredSpaceToBatchPaddings(inputShape, blockShape, basePadding) {\n    const padStart = basePadding.map(b => b[0]);\n    const origPadEnd = basePadding.map(b => b[1]);\n    const fullInputShape = inputShape.concat(padStart, origPadEnd);\n    const padEndExtra = blockShape.map((b, i) => (b - fullInputShape[i] % b) % b);\n    const padEnd = origPadEnd.map((s, i) => s + padEndExtra[i]);\n    const paddings = blockShape.map((_, i) => [padStart[i], padEnd[i]]);\n    const crops = blockShape.map((_, i) => [0, padEndExtra[i]]);\n    return [paddings, crops];\n}\n// Helper function to compute base paddings for pool with dilation > 1.\n// tslint:disable-next-line:max-line-length\n// https://github.com/tensorflow/tensorflow/blob/50f6bb67dc98c9b74630b6047aae7a4f8a40fd02/tensorflow/python/ops/nn_ops.py#L524\nfunction withSpaceToBatchBasePaddings(filterShape, dilation) {\n    // Spatial dimensions of the filters and the upsampled filters in which we\n    // introduce (rate - 1) zeros between consecutive filter values.\n    const dilatedFilterShape = filterShape.map((s, i) => {\n        return s + (s - 1) * (dilation[i] - 1);\n    });\n    const padExtraShape = dilatedFilterShape.map(s => s - 1);\n    // When padding is odd, we pad more at end, following the same\n    // convention as conv2d.\n    const padExtraStart = padExtraShape.map(s => Math.floor(s / 2));\n    const padExtraEnd = padExtraShape.map((s, i) => s - padExtraStart[i]);\n    return padExtraShape.map((_, i) => {\n        return [padExtraStart[i], padExtraEnd[i]];\n    });\n}\nexport const pool = op({ pool_ });\n//# sourceMappingURL=pool.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Prod } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { parseAxisParam } from '../util';\nimport { expandShapeToKeepDim, getAxesPermutation, getInnerMostAxes } from './axis_util';\nimport { cast } from './cast';\nimport { op } from './operation';\nimport { reshape } from './reshape';\nimport { transpose } from './transpose';\n/**\n * Computes the product of elements across dimensions of a `tf.Tensor`.\n *\n * Reduces the input along the dimensions given in `axes`. Unless `keepDims`\n * is true, the rank of the `tf.Tensor` is reduced by 1 for each entry in\n * `axes`. If `keepDims` is true, the reduced dimensions are retained with\n * length 1. If `axes` has no entries, all dimensions are reduced, and a\n * `tf.Tensor` with a single element is returned.\n *\n * ```js\n * const x = tf.tensor1d([1, 2, 3]);\n *\n * x.prod().print();  // or tf.prod(x)\n * ```\n *\n * ```js\n * const x = tf.tensor2d([1, 2, 3, 4], [2, 2]);\n *\n * const axis = 1;\n * x.prod(axis).print();  // or tf.prod(x, axis)\n * ```\n *\n * @param x The input tensor to compute the product over. If the dtype is `bool`\n *   it will be converted to `int32` and the output dtype will be `int32`.\n * @param axis The dimension(s) to reduce. By default it reduces\n *     all dimensions.\n * @param keepDims If true, retains reduced dimensions with size 1.\n *\n * @doc {heading: 'Operations', subheading: 'Reduction'}\n */\nfunction prod_(x, axis = null, keepDims = false) {\n    let $x = convertToTensor(x, 'x', 'prod');\n    const forward = (backend) => {\n        if ($x.dtype === 'bool') {\n            $x = cast($x, 'int32');\n        }\n        const axes = parseAxisParam(axis, $x.shape);\n        const permutation = getAxesPermutation(axes, $x.rank);\n        let reductionAxes = axes;\n        let permutedX = $x;\n        if (permutation != null) {\n            permutedX = transpose($x, permutation);\n            reductionAxes = getInnerMostAxes(reductionAxes.length, $x.rank);\n        }\n        let value = backend.prod(permutedX, reductionAxes);\n        if (keepDims) {\n            const newShape = expandShapeToKeepDim(value.shape, axes);\n            value = reshape(value, newShape);\n        }\n        return value;\n    };\n    const inputs = { x: $x };\n    const attrs = { axis, keepDims };\n    return ENGINE.runKernelFunc(forward, inputs, null /* grad */, Prod, attrs);\n}\nexport const prod = op({ prod_ });\n//# sourceMappingURL=prod.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Selu } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes scaled exponential linear element-wise.\n *\n * `x < 0 ? scale * alpha * (exp(x) - 1) : x`\n *\n * ```js\n * const x = tf.tensor1d([-1, 2, -3, 4]);\n *\n * x.selu().print();  // or tf.selu(x)\n * ```\n * @param x The input tensor.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction selu_(x) {\n    const $x = convertToTensor(x, 'x', 'selu');\n    const forward = (backend, save) => {\n        const res = backend.selu($x);\n        save([$x]);\n        return res;\n    };\n    const inputs = { x: $x };\n    return ENGINE.runKernelFunc(forward, inputs, null /* grad */, Selu);\n}\nexport const selu = op({ selu_ });\n//# sourceMappingURL=selu.js.map","import { convertToTensor } from '../tensor_util_env';\nimport * as util from '../util';\nimport { conv2d } from './conv2d';\nimport { depthwiseConv2d } from './depthwise_conv2d';\nimport { op } from './operation';\nimport { reshape } from './reshape';\n/**\n * 2-D convolution with separable filters.\n *\n * Performs a depthwise convolution that acts separately on channels followed\n * by a pointwise convolution that mixes channels. Note that this is\n * separability between dimensions [1, 2] and 3, not spatial separability\n * between dimensions 1 and 2.\n *\n * See\n * [https://www.tensorflow.org/api_docs/python/tf/nn/separable_conv2d](\n *     https://www.tensorflow.org/api_docs/python/tf/nn/separable_conv2d)\n * for more details.\n *\n * @param x The input tensor, of rank 4 or rank 3, of shape\n *     `[batch, height, width, inChannels]`. If rank 3, batch of 1 is\n * assumed.\n * @param depthwiseFilter The depthwise filter tensor, rank 4, of shape\n *     `[filterHeight, filterWidth, inChannels, channelMultiplier]`. This is\n *     the filter used in the first step.\n * @param pointwiseFilter The pointwise filter tensor, rank 4, of shape\n *     `[1, 1, inChannels * channelMultiplier, outChannels]`. This is\n *     the filter used in the second step.\n * @param strides The strides of the convolution: `[strideHeight,\n * strideWidth]`. If strides is a single number, then `strideHeight ==\n * strideWidth`.\n * @param pad The type of padding algorithm.\n *   - `same` and stride 1: output will be of same size as input,\n *       regardless of filter size.\n *   - `valid`: output will be smaller than input if filter is larger\n *       than 1x1.\n *   - For more info, see this guide:\n *     [https://www.tensorflow.org/api_guides/python/nn#Convolution](\n *          https://www.tensorflow.org/api_guides/python/nn#Convolution)\n * @param dilations The dilation rates: `[dilationHeight, dilationWidth]`\n *     in which we sample input values across the height and width dimensions\n *     in atrous convolution. Defaults to `[1, 1]`. If `rate` is a single\n *     number, then `dilationHeight == dilationWidth`. If it is greater than\n *     1, then all values of `strides` must be 1.\n * @param dataFormat: An optional string from: \"NHWC\", \"NCHW\". Defaults to\n *     \"NHWC\". Specify the data format of the input and output data. With the\n *     default format \"NHWC\", the data is stored in the order of: [batch,\n *     height, width, channels]. Only \"NHWC\" is currently supported.\n *\n * @doc {heading: 'Operations', subheading: 'Convolution'}\n */\nfunction separableConv2d_(x, depthwiseFilter, pointwiseFilter, strides, pad, dilation = [1, 1], dataFormat = 'NHWC') {\n    const $x = convertToTensor(x, 'x', 'separableConv2d');\n    const $depthwiseFilter = convertToTensor(depthwiseFilter, 'depthwiseFilter', 'separableConv2d');\n    const $pointwiseFilter = convertToTensor(pointwiseFilter, 'pointwiseFilter', 'separableConv2d');\n    let x4D = $x;\n    let reshapedTo4D = false;\n    if ($x.rank === 3) {\n        reshapedTo4D = true;\n        x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);\n    }\n    if (dataFormat === 'NCHW') {\n        throw new Error('separableConv2d currently does not support dataFormat NCHW; only ' +\n            'NHWC is supported');\n    }\n    util.assert(x4D.rank === 4, () => `Error in separableConv2d: input must be rank 4, but got ` +\n        `rank ${x4D.rank}.`);\n    util.assert($depthwiseFilter.rank === 4, () => `Error in separableConv2d: depthwise filter must be rank 4, but ` +\n        `got rank ${$depthwiseFilter.rank}.`);\n    util.assert($pointwiseFilter.rank === 4, () => `Error in separableConv2d: pointwise filter must be rank 4, but ` +\n        `got rank ${$depthwiseFilter.rank}.`);\n    util.assert($pointwiseFilter.shape[0] === 1, () => `Error in separableConv2d: the first dimension of pointwise filter ` +\n        ` must be 1, but got ${$pointwiseFilter.shape[0]}.`);\n    util.assert($pointwiseFilter.shape[1] === 1, () => `Error in separableConv2d: the second dimension of pointwise ` +\n        `filter must be 1, but got ${$pointwiseFilter.shape[1]}.`);\n    const inChannels = $depthwiseFilter.shape[2];\n    const channelMultiplier = $depthwiseFilter.shape[3];\n    util.assert($pointwiseFilter.shape[2] === inChannels * channelMultiplier, () => `Error in separableConv2d: the third dimension of pointwise filter ` +\n        `must be ${inChannels * channelMultiplier}, ` +\n        `but got ${$pointwiseFilter.shape[2]}.`);\n    const depthwise = depthwiseConv2d(x4D, $depthwiseFilter, strides, pad, dataFormat, dilation);\n    const pointwiseStride = 1;\n    const res = conv2d(depthwise, $pointwiseFilter, pointwiseStride, 'valid', dataFormat);\n    if (reshapedTo4D) {\n        return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);\n    }\n    return res;\n}\nexport const separableConv2d = op({ separableConv2d_ });\n//# sourceMappingURL=separable_conv2d.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { TopK } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Finds the values and indices of the `k` largest entries along the last\n * dimension.\n *\n * If the input is a vector (rank=1), finds the k largest entries in the vector\n * and outputs their values and indices as vectors. Thus values[j] is the j-th\n * largest entry in input, and its index is indices[j].\n * For higher rank inputs, computes the top k entries along the last dimension.\n *\n * If two elements are equal, the lower-index element appears first.\n *\n * ```js\n * const a = tf.tensor2d([[1, 5], [4, 3]]);\n * const {values, indices} = tf.topk(a);\n * values.print();\n * indices.print();\n * ```\n * @param x 1-D or higher `tf.Tensor` with last dimension being at least `k`.\n * @param k Number of top elements to look for along the last dimension.\n * @param sorted If true, the resulting `k` elements will be sorted by the\n *     values in descending order.\n *\n * @doc {heading: 'Operations', subheading: 'Evaluation'}\n */\nfunction topk_(x, k = 1, sorted = true) {\n    const $x = convertToTensor(x, 'x', 'topk');\n    if ($x.rank === 0) {\n        throw new Error('topk() expects the input to be of rank 1 or higher');\n    }\n    const lastDim = $x.shape[$x.shape.length - 1];\n    if (k > lastDim) {\n        throw new Error(`'k' passed to topk() must be <= the last dimension (${lastDim}) ` +\n            `but got ${k}`);\n    }\n    const inputs = { x: $x };\n    const attrs = { k, sorted };\n    const [values, indices] = ENGINE.runKernelFunc(b => b.topk($x, k, sorted), inputs, null /* grad */, TopK, attrs);\n    return { values, indices };\n}\nexport const topk = op({ topk_ });\n//# sourceMappingURL=topk.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { ZerosLike } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Creates a `tf.Tensor` with all elements set to 0 with the same shape as the\n * given tensor.\n *\n * ```js\n * const x = tf.tensor([1, 2]);\n * tf.zerosLike(x).print();\n * ```\n *\n * @param x The tensor of required shape.\n *\n * @doc {heading: 'Tensors', subheading: 'Creation'}\n */\nfunction zerosLike_(x) {\n    const $x = convertToTensor(x, 'x', 'zerosLike');\n    const inputs = { x: $x };\n    return ENGINE.runKernelFunc(backend => backend.zerosLike($x), inputs, null /* grad */, ZerosLike);\n}\nexport const zerosLike = op({ zerosLike_ });\n//# sourceMappingURL=zeros_like.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Transpose } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport * as util from '../util';\nimport { op } from './operation';\n/**\n * Transposes the `tf.Tensor`. Permutes the dimensions according to `perm`.\n *\n * The returned `tf.Tensor`'s dimension `i` will correspond to the input\n * dimension `perm[i]`. If `perm` is not given, it is set to `[n-1...0]`,\n * where `n` is the rank of the input `tf.Tensor`. Hence by default, this\n * operation performs a regular matrix transpose on 2-D input `tf.Tensor`s.\n *\n * ```js\n * const a = tf.tensor2d([1, 2, 3, 4, 5, 6], [2, 3]);\n *\n * a.transpose().print();  // or tf.transpose(a)\n * ```\n *\n * @param x The tensor to transpose.\n * @param perm The permutation of the dimensions of a.\n *\n * @doc {heading: 'Operations', subheading: 'Matrices'}\n */\nfunction transpose_(x, perm) {\n    const $x = convertToTensor(x, 'x', 'transpose');\n    if (perm == null) {\n        perm = $x.shape.map((s, i) => i).reverse();\n    }\n    util.assert($x.rank === perm.length, () => `Error in transpose: rank of input ${$x.rank} ` +\n        `must match length of perm ${perm}.`);\n    perm.forEach(axis => {\n        util.assert(axis >= 0 && axis < $x.rank, () => `All entries in 'perm' must be between 0 and ${$x.rank - 1}` +\n            ` but got ${perm}`);\n    });\n    if ($x.rank <= 1) {\n        return $x.clone();\n    }\n    const inputs = { x: $x };\n    const attrs = { perm };\n    return ENGINE.runKernelFunc(backend => backend.transpose($x, perm), inputs, null /* gradient */, Transpose, attrs);\n}\nexport const transpose = op({ transpose_ });\n//# sourceMappingURL=transpose.js.map","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes square of `x` element-wise: `x ^ 2`\n *\n * ```js\n * const x = tf.tensor1d([1, 2, Math.sqrt(2), -1]);\n *\n * x.square().print();  // or tf.square(x)\n * ```\n * @param x The input Tensor.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction square_(x) {\n    const $x = convertToTensor(x, 'x', 'square');\n    const attrs = {};\n    const inputsToSave = [$x];\n    const outputsToSave = [];\n    return ENGINE.runKernelFunc((backend, save) => {\n        save([$x]);\n        return backend.square($x);\n    }, { x: $x }, null /* grad */, 'Square', attrs, inputsToSave, outputsToSave);\n}\nexport const square = op({ square_ });\n//# sourceMappingURL=square.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n// Returns the image center in pixels.\nexport function getImageCenter(center, imageHeight, imageWidth) {\n    const centerX = imageWidth * (typeof center === 'number' ? center : center[0]);\n    const centerY = imageHeight * (typeof center === 'number' ? center : center[1]);\n    return [centerX, centerY];\n}\n//# sourceMappingURL=rotate_util.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Slice } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\nimport * as slice_util from './slice_util';\n/**\n * Extracts a slice from a `tf.Tensor` starting at coordinates `begin`\n * and is of size `size`.\n *\n * Also available are stricter rank-specific methods with the same signature\n * as this method that assert that `x` is of the given rank:\n *   - `tf.slice1d`\n *   - `tf.slice2d`\n *   - `tf.slice3d`\n *   - `tf.slice4d`\n *\n * ```js\n * const x = tf.tensor1d([1, 2, 3, 4]);\n *\n * x.slice([1], [2]).print();\n * ```\n *\n * ```js\n * const x = tf.tensor2d([1, 2, 3, 4], [2, 2]);\n *\n * x.slice([1, 0], [1, 2]).print();\n * ```\n * @param x The input `tf.Tensor` to slice from.\n * @param begin The coordinates to start the slice from. The length can be\n *     less than the rank of x - the rest of the axes will have implicit 0 as\n *     start. Can also be a single number, in which case it specifies the\n *     first axis.\n * @param size The size of the slice. The length can be less than the rank of\n *     x - the rest of the axes will have implicit -1. A value of -1 requests\n *     the rest of the dimensions in the axis. Can also be a single number,\n *     in which case it specifies the size of the first axis.\n *\n * @doc {heading: 'Tensors', subheading: 'Slicing and Joining'}\n */\nfunction slice_(x, begin, size) {\n    const $x = convertToTensor(x, 'x', 'slice');\n    if ($x.rank === 0) {\n        throw new Error('Slicing scalar is not possible');\n    }\n    const [begin_, size_] = slice_util.parseSliceParams($x, begin, size);\n    slice_util.assertParamsValid($x, begin_, size_);\n    const forward = (backend, save) => {\n        save([$x]);\n        return backend.slice($x, begin_, size_);\n    };\n    const inputs = { x: $x };\n    const attrs = { begin, size };\n    return ENGINE.runKernelFunc(forward, inputs, null /* grad */, Slice, attrs);\n}\nexport const slice = op({ slice_ });\n//# sourceMappingURL=slice.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { OnesLike } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { complex } from './complex';\nimport { imag } from './imag';\nimport { op } from './operation';\nimport { real } from './real';\nimport { zerosLike } from './zeros_like';\n/**\n * Creates a `tf.Tensor` with all elements set to 1 with the same shape as the\n * given tensor.\n *\n * ```js\n * const x = tf.tensor([1, 2]);\n * tf.onesLike(x).print();\n * ```\n * @param x A tensor.\n *\n * @doc {heading: 'Tensors', subheading: 'Creation'}\n */\nfunction onesLike_(x) {\n    const $x = convertToTensor(x, 'x', 'onesLike');\n    const forward = (backend, save) => {\n        if ($x.dtype === 'complex64') {\n            const r = onesLike(real($x));\n            const i = zerosLike(imag($x));\n            return complex(r, i);\n        }\n        return backend.onesLike($x);\n    };\n    const inputs = { x: $x };\n    return ENGINE.runKernelFunc(forward, inputs, null /* grad */, OnesLike);\n}\nexport const onesLike = op({ onesLike_ });\n//# sourceMappingURL=ones_like.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Reciprocal } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes reciprocal of x element-wise: `1 / x`\n *\n * ```js\n * const x = tf.tensor1d([0, 1, 2]);\n *\n * x.reciprocal().print();  // or tf.reciprocal(x)\n * ```\n * @param x The input tensor.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction reciprocal_(x) {\n    const $x = convertToTensor(x, 'x', 'reciprocal');\n    const inputs = { x: $x };\n    return ENGINE.runKernelFunc((backend, save) => {\n        const res = backend.reciprocal($x);\n        save([$x]);\n        return res;\n    }, inputs, null /* grad */, Reciprocal);\n}\nexport const reciprocal = op({ reciprocal_ });\n//# sourceMappingURL=reciprocal.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Round } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes round of input `tf.Tensor` element-wise: `round(x)`.\n * It implements banker's rounding.\n *\n * ```js\n * const x = tf.tensor1d([.6, 1.1, -3.3]);\n *\n * x.round().print();  // or tf.round(x)\n * ```\n * @param x The input tensor.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction round_(x) {\n    const $x = convertToTensor(x, 'x', 'round');\n    const inputs = { x: $x };\n    return ENGINE.runKernelFunc((backend) => backend.round($x), inputs, null /* grad */, Round);\n}\nexport const round = op({ round_ });\n//# sourceMappingURL=round.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Sign } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Returns an element-wise indication of the sign of a number.\n *\n * ```js\n * const x = tf.tensor1d([.6, 1.1, -3.3, NaN, 0]);\n *\n * x.sign().print();  // or tf.sign(x)\n * ```\n * @param x The input Tensor.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction sign_(x) {\n    const $x = convertToTensor(x, 'x', 'sign');\n    const inputs = { x: $x };\n    return ENGINE.runKernelFunc(backend => backend.sign($x), inputs, null /* grad */, Sign);\n}\nexport const sign = op({ sign_ });\n//# sourceMappingURL=sign.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Softmax } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes the softmax normalized vector given the logits.\n *\n * ```js\n * const a = tf.tensor1d([1, 2, 3]);\n *\n * a.softmax().print();  // or tf.softmax(a)\n * ```\n *\n * ```js\n * const a = tf.tensor2d([2, 4, 6, 1, 2, 3], [2, 3]);\n *\n * a.softmax().print();  // or tf.softmax(a)\n * ```\n *\n * @param logits The logits array.\n * @param dim The dimension softmax would be performed on. Defaults to `-1`\n *     which indicates the last dimension.\n *\n * @doc {heading: 'Operations', subheading: 'Normalization'}\n */\nfunction softmax_(logits, dim = -1) {\n    const $logits = convertToTensor(logits, 'logits', 'softmax', 'float32');\n    if (dim === -1) {\n        dim = $logits.rank - 1;\n    }\n    if (dim !== $logits.rank - 1) {\n        throw Error('Softmax along a non-last dimension is not yet supported. ' +\n            `Logits was rank ${$logits.rank} and dim was ${dim}`);\n    }\n    const inputs = { logits: $logits };\n    const attrs = { dim };\n    return ENGINE.runKernelFunc((backend, save) => {\n        const y = backend.softmax($logits, dim);\n        save([y]);\n        return y;\n    }, inputs, null /* grad */, Softmax, attrs);\n}\nexport const softmax = op({ softmax_ });\n//# sourceMappingURL=softmax.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { StridedSlice } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\nimport { reshape } from './reshape';\nimport { slice } from './slice';\nimport { computeOutShape, getNormalizedAxes, maskToAxes } from './slice_util';\n/**\n * Extracts a strided slice of a tensor.\n *\n * Roughly speaking, this op extracts a slice of size (end-begin)/stride from\n * the given input tensor (x). Starting at the location specified by begin the\n * slice continues by adding stride to the index until all dimensions are not\n * less than end. Note that a stride can be negative, which causes a reverse\n * slice.\n *\n * ```js\n * const t = tf.tensor3d([1, 1, 1 ,2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 6, 6, 6],\n *    [3, 2, 3]);\n * t.stridedSlice([1, 0, 0], [2, 1, 3], [1, 1, 1]).print()  // [[[3, 3, 3]]]\n * t.stridedSlice([1, 0, 0], [2, 2, 3], [1, 1, 1]).print()  // [[[3, 3, 3],\n *                                                     // [4, 4, 4]]]\n * t.stridedSlice([1, -1, 0], [2, -3, 3], [1, -1, 1]).print() // [[[4, 4, 4],\n *                                                     // [3, 3, 3]]]\n * ```\n *\n * @param x The tensor to stride slice.\n * @param begin The coordinates to start the slice from.\n * @param end: The coordinates to end the slice at.\n * @param strides: The size of the slice.\n * @param beginMask: If the ith bit of beginMask is set, begin[i] is ignored\n *      and the fullest possible range in that dimension is used instead.\n * @param endMask: If the ith bit of endMask is set, end[i] is ignored\n *      and the fullest possible range in that dimension is used instead.\n * @param shrinkAxisMask: a bitmask where bit i implies that\n * the ith specification should shrink the dimensionality. begin and end must\n * imply a slice of size 1 in the dimension.\n *\n * @doc {heading: 'Operations', subheading: 'Slicing and Joining'}\n */\nfunction stridedSlice_(x, begin, end, strides, beginMask = 0, endMask = 0, ellipsisMask = 0, newAxisMask = 0, shrinkAxisMask = 0) {\n    let $x = convertToTensor(x, 'x', 'stridedSlice');\n    const forward = (backend) => {\n        if (strides == null) {\n            strides = new Array(begin.length);\n        }\n        const ellipsisAxes = maskToAxes(ellipsisMask);\n        if (ellipsisAxes.length > 1) {\n            throw new Error('Multiple ellipses in slice is not allowed.');\n        }\n        if (ellipsisMask !== 0 && newAxisMask !== 0) {\n            throw new Error('Using both ellipsisMask and newAxisMask is not yet supported.');\n        }\n        if (ellipsisMask !== 0 && shrinkAxisMask !== 0) {\n            throw new Error('Using both ellipsisMask and shrinkAxisMask is not yet supported.');\n        }\n        const numInterpolatedAxes = $x.rank - begin.length;\n        // Expand the dims of x based on the newAxisMask.\n        const expandAxes = maskToAxes(newAxisMask);\n        const newShape = $x.shape.slice();\n        expandAxes.forEach(axis => {\n            begin[axis] = 0;\n            end[axis] = 1;\n            newShape.splice(axis, 0, 1);\n        });\n        $x = reshape($x, newShape);\n        const { begin: normalizedBegin, end: normalizedEnd, strides: normalizedStrides } = getNormalizedAxes($x.shape, ellipsisAxes, numInterpolatedAxes, begin, end, strides, beginMask, endMask, ellipsisMask);\n        begin = normalizedBegin;\n        end = normalizedEnd;\n        strides = normalizedStrides;\n        const shrinkAxes = maskToAxes(shrinkAxisMask);\n        // Adjust the ends based on the shrink mask.\n        shrinkAxes.forEach(axis => {\n            end[axis] = begin[axis] + 1;\n            strides[axis] = 1;\n        });\n        // Figure out the output shape.\n        const size = computeOutShape(begin, end, strides);\n        // Remove the axes based on shrinkMask.\n        const outShape = size.filter((_, axis) => shrinkAxes.indexOf(axis) === -1);\n        const nonStrided = strides.every(v => v === 1);\n        if (nonStrided) {\n            return reshape(slice($x, begin, size), outShape);\n        }\n        const res = backend.stridedSlice($x, begin, end, strides);\n        return reshape(res, outShape);\n    };\n    const inputs = { x: $x };\n    const attrs = {\n        begin,\n        end,\n        strides,\n        beginMask,\n        endMask,\n        ellipsisMask,\n        newAxisMask,\n        shrinkAxisMask\n    };\n    return ENGINE.runKernelFunc(forward, inputs, null /* grad */, StridedSlice, attrs);\n}\nexport const stridedSlice = op({ stridedSlice_ });\n//# sourceMappingURL=strided_slice.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Tan } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes tan of the input `tf.Tensor` element-wise, `tan(x)`\n *\n * ```js\n * const x = tf.tensor1d([0, Math.PI / 2, Math.PI * 3 / 4]);\n *\n * x.tan().print();  // or tf.tan(x)\n * ```\n * @param x The input tensor.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction tan_(x) {\n    const $x = convertToTensor(x, 'x', 'tan');\n    const inputs = { x: $x };\n    return ENGINE.runKernelFunc((backend, save) => {\n        const res = backend.tan($x);\n        save([$x]);\n        return res;\n    }, inputs, null /* grad */, Tan);\n}\nexport const tan = op({ tan_ });\n//# sourceMappingURL=tan.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Tanh } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes hyperbolic tangent of the input `tf.Tensor` element-wise: `tanh(x)`\n *\n * ```js\n * const x = tf.tensor1d([0, 1, -1, 70]);\n *\n * x.tanh().print();  // or tf.tanh(x)\n * ```\n * @param x The input tensor.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction tanh_(x) {\n    const $x = convertToTensor(x, 'x', 'tanh');\n    const inputs = { x: $x };\n    return ENGINE.runKernelFunc((backend, save) => {\n        const y = backend.tanh($x);\n        save([y]);\n        return y;\n    }, inputs, null /* grad */, Tanh);\n}\nexport const tanh = op({ tanh_ });\n//# sourceMappingURL=tanh.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { SelectV2 } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { assert, assertShapesMatch } from '../util';\nimport { broadcastTo } from './broadcast_to';\nimport { assertAndGetBroadcastShape } from './broadcast_util';\nimport { op } from './operation';\n/**\n * Returns the elements, either `a` or `b` depending on the `condition`.\n *\n * If the condition is true, select from `a`, otherwise select from `b`.\n *\n * ```js\n * const cond = tf.tensor1d([false, false, true], 'bool');\n * const a = tf.tensor1d([1 , 2, 3]);\n * const b = tf.tensor1d([-1, -2, -3]);\n *\n * a.where(cond, b).print();\n * ```\n *\n * @param condition The input condition. Must be of dtype bool.\n * @param a If `condition` is rank 1, `a` may have a higher rank but\n *     its first dimension must match the size of `condition`.\n * @param b A tensor with the same dtype as `a` and with shape that is\n *     compatible with `a`.\n * @return A tensor with same dtype as `a` and `b`, and shape that is\n *     broadcastable from `a` and `b`.\n *\n * @doc {heading: 'Operations', subheading: 'Logical'}\n */\nfunction where_(condition, a, b) {\n    const $a = convertToTensor(a, 'a', 'where');\n    const $b = convertToTensor(b, 'b', 'where');\n    const $condition = convertToTensor(condition, 'condition', 'where', 'bool');\n    // TODO: move this logic to forward function when the broadcastTo op is\n    // implemented in WASM.\n    // Find the broadcastable shape for $a and $b.\n    const broadcastShape = assertAndGetBroadcastShape($a.shape, $b.shape);\n    const $broadcastedA = broadcastTo($a, broadcastShape);\n    const $broadcastedB = broadcastTo($b, broadcastShape);\n    if ($condition.rank === 1) {\n        // If condition rank is 1, then the first dimension must match the size of\n        // condition.\n        assert($condition.shape[0] === $a.shape[0], () => 'The first dimension of `a` must match the size of `condition`.');\n    }\n    if ($condition.rank !== 1) {\n        // A must have the same shape as condition.\n        assertShapesMatch($condition.shape, $broadcastedB.shape, 'Error in where: ');\n    }\n    const forward = (backend, save) => {\n        const res = backend.select($condition, $broadcastedA, $broadcastedB);\n        save([$condition]);\n        return res;\n    };\n    const inputs = {\n        condition: $condition,\n        t: $broadcastedA,\n        e: $broadcastedB\n    };\n    return ENGINE.runKernelFunc(forward, inputs, null /* gradient */, SelectV2);\n}\nexport const where = op({ where_ });\n//# sourceMappingURL=where.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nexport const OP_SCOPE_SUFFIX = '__op';\n/**\n * Used for wrapping functions that perform math operations on\n * Tensors. The function will be wrapped in a named scope that cleans all\n * memory usage after the function is done.\n */\nexport function op(f) {\n    const keys = Object.keys(f);\n    if (keys.length !== 1) {\n        throw new Error(`Please provide an object with a single key ` +\n            `(operation name) mapping to a function. Got an object with ` +\n            `${keys.length} keys.`);\n    }\n    let opName = keys[0];\n    const fn = f[opName];\n    // Strip the underscore from the end of the function name.\n    if (opName.endsWith('_')) {\n        opName = opName.substring(0, opName.length - 1);\n    }\n    // add an __op suffix to distinguish ops from kernels in tf.profile\n    opName = opName + OP_SCOPE_SUFFIX;\n    // tslint:disable-next-line:no-any\n    const f2 = (...args) => {\n        ENGINE.startScope(opName);\n        try {\n            const result = fn(...args);\n            if (result instanceof Promise) {\n                console.error('Cannot return a Promise inside of tidy.');\n            }\n            ENGINE.endScope(result);\n            return result;\n        }\n        catch (ex) {\n            ENGINE.endScope(null);\n            throw ex;\n        }\n    };\n    Object.defineProperty(f2, 'name', { value: opName, configurable: true });\n    // tslint:disable-next-line:no-any\n    return f2;\n}\n//# sourceMappingURL=operation.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Sqrt } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes square root of the input `tf.Tensor` element-wise: `y = sqrt(x)`\n *\n * ```js\n * const x = tf.tensor1d([1, 2, 4, -1]);\n *\n * x.sqrt().print();  // or tf.sqrt(x)\n * ```\n * @param x The input tensor.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction sqrt_(x) {\n    const $x = convertToTensor(x, 'x', 'sqrt');\n    const inputs = { x: $x };\n    return ENGINE.runKernelFunc((backend, save) => {\n        const res = backend.sqrt($x);\n        save([$x]);\n        return res;\n    }, inputs, null /* grad */, Sqrt);\n}\nexport const sqrt = op({ sqrt_ });\n//# sourceMappingURL=sqrt.js.map","/**\n * @license\n * Copyright 2017 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport * as util from '../util';\nexport function assertParamsValid(input, begin, size) {\n    util.assert(input.rank === begin.length, () => `Error in slice${input.rank}D: Length of begin ${begin} must ` +\n        `match the rank of the array (${input.rank}).`);\n    util.assert(input.rank === size.length, () => `Error in slice${input.rank}D: Length of size ${size} must ` +\n        `match the rank of the array (${input.rank}).`);\n    for (let i = 0; i < input.rank; ++i) {\n        util.assert(begin[i] + size[i] <= input.shape[i], () => `Error in slice${input.rank}D: begin[${i}] + size[${i}] ` +\n            `(${begin[i] + size[i]}) would overflow input.shape[${i}] (${input.shape[i]})`);\n    }\n}\n/** Converts a binary mask to an array of axes. Used in stridedSlice(). */\nexport function maskToAxes(mask) {\n    const axes = [];\n    let axis = 0;\n    while (mask > 0) {\n        if (mask & 1) {\n            axes.push(axis);\n        }\n        mask /= 2;\n        axis++;\n    }\n    return axes;\n}\n/** Computes the output shape given the strided slice params. */\nexport function computeOutShape(begin, end, strides) {\n    const size = [];\n    for (let axis = 0; axis < begin.length; axis++) {\n        size[axis] = Math.ceil((end[axis] - begin[axis]) / strides[axis]);\n    }\n    return size;\n}\n// Creates full selection at the elided dimensions. If the dimension matches\n// the ellipsis mask, override the current stride value. Otherwise, insert.\nexport function stridesWithElidedDims(strides, ellipsisInsertionIndex, numElidedAxes, inputShape) {\n    const newStrides = [...strides];\n    for (let i = newStrides.length; i < inputShape.length; i++) {\n        newStrides.push(1);\n    }\n    for (let i = 0; i < numElidedAxes; i++) {\n        if (i === 0) {\n            newStrides[ellipsisInsertionIndex] = 1;\n        }\n        else {\n            newStrides.splice(ellipsisInsertionIndex, 0 /* num elements to delete */, 1 /* element to add */);\n            newStrides.pop();\n        }\n    }\n    return newStrides;\n}\nfunction unnormalizeAxis(ellipsisInsertionIndex, numElidedAxes, normalizedAxis) {\n    if (normalizedAxis <= ellipsisInsertionIndex) {\n        return normalizedAxis;\n    }\n    return normalizedAxis - (numElidedAxes - 1);\n}\nfunction getElidedAxes(numElidedAxes, ellipsisInsertionIndex) {\n    const elidedAxes = [];\n    for (let i = 0; i < numElidedAxes; i++) {\n        elidedAxes.push(ellipsisInsertionIndex + i);\n    }\n    return elidedAxes;\n}\n// Normalize the start, end and strides.\nexport function getNormalizedAxes(inputShape, ellipsisAxes, numInterpolatedAxes, begin, end, strides, beginMask, endMask, ellipsisMask) {\n    const inputRank = inputShape.length;\n    let normalizedBegin = new Array(inputRank), normalizedEnd = new Array(inputRank), normalizedStrides = new Array(inputRank);\n    if (ellipsisAxes.length && numInterpolatedAxes > 0) {\n        const fullIndex = ellipsisAxes[0];\n        // The ellipsis applies to the masked index as well as any dimensions\n        // that are interpolated.\n        const numElidedAxes = numInterpolatedAxes + 1;\n        normalizedBegin = startIndicesWithElidedDims(beginMask, fullIndex, numElidedAxes, begin, inputShape);\n        normalizedEnd = stopIndicesWithElidedDims(endMask, fullIndex, numElidedAxes, end, inputShape);\n        normalizedStrides =\n            stridesWithElidedDims(strides, fullIndex, numElidedAxes, inputShape);\n    }\n    else {\n        for (let axis = 0; axis < inputRank; axis++) {\n            normalizedBegin[axis] = startForAxis(beginMask, begin, strides, inputShape, axis, ellipsisMask);\n            normalizedEnd[axis] =\n                stopForAxis(endMask, end, strides, inputShape, axis, ellipsisMask);\n            normalizedStrides[axis] = stridesForAxis(strides, axis, ellipsisMask);\n        }\n    }\n    return {\n        begin: normalizedBegin,\n        end: normalizedEnd,\n        strides: normalizedStrides\n    };\n}\n// Creates full selection at the elided dimensions. If the dimension matches\n// the ellipsis mask, override the current start value. Otherwise, insert.\nexport function startIndicesWithElidedDims(beginMask, ellipsisInsertionIndex, numElidedAxes, originalBegin, inputShape) {\n    const newIndices = [...inputShape];\n    const elidedAxes = getElidedAxes(numElidedAxes, ellipsisInsertionIndex);\n    for (let axis = 0; axis < newIndices.length; axis++) {\n        if (elidedAxes.indexOf(axis) > -1) {\n            newIndices[axis] = 0;\n        }\n        else {\n            const originalAxis = unnormalizeAxis(ellipsisInsertionIndex, numElidedAxes, axis);\n            let originalValue = originalBegin[originalAxis];\n            if (beginMask & 1 << originalAxis) {\n                originalValue = 0;\n            }\n            newIndices[axis] = originalValue;\n        }\n    }\n    return newIndices;\n}\n// Creates full selection at the elided dimensions. If the dimension matches\n// the ellipsis mask, override the current stop value. Otherwise, insert.\nexport function stopIndicesWithElidedDims(endMask, ellipsisInsertionIndex, numElidedAxes, originalEnd, inputShape) {\n    const newIndices = [...inputShape];\n    const elidedAxes = getElidedAxes(numElidedAxes, ellipsisInsertionIndex);\n    for (let axis = 0; axis < newIndices.length; axis++) {\n        if (elidedAxes.indexOf(axis) > -1) {\n            newIndices[axis] = Number.MAX_SAFE_INTEGER;\n        }\n        else {\n            const originalAxis = unnormalizeAxis(ellipsisInsertionIndex, numElidedAxes, axis);\n            let originalValue = originalEnd[originalAxis];\n            if (endMask & 1 << originalAxis) {\n                originalValue = Number.MAX_SAFE_INTEGER;\n            }\n            newIndices[axis] = originalValue;\n        }\n    }\n    for (let i = 0; i < newIndices.length; i++) {\n        // Handle negative indices\n        const axisSize = inputShape[i];\n        if (newIndices[i] < 0) {\n            newIndices[i] += axisSize;\n        }\n        newIndices[i] = util.clamp(0, newIndices[i], inputShape[i]);\n    }\n    return newIndices;\n}\nexport function stridesForAxis(strides, axis, ellipsisMask) {\n    let stride = strides[axis];\n    if (ellipsisMask & (1 << axis) || stride == null) {\n        stride = 1;\n    }\n    return stride;\n}\nexport function startForAxis(beginMask, startIndices, strides, inputShape, axis, ellipsisMask) {\n    // Begin with the specified index\n    let start = startIndices[axis];\n    const stride = strides[axis] || 1;\n    // Check the axis bit from right of masked axes, or the begin index is not set\n    // for the axis.\n    if (beginMask & 1 << axis || ellipsisMask & 1 << axis || start == null) {\n        if (stride > 0) {\n            // Forward iteration - use the first element. These values will get\n            // clamped below (Note: We could have set them to 0 and axis_size-1, but\n            // use lowest() and max() to maintain symmetry with StopForAxis())\n            start = Number.MIN_SAFE_INTEGER;\n        }\n        else {\n            // Backward iteration - use the last element.\n            start = Number.MAX_SAFE_INTEGER;\n        }\n    }\n    // Handle negative indices\n    const axisSize = inputShape[axis];\n    if (start < 0) {\n        start += axisSize;\n    }\n    // Clamping\n    start = util.clamp(0, start, axisSize - 1);\n    return start;\n}\nexport function stopForAxis(endMask, stopIndices, strides, inputShape, axis, ellipsisMask) {\n    // Begin with the specified index\n    let stop = stopIndices[axis];\n    const stride = strides[axis] || 1;\n    // Check the axis bit from right of masked axes, or if the stop index is not\n    // set for this axis.\n    if (endMask & (1 << axis) || ellipsisMask & (1 << axis) || stop == null) {\n        if (stride > 0) {\n            // Forward iteration - use the last element. These values will get\n            // clamped below\n            stop = Number.MAX_SAFE_INTEGER;\n        }\n        else {\n            // Backward iteration - use the first element.\n            stop = Number.MIN_SAFE_INTEGER;\n        }\n    }\n    // Handle negative indices\n    const axisSize = inputShape[axis];\n    if (stop < 0) {\n        stop += axisSize;\n    }\n    // Clamping\n    // Because the end index points one past the last element, we need slightly\n    // different clamping ranges depending on the direction.\n    if (stride > 0) {\n        // Forward iteration\n        stop = util.clamp(0, stop, axisSize);\n    }\n    else {\n        // Backward iteration\n        stop = util.clamp(-1, stop, axisSize - 1);\n    }\n    return stop;\n}\n/**\n * Returns true if the slice occupies a continous set of elements in the\n * 'flat' space.\n */\nexport function isSliceContinous(shape, begin, size) {\n    // Index of the first axis that has size > 1.\n    let firstNonOneAxis = size.length;\n    for (let i = 0; i < size.length; i++) {\n        if (size[i] > 1) {\n            firstNonOneAxis = i;\n            break;\n        }\n    }\n    for (let i = firstNonOneAxis + 1; i < size.length; i++) {\n        if (begin[i] > 0 || size[i] !== shape[i]) {\n            return false;\n        }\n    }\n    return true;\n}\nexport function computeFlatOffset(begin, strides) {\n    let flatOffset = begin.length > 0 ? begin[begin.length - 1] : 1;\n    for (let i = 0; i < begin.length - 1; i++) {\n        flatOffset += begin[i] * strides[i];\n    }\n    return flatOffset;\n}\nexport function parseSliceParams(x, begin, size) {\n    // The following logic allows for more ergonomic calls.\n    let begin_;\n    if (typeof begin === 'number') {\n        begin_ = [begin, ...new Array(x.rank - 1).fill(0)];\n    }\n    else if (begin.length < x.rank) {\n        begin_ = begin.concat(new Array(x.rank - begin.length).fill(0));\n    }\n    else {\n        begin_ = begin.slice();\n    }\n    begin_.forEach(d => {\n        util.assert(d !== -1, () => 'slice() does not support negative begin indexing.');\n    });\n    let size_;\n    if (size == null) {\n        size_ = new Array(x.rank).fill(-1);\n    }\n    else if (typeof size === 'number') {\n        size_ = [size, ...new Array(x.rank - 1).fill(-1)];\n    }\n    else if (size.length < x.rank) {\n        size_ = size.concat(new Array(x.rank - size.length).fill(-1));\n    }\n    else {\n        size_ = size;\n    }\n    size_ = size_.map((d, i) => {\n        if (d >= 0) {\n            return d;\n        }\n        else {\n            util.assert(d === -1, () => `Negative size values should be exactly -1 but got ` +\n                `${d} for the slice() size at index ${i}.`);\n            return x.shape[i] - begin_[i];\n        }\n    });\n    return [begin_, size_];\n}\n//# sourceMappingURL=slice_util.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { makeZerosTypedArray, sizeFromShape } from '../util';\nimport { complex } from './complex';\n/**\n * Creates a `tf.Tensor` with all elements set to 0.\n *\n * ```js\n * tf.zeros([2, 2]).print();\n * ```\n *\n * @param shape An array of integers defining the output tensor shape.\n * @param dtype The type of an element in the resulting tensor. Can\n *     be 'float32', 'int32' or 'bool'. Defaults to 'float'.\n *\n * @doc {heading: 'Tensors', subheading: 'Creation'}\n */\nexport function zeros(shape, dtype = 'float32') {\n    if (dtype === 'complex64') {\n        const real = zeros(shape, 'float32');\n        const imag = zeros(shape, 'float32');\n        return complex(real, imag);\n    }\n    const values = makeZerosTypedArray(sizeFromShape(shape), dtype);\n    return ENGINE.makeTensor(values, shape, dtype);\n}\n//# sourceMappingURL=zeros.js.map","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport '../flags';\nimport { env } from '../environment';\nimport { BrowserIndexedDB, BrowserIndexedDBManager } from '../io/indexed_db';\nimport { BrowserLocalStorage, BrowserLocalStorageManager } from '../io/local_storage';\nimport { ModelStoreManagerRegistry } from '../io/model_management';\nexport class PlatformBrowser {\n    fetch(path, init) {\n        return fetch(path, init);\n    }\n    now() {\n        return performance.now();\n    }\n    encode(text, encoding) {\n        if (encoding !== 'utf-8' && encoding !== 'utf8') {\n            throw new Error(`Browser's encoder only supports utf-8, but got ${encoding}`);\n        }\n        if (this.textEncoder == null) {\n            this.textEncoder = new TextEncoder();\n        }\n        return this.textEncoder.encode(text);\n    }\n    decode(bytes, encoding) {\n        return new TextDecoder(encoding).decode(bytes);\n    }\n}\nif (env().get('IS_BROWSER')) {\n    env().setPlatform('browser', new PlatformBrowser());\n    // Register LocalStorage IOHandler\n    try {\n        ModelStoreManagerRegistry.registerManager(BrowserLocalStorage.URL_SCHEME, new BrowserLocalStorageManager());\n    }\n    catch (err) {\n    }\n    // Register IndexedDB IOHandler\n    try {\n        ModelStoreManagerRegistry.registerManager(BrowserIndexedDB.URL_SCHEME, new BrowserIndexedDBManager());\n    }\n    catch (err) {\n    }\n}\n//# sourceMappingURL=platform_browser.js.map","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { env } from '../environment';\n// We are wrapping this within an object so it can be stubbed by Jasmine.\nexport const getNodeFetch = {\n    // tslint:disable-next-line:no-require-imports\n    importFetch: () => require('node-fetch')\n};\nlet systemFetch;\n// These getters and setters are for testing so we don't export a mutable\n// variable.\nexport function resetSystemFetch() {\n    systemFetch = null;\n}\nexport function setSystemFetch(fetchFn) {\n    systemFetch = fetchFn;\n}\nexport function getSystemFetch() {\n    return systemFetch;\n}\nexport class PlatformNode {\n    constructor() {\n        // tslint:disable-next-line:no-require-imports\n        this.util = require('util');\n        // According to the spec, the built-in encoder can do only UTF-8 encoding.\n        // https://developer.mozilla.org/en-US/docs/Web/API/TextEncoder/TextEncoder\n        this.textEncoder = new this.util.TextEncoder();\n    }\n    fetch(path, requestInits) {\n        if (env().global.fetch != null) {\n            return env().global.fetch(path, requestInits);\n        }\n        if (systemFetch == null) {\n            systemFetch = getNodeFetch.importFetch();\n        }\n        return systemFetch(path, requestInits);\n    }\n    now() {\n        const time = process.hrtime();\n        return time[0] * 1000 + time[1] / 1000000;\n    }\n    encode(text, encoding) {\n        if (encoding !== 'utf-8' && encoding !== 'utf8') {\n            throw new Error(`Node built-in encoder only supports utf-8, but got ${encoding}`);\n        }\n        return this.textEncoder.encode(text);\n    }\n    decode(bytes, encoding) {\n        if (bytes.length === 0) {\n            return '';\n        }\n        return new this.util.TextDecoder(encoding).decode(bytes);\n    }\n}\nif (env().get('IS_NODE')) {\n    env().setPlatform('node', new PlatformNode());\n}\n//# sourceMappingURL=platform_node.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { convertToTensorArray } from '../tensor_util_env';\nimport * as util from '../util';\nimport { concat } from './concat';\nimport { expandDims } from './expand_dims';\nimport { op } from './operation';\n/**\n * Stacks a list of rank-`R` `tf.Tensor`s into one rank-`(R+1)` `tf.Tensor`.\n *\n * ```js\n * const a = tf.tensor1d([1, 2]);\n * const b = tf.tensor1d([3, 4]);\n * const c = tf.tensor1d([5, 6]);\n * tf.stack([a, b, c]).print();\n * ```\n *\n * @param tensors A list of tensor objects with the same shape and dtype.\n * @param axis The axis to stack along. Defaults to 0 (the first dim).\n *\n * @doc {heading: 'Tensors', subheading: 'Slicing and Joining'}\n */\nfunction stack_(tensors, axis = 0) {\n    const $tensors = convertToTensorArray(tensors, 'tensors', 'stack');\n    util.assert($tensors.length >= 1, () => 'Pass at least one tensor to tf.stack');\n    if ($tensors.length === 1) {\n        return expandDims($tensors[0], axis);\n    }\n    const rank = $tensors[0].rank;\n    const shape = $tensors[0].shape;\n    const dtype = $tensors[0].dtype;\n    util.assert(axis <= rank, () => 'Axis must be <= rank of the tensor');\n    $tensors.forEach(t => {\n        util.assertShapesMatch(shape, t.shape, 'All tensors passed to stack must have matching shapes');\n        util.assert(dtype === t.dtype, () => 'All tensors passed to stack must have matching dtypes');\n    });\n    const expandedTensors = $tensors.map(t => expandDims(t, axis));\n    // Stack exists in the TensorFlow C++ API\n    // (https://www.tensorflow.org/api_docs/cc/class/tensorflow/ops/stack) but not\n    // in\n    // https://raw.githubusercontent.com/tensorflow/tensorflow/master/tensorflow/core/ops/ops.pbtxt.\n    // Therefore we are treating it like a high-level op rather than\n    // creating a dedicated stack kernel.\n    return concat(expandedTensors, axis);\n}\nexport const stack = op({ stack_ });\n//# sourceMappingURL=stack.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Pow } from '../kernel_names';\nimport { makeTypesMatch } from '../tensor_util';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes the power of one `tf.Tensor` to another. Supports broadcasting.\n *\n * Given a `tf.Tensor` x and a `tf.Tensor` y, this operation computes x^y for\n * corresponding elements in x and y. The result's dtype will be the upcasted\n * type of the `base` and `exp` dtypes.\n *\n * ```js\n * const a = tf.tensor([[2, 3], [4, 5]])\n * const b = tf.tensor([[1, 2], [3, 0]]).toInt();\n *\n * a.pow(b).print();  // or tf.pow(a, b)\n * ```\n *\n * ```js\n * const a = tf.tensor([[1, 2], [3, 4]])\n * const b = tf.tensor(2).toInt();\n *\n * a.pow(b).print();  // or tf.pow(a, b)\n * ```\n * We also expose `powStrict` which has the same signature as this op and\n * asserts that `base` and `exp` are the same shape (does not broadcast).\n *\n * @param base The base `tf.Tensor` to pow element-wise.\n * @param exp The exponent `tf.Tensor` to pow element-wise.\n *\n * @doc {heading: 'Operations', subheading: 'Arithmetic'}\n */\nfunction pow_(base, exp) {\n    let $base = convertToTensor(base, 'base', 'pow');\n    let $exp = convertToTensor(exp, 'exp', 'pow');\n    [$base, $exp] = makeTypesMatch($base, $exp);\n    const inputs = { a: $base, b: $exp };\n    const forward = (backend, save) => {\n        const y = backend.pow($base, $exp);\n        save([$base, $exp, y]);\n        return y;\n    };\n    return ENGINE.runKernelFunc(forward, inputs, null /* gradient */, Pow);\n}\nexport const pow = op({ pow_ });\n//# sourceMappingURL=pow.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport * as util from '../util';\nfunction nonMaxSuppSanityCheck(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma) {\n    if (iouThreshold == null) {\n        iouThreshold = 0.5;\n    }\n    if (scoreThreshold == null) {\n        scoreThreshold = Number.NEGATIVE_INFINITY;\n    }\n    if (softNmsSigma == null) {\n        softNmsSigma = 0.0;\n    }\n    const numBoxes = boxes.shape[0];\n    maxOutputSize = Math.min(maxOutputSize, numBoxes);\n    util.assert(0 <= iouThreshold && iouThreshold <= 1, () => `iouThreshold must be in [0, 1], but was '${iouThreshold}'`);\n    util.assert(boxes.rank === 2, () => `boxes must be a 2D tensor, but was of rank '${boxes.rank}'`);\n    util.assert(boxes.shape[1] === 4, () => `boxes must have 4 columns, but 2nd dimension was ${boxes.shape[1]}`);\n    util.assert(scores.rank === 1, () => 'scores must be a 1D tensor');\n    util.assert(scores.shape[0] === numBoxes, () => `scores has incompatible shape with boxes. Expected ${numBoxes}, ` +\n        `but was ${scores.shape[0]}`);\n    util.assert(0 <= softNmsSigma && softNmsSigma <= 1, () => `softNmsSigma must be in [0, 1], but was '${softNmsSigma}'`);\n    return { maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma };\n}\nexport { nonMaxSuppSanityCheck };\n//# sourceMappingURL=nonmax_util.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { inferShape } from '../tensor_util_env';\nimport { assertNonNull } from '../util';\nimport { makeTensor } from './tensor_ops_util';\n/**\n * Creates rank-1 `tf.Tensor` with the provided values, shape and dtype.\n *\n * The same functionality can be achieved with `tf.tensor`, but in general\n * we recommend using `tf.tensor1d` as it makes the code more readable.\n *\n * ```js\n * tf.tensor1d([1, 2, 3]).print();\n * ```\n *\n * @param values The values of the tensor. Can be array of numbers,\n *     or a `TypedArray`.\n * @param dtype The data type.\n *\n * @doc {heading: 'Tensors', subheading: 'Creation'}\n */\nexport function tensor1d(values, dtype) {\n    assertNonNull(values);\n    const inferredShape = inferShape(values, dtype);\n    if (inferredShape.length !== 1) {\n        throw new Error('tensor1d() requires values to be a flat/TypedArray');\n    }\n    const shape = null;\n    return makeTensor(values, shape, inferredShape, dtype);\n}\n//# sourceMappingURL=tensor1d.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { SplitV } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { parseAxisParam } from '../util';\nimport { op } from './operation';\nimport { prepareSplitSize } from './split_util';\n/**\n * Splits a `tf.Tensor` into sub tensors.\n *\n * If `numOrSizeSplits` is a number, splits `x` along dimension `axis`\n * into `numOrSizeSplits` smaller tensors.\n * Requires that `numOrSizeSplits` evenly divides `x.shape[axis]`.\n *\n * If `numOrSizeSplits` is a number array, splits `x` into\n * `numOrSizeSplits.length` pieces. The shape of the `i`-th piece has the\n * same size as `x` except along dimension `axis` where the size is\n * `numOrSizeSplits[i]`.\n *\n * ```js\n * const x = tf.tensor2d([1, 2, 3, 4, 5, 6, 7, 8], [2, 4]);\n * const [a, b] = tf.split(x, 2, 1);\n * a.print();\n * b.print();\n *\n * const [c, d, e] = tf.split(x, [1, 2, 1], 1);\n * c.print();\n * d.print();\n * e.print();\n * ```\n *\n * @param x The input tensor to split.\n * @param numOrSizeSplits Either an integer indicating the number of\n * splits along the axis or an array of integers containing the sizes of\n * each output tensor along the axis. If a number then it must evenly divide\n * `x.shape[axis]`; otherwise the sum of sizes must match `x.shape[axis]`.\n * Can contain one -1 indicating that dimension is to be inferred.\n * @param axis The dimension along which to split. Defaults to 0 (the first\n * dim).\n *\n * @doc {heading: 'Tensors', subheading: 'Slicing and Joining'}\n */\nfunction split_(x, numOrSizeSplits, axis = 0) {\n    const $x = convertToTensor(x, 'x', 'split');\n    const forward = (backend, _) => {\n        const $axis = parseAxisParam(axis, $x.shape)[0];\n        const splitSizes = prepareSplitSize($x, numOrSizeSplits, $axis);\n        return backend.split($x, splitSizes, $axis);\n    };\n    const inputs = { x: $x };\n    const attr = { numOrSizeSplits, axis };\n    return ENGINE.runKernelFunc(forward, inputs, null /* grad */, SplitV, attr);\n}\nexport const split = op({ split_ });\n//# sourceMappingURL=split.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Reshape } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport * as util from '../util';\nimport { op } from './operation';\n/**\n * Reshapes a `tf.Tensor` to a given shape.\n *\n * Given an input tensor, returns a new tensor with the same values as the\n * input tensor with shape `shape`.\n *\n * If one component of shape is the special value -1, the size of that\n * dimension is computed so that the total size remains constant. In\n * particular, a shape of [-1] flattens into 1-D. At most one component of\n * shape can be -1.\n *\n * If shape is 1-D or higher, then the operation returns a tensor with shape\n * shape filled with the values of tensor. In this case, the number of\n * elements implied by shape must be the same as the number of elements in\n * tensor.\n *\n * ```js\n * const x = tf.tensor1d([1, 2, 3, 4]);\n * x.reshape([2, 2]).print();\n * ```\n *\n * @param x The input tensor to be reshaped.\n * @param shape An array of integers defining the output tensor shape.\n *\n * @doc {heading: 'Tensors', subheading: 'Transformations'}\n */\nfunction reshape_(x, shape) {\n    const $x = convertToTensor(x, 'x', 'reshape', null);\n    shape = util.inferFromImplicitShape(shape, $x.size);\n    util.assert($x.size === util.sizeFromShape(shape), () => 'new shape and old shape must have the same number of elements.');\n    const inputs = { x: $x };\n    const attrs = { shape };\n    const forward = (backend, save) => {\n        save([$x]);\n        return backend.reshape($x, shape);\n    };\n    return ENGINE.runKernelFunc(forward, inputs, null /* grad */, Reshape, attrs);\n}\nexport const reshape = op({ reshape_ });\n//# sourceMappingURL=reshape.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { makeOnesTypedArray, sizeFromShape } from '../util';\nimport { complex } from './complex';\nimport { zeros } from './zeros';\n/**\n * Creates a `tf.Tensor` with all elements set to 1.\n *\n * ```js\n * tf.ones([2, 2]).print();\n * ```\n *\n * @param shape An array of integers defining the output tensor shape.\n * @param dtype The type of an element in the resulting tensor. Defaults to\n *     'float'.\n *\n * @doc {heading: 'Tensors', subheading: 'Creation'}\n */\nexport function ones(shape, dtype = 'float32') {\n    if (dtype === 'complex64') {\n        const real = ones(shape, 'float32');\n        const imag = zeros(shape, 'float32');\n        return complex(real, imag);\n    }\n    const values = makeOnesTypedArray(sizeFromShape(shape), dtype);\n    return ENGINE.makeTensor(values, shape, dtype);\n}\n//# sourceMappingURL=ones.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Relu } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\nimport { cast } from './cast';\n/**\n * Computes rectified linear element-wise: `max(x, 0)`.\n *\n * ```js\n * const x = tf.tensor1d([-1, 2, -3, 4]);\n *\n * x.relu().print();  // or tf.relu(x)\n * ```\n * @param x The input tensor. If the dtype is `bool`, the output dtype will be\n *     `int32'.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction relu_(x) {\n    const $x = convertToTensor(x, 'x', 'relu');\n    const forward = (backend, save) => {\n        save([$x]);\n        if ($x.dtype === 'bool') {\n            return cast($x, 'int32');\n        }\n        return backend.relu($x);\n    };\n    const inputs = { x: $x };\n    return ENGINE.runKernelFunc(forward, inputs, null /* grad */, Relu);\n}\nexport const relu = op({ relu_ });\n//# sourceMappingURL=relu.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Step } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes step of the input `tf.Tensor` element-wise: `x > 0 ? 1 : alpha * x`\n *\n * ```js\n * const x = tf.tensor1d([0, 2, -1, -3]);\n *\n * x.step(.5).print();  // or tf.step(x, .5)\n * ```\n * @param x The input tensor.\n * @param alpha The gradient when input is negative.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction step_(x, alpha = 0.0) {\n    const $x = convertToTensor(x, 'x', 'step');\n    const inputs = { x: $x };\n    const attrs = { alpha };\n    return ENGINE.runKernelFunc(backend => backend.step($x, alpha), inputs, null /* grad */, Step, attrs);\n}\nexport const step = op({ step_ });\n//# sourceMappingURL=step.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { assert, assertNonNegativeIntegerDimensions, flatten, inferDtype, isTypedArray, sizeFromShape, toTypedArray } from '../util';\n/** This is shared code across all tensor creation methods. */\nexport function makeTensor(values, shape, inferredShape, dtype) {\n    if (dtype == null) {\n        dtype = inferDtype(values);\n    }\n    if (dtype === 'complex64') {\n        throw new Error(`Cannot construct a complex64 tensor directly. ` +\n            `Please use tf.complex(real, imag).`);\n    }\n    if (!isTypedArray(values) && !Array.isArray(values) &&\n        typeof values !== 'number' && typeof values !== 'boolean' &&\n        typeof values !== 'string') {\n        throw new Error('values passed to tensor(values) must be a number/boolean/string or ' +\n            'an array of numbers/booleans/strings, or a TypedArray');\n    }\n    if (shape != null) {\n        assertNonNegativeIntegerDimensions(shape);\n        const providedSize = sizeFromShape(shape);\n        const inferredSize = sizeFromShape(inferredShape);\n        assert(providedSize === inferredSize, () => `Based on the provided shape, [${shape}], the tensor should have ` +\n            `${providedSize} values but has ${inferredSize}`);\n        for (let i = 0; i < inferredShape.length; ++i) {\n            const inferred = inferredShape[i];\n            const flatDimsDontMatch = i === inferredShape.length - 1 ?\n                inferred !== sizeFromShape(shape.slice(i)) :\n                true;\n            assert(inferredShape[i] === shape[i] || !flatDimsDontMatch, () => `Error creating a new Tensor. Inferred shape ` +\n                `(${inferredShape}) does not match the provided ` +\n                `shape (${shape}). `);\n        }\n    }\n    if (!isTypedArray(values) && !Array.isArray(values)) {\n        values = [values];\n    }\n    shape = shape || inferredShape;\n    values = dtype !== 'string' ?\n        toTypedArray(values, dtype) :\n        flatten(values, [], true);\n    return ENGINE.makeTensor(values, shape, dtype);\n}\n//# sourceMappingURL=tensor_ops_util.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Tile } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport * as util from '../util';\nimport { op } from './operation';\n/**\n * Construct a tensor by repeating it the number of times given by reps.\n *\n * This operation creates a new tensor by replicating `input` `reps`\n * times. The output tensor's i'th dimension has `input.shape[i] *\n * reps[i]` elements, and the values of `input` are replicated\n * `reps[i]` times along the i'th dimension. For example, tiling\n * `[a, b, c, d]` by `[2]` produces `[a, b, c, d, a, b, c, d]`.\n *\n * ```js\n * const a = tf.tensor1d([1, 2]);\n *\n * a.tile([2]).print();    // or a.tile([2])\n * ```\n *\n * ```js\n * const a = tf.tensor2d([1, 2, 3, 4], [2, 2]);\n *\n * a.tile([1, 2]).print();  // or a.tile([1, 2])\n * ```\n * @param x The tensor to tile.\n * @param reps Determines the number of replications per dimension.\n *\n * @doc {heading: 'Tensors', subheading: 'Slicing and Joining'}\n */\nfunction tile_(x, reps) {\n    const parseAs = null;\n    const $x = convertToTensor(x, 'x', 'tile', parseAs);\n    util.assert($x.rank === reps.length, () => `Error in transpose: rank of input ${$x.rank} ` +\n        `must match length of reps ${reps}.`);\n    const forward = (backend, save) => {\n        const res = backend.tile($x, reps);\n        save([$x]);\n        return res;\n    };\n    const inputsToSave = [$x];\n    const inputs = { x: $x };\n    const attrs = { reps };\n    return ENGINE.runKernelFunc(forward, inputs, null /* grad */, Tile, attrs, inputsToSave);\n}\nexport const tile = op({ tile_ });\n//# sourceMappingURL=tile.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Real } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Returns the real part of a complex (or real) tensor.\n *\n * Given a tensor input, this operation returns a tensor of type float that is\n * the real part of each element in input considered as a complex number.\n *\n * If the input is real, it simply makes a clone.\n *\n * ```js\n * const x = tf.complex([-2.25, 3.25], [4.75, 5.75]);\n * tf.real(x).print();\n * ```\n *\n * @doc {heading: 'Tensors', subheading: 'Creation'}\n */\nfunction real_(input) {\n    const $input = convertToTensor(input, 'input', 'real');\n    const forward = (backend) => {\n        return backend.real($input);\n    };\n    const inputs = { input: $input };\n    return ENGINE.runKernelFunc(forward, inputs, null /* gradient */, Real);\n}\nexport const real = op({ real_ });\n//# sourceMappingURL=real.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Reverse } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { parseAxisParam } from '../util';\nimport { clone } from './clone';\nimport { op } from './operation';\nimport { reshape } from './reshape';\n/**\n * Reverses a `tf.Tensor` along a specified axis.\n *\n * Also available are stricter rank-specific methods that assert that `x` is\n * of the given rank:\n *   - `tf.reverse1d`\n *   - `tf.reverse2d`\n *   - `tf.reverse3d`\n *   - `tf.reverse4d`\n *\n * Except `tf.reverse1d` (which does not have axis param), all methods have\n * same signature as this method.\n *\n * ```js\n * const x = tf.tensor1d([1, 2, 3, 4]);\n *\n * x.reverse().print();\n * ```\n *\n * ```js\n * const x = tf.tensor2d([1, 2, 3, 4], [2, 2]);\n *\n * const axis = 1;\n * x.reverse(axis).print();\n * ```\n * @param x The input tensor to be reversed.\n * @param axis The set of dimensions to reverse. Must be in the\n *     range [-rank(x), rank(x)). Defaults to all axes.\n *\n * @doc {heading: 'Tensors', subheading: 'Slicing and Joining'}\n */\nfunction reverse_(x, axis) {\n    const $x = convertToTensor(x, 'x', 'reverse');\n    const forward = (backend) => {\n        const axes = parseAxisParam(axis, $x.shape);\n        if ($x.rank === 0) {\n            return clone($x);\n        }\n        const res = backend.reverse($x, axes);\n        return reshape(res, $x.shape);\n    };\n    const inputs = { x: $x };\n    const attrs = { dims: axis };\n    return ENGINE.runKernelFunc(forward, inputs, null /* gradient */, Reverse, attrs);\n}\nexport const reverse = op({ reverse_ });\n//# sourceMappingURL=reverse.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Unpack } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport * as util from '../util';\nimport { op } from './operation';\n/**\n * Unstacks a `tf.Tensor` of rank-`R` into a list of rank-`(R-1)` `tf.Tensor`s.\n *\n * ```js\n * const a = tf.tensor2d([1, 2, 3, 4], [2, 2]);\n *\n * tf.unstack(a).forEach(tensor => tensor.print());\n * ```\n *\n * @param x A tensor object.\n * @param axis The axis to unstack along. Defaults to 0 (the first dim).\n *\n * @doc {heading: 'Tensors', subheading: 'Slicing and Joining'}\n */\nfunction unstack_(x, axis = 0) {\n    const $x = convertToTensor(x, 'x', 'unstack');\n    util.assert(axis >= -$x.shape.length && axis < $x.shape.length, () => `Axis = ${axis} is not in [-${$x.shape.length}, ${$x.shape.length})`);\n    if (axis < 0) {\n        axis += $x.shape.length;\n    }\n    const inputs = { value: $x };\n    const attrs = { axis };\n    const forward = (backend) => backend.unstack($x, axis);\n    return ENGINE.runKernelFunc(forward, inputs, null /* grad */, Unpack, attrs);\n}\nexport const unstack = op({ unstack_ });\n//# sourceMappingURL=unstack.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { NotEqual } from '../kernel_names';\nimport { makeTypesMatch } from '../tensor_util';\nimport { convertToTensor } from '../tensor_util_env';\nimport { assertAndGetBroadcastShape } from './broadcast_util';\nimport { op } from './operation';\n/**\n * Returns the truth value of (a != b) element-wise. Supports broadcasting.\n *\n * ```js\n * const a = tf.tensor1d([1, 2, 3]);\n * const b = tf.tensor1d([0, 2, 3]);\n *\n * a.notEqual(b).print();\n * ```\n * @param a The first input tensor.\n * @param b The second input tensor. Must have the same dtype as `a`.\n *\n * @doc {heading: 'Operations', subheading: 'Logical'}\n */\nfunction notEqual_(a, b) {\n    let $a = convertToTensor(a, 'a', 'notEqual');\n    let $b = convertToTensor(b, 'b', 'notEqual');\n    [$a, $b] = makeTypesMatch($a, $b);\n    assertAndGetBroadcastShape($a.shape, $b.shape);\n    const forward = (backend) => backend.notEqual($a, $b);\n    const inputs = { a: $a, b: $b };\n    return ENGINE.runKernelFunc(forward, inputs, null /* grad */, NotEqual);\n}\nexport const notEqual = op({ notEqual_ });\n//# sourceMappingURL=not_equal.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { SquaredDifference } from '../kernel_names';\nimport { makeTypesMatch } from '../tensor_util';\nimport { convertToTensor } from '../tensor_util_env';\nimport { assertAndGetBroadcastShape } from './broadcast_util';\nimport { op } from './operation';\n/**\n * Returns (a - b) * (a - b) element-wise.\n * Supports broadcasting.\n *\n * ```js\n * const a = tf.tensor1d([1, 4, 3, 16]);\n * const b = tf.tensor1d([1, 2, 9, 4]);\n *\n * a.squaredDifference(b).print();  // or tf.squaredDifference(a, b)\n * ```\n *\n * ```js\n * // Broadcast squared difference  a with b.\n * const a = tf.tensor1d([2, 4, 6, 8]);\n * const b = tf.scalar(5);\n *\n * a.squaredDifference(b).print();  // or tf.squaredDifference(a, b)\n * ```\n *\n * @param a The first tensor.\n * @param b The second tensor. Must have the same type as `a`.\n *\n * @doc {heading: 'Operations', subheading: 'Arithmetic'}\n */\nfunction squaredDifference_(a, b) {\n    let $a = convertToTensor(a, 'a', 'squaredDifference');\n    let $b = convertToTensor(b, 'b', 'squaredDifference');\n    [$a, $b] = makeTypesMatch($a, $b);\n    assertAndGetBroadcastShape($a.shape, $b.shape);\n    const forward = (backend, save) => {\n        const res = backend.squaredDifference($a, $b);\n        save([$a, $b]);\n        return res;\n    };\n    const inputs = { a: $a, b: $b };\n    const attrs = {};\n    return ENGINE.runKernelFunc(forward, inputs, null /* grad */, SquaredDifference, attrs);\n}\nexport const squaredDifference = op({ squaredDifference_ });\n//# sourceMappingURL=squared_difference.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { SpaceToBatchND } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport * as util from '../util';\nimport { op } from './operation';\n/**\n * This operation divides \"spatial\" dimensions `[1, ..., M]` of the input into\n * a grid of blocks of shape `blockShape`, and interleaves these blocks with\n * the \"batch\" dimension (0) such that in the output, the spatial\n * dimensions `[1, ..., M]` correspond to the position within the grid,\n * and the batch dimension combines both the position within a spatial block\n * and the original batch position. Prior to division into blocks,\n * the spatial dimensions of the input are optionally zero padded\n * according to `paddings`. See below for a precise description.\n *\n * ```js\n * const x = tf.tensor4d([1, 2, 3, 4], [1, 2, 2, 1]);\n * const blockShape = [2, 2];\n * const paddings = [[0, 0], [0, 0]];\n *\n * x.spaceToBatchND(blockShape, paddings).print();\n * ```\n *\n * @param x A `tf.Tensor`. N-D with `x.shape` = `[batch] + spatialShape +\n * remainingShape`, where spatialShape has `M` dimensions.\n * @param blockShape A 1-D array. Must have shape `[M]`, all values must\n * be >= 1.\n * @param paddings A 2-D array. Must have shape `[M, 2]`, all values must be >=\n *     0. `paddings[i] = [padStart, padEnd]` specifies the amount to zero-pad\n * from input dimension `i + 1`, which corresponds to spatial dimension `i`. It\n * is required that\n * `(inputShape[i + 1] + padStart + padEnd) % blockShape[i] === 0`\n *\n * This operation is equivalent to the following steps:\n *\n * 1. Zero-pad the start and end of dimensions `[1, ..., M]` of the input\n * according to `paddings` to produce `padded` of shape paddedShape.\n *\n * 2. Reshape `padded` to `reshapedPadded` of shape:\n * `[batch] + [paddedShape[1] / blockShape[0], blockShape[0], ...,\n * paddedShape[M] / blockShape[M-1], blockShape[M-1]] + remainingShape`\n *\n * 3. Permute dimensions of `reshapedPadded` to produce `permutedReshapedPadded`\n * of shape: `blockShape + [batch] + [paddedShape[1] / blockShape[0], ...,\n * paddedShape[M] / blockShape[M-1]] + remainingShape`\n *\n * 4. Reshape `permutedReshapedPadded` to flatten `blockShape` into the\n * batch dimension, producing an output tensor of shape:\n * `[batch * prod(blockShape)] + [paddedShape[1] / blockShape[0], ...,\n * paddedShape[M] / blockShape[M-1]] + remainingShape`\n *\n * @doc {heading: 'Tensors', subheading: 'Transformations'}\n */\nfunction spaceToBatchND_(x, blockShape, paddings) {\n    const $x = convertToTensor(x, 'x', 'spaceToBatchND');\n    util.assert($x.rank >= 1 + blockShape.length, () => `input rank ${$x.rank} should be > than [blockShape] ${blockShape.length}`);\n    util.assert(paddings.length === blockShape.length, () => `paddings.shape[0] ${paddings.length} must be equal to [blockShape] ${blockShape.length}`);\n    util.assert($x.shape.reduce((a, b, i) => {\n        if (i > 0 && i <= blockShape.length) {\n            return a &&\n                ((b + paddings[i - 1][0] + paddings[i - 1][1]) %\n                    blockShape[i - 1] ===\n                    0);\n        }\n        return a;\n    }, true), () => `input spatial dimensions ${$x.shape.slice(1)} with paddings ${paddings.toString()} must be divisible by blockShapes ${blockShape.toString()}`);\n    const forward = backend => backend.spaceToBatchND($x, blockShape, paddings);\n    const inputs = { x: $x };\n    const attrs = { blockShape, paddings };\n    return ENGINE.runKernelFunc(forward, inputs, null /* gradient */, SpaceToBatchND, attrs);\n}\nexport const spaceToBatchND = op({ spaceToBatchND_ });\n//# sourceMappingURL=space_to_batch_nd.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { inferShape } from '../tensor_util_env';\nimport { makeTensor } from './tensor_ops_util';\n/**\n * Creates a `tf.Tensor` with the provided values, shape and dtype.\n *\n * ```js\n * // Pass an array of values to create a vector.\n * tf.tensor([1, 2, 3, 4]).print();\n * ```\n *\n * ```js\n * // Pass a nested array of values to make a matrix or a higher\n * // dimensional tensor.\n * tf.tensor([[1, 2], [3, 4]]).print();\n * ```\n *\n * ```js\n * // Pass a flat array and specify a shape yourself.\n * tf.tensor([1, 2, 3, 4], [2, 2]).print();\n * ```\n *\n * @param values The values of the tensor. Can be nested array of numbers,\n *     or a flat array, or a `TypedArray`. If the values are strings,\n *     they will be encoded as utf-8 and kept as `Uint8Array[]`.\n * @param shape The shape of the tensor. Optional. If not provided,\n *   it is inferred from `values`.\n * @param dtype The data type.\n *\n * @doc {heading: 'Tensors', subheading: 'Creation'}\n */\nexport function tensor(values, shape, dtype) {\n    const inferredShape = inferShape(values, dtype);\n    return makeTensor(values, shape, inferredShape, dtype);\n}\n//# sourceMappingURL=tensor.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { inferShape } from '../tensor_util_env';\nimport { assertNonNull } from '../util';\nimport { makeTensor } from './tensor_ops_util';\n/**\n * Creates rank-2 `tf.Tensor` with the provided values, shape and dtype.\n *\n * The same functionality can be achieved with `tf.tensor`, but in general\n * we recommend using `tf.tensor2d` as it makes the code more readable.\n *\n *  ```js\n * // Pass a nested array.\n * tf.tensor2d([[1, 2], [3, 4]]).print();\n * ```\n * ```js\n * // Pass a flat array and specify a shape.\n * tf.tensor2d([1, 2, 3, 4], [2, 2]).print();\n * ```\n *\n * @param values The values of the tensor. Can be nested array of numbers,\n *     or a flat array, or a `TypedArray`.\n * @param shape The shape of the tensor. If not provided, it is inferred from\n *     `values`.\n * @param dtype The data type.\n *\n * @doc {heading: 'Tensors', subheading: 'Creation'}\n */\nexport function tensor2d(values, shape, dtype) {\n    assertNonNull(values);\n    if (shape != null && shape.length !== 2) {\n        throw new Error('tensor2d() requires shape to have two numbers');\n    }\n    const inferredShape = inferShape(values, dtype);\n    if (inferredShape.length !== 2 && inferredShape.length !== 1) {\n        throw new Error('tensor2d() requires values to be number[][] or flat/TypedArray');\n    }\n    if (inferredShape.length === 1 && shape == null) {\n        throw new Error('tensor2d() requires shape to be provided when `values` ' +\n            'are a flat/TypedArray');\n    }\n    return makeTensor(values, shape, inferredShape, dtype);\n}\n//# sourceMappingURL=tensor2d.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../../engine';\nimport { IFFT } from '../../kernel_names';\nimport { assert } from '../../util';\nimport { op } from '../operation';\nimport { reshape } from '../reshape';\n/**\n * Inverse fast Fourier transform.\n *\n * Computes the inverse 1-dimensional discrete Fourier transform over the\n * inner-most dimension of input.\n *\n * ```js\n * const real = tf.tensor1d([1, 2, 3]);\n * const imag = tf.tensor1d([1, 2, 3]);\n * const x = tf.complex(real, imag);\n *\n * x.ifft().print();  // tf.spectral.ifft(x).print();\n * ```\n * @param input The complex input to compute an ifft over.\n *\n * @doc {heading: 'Operations', subheading: 'Spectral', namespace: 'spectral'}\n */\nfunction ifft_(input) {\n    assert(input.dtype === 'complex64', () => `The dtype for tf.spectral.ifft() must be complex64 ` +\n        `but got ${input.dtype}.`);\n    const inputs = { input };\n    return ENGINE.runKernelFunc(backend => {\n        // Collapse all outer dimensions to a single batch dimension.\n        const innerDimensionSize = input.shape[input.shape.length - 1];\n        const batch = input.size / innerDimensionSize;\n        const input2D = reshape(input, [batch, innerDimensionSize]);\n        const result = backend.ifft(input2D);\n        return reshape(result, input.shape);\n    }, inputs, null /* gradient */, IFFT);\n}\nexport const ifft = op({ ifft_ });\n//# sourceMappingURL=ifft.js.map"],"sourceRoot":""}