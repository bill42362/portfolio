{"version":3,"sources":["webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/slice_util.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/sigmoid.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/squeeze.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/spectral/fft.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/spectral/rfft.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/norm.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/relu6.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/prelu.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/unsorted_segment_sum.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/pad.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/signal_ops_util.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/signal/hamming_window.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/signal/hann_window.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/signal/frame.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/signal/stft.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/ops.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/tensor.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/sum.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/scatter_nd_util.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/range.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/selu_util.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/sub.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/scalar.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/print.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/spectral/irfft.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/tensor3d.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/reduce_util.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/sin.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/sinh.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/rsqrt.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/softplus.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/one_hot.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/pool.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/prod.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/selu.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/separable_conv2d.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/topk.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/unique.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/zeros_like.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/square.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/slice.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/rotate_util.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/split_util.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/segment_util.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/ones_like.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/reciprocal.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/operation.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/round.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/sign.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/softmax.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/strided_slice.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/tan.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/tanh.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/where.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/sqrt.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/transpose.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/platforms/platform_browser.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/platforms/platform_node.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/stack.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/zeros.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/pow.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/nonmax_util.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/tensor1d.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/split.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/unstack.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/ones.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/relu.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/step.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/tensor_ops_util.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/tile.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/reshape.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/reverse.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/not_equal.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/squared_difference.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/space_to_batch_nd.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/tensor2d.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/spectral/ifft.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/real.js"],"names":["assertParamsValid","input","begin","size","inputRank","shape","length","i","maskToAxes","mask","axes","axis","push","computeOutShape","end","strides","Math","ceil","stridesWithElidedDims","ellipsisInsertionIndex","numElidedAxes","inputShape","newStrides","splice","pop","unnormalizeAxis","normalizedAxis","getElidedAxes","elidedAxes","getNormalizedAxes","ellipsisAxes","numInterpolatedAxes","beginMask","endMask","ellipsisMask","normalizedBegin","Array","normalizedEnd","normalizedStrides","fullIndex","startIndicesWithElidedDims","stopIndicesWithElidedDims","startForAxis","stopForAxis","stridesForAxis","originalBegin","newIndices","indexOf","originalAxis","originalValue","originalEnd","Number","MAX_SAFE_INTEGER","axisSize","stride","startIndices","start","MIN_SAFE_INTEGER","stopIndices","stop","isSliceContinous","firstNonOneAxis","computeFlatOffset","flatOffset","parseSliceParams","x","begin_","xRank","size_","fill","concat","slice","forEach","d","map","sliceInfo","xShape","newAxisMask","shrinkAxisMask","$begin","$end","$strides","Error","expandAxes","newShape","shrinkAxes","outShape","filter","_","nonStrided","every","v","sigmoid","sigmoid_","inputs","runKernel","squeeze","squeeze_","$x","fft","fft_","dtype","rfft","rfft_","fftLength","innerDimensionSize","batch","adjustedInput","zerosShape","zerosInput","complexInput","ret","half","floor","realValues","imagValues","realComplexConjugate","imagComplexConjugate","outputShape","normImpl","p","rank","isArray","Infinity","norm","norm_","ord","keepDims","keepDimsShape","relu6","relu6_","prelu","prelu_","alpha","unsortedSegmentSum","unsortedSegmentSum_","segmentIds","numSegments","$segmentIds","attrs","pad","pad_","paddings","constantValue","cosineWindow","windowLength","a","b","even","newValues","Float32Array","cosArg","PI","cos","tensor1d","hammingWindow_","hannWindow","hannWindow_","frame_","signal","frameLength","frameStep","padEnd","padValue","output","padLen","tensor2d","reshape","stft_","windowFn","value","pow","log","framedSignal","windowedSignal","mul","ifft","irfft","flipLeftRight","resizeNearestNeighbor","resizeBilinear","rotateWithOffset","cropAndResize","nonMaxSuppression","nonMaxSuppressionAsync","nonMaxSuppressionWithScore","nonMaxSuppressionWithScoreAsync","nonMaxSuppressionPadded","nonMaxSuppressionPaddedAsync","qr","tensor","values","inferredShape","sum","sum_","validateUpdateShape","indices","updates","sliceDim","batchDim","shapeError","validateInput","calculateShapes","indicesRank","sliceRank","totalNd","sliceSize","safeSliceDim","numUpdates","outputSize","range","step","SELU_SCALEALPHA","SELU_SCALE","sub","sub_","$a","$b","scalar","Uint8Array","print","verbose","console","toString","irfft_","realInput","imagInput","realConjugate","imagConjugate","r","temp","dispose","tensor3d","PARALLELIZE_THRESHOLD","computeOptimalWindowSize","inSize","sqrt","sin","sin_","sinh","sinh_","rsqrt","rsqrt_","softplus","softplus_","oneHot","oneHot_","depth","onValue","offValue","pool","pool_","windowShape","poolingType","dilations","x4D","reshapedTo4D","convInfo","dilation","dilationHeight","dilationWidth","basePadding","filterShape","padExtraShape","s","padExtraStart","padExtraEnd","withSpaceToBatchBasePaddings","filterHeight","filterWidth","isDilationOne","adjustedPadding","adjustedCrops","blockShape","padStart","origPadEnd","fullInputShape","padEndExtra","crops","requiredSpaceToBatchPaddings","inHeight","inWidth","convertedPad","convertedX","y","res","prod","prod_","selu","selu_","separableConv2d","separableConv2d_","depthwiseFilter","pointwiseFilter","dataFormat","$depthwiseFilter","$pointwiseFilter","inChannels","channelMultiplier","depthwise","topk","topk_","k","sorted","lastDim","unique","unique_","zerosLike","zerosLike_","square","square_","slice_","getImageCenter","center","imageHeight","imageWidth","prepareSplitSize","numOrSizeSplits","splitSizes","numOfNegs","reduce","count","negIndex","total","segOpComputeOptimalWindowSize","done","aShape","dim","collectGatherOpShapeInfo","batchDims","dimSize","batchSize","outerSize","onesLike","onesLike_","reciprocal","reciprocal_","op","f","keys","Object","opName","fn","endsWith","substring","f2","args","startScope","result","error","endScope","ex","defineProperty","configurable","round","round_","sign","sign_","softmax","softmax_","logits","$logits","stridedSlice","stridedSlice_","tan","tan_","tanh","tanh_","where","where_","condition","$condition","broadcastShape","$broadcastedA","$broadcastedB","t","e","sqrt_","transpose","transpose_","perm","reverse","clone","PlatformBrowser","path","init","fetch","performance","now","text","encoding","this","textEncoder","TextEncoder","encode","bytes","TextDecoder","decode","get","setPlatform","registerManager","URL_SCHEME","err","getNodeFetch","systemFetch","PlatformNode","util","requestInits","global","time","process","hrtime","stack","stack_","tensors","$tensors","zeros","real","imag","makeTensor","pow_","base","exp","$base","$exp","nonMaxSuppSanityCheck","boxes","scores","maxOutputSize","iouThreshold","scoreThreshold","softNmsSigma","NEGATIVE_INFINITY","numBoxes","min","split","split_","attr","unstack","unstack_","ones","relu","relu_","step_","providedSize","inferredSize","inferred","flatDimsDontMatch","tile","tile_","reps","reshape_","reverse_","dims","notEqual","notEqual_","squaredDifference","squaredDifference_","spaceToBatchND","spaceToBatchND_","ifft_","real_"],"mappings":";sJAAA,ksBAiBO,SAASA,EAAkBC,EAAOC,EAAOC,GAC5C,MAAMC,EAAYH,EAAMI,MAAMC,OAC9B,IAAYF,IAAcF,EAAMI,QAAQ,IAAM,iBAAiBF,uBAA+BF,uCAC1DE,QACpC,IAAYA,IAAcD,EAAKG,QAAQ,IAAM,iBAAiBF,sBAA8BD,uCACxDC,QACpC,IAAK,IAAIG,EAAI,EAAGA,EAAIH,IAAaG,EAC7B,IAAYL,EAAMK,GAAKJ,EAAKI,IAAMN,EAAMI,MAAME,IAAI,IAAM,iBAAiBH,aAAqBG,aAAaA,OACnGL,EAAMK,GAAKJ,EAAKI,kCAAkCA,OAAON,EAAMI,MAAME,QAI9E,SAASC,EAAWC,GACvB,MAAMC,EAAO,GACb,IAAIC,EAAO,EACX,KAAOF,EAAO,GACC,EAAPA,GACAC,EAAKE,KAAKD,GAEdF,GAAQ,EACRE,IAEJ,OAAOD,EAGJ,SAASG,EAAgBX,EAAOY,EAAKC,GACxC,MAAMZ,EAAO,GACb,IAAK,IAAIQ,EAAO,EAAGA,EAAOT,EAAMI,OAAQK,IACpCR,EAAKQ,GAAQK,KAAKC,MAAMH,EAAIH,GAAQT,EAAMS,IAASI,EAAQJ,IAE/D,OAAOR,EAIJ,SAASe,EAAsBH,EAASI,EAAwBC,EAAeC,GAClF,MAAMC,EAAa,IAAIP,GACvB,IAAK,IAAIR,EAAIe,EAAWhB,OAAQC,EAAIc,EAAWf,OAAQC,IACnDe,EAAWV,KAAK,GAEpB,IAAK,IAAIL,EAAI,EAAGA,EAAIa,EAAeb,IACrB,IAANA,EACAe,EAAWH,GAA0B,GAGrCG,EAAWC,OAAOJ,EAAwB,EAAgC,GAC1EG,EAAWE,OAGnB,OAAOF,EAEX,SAASG,EAAgBN,EAAwBC,EAAeM,GAC5D,OAAIA,GAAkBP,EACXO,EAEJA,GAAkBN,EAAgB,GAE7C,SAASO,EAAcP,EAAeD,GAClC,MAAMS,EAAa,GACnB,IAAK,IAAIrB,EAAI,EAAGA,EAAIa,EAAeb,IAC/BqB,EAAWhB,KAAKO,EAAyBZ,GAE7C,OAAOqB,EAGJ,SAASC,EAAkBR,EAAYS,EAAcC,EAAqB7B,EAAOY,EAAKC,EAASiB,EAAWC,EAASC,GACtH,MAAM9B,EAAYiB,EAAWf,OAC7B,IAAI6B,EAAkB,IAAIC,MAAMhC,GAAYiC,EAAgB,IAAID,MAAMhC,GAAYkC,EAAoB,IAAIF,MAAMhC,GAChH,GAAI0B,EAAaxB,QAAUyB,EAAsB,EAAG,CAChD,MAAMQ,EAAYT,EAAa,GAGzBV,EAAgBW,EAAsB,EAC5CI,EAAkBK,EAA2BR,EAAWO,EAAWnB,EAAelB,EAAOmB,GACzFgB,EAAgBI,EAA0BR,EAASM,EAAWnB,EAAeN,EAAKO,GAClFiB,EACIpB,EAAsBH,EAASwB,EAAWnB,EAAeC,QAG7D,IAAK,IAAIV,EAAO,EAAGA,EAAOP,EAAWO,IACjCwB,EAAgBxB,GAAQ+B,EAAaV,EAAW9B,EAAOa,EAASM,EAAYV,EAAMuB,GAClFG,EAAc1B,GACVgC,EAAYV,EAASnB,EAAKC,EAASM,EAAYV,EAAMuB,GACzDI,EAAkB3B,GAAQiC,EAAe7B,EAASJ,EAAMuB,GAGhE,MAAO,CACHhC,MAAOiC,EACPrB,IAAKuB,EACLtB,QAASuB,GAKV,SAASE,EAA2BR,EAAWb,EAAwBC,EAAeyB,EAAexB,GACxG,MAAMyB,EAAa,IAAIzB,GACjBO,EAAaD,EAAcP,EAAeD,GAChD,IAAK,IAAIR,EAAO,EAAGA,EAAOmC,EAAWxC,OAAQK,IACzC,GAAIiB,EAAWmB,QAAQpC,IAAS,EAC5BmC,EAAWnC,GAAQ,MAElB,CACD,MAAMqC,EAAevB,EAAgBN,EAAwBC,EAAeT,GAC5E,IAAIsC,EAAgBJ,EAAcG,GAC9BhB,EAAY,GAAKgB,IACjBC,EAAgB,GAEpBH,EAAWnC,GAAQsC,EAG3B,OAAOH,EAIJ,SAASL,EAA0BR,EAASd,EAAwBC,EAAe8B,EAAa7B,GACnG,MAAMyB,EAAa,IAAIzB,GACjBO,EAAaD,EAAcP,EAAeD,GAChD,IAAK,IAAIR,EAAO,EAAGA,EAAOmC,EAAWxC,OAAQK,IACzC,GAAIiB,EAAWmB,QAAQpC,IAAS,EAC5BmC,EAAWnC,GAAQwC,OAAOC,qBAEzB,CACD,MAAMJ,EAAevB,EAAgBN,EAAwBC,EAAeT,GAC5E,IAAIsC,EAAgBC,EAAYF,GAC5Bf,EAAU,GAAKe,IACfC,EAAgBE,OAAOC,kBAE3BN,EAAWnC,GAAQsC,EAG3B,IAAK,IAAI1C,EAAI,EAAGA,EAAIuC,EAAWxC,OAAQC,IAAK,CAExC,MAAM8C,EAAWhC,EAAWd,GACxBuC,EAAWvC,GAAK,IAChBuC,EAAWvC,IAAM8C,GAErBP,EAAWvC,GAAK,IAAW,EAAGuC,EAAWvC,GAAIc,EAAWd,IAE5D,OAAOuC,EAEJ,SAASF,EAAe7B,EAASJ,EAAMuB,GAC1C,IAAIoB,EAASvC,EAAQJ,GAIrB,OAHIuB,EAAgB,GAAKvB,GAAmB,MAAV2C,KAC9BA,EAAS,GAENA,EAEJ,SAASZ,EAAaV,EAAWuB,EAAcxC,EAASM,EAAYV,EAAMuB,GAE7E,IAAIsB,EAAQD,EAAa5C,GACzB,MAAM2C,EAASvC,EAAQJ,IAAS,GAG5BqB,EAAY,GAAKrB,GAAQuB,EAAe,GAAKvB,GAAiB,MAAT6C,KAKjDA,EAJAF,EAAS,EAIDH,OAAOM,iBAIPN,OAAOC,kBAIvB,MAAMC,EAAWhC,EAAWV,GAM5B,OALI6C,EAAQ,IACRA,GAASH,GAGbG,EAAQ,IAAW,EAAGA,EAAOH,EAAW,GACjCG,EAEJ,SAASb,EAAYV,EAASyB,EAAa3C,EAASM,EAAYV,EAAMuB,GAEzE,IAAIyB,EAAOD,EAAY/C,GACvB,MAAM2C,EAASvC,EAAQJ,IAAS,GAG5BsB,EAAW,GAAKtB,GAASuB,EAAgB,GAAKvB,GAAiB,MAARgD,KAInDA,EAHAL,EAAS,EAGFH,OAAOC,iBAIPD,OAAOM,kBAItB,MAAMJ,EAAWhC,EAAWV,GAe5B,OAdIgD,EAAO,IACPA,GAAQN,GAORM,EAFAL,EAAS,EAEF,IAAW,EAAGK,EAAMN,GAIpB,KAAY,EAAGM,EAAMN,EAAW,GAEpCM,EAMJ,SAASC,EAAiBvD,EAAOH,EAAOC,GAE3C,IAAI0D,EAAkB1D,EAAKG,OAC3B,IAAK,IAAIC,EAAI,EAAGA,EAAIJ,EAAKG,OAAQC,IAC7B,GAAIJ,EAAKI,GAAK,EAAG,CACbsD,EAAkBtD,EAClB,MAGR,IAAK,IAAIA,EAAIsD,EAAkB,EAAGtD,EAAIJ,EAAKG,OAAQC,IAC/C,GAAIL,EAAMK,GAAK,GAAKJ,EAAKI,KAAOF,EAAME,GAClC,OAAO,EAGf,OAAO,EAEJ,SAASuD,EAAkB5D,EAAOa,GACrC,IAAIgD,EAAa7D,EAAMI,OAAS,EAAIJ,EAAMA,EAAMI,OAAS,GAAK,EAC9D,IAAK,IAAIC,EAAI,EAAGA,EAAIL,EAAMI,OAAS,EAAGC,IAClCwD,GAAc7D,EAAMK,GAAKQ,EAAQR,GAErC,OAAOwD,EAEJ,SAASC,EAAiBC,EAAG/D,EAAOC,GAEvC,IAAI+D,EACJ,MAAMC,EAAQF,EAAE5D,MAAMC,OAatB,IAAI8D,EAuBJ,OAlCIF,EADiB,iBAAVhE,EACE,CAACA,KAAU,IAAIkC,MAAM+B,EAAQ,GAAGE,KAAK,IAEzCnE,EAAMI,OAAS6D,EACXjE,EAAMoE,OAAO,IAAIlC,MAAM+B,EAAQjE,EAAMI,QAAQ+D,KAAK,IAGlDnE,EAAMqE,QAEnBL,EAAOM,SAAQC,IACX,KAAmB,IAAPA,GAAU,IAAM,yDAI5BL,EADQ,MAARjE,EACQ,IAAIiC,MAAM+B,GAAOE,MAAM,GAEV,iBAATlE,EACJ,CAACA,KAAS,IAAIiC,MAAM+B,EAAQ,GAAGE,MAAM,IAExClE,EAAKG,OAAS6D,EACXhE,EAAKmE,OAAO,IAAIlC,MAAM+B,EAAQhE,EAAKG,QAAQ+D,MAAM,IAGjDlE,EAEZiE,EAAQA,EAAMM,KAAI,CAACD,EAAGlE,IACdkE,GAAK,EACEA,GAGP,KAAmB,IAAPA,GAAU,IAClB,qDAAGA,mCAAmClE,OACnC0D,EAAE5D,MAAME,GAAK2D,EAAO3D,MAG5B,CAAC2D,EAAQE,GAEb,SAASO,EAAUC,EAAQ1E,EAAOY,EAAKC,EAASiB,EAAWC,EAASC,EAAc2C,EAAaC,GAElG,IAAIC,EAAS7E,EAAMqE,QACfS,EAAOlE,EAAIyD,QACXU,EAAWlE,EACA,MAAXA,IACAkE,EAAW,IAAI7C,MAAM2C,EAAOzE,SAEhC,MAAMwB,EAAetB,EAAW0B,GAChC,GAAIJ,EAAaxB,OAAS,EACtB,MAAM,IAAI4E,MAAM,8CAEpB,GAAqB,IAAjBhD,GAAsC,IAAhB2C,EACtB,MAAM,IAAIK,MAAM,iEAEpB,GAAqB,IAAjBhD,GAAyC,IAAnB4C,EACtB,MAAM,IAAII,MAAM,oEAEpB,MAAMnD,EAAsB6C,EAAOtE,OAASyE,EAAOzE,OAE7C6E,EAAa3E,EAAWqE,GACxBO,EAAWR,EAAOL,QACxBY,EAAWX,SAAQ7D,IACfoE,EAAOpE,GAAQ,EACfqE,EAAKrE,GAAQ,EACbyE,EAAS7D,OAAOZ,EAAM,EAAG,MAE7B,MAAQT,MAAOiC,EAAiBrB,IAAKuB,EAAetB,QAASuB,GAAsBT,EAAkBuD,EAAUtD,EAAcC,EAAqBgD,EAAQC,EAAMC,EAAUjD,EAAWC,EAASC,GAC9L6C,EAAS5C,EACT6C,EAAO3C,EACP4C,EAAW3C,EACX,MAAM+C,EAAa7E,EAAWsE,GAE9BO,EAAWb,SAAQ7D,IACfqE,EAAKrE,GAAQoE,EAAOpE,GAAQ,EAC5BsE,EAAStE,GAAQ,KAGrB,MAAMR,EAAOU,EAAgBkE,EAAQC,EAAMC,GAErCK,EAAWnF,EAAKoF,QAAO,CAACC,EAAG7E,KAAuC,IAA9B0E,EAAWtC,QAAQpC,KAE7D,MAAO,CAAE8E,WADUR,EAASS,OAAMC,GAAW,IAANA,IAClBZ,SAAQC,OAAMC,WAAU9E,OAAMiF,WAAUE,c,iCC/UjE,kEAqCO,MAAMM,EAAU,YAAG,CAAEC,SAL5B,SAAkB5B,GACd,MACM6B,EAAS,CAAE7B,EADN,YAAgBA,EAAG,IAAK,YAEnC,OAAO,IAAO8B,UAAU,KAASD,O,iCCnCrC,kEAuCO,MAAME,EAAU,YAAG,CAAEC,SAJ5B,SAAkBhC,EAAGtD,GACjB,MAAMuF,EAAK,YAAgBjC,EAAG,IAAK,WACnC,OAAO,YAAQiC,EAAI,YAAaA,EAAG7F,MAAOM,GAAMyE,c,iCCrCpD,kEA2CO,MAAMe,EAAM,YAAG,CAAEC,KANxB,SAAcnG,GACV,YAAuB,cAAhBA,EAAMoG,OAAuB,IAChC,6DAAWpG,EAAMoG,WACrB,MAAMP,EAAS,CAAE7F,SACjB,OAAO,IAAO8F,UAAU,KAAKD,O,iCCzCjC,qIAgFO,MAAMQ,EAAO,YAAG,CAAEC,MArCzB,SAAetG,EAAOuG,GAClB,YAAuB,YAAhBvG,EAAMoG,OAAqB,IAAM,mDAAmDpG,EAAMoG,UACjG,IAAII,EAAqBxG,EAAMI,MAAMJ,EAAMI,MAAMC,OAAS,GAC1D,MAAMoG,EAAQzG,EAAME,KAAOsG,EAC3B,IAAIE,EACJ,GAAiB,MAAbH,GAAqBA,EAAYC,EAAoB,CAErD,MAAMvG,EAAQD,EAAMI,MAAMqE,KAAIiB,GAAK,IAC7BxF,EAAOF,EAAMI,MAAMqE,KAAIiB,GAAKA,IAClCxF,EAAKF,EAAMI,MAAMC,OAAS,GAAKkG,EAC/BG,EAAgB,YAAM1G,EAAOC,EAAOC,GACpCsG,EAAqBD,OAEpB,GAAiB,MAAbA,GAAqBA,EAAYC,EAAoB,CAE1D,MAAMG,EAAa3G,EAAMI,MAAMqE,KAAIiB,GAAKA,IACxCiB,EAAW3G,EAAMI,MAAMC,OAAS,GAAKkG,EAAYC,EACjDE,EAAgB,YAAO,CAAC1G,EAAO,YAAM2G,IAAc3G,EAAMI,MAAMC,OAAS,GACxEmG,EAAqBD,OAGrBG,EAAgB1G,EAGpB,MAAM4G,EAAa,YAAUF,GACvBG,EAAe,YAAQ,YAAQH,EAAeE,GAAa,CAACH,EAAOD,IACnEM,EAAM,YAAID,GAEVE,EAAOhG,KAAKiG,MAAMR,EAAqB,GAAK,EAC5CS,EAAa,YAAKH,GAClBI,EAAa,YAAKJ,GAClBK,EAAuB,YAAMF,EAAY,CAACF,EAAMP,EAAqBO,GAAOE,EAAW7G,MAAMC,OAAS,GACtG+G,EAAuB,YAAMF,EAAY,CAACH,EAAMP,EAAqBO,GAAOG,EAAW9G,MAAMC,OAAS,GACtGgH,EAAcX,EAActG,MAAMkE,QAExC,OADA+C,EAAYX,EAActG,MAAMC,OAAS,GAAK0G,EACvC,YAAQ,YAAQI,EAAqB,GAAIC,EAAqB,IAAKC,O,iCC9E9E,0IA6EA,SAASC,EAAStD,EAAGuD,EAAG7G,EAAO,MAC3B,GAAe,IAAXsD,EAAEwD,KACF,OAAO,YAAIxD,GAGf,GAAe,IAAXA,EAAEwD,MAAuB,OAAT9G,EAChB,OAAO4G,EAAS,YAAQtD,EAAG,EAAE,IAAKuD,EAAG7G,GAGzC,GAAe,IAAXsD,EAAEwD,MAA8B,iBAAT9G,GACvByB,MAAMsF,QAAQ/G,IAAyB,IAAhBA,EAAKL,OAAc,CAC1C,GAAU,IAANkH,EACA,OAAO,YAAI,YAAIvD,GAAItD,GAEvB,GAAI6G,IAAMG,IACN,OAAO,YAAI,YAAI1D,GAAItD,GAEvB,GAAI6G,KAAOG,IACP,OAAO,YAAI,YAAI1D,GAAItD,GAEvB,GAAU,cAAN6G,GAA2B,IAANA,EAErB,OAAO,YAAK,YAAI,YAAI,YAAIvD,GAAI,YAAO,EAAG,UAAWtD,IAErD,MAAM,IAAIuE,MAAM,qCAAqCsC,KAGzD,GAAIpF,MAAMsF,QAAQ/G,IAAyB,IAAhBA,EAAKL,OAAc,CAC1C,GAAU,IAANkH,EACA,OAAO,YAAI,YAAI,YAAIvD,GAAItD,EAAK,IAAKA,EAAK,GAAK,GAE/C,GAAI6G,IAAMG,IACN,OAAO,YAAI,YAAI,YAAI1D,GAAItD,EAAK,IAAKA,EAAK,IAE1C,GAAI6G,KAAOG,IACP,OAAO,YAAI,YAAI,YAAI1D,GAAItD,EAAK,IAAKA,EAAK,IAE1C,GAAU,QAAN6G,GAAqB,cAANA,EAEf,OAAO,YAAK,YAAI,YAAOvD,GAAItD,IAE/B,MAAM,IAAIuE,MAAM,qCAAqCsC,KAEzD,MAAM,IAAItC,MAAM,gCAAgCvE,KAE7C,MAAMiH,EAAO,YAAG,CAAEC,MAvDzB,SAAe5D,EAAG6D,EAAM,YAAanH,EAAO,KAAMoH,GAAW,GAEzD,MAAMH,EAAOL,EADbtD,EAAI,YAAgBA,EAAG,IAAK,QACH6D,EAAKnH,GAC9B,IAAIqH,EAAgBJ,EAAKvH,MACzB,GAAI0H,EAAU,CACV,MAAMrH,EAAO,YAAeC,EAAMsD,EAAE5D,OACpC2H,EAAgB,IAA+BJ,EAAKvH,MAAOK,GAE/D,OAAO,YAAQkH,EAAMI,O,iCC3EzB,kEAsCO,MAAMC,EAAQ,YAAG,CAAEC,OAL1B,SAAgBjE,GACZ,MACM6B,EAAS,CAAE7B,EADN,YAAgBA,EAAG,IAAK,UAEnC,OAAO,IAAO8B,UAAU,KAAOD,O,iCCpCnC,kEA0CO,MAAMqC,EAAQ,YAAG,CAAEC,OAN1B,SAAgBnE,EAAGoE,GACf,MAEMvC,EAAS,CAAE7B,EAFN,YAAgBA,EAAG,IAAK,SAEXoE,MADT,YAAgBA,EAAO,QAAS,UAE/C,OAAO,IAAOtC,UAAU,KAAOD,O,iCCxCnC,yEA+CO,MAAMwC,EAAqB,YAAG,CAAEC,oBARvC,SAA6BtE,EAAGuE,EAAYC,GACxC,MAAMvC,EAAK,YAAgBjC,EAAG,IAAK,sBAC7ByE,EAAc,YAAgBF,EAAY,aAAc,qBAAsB,SACpF,YAAO,YAAMC,IAAc,IAAM,qCACjC,MAAM3C,EAAS,CAAE7B,EAAGiC,EAAIsC,WAAYE,GAC9BC,EAAQ,CAAEF,eAChB,OAAO,IAAO1C,UAAU,KAAoBD,EAAQ6C,O,iCC7CxD,kEAsDO,MAAMC,EAAM,YAAG,CAAEC,KATxB,SAAc5E,EAAG6E,EAAUC,EAAgB,GACvC,MAAM7C,EAAK,YAAgBjC,EAAG,IAAK,OACnC,GAAgB,IAAZiC,EAAGuB,KACH,MAAM,IAAIvC,MAAM,sDAEpB,MAAMyD,EAAQ,CAAEG,WAAUC,iBACpBjD,EAAS,CAAE7B,EAAGiC,GACpB,OAAO,IAAOH,UAAU,KAAOD,EAAQ6C,O,8gCC/BpC,SAASK,EAAaC,EAAcC,EAAGC,GAC1C,MAAMC,EAAO,EAAIH,EAAe,EAC1BI,EAAY,IAAIC,aAAaL,GACnC,IAAK,IAAI1I,EAAI,EAAGA,EAAI0I,IAAgB1I,EAAG,CACnC,MAAMgJ,EAAU,EAAMvI,KAAKwI,GAAKjJ,GAAM0I,EAAeG,EAAO,GAC5DC,EAAU9I,GAAK2I,EAAIC,EAAInI,KAAKyI,IAAIF,GAEpC,OAAO,OAAAG,EAAA,GAASL,EAAW,WCKF,YAAG,CAAEM,eAHlC,SAAwBV,GACpB,OAAOD,EAAaC,EAAc,IAAM,QCErC,MAAMW,EAAa,YAAG,CAAEC,YAH/B,SAAqBZ,GACjB,OAAOD,EAAaC,EAAc,GAAK,O,aC6BpC,MAAM,EAAQ,YAAG,CAAEa,OAtB1B,SAAgBC,EAAQC,EAAaC,EAAWC,GAAS,EAAOC,EAAW,GACvE,IAAI3G,EAAQ,EACZ,MAAM4G,EAAS,GACf,KAAO5G,EAAQwG,GAAeD,EAAO5J,MACjCiK,EAAOxJ,KAAK,OAAA2D,EAAA,GAAMwF,EAAQvG,EAAOwG,IACjCxG,GAASyG,EAEb,GAAIC,EACA,KAAO1G,EAAQuG,EAAO5J,MAAM,CACxB,MAAMkK,EAAU7G,EAAQwG,EAAeD,EAAO5J,KACxCyI,EAAM,OAAAtE,EAAA,GAAO,CACf,OAAAC,EAAA,GAAMwF,EAAQvG,EAAOwG,EAAcK,GAAS,OAAAhG,EAAA,GAAK,CAACgG,GAASF,KAE/DC,EAAOxJ,KAAKgI,GACZpF,GAASyG,EAGjB,OAAsB,IAAlBG,EAAO9J,OACA,OAAAgK,EAAA,GAAS,GAAI,CAAC,EAAGN,IAErB,OAAAO,EAAA,GAAQ,OAAAjG,EAAA,GAAO8F,GAAS,CAACA,EAAO9J,OAAQ0J,OCN/B,YAAG,CAAEQ,MAZzB,SAAeT,EAAQC,EAAaC,EAAWzD,EAAWiE,EAAWb,GJvB9D,IAA6Bc,EIwBf,MAAblE,IJxB4BkE,EIyBIV,EAAhCxD,EJvBGxF,KAAKiG,MAAMjG,KAAK2J,IAAI,EAAG3J,KAAKC,KAAKD,KAAK4J,IAAIF,GAAS1J,KAAK4J,IAAI,OIyBnE,MAAMC,EAAe,EAAMd,EAAQC,EAAaC,GAC1Ca,EAAiB,OAAAC,EAAA,GAAIF,EAAcJ,EAAST,IAC5CI,EAAS,GACf,IAAK,IAAI7J,EAAI,EAAGA,EAAIsK,EAAaxK,MAAM,GAAIE,IACvC6J,EAAOxJ,KAAK,OAAA0F,EAAA,GAAK,OAAA/B,EAAA,GAAMuG,EAAgB,CAACvK,EAAG,GAAI,CAAC,EAAGyJ,IAAexD,IAEtE,OAAO,OAAAlC,EAAA,GAAO8F,M,oNCqKdjE,EAAA,EACA6E,EAAA,EACA1E,EAAA,EACA2E,EAAA,EAJJ,MA6BM,GAAQ,CACVC,cAAA,IACAC,sBAAA,IACAC,eAAA,IACAC,iBAAA,IACAC,cAAA,IACAC,kBAAA,IACAC,uBAAA,IACAC,2BAAA,IACAC,gCAAA,IACAC,wBAAA,IACAC,6BAAA,KAOA,IACA,IACAC,EAAA,EAaA,IACA,IACA,IACA,IACA,IACA,IACA,IACA,KACA,M,iCC5RJ,qDA8CO,SAASC,EAAOC,EAAQ1L,EAAOgG,GAClC,MAAM2F,EAAgB,YAAWD,EAAQ1F,GACzC,OAAO,YAAW0F,EAAQ1L,EAAO2L,EAAe3F,K,gCChDpD,0EA4DO,MAAM4F,EAAM,YAAG,CAAEC,KATxB,SAAcjI,EAAGtD,EAAO,KAAMoH,GAAW,GACrC,IAAI7B,EAAK,YAAgBjC,EAAG,IAAK,OAChB,SAAbiC,EAAGG,QACHH,EAAK,YAAKA,EAAI,UAElB,MAAMJ,EAAS,CAAE7B,EAAGiC,GACdyC,EAAQ,CAAEhI,OAAMoH,YACtB,OAAO,IAAOhC,UAAU,KAAKD,EAAQ6C,O,iCC1DzC,oKAOO,SAASwD,EAAoB9L,EAAO+L,EAASC,GAChD,MAAMC,EAAYF,EAAQ3E,KAAO,EAAK2E,EAAQ/L,MAAM+L,EAAQ3E,KAAO,GAAK,EAClE8E,EAAYH,EAAQ3E,KAAO,EAAK2E,EAAQ3E,KAAO,EAAI,EACnD+E,EACF,6FAAwCH,EAAQhM,yBAC5B+L,EAAQ/L,iBAAiBA,gBAC9BiM,oBAA2BC,KAC9C,GAAIF,EAAQ5E,KAAO8E,EACf,MAAM,IAAIrH,MAAMsH,EAAa,kBAAkBD,OAEnD,GAAIlM,EAAMC,OAASgM,GAAYD,EAAQ5E,KAAO8E,GAC1C,MAAM,IAAIrH,MAAMsH,EACZ,0BAA0BF,GAAYD,EAAQ5E,KAAO8E,MAE7D,GAAIF,EAAQ5E,OAAS8E,EAAWlM,EAAMC,OAASgM,EAC3C,MAAM,IAAIpH,MAAMsH,EAAa,oBAAmBD,EAAWlM,EAAMC,OAASgM,IAE9E,IAAK,IAAI7H,EAAI,EAAGA,EAAI8H,IAAY9H,EAC5B,GAAI4H,EAAQhM,MAAMoE,KAAO2H,EAAQ/L,MAAMoE,GACnC,MAAM,IAAIS,MAAMsH,EACZ,kBAAkB/H,OAAO4H,EAAQhM,MAAMoE,wBAAwBA,OAAO2H,EAAQ/L,MAAMoE,QAGhG,IAAK,IAAIA,EAAI,EAAGA,EAAI4H,EAAQ5E,KAAO8E,IAAY9H,EAC3C,GAAI4H,EAAQhM,MAAMoE,EAAI8H,KAAclM,EAAMoE,EAAI6H,GAC1C,MAAM,IAAIpH,MAAMsH,EACZ,kBAAkB/H,EAAI8H,OAAcF,EAAQhM,MAAMoE,EAAI8H,gBAAuB9H,EAAI8H,OAAclM,EAAMoE,EAAI8H,OAWlH,SAASE,EAAcJ,EAASD,EAAS/L,GAC5C,GAAI+L,EAAQ3E,KAAO,EACf,MAAM,IAAIvC,MACN,+EAAqBkH,EAAQ3E,SAErC,GAAI4E,EAAQ5E,KAAO,EACf,MAAM,IAAIvC,MACN,+EAAqBmH,EAAQ5E,SAErC,GAAsB,UAAlB2E,EAAQ/F,MACR,MAAM,IAAInB,MAAM,0DAA0DkH,EAAQ/F,SAEtF,GAAIhG,EAAMC,OAAS,EACf,MAAM,IAAI4E,MAAM,6DAA6D7E,KAEjF,GAAqB,IAAjBA,EAAMC,OAAc,CACpB,GAAqB,IAAjB8L,EAAQjM,KACR,MAAM,IAAI+E,MAAM,sDAAsDkH,EAAQ/L,SAElF,GAAqB,IAAjBgM,EAAQlM,KACR,MAAM,IAAI+E,MAAM,sDAAsDmH,EAAQhM,SAGtF8L,EAAoB9L,EAAO+L,EAASC,GAWjC,SAASK,EAAgBL,EAASD,EAAS/L,GAE9C,MAAMsM,EAAcP,EAAQ/L,MAAMC,OAC5BsM,EAAaD,EAAc,EAAKP,EAAQ/L,MAAMsM,EAAc,GAAK,EAIjEE,EAAUxM,EAAMC,OACtB,IAAIwM,EAAY,EAChB,IAAK,IAAIvM,EAAIqM,EAAWrM,EAAIsM,IAAWtM,EACnCuM,GAAazM,EAAME,GAEvB,MAAMwM,EAAgBH,EAAY,EAAK,EAAIA,EAI3C,MAAO,CAAEA,YAAWI,WAHD,YAAcZ,EAAQ/L,OAAS0M,EAGlBD,YAAW/L,QAF3B,IAAI,YAAeV,EAAMkE,MAAM,EAAGqI,IAAa,GAEXK,WADjC,YAAc5M,M,iCC7FrC,oDAqCO,SAAS6M,EAAM1J,EAAOG,EAAMwJ,EAAO,EAAG9G,EAAQ,WACjD,GAAa,IAAT8G,EACA,MAAM,IAAIjI,MAAM,8BAEpB,MAAMyD,EAAQ,CAAEnF,QAAOG,OAAMwJ,OAAM9G,SACnC,OAAO,IAAON,UAAU,KAAO,GAAiB4C,K,iCC1CpD,oEAgBO,MAAMyE,EAAkB,mBAClBC,EAAa,oB,gCCjB1B,0EAmDO,MAAMC,EAAM,YAAG,CAAEC,KAPxB,SAAcrE,EAAGC,GACb,IAAIqE,EAAK,YAAgBtE,EAAG,IAAK,OAC7BuE,EAAK,YAAgBtE,EAAG,IAAK,QAChCqE,EAAIC,GAAM,YAAeD,EAAIC,GAC9B,MAAM3H,EAAS,CAAEoD,EAAGsE,EAAIrE,EAAGsE,GAC3B,OAAO,IAAO1H,UAAU,KAAKD,O,gCCjDjC,qDAiCO,SAAS4H,EAAOhD,EAAOrE,GAC1B,IAAM,YAAaqE,IAAoB,WAAVrE,GAAuBjE,MAAMsF,QAAQgD,KACpD,cAAVrE,EACA,MAAM,IAAInB,MAAM,kFAGpB,GAAc,WAAVmB,GAAsB,YAAaqE,MACjCA,aAAiBiD,YACnB,MAAM,IAAIzI,MAAM,6EAKpB,OAAO,YAAWwF,EAFJ,GACQ,GACyBrE,K,iCCjB5C,SAASuH,EAAM3J,EAAG4J,GAAU,GAC/BC,QAAQlD,IAAI3G,EAAE8J,SAASF,IA9B3B,mC,iCCAA,4HA2EO,MAAM5C,EAAQ,YAAG,CAAE+C,OA/B1B,SAAgB/N,GACZ,MAAMwG,EAAqBxG,EAAMI,MAAMJ,EAAMI,MAAMC,OAAS,GACtDoG,EAAQzG,EAAME,KAAOsG,EAC3B,IAAIM,EACJ,GAAIN,GAAsB,EAAG,CACzB,MAAMK,EAAe,YAAQ7G,EAAO,CAACyG,EAAOD,IAC5CM,EAAM,YAAKD,OAEV,CAGD,MAAMQ,EAAc,CAACZ,EAAO,GAAKD,EAAqB,IAChDwH,EAAY,YAAQ,YAAKhO,GAAQ,CAACyG,EAAOD,IACzCyH,EAAY,YAAQ,YAAKjO,GAAQ,CAACyG,EAAOD,IACzC0H,EAAgB,YAAQ,YAAMF,EAAW,CAAC,EAAG,GAAI,CAACvH,EAAOD,EAAqB,IAAK,GACnF2H,EAAgB,YAAI,YAAQ,YAAMF,EAAW,CAAC,EAAG,GAAI,CAACxH,EAAOD,EAAqB,IAAK,GAAI,aAAQ,IACnG4H,EAAI,YAAO,CAACJ,EAAWE,GAAgB,GACvC5N,EAAI,YAAO,CAAC2N,EAAWE,GAAgB,GACvCtH,EAAe,YAAQ,YAAQuH,EAAG9N,GAAI,CAAC+G,EAAY,GAAIA,EAAY,KACzEP,EAAM,YAAKD,GAIf,GAFAC,EAAM,YAAKA,GAEQ,IAAf9G,EAAMwH,MAAiC,IAAnBxH,EAAMI,MAAM,GAAU,CAC1C,MAAMiO,EAAOvH,EACPL,EAAQzG,EAAMI,MAAM,GAC1B0G,EAAM,YAAQA,EAAK,CAACL,EAAOK,EAAI1G,MAAM,GAAKqG,EAAOK,EAAI1G,MAAM,KAC3DiO,EAAKC,UAET,OAAOxH,M,iCCzEX,4DA0CO,SAASyH,EAASzC,EAAQ1L,EAAOgG,GAEpC,GADA,YAAc0F,GACD,MAAT1L,GAAkC,IAAjBA,EAAMC,OACvB,MAAM,IAAI4E,MAAM,mDAEpB,MAAM8G,EAAgB,YAAWD,EAAQ1F,GACzC,GAA6B,IAAzB2F,EAAc1L,QAAyC,IAAzB0L,EAAc1L,OAC5C,MAAM,IAAI4E,MAAM,oEAEpB,GAA6B,IAAzB8G,EAAc1L,QAAyB,MAATD,EAC9B,MAAM,IAAI6E,MAAM,2EAGpB,OAAO,YAAW6G,EAAQ1L,EAAO2L,EAAe3F,K,iCCvDpD,+EAqBO,MAAMoI,EAAwB,GAC9B,SAASC,EAAyBC,GACrC,OAAIA,GAAUF,EACHE,EAEJ,YAAeA,EAAQ3N,KAAKiG,MAAMjG,KAAK4N,KAAKD,O,iCC1BvD,kEAqCO,MAAME,EAAM,YAAG,CAAEC,KALxB,SAAc7K,GACV,MACM6B,EAAS,CAAE7B,EADN,YAAgBA,EAAG,IAAK,QAEnC,OAAO,IAAO8B,UAAU,KAAKD,O,iCCnCjC,kEAqCO,MAAMiJ,EAAO,YAAG,CAAEC,MALzB,SAAe/K,GACX,MACM6B,EAAS,CAAE7B,EADN,YAAgBA,EAAG,IAAK,SAEnC,OAAO,IAAO8B,UAAU,KAAMD,O,iCCnClC,kEAsCO,MAAMmJ,EAAQ,YAAG,CAAEC,OAL1B,SAAgBjL,GACZ,MACM6B,EAAS,CAAE7B,EADN,YAAgBA,EAAG,IAAK,UAEnC,OAAO,IAAO8B,UAAU,KAAOD,O,iCCpCnC,kEAqCO,MAAMqJ,EAAW,YAAG,CAAEC,UAL7B,SAAmBnL,GACf,MACM6B,EAAS,CAAE7B,EADN,YAAgBA,EAAG,IAAK,aAEnC,OAAO,IAAO8B,UAAU,KAAUD,O,iCCnCtC,kEAgDO,MAAMuJ,EAAS,YAAG,CAAEC,QAT3B,SAAiBlD,EAASmD,EAAOC,EAAU,EAAGC,EAAW,GACrD,GAAIF,EAAQ,EACR,MAAM,IAAIrK,MAAM,iDAAiDqK,KAErE,MACMzJ,EAAS,CAAEsG,QADA,YAAgBA,EAAS,UAAW,SAAU,UAEzDzD,EAAQ,CAAE4G,QAAOC,UAASC,YAChC,OAAO,IAAO1J,UAAU,KAAQD,EAAQ6C,O,iCC9C5C,4GAgIO,MAAM+G,EAAO,YAAG,CAAEC,MA7EzB,SAAe1P,EAAO2P,EAAaC,EAAajH,EAAKkH,EAAW/O,GAC3C,MAAb+O,IACAA,EAAY,CAAC,EAAG,IAEL,MAAX/O,IACAA,EAAU,GAEF,IAAR6H,IACAA,EAAM,SAEV,MAAM1C,EAAK,YAAgBjG,EAAO,IAAK,WACvC,IAAI8P,EAAM7J,EACN8J,GAAe,EACH,IAAZ9J,EAAGuB,OACHuI,GAAe,EACfD,EAAM,YAAQ7J,EAAI,CAAC,EAAGA,EAAG7F,MAAM,GAAI6F,EAAG7F,MAAM,GAAI6F,EAAG7F,MAAM,MAE7D,IAAY,IAAyCU,EAAS+O,IAAY,IACtE,qEAAe/O,oBAA0B+O,OAC7C,MAAMG,EAAW,IAA4BF,EAAI1P,MAAOuP,EAAa7O,EAAS+O,EAAWlH,GACnFsH,EAAW,CAACD,EAASE,eAAgBF,EAASG,eAKpD,IAAIC,EAEAA,EADQ,SAARzH,EAoCR,SAAsC0H,EAAaJ,GAG/C,MAGMK,EAHqBD,EAAY5L,KAAI,CAAC8L,EAAGjQ,IACpCiQ,GAAKA,EAAI,IAAMN,EAAS3P,GAAK,KAECmE,KAAI8L,GAAKA,EAAI,IAGhDC,EAAgBF,EAAc7L,KAAI8L,GAAKxP,KAAKiG,MAAMuJ,EAAI,KACtDE,EAAcH,EAAc7L,KAAI,CAAC8L,EAAGjQ,IAAMiQ,EAAIC,EAAclQ,KAClE,OAAOgQ,EAAc7L,KAAI,CAACc,EAAGjF,IAClB,CAACkQ,EAAclQ,GAAImQ,EAAYnQ,MA/CxBoQ,CAA6B,CAACV,EAASW,aAAcX,EAASY,aAAcX,GAG5E,CAAC,CAAC,EAAG,GAAI,CAAC,EAAG,IAE/B,MAAMY,EAAgC,IAAhBZ,EAAS,IAA4B,IAAhBA,EAAS,IAC7Ca,EAAiBC,GAgB5B,SAAsC3P,EAAY4P,EAAYZ,GAC1D,MAAMa,EAAWb,EAAY3L,KAAIyE,GAAKA,EAAE,KAClCgI,EAAad,EAAY3L,KAAIyE,GAAKA,EAAE,KACpCiI,EAAiB/P,EAAWiD,OAAO4M,EAAUC,GAC7CE,EAAcJ,EAAWvM,KAAI,CAACyE,EAAG5I,KAAO4I,EAAIiI,EAAe7Q,GAAK4I,GAAKA,IACrEe,EAASiH,EAAWzM,KAAI,CAAC8L,EAAGjQ,IAAMiQ,EAAIa,EAAY9Q,KAClDuI,EAAWmI,EAAWvM,KAAI,CAACc,EAAGjF,IAAM,CAAC2Q,EAAS3Q,GAAI2J,EAAO3J,MACzD+Q,EAAQL,EAAWvM,KAAI,CAACc,EAAGjF,IAAM,CAAC,EAAG8Q,EAAY9Q,MACvD,MAAO,CAACuI,EAAUwI,GAxBuBC,CAA6B,CAACtB,EAASuB,SAAUvB,EAASwB,SAAUvB,EAAUG,GACjHqB,EAAeZ,EAAgBlI,EAAM,QACrC+I,EAAab,EAAgBf,EAAM,YAAeA,EAAKG,EAAUa,GAIjEa,GAH4B,QAAhB/B,EACd,IAAM,YAAQ8B,EAAY/B,EAAa7O,EAAS2Q,GAChD,IAAM,YAAQC,EAAY/B,EAAa7O,EAAS2Q,MAE9CG,EAAMf,EAAgBc,EAAI,YAAeA,EAAG1B,EAAUc,GAC5D,OAAIhB,EACO,YAAQ6B,EAAK,CAACA,EAAIxR,MAAM,GAAIwR,EAAIxR,MAAM,GAAIwR,EAAIxR,MAAM,KAExDwR,M,iCC/FX,0EA6DO,MAAMC,EAAO,YAAG,CAAEC,MAVzB,SAAe9N,EAAGtD,EAAO,KAAMoH,GAAW,GACtC,IAAI7B,EAAK,YAAgBjC,EAAG,IAAK,QAChB,SAAbiC,EAAGG,QAEHH,EAAK,YAAKA,EAAI,UAElB,MAAMJ,EAAS,CAAE7B,EAAGiC,GACdyC,EAAQ,CAAEhI,OAAMoH,YACtB,OAAO,IAAOhC,UAAU,KAAMD,EAAQ6C,O,iCC3D1C,kEAuCO,MAAMqJ,EAAO,YAAG,CAAEC,MALzB,SAAehO,GACX,MACM6B,EAAS,CAAE7B,EADN,YAAgBA,EAAG,IAAK,SAEnC,OAAO,IAAO8B,UAAU,KAAMD,O,iCCrClC,kFAwFO,MAAMoM,EAAkB,YAAG,CAAEC,iBArCpC,SAA0BlO,EAAGmO,EAAiBC,EAAiBtR,EAAS6H,EAAKsH,EAAW,CAAC,EAAG,GAAIoC,EAAa,QACzG,MAAMpM,EAAK,YAAgBjC,EAAG,IAAK,mBAC7BsO,EAAmB,YAAgBH,EAAiB,kBAAmB,mBACvEI,EAAmB,YAAgBH,EAAiB,kBAAmB,mBAC7E,IAAItC,EAAM7J,EACN8J,GAAe,EAKnB,GAJgB,IAAZ9J,EAAGuB,OACHuI,GAAe,EACfD,EAAM,YAAQ7J,EAAI,CAAC,EAAGA,EAAG7F,MAAM,GAAI6F,EAAG7F,MAAM,GAAI6F,EAAG7F,MAAM,MAE1C,SAAfiS,EACA,MAAM,IAAIpN,MAAM,sFAGpB,IAAyB,IAAb6K,EAAItI,MAAY,IACxB,gEAAQsI,EAAItI,UAChB,IAAsC,IAA1B8K,EAAiB9K,MAAY,IACrC,2EAAY8K,EAAiB9K,UACjC,IAAsC,IAA1B+K,EAAiB/K,MAAY,IACrC,2EAAY8K,EAAiB9K,UACjC,IAA0C,IAA9B+K,EAAiBnS,MAAM,IAAU,IACzC,yFAAuBmS,EAAiBnS,MAAM,QAClD,IAA0C,IAA9BmS,EAAiBnS,MAAM,IAAU,IACzC,yFAA6BmS,EAAiBnS,MAAM,QACxD,MAAMoS,EAAaF,EAAiBlS,MAAM,GACpCqS,EAAoBH,EAAiBlS,MAAM,GACjD,IAAYmS,EAAiBnS,MAAM,KAAOoS,EAAaC,GAAmB,IACtE,6EAAWD,EAAaC,cACbF,EAAiBnS,MAAM,QACtC,MAAMsS,EAAY,YAAgB5C,EAAKwC,EAAkBxR,EAAS6H,EAAK0J,EAAYpC,GAE7E2B,EAAM,YAAOc,EAAWH,EADN,EACyC,QAASF,GAC1E,OAAItC,EACO,YAAQ6B,EAAK,CAACA,EAAIxR,MAAM,GAAIwR,EAAIxR,MAAM,GAAIwR,EAAIxR,MAAM,KAExDwR,M,iCCtFX,kEA2DO,MAAMe,EAAO,YAAG,CAAEC,MAfzB,SAAe5O,EAAG6O,EAAI,EAAGC,GAAS,GAC9B,MAAM7M,EAAK,YAAgBjC,EAAG,IAAK,QACnC,GAAgB,IAAZiC,EAAGuB,KACH,MAAM,IAAIvC,MAAM,sDAEpB,MAAM8N,EAAU9M,EAAG7F,MAAM6F,EAAG7F,MAAMC,OAAS,GAC3C,GAAIwS,EAAIE,EACJ,MAAM,IAAI9N,MAAM,uDAAuD8N,cACxDF,KAEnB,MAAMhN,EAAS,CAAE7B,EAAGiC,GACdyC,EAAQ,CAAEmK,IAAGC,WACZhH,EAAQK,GAAW,IAAOrG,UAAU,KAAMD,EAAQ6C,GACzD,MAAO,CAAEoD,SAAQK,e,iCCzDrB,yEA8EO,MAAM6G,EAAS,YAAG,CAAEC,QAR3B,SAAiBjP,EAAGtD,EAAO,GACvB,MAAMuF,EAAK,YAAgBjC,EAAG,IAAK,SAAU,qBAC7C,YAAOiC,EAAGuB,KAAO,GAAG,IAAM,yCAC1B,MAAM3B,EAAS,CAAE7B,EAAGiC,GACdyC,EAAQ,CAAEhI,SACToL,EAAQK,GAAW,IAAOrG,UAAU,KAAQD,EAAQ6C,GAC3D,MAAO,CAAEoD,SAAQK,e,gCC5ErB,kEAsCO,MAAM+G,EAAY,YAAG,CAAEC,WAL9B,SAAoBnP,GAChB,MACM6B,EAAS,CAAE7B,EADN,YAAgBA,EAAG,IAAK,cAEnC,OAAO,IAAO8B,UAAU,KAAWD,O,gCCpCvC,2DAoCO,MAAMuN,EAAS,YAAG,CAAEC,QAL3B,SAAiBrP,GACb,MAAMiC,EAAK,YAAgBjC,EAAG,IAAK,UAEnC,OAAO,IAAO8B,UAAU,SAAU,CAAE9B,EAAGiC,GADzB,Q,gCCjClB,kEA+DO,MAAM3B,EAAQ,YAAG,CAAEgP,OAT1B,SAAgBtP,EAAG/D,EAAOC,GACtB,MAAM+F,EAAK,YAAgBjC,EAAG,IAAK,QAAS,qBAC5C,GAAgB,IAAZiC,EAAGuB,KACH,MAAM,IAAIvC,MAAM,kCAEpB,MAAMY,EAAS,CAAE7B,EAAGiC,GACdyC,EAAQ,CAAEzI,QAAOC,QACvB,OAAO,IAAO4F,UAAU,KAAOD,EAAQ6C,O,iCC5CpC,SAAS6K,EAAeC,EAAQC,EAAaC,GAGhD,MAAO,CAFSA,GAAgC,iBAAXF,EAAsBA,EAASA,EAAO,IAC3DC,GAAiC,iBAAXD,EAAsBA,EAASA,EAAO,KAnBhF,mC,iCCAA,6CAMO,SAASG,EAAiB3P,EAAG4P,EAAiBlT,EAAO,GACxD,IAAImT,EAAa,GACjB,GAAiC,iBAAtB,EACP,YAAO7P,EAAE5D,MAAMM,GAAQkT,GAAoB,GAAG,IAAM,kDACpDC,EACI,IAAI1R,MAAMyR,GAAiBxP,KAAKJ,EAAE5D,MAAMM,GAAQkT,OAEnD,CACD,MAAME,EAAYF,EAAgBG,QAAO,CAACC,EAAOvJ,MAC9B,IAAXA,IACAuJ,GAAS,GAENA,IACR,GACH,YAAOF,GAAa,GAAG,IAAM,4DAC7B,MAAMG,EAAWL,EAAgB9Q,SAAS,GAG1C,IAAkB,IAAdmR,EAAiB,CACjB,MAAMC,EAAQN,EAAgBG,QAAO,CAAC9K,EAAGC,IAAMA,EAAI,EAAID,EAAIC,EAAID,IAC/D2K,EAAgBK,GAAYjQ,EAAE5D,MAAMM,GAAQwT,EAEhD,YAAOlQ,EAAE5D,MAAMM,KAAUkT,EAAgBG,QAAO,CAAC9K,EAAGC,IAAMD,EAAIC,KAAI,IAAM,gEACxE2K,EAAaD,EAEjB,OAAOC,I,iCC/BX,kMAkBO,SAASM,EAA8BzF,EAAQlG,GAClD,IACIoJ,EADAwC,GAAO,EASX,IAPI1F,GAAU,KACVkD,EAAMlD,EACN0F,GAAO,GAGPxC,EAAM,YAAelD,EAAQ3N,KAAKiG,MAAMjG,KAAK4N,KAAKD,MAE9C0F,GACAxC,EAAMpJ,GAAeoJ,IAAQlD,EAC7B0F,GAAO,EAGPxC,EAAM,YAAelD,EAAQkD,EAAM,GAG3C,OAAOA,EAEJ,SAAShR,EAAgByT,EAAQ3T,EAAM8H,GAC1C,MAAMnD,EAAW,GACXmC,EAAO6M,EAAOhU,OACpB,IAAK,IAAIiU,EAAM,EAAGA,EAAM9M,EAAM8M,IACtBA,IAAQ5T,EACR2E,EAAS1E,KAAK0T,EAAOC,IAGrBjP,EAAS1E,KAAK6H,GAGtB,OAAOnD,EAEJ,SAASkP,EAAyBvQ,EAAGmI,EAASzL,EAAM8T,GACvD,MAAM9H,EAAcP,EAAQ/L,MAAMC,OAC5B6D,EAAQF,EAAE5D,MAAMC,OACtB,GAAkB,IAAdmU,IACIA,GAAa9H,GAAe8H,EAAY9H,GACxC,MAAM,IAAIzH,MAAM,sCAAsCyH,MAAgBA,eAAyB8H,KAMvG,GAHIA,EAAY,IACZA,GAAa9H,GAEb8H,EAAYtQ,EACZ,MAAM,IAAIe,MAAM,cAAcuP,uCAChCtQ,OAEF,GAAIxD,EAAO8T,EACP,MAAM,IAAIvP,MAAM,cAAcuP,0CAAkD9T,OAEpF,IAAK,IAAIJ,EAAI,EAAGA,EAAIkU,IAAalU,EAC7B,GAAI0D,EAAE5D,MAAME,KAAO6L,EAAQ/L,MAAME,GAC7B,MAAM,IAAI2E,MAAM,WAAW3E,OAAO0D,EAAE5D,MAAME,uCAAuCA,OAAO6L,EAAQ/L,MAAME,OAG9G,MAAMmU,EAAUzQ,EAAE5D,MAAMM,GAClB2G,EAAc,GACpB,IAAIqN,EAAY,EACZC,EAAY,EACZ9H,EAAY,EAChB,IAAK,IAAIvM,EAAI,EAAGA,EAAIkU,IAAalU,EAC7B+G,EAAY1G,KAAKqD,EAAE5D,MAAME,IACzBoU,GAAa1Q,EAAE5D,MAAME,GAEzB,IAAK,IAAIA,EAAIkU,EAAWlU,EAAII,EAAMJ,IAC9B+G,EAAY1G,KAAKqD,EAAE5D,MAAME,IACzBqU,GAAa3Q,EAAE5D,MAAME,GAEzB,IAAK,IAAIA,EAAIkU,EAAWlU,EAAIoM,EAAapM,IACrC+G,EAAY1G,KAAKwL,EAAQ/L,MAAME,IAEnC,IAAK,IAAIA,EAAII,EAAO,EAAGJ,EAAI4D,EAAO5D,IAC9B+G,EAAY1G,KAAKqD,EAAE5D,MAAME,IACzBuM,GAAa7I,EAAE5D,MAAME,GAEzB,MAAO,CAAEoU,YAAW7H,YAAW8H,YAAWF,UAASpN,iB,iCC9FvD,kEAqCO,MAAMuN,EAAW,YAAG,CAAEC,UAL7B,SAAmB7Q,GACf,MACM6B,EAAS,CAAE7B,EADN,YAAgBA,EAAG,IAAK,aAEnC,OAAO,IAAO8B,UAAU,KAAUD,O,iCCnCtC,kEAqCO,MAAMiP,EAAa,YAAG,CAAEC,YAL/B,SAAqB/Q,GACjB,MACM6B,EAAS,CAAE7B,EADN,YAAgBA,EAAG,IAAK,eAEnC,OAAO,IAAO8B,UAAU,KAAYD,O,+BCnCxC,oDAwBO,SAASmP,EAAGC,GACf,MAAMC,EAAOC,OAAOD,KAAKD,GACzB,GAAoB,IAAhBC,EAAK7U,OACL,MAAM,IAAI4E,MAEN,yGAAGiQ,EAAK7U,gBAEhB,IAAI+U,EAASF,EAAK,GAClB,MAAMG,EAAKJ,EAAEG,GAETA,EAAOE,SAAS,OAChBF,EAASA,EAAOG,UAAU,EAAGH,EAAO/U,OAAS,IAGjD+U,GApB2B,OAsB3B,MAAMI,EAAK,IAAIC,KACX,IAAOC,WAAWN,GAClB,IACI,MAAMO,EAASN,KAAMI,GAKrB,OAJI,YAAUE,IACV9H,QAAQ+H,MAAM,2CAElB,IAAOC,SAASF,GACTA,EAEX,MAAOG,GAEH,MADA,IAAOD,SAAS,MACVC,IAKd,OAFAX,OAAOY,eAAeP,EAAI,OAAQ,CAAE/K,MAAO2K,EAAQY,cAAc,IAE1DR,I,iCCzDX,kEAsCO,MAAMS,EAAQ,YAAG,CAAEC,OAL1B,SAAgBlS,GACZ,MACM6B,EAAS,CAAE7B,EADN,YAAgBA,EAAG,IAAK,UAEnC,OAAO,IAAO8B,UAAU,KAAOD,O,iCCpCnC,kEAqCO,MAAMsQ,EAAO,YAAG,CAAEC,MALzB,SAAepS,GACX,MACM6B,EAAS,CAAE7B,EADN,YAAgBA,EAAG,IAAK,SAEnC,OAAO,IAAO8B,UAAU,KAAMD,O,iCCnClC,kEAsDO,MAAMwQ,EAAU,YAAG,CAAEC,SAb5B,SAAkBC,EAAQjC,GAAM,GAC5B,MAAMkC,EAAU,YAAgBD,EAAQ,SAAU,UAAW,WAI7D,IAHa,IAATjC,IACAA,EAAMkC,EAAQhP,KAAO,GAErB8M,IAAQkC,EAAQhP,KAAO,EACvB,MAAMvC,MACF,4EAAmBuR,EAAQhP,oBAAoB8M,KAEvD,MAAMzO,EAAS,CAAE0Q,OAAQC,GACnB9N,EAAQ,CAAE4L,OAChB,OAAO,IAAOxO,UAAU,KAASD,EAAQ6C,O,iCCpD7C,kEAoEO,MAAM+N,EAAe,YAAG,CAAEC,cAfjC,SAAuB1S,EAAG/D,EAAOY,EAAKC,EAASiB,EAAY,EAAGC,EAAU,EAAGC,EAAe,EAAG2C,EAAc,EAAGC,EAAiB,GAC3H,MACMgB,EAAS,CAAE7B,EADN,YAAgBA,EAAG,IAAK,iBAE7B0E,EAAQ,CACVzI,QACAY,MACAC,UACAiB,YACAC,UACAC,eACA2C,cACAC,kBAEJ,OAAO,IAAOiB,UAAU,KAAcD,EAAQ6C,O,iCClElD,kEAqCO,MAAMiO,EAAM,YAAG,CAAEC,KALxB,SAAc5S,GACV,MACM6B,EAAS,CAAE7B,EADN,YAAgBA,EAAG,IAAK,QAEnC,OAAO,IAAO8B,UAAU,KAAKD,O,iCCnCjC,kEAqCO,MAAMgR,EAAO,YAAG,CAAEC,MALzB,SAAe9S,GACX,MACM6B,EAAS,CAAE7B,EADN,YAAgBA,EAAG,IAAK,SAEnC,OAAO,IAAO8B,UAAU,KAAMD,O,gCCnClC,yFAwEO,MAAMkR,EAAQ,YAAG,CAAEC,OA1B1B,SAAgBC,EAAWhO,EAAGC,GAC1B,MAAMqE,EAAK,YAAgBtE,EAAG,IAAK,SAC7BuE,EAAK,YAAgBtE,EAAG,IAAK,SAC7BgO,EAAa,YAAgBD,EAAW,YAAa,QAAS,QAI9DE,EAAiB,YAA2B5J,EAAGnN,MAAOoN,EAAGpN,OACzDgX,EAAgB,YAAY7J,EAAI4J,GAChCE,EAAgB,YAAY7J,EAAI2J,GACd,IAApBD,EAAW1P,MAGX,YAAO0P,EAAW9W,MAAM,KAAOmN,EAAGnN,MAAM,IAAI,IAAM,mEAE9B,IAApB8W,EAAW1P,MAEX,YAAkB0P,EAAW9W,MAAOiX,EAAcjX,MAAO,oBAE7D,MAAMyF,EAAS,CACXoR,UAAWC,EACXI,EAAGF,EACHG,EAAGF,GAEP,OAAO,IAAOvR,UAAU,KAAQD,O,gCCtEpC,kEAqCO,MAAM8I,EAAO,YAAG,CAAE6I,MALzB,SAAexT,GACX,MACM6B,EAAS,CAAE7B,EADN,YAAgBA,EAAG,IAAK,SAEnC,OAAO,IAAO8B,UAAU,KAAMD,O,gCCnClC,yEA0DO,MAAM4R,EAAY,YAAG,CAAEC,WAlB9B,SAAoB1T,EAAG2T,GACnB,MAAM1R,EAAK,YAAgBjC,EAAG,IAAK,aAUnC,GATY,MAAR2T,IACAA,EAAO1R,EAAG7F,MAAMqE,KAAI,CAAC8L,EAAGjQ,IAAMA,IAAGsX,WAErC,IAAY3R,EAAGuB,OAASmQ,EAAKtX,QAAQ,IAAM,qCAAqC4F,EAAGuB,kCAClDmQ,OACjCA,EAAKpT,SAAQ7D,IACT,IAAYA,GAAQ,GAAKA,EAAOuF,EAAGuB,MAAM,IAAM,gDAA+CvB,EAAGuB,KAAO,GACpG,YAAYmQ,SAEhB1R,EAAGuB,MAAQ,EACX,OAAOvB,EAAG4R,QAEd,MAAMhS,EAAS,CAAE7B,EAAGiC,GACdyC,EAAQ,CAAEiP,QAChB,OAAO,IAAO7R,UAAU,KAAWD,EAAQ6C,O,iCCxD/C,6CAqBO,MAAMoP,EACT,MAAMC,EAAMC,GACR,OAAOC,MAAMF,EAAMC,GAEvB,MACI,OAAOE,YAAYC,MAEvB,OAAOC,EAAMC,GACT,GAAiB,UAAbA,GAAqC,SAAbA,EACxB,MAAM,IAAIpT,MAAM,kDAAkDoT,KAKtE,OAHwB,MAApBC,KAAKC,cACLD,KAAKC,YAAc,IAAIC,aAEpBF,KAAKC,YAAYE,OAAOL,GAEnC,OAAOM,EAAOL,GACV,OAAO,IAAIM,YAAYN,GAAUO,OAAOF,IAGhD,GAAI,cAAMG,IAAI,cAAe,CACzB,cAAMC,YAAY,UAAW,IAAIhB,GAEjC,IACI,IAA0BiB,gBAAgB,IAAoBC,WAAY,IAAI,KAElF,MAAOC,IAGP,IACI,IAA0BF,gBAAgB,IAAiBC,WAAY,IAAI,KAE/E,MAAOC,O,kCCrDX,wBAkBO,MAAMC,EAEI,IAAM,EAAQ,KAE/B,IAAIC,EAYG,MAAMC,EACT,cAEId,KAAKe,KAAO,EAAQ,KAGpBf,KAAKC,YAAc,IAAID,KAAKe,KAAKb,YAErC,MAAMT,EAAMuB,GACR,OAA0B,MAAtB,cAAMC,OAAOtB,MACN,cAAMsB,OAAOtB,MAAMF,EAAMuB,IAEjB,MAAfH,IACAA,EAAcD,KAEXC,EAAYpB,EAAMuB,IAE7B,MACI,MAAME,EAAOC,EAAQC,SACrB,OAAiB,IAAVF,EAAK,GAAYA,EAAK,GAAK,IAEtC,OAAOpB,EAAMC,GACT,GAAiB,UAAbA,GAAqC,SAAbA,EACxB,MAAM,IAAIpT,MAAM,sDAAsDoT,KAE1E,OAAOC,KAAKC,YAAYE,OAAOL,GAEnC,OAAOM,EAAOL,GACV,OAAqB,IAAjBK,EAAMrY,OACC,GAEJ,IAAIiY,KAAKe,KAAKV,YAAYN,GAAUO,OAAOF,IAGtD,cAAMG,IAAI,YACV,cAAMC,YAAY,OAAQ,IAAIM,K,mDCrElC,yEA8CO,MAAMO,EAAQ,YAAG,CAAEC,OAV1B,SAAgBC,EAASnZ,EAAO,GAC5B,MAAMoZ,EAAW,YAAqBD,EAAS,UAAW,QAAS,qBACnE,IAAYC,EAASzZ,QAAU,GAAG,IAAM,yCACpCyZ,EAASzZ,OAAS,GAClB,IAAYK,GAAQoZ,EAAS,GAAGtS,MAAM,IAAM,uCAEhD,MAAM3B,EAASiU,EACTpR,EAAQ,CAAEhI,QAChB,OAAO,IAAOoF,UAAU,KAAMD,EAAQ6C,O,gCC5C1C,4DAgCO,SAASqR,EAAM3Z,EAAOgG,EAAQ,WACjC,GAAc,cAAVA,EAAuB,CACvB,MAAM4T,EAAOD,EAAM3Z,EAAO,WACpB6Z,EAAOF,EAAM3Z,EAAO,WAC1B,OAAO,YAAQ4Z,EAAMC,GAEzB,MAAMnO,EAAS,YAAoB,YAAc1L,GAAQgG,GACzD,OAAO,IAAO8T,WAAWpO,EAAQ1L,EAAOgG,K,gCCvC5C,0EAwDO,MAAMsE,EAAM,YAAG,CAAEyP,KAPxB,SAAcC,EAAMC,GAChB,IAAIC,EAAQ,YAAgBF,EAAM,OAAQ,OACtCG,EAAO,YAAgBF,EAAK,MAAO,QACtCC,EAAOC,GAAQ,YAAeD,EAAOC,GACtC,MAAM1U,EAAS,CAAEoD,EAAGqR,EAAOpR,EAAGqR,GAC9B,OAAO,IAAOzU,UAAU,KAAKD,O,gCCtDjC,6CAiBA,SAAS2U,EAAsBC,EAAOC,EAAQC,EAAeC,EAAcC,EAAgBC,GACnE,MAAhBF,IACAA,EAAe,IAEG,MAAlBC,IACAA,EAAiB3X,OAAO6X,mBAER,MAAhBD,IACAA,EAAe,GAEnB,MAAME,EAAWP,EAAMra,MAAM,GAS7B,OARAua,EAAgB5Z,KAAKka,IAAIN,EAAeK,GACxC,IAAY,GAAKJ,GAAgBA,GAAgB,GAAG,IAAM,4CAA4CA,OACtG,IAA2B,IAAfH,EAAMjT,MAAY,IAAM,+CAA+CiT,EAAMjT,UACzF,IAA+B,IAAnBiT,EAAMra,MAAM,IAAU,IAAM,oDAAoDqa,EAAMra,MAAM,OACxG,IAA4B,IAAhBsa,EAAOlT,MAAY,IAAM,+BACrC,IAAYkT,EAAOta,MAAM,KAAO4a,GAAU,IAAM,sDAAsDA,cACvFN,EAAOta,MAAM,OAC5B,IAAY,GAAK0a,GAAgBA,GAAgB,GAAG,IAAM,4CAA4CA,OAC/F,CAAEH,gBAAeC,eAAcC,iBAAgBC,kB,gCCpC1D,4DAmCO,SAASrR,EAASqC,EAAQ1F,GAC7B,YAAc0F,GACd,MAAMC,EAAgB,YAAWD,EAAQ1F,GACzC,GAA6B,IAAzB2F,EAAc1L,OACd,MAAM,IAAI4E,MAAM,sDAGpB,OAAO,YAAW6G,EADJ,KACmBC,EAAe3F,K,gCC1CpD,kEA6DO,MAAM8U,EAAQ,YAAG,CAAEC,OAN1B,SAAgBnX,EAAG4P,EAAiBlT,EAAO,GACvC,MACMmF,EAAS,CAAE7B,EADN,YAAgBA,EAAG,IAAK,UAE7BoX,EAAO,CAAExH,kBAAiBlT,QAChC,OAAO,IAAOoF,UAAU,KAAQD,EAAQuV,O,gCC3D5C,yEA0CO,MAAMC,EAAU,YAAG,CAAEC,SAP5B,SAAkBtX,EAAGtD,EAAO,GACxB,MAAMuF,EAAK,YAAgBjC,EAAG,IAAK,UAAW,qBAC9C,IAAYtD,IAASuF,EAAG7F,MAAMC,QAAUK,EAAOuF,EAAG7F,MAAMC,QAAQ,IAAM,UAAUK,iBAAoBuF,EAAG7F,MAAMC,WAAW4F,EAAG7F,MAAMC,YACjI,MAAMwF,EAAS,CAAE4E,MAAOxE,GAClByC,EAAQ,CAAEhI,QAChB,OAAO,IAAOoF,UAAU,KAAQD,EAAQ6C,O,gCCxC5C,oEAiCO,SAAS6S,EAAKnb,EAAOgG,EAAQ,WAChC,GAAc,cAAVA,EAAuB,CACvB,MAAM4T,EAAOuB,EAAKnb,EAAO,WACnB6Z,EAAO,YAAM7Z,EAAO,WAC1B,OAAO,YAAQ4Z,EAAMC,GAEzB,MAAMnO,EAAS,YAAmB,YAAc1L,GAAQgG,GACxD,OAAO,IAAO8T,WAAWpO,EAAQ1L,EAAOgG,K,gCCxC5C,kEAsCO,MAAMoV,EAAO,YAAG,CAAEC,MALzB,SAAezX,GACX,MACM6B,EAAS,CAAE7B,EADN,YAAgBA,EAAG,IAAK,SAEnC,OAAO,IAAO8B,UAAU,KAAMD,O,gCCpClC,kEAuCO,MAAMqH,EAAO,YAAG,CAAEwO,MANzB,SAAe1X,EAAGoE,EAAQ,GACtB,MACMvC,EAAS,CAAE7B,EADN,YAAgBA,EAAG,IAAK,SAE7B0E,EAAQ,CAAEN,SAChB,OAAO,IAAOtC,UAAU,KAAMD,EAAQ6C,O,gCCrC1C,4DAmBO,SAASwR,EAAWpO,EAAQ1L,EAAO2L,EAAe3F,GAIrD,GAHa,MAATA,IACAA,EAAQ,YAAW0F,IAET,cAAV1F,EACA,MAAM,IAAInB,MAAM,oFAGpB,IAAK,YAAa6G,KAAY3J,MAAMsF,QAAQqE,IACtB,iBAAXA,GAAyC,kBAAXA,GACnB,iBAAXA,EACP,MAAM,IAAI7G,MAAM,4HAGpB,GAAa,MAAT7E,EAAe,CACf,YAAmCA,GACnC,MAAMub,EAAe,YAAcvb,GAC7Bwb,EAAe,YAAc7P,GACnC,YAAO4P,IAAiBC,GAAc,IAAM,iCAAiCxb,8BACtEub,oBAA+BC,MACtC,IAAK,IAAItb,EAAI,EAAGA,EAAIyL,EAAc1L,SAAUC,EAAG,CAC3C,MAAMub,EAAW9P,EAAczL,GACzBwb,EAAoBxb,IAAMyL,EAAc1L,OAAS,GACnDwb,IAAa,YAAczb,EAAMkE,MAAMhE,IAE3C,YAAOyL,EAAczL,KAAOF,EAAME,KAAOwb,GAAmB,IACxD,gDAAI/P,yCACM3L,UAUtB,OAPK,YAAa0L,IAAY3J,MAAMsF,QAAQqE,KACxCA,EAAS,CAACA,IAEd1L,EAAQA,GAAS2L,EACjBD,EAAmB,WAAV1F,EACL,uBAAa0F,EAAQ1F,GACrB,YAAQ0F,EAAQ,IAAI,GACjB,IAAOoO,WAAWpO,EAAQ1L,EAAOgG,K,gCCxD5C,yEAsDO,MAAM2V,EAAO,YAAG,CAAEC,MARzB,SAAehY,EAAGiY,GACd,MAAMhW,EAAK,YAAgBjC,EAAG,IAAK,OAAQ,qBAC3C,IAAYiC,EAAGuB,OAASyU,EAAK5b,QAAQ,IAAM,qCAAqC4F,EAAGuB,kCAClDyU,OACjC,MAAMpW,EAAS,CAAE7B,EAAGiC,GACdyC,EAAQ,CAAEuT,QAChB,OAAO,IAAOnW,UAAU,KAAMD,EAAQ6C,O,+BCpD1C,kEAoDO,MAAM4B,EAAU,YAAG,CAAE4R,SAN5B,SAAkBlY,EAAG5D,GACjB,MACMyF,EAAS,CAAE7B,EADN,YAAgBA,EAAG,IAAK,UAAW,sBAExC0E,EAAQ,CAAEtI,SAChB,OAAO,IAAO0F,UAAU,KAASD,EAAQ6C,O,gCClD7C,kEAyDO,MAAMkP,EAAU,YAAG,CAAEuE,SAN5B,SAAkBnY,EAAGtD,GACjB,MACMmF,EAAS,CAAE7B,EADN,YAAgBA,EAAG,IAAK,YAE7B0E,EAAQ,CAAE0T,KAAM1b,GACtB,OAAO,IAAOoF,UAAU,KAASD,EAAQ6C,O,gCCvD7C,kFA4CO,MAAM2T,EAAW,YAAG,CAAEC,UAR7B,SAAmBrT,EAAGC,GAClB,IAAIqE,EAAK,YAAgBtE,EAAG,IAAK,YAC7BuE,EAAK,YAAgBtE,EAAG,IAAK,aAChCqE,EAAIC,GAAM,YAAeD,EAAIC,GAC9B,YAA2BD,EAAGnN,MAAOoN,EAAGpN,OACxC,MAAMyF,EAAS,CAAEoD,EAAGsE,EAAIrE,EAAGsE,GAC3B,OAAO,IAAO1H,UAAU,KAAUD,O,gCC1CtC,kFAuDO,MAAM0W,EAAoB,YAAG,CAAEC,mBATtC,SAA4BvT,EAAGC,GAC3B,IAAIqE,EAAK,YAAgBtE,EAAG,IAAK,qBAC7BuE,EAAK,YAAgBtE,EAAG,IAAK,sBAChCqE,EAAIC,GAAM,YAAeD,EAAIC,GAC9B,YAA2BD,EAAGnN,MAAOoN,EAAGpN,OACxC,MAAMyF,EAAS,CAAEoD,EAAGsE,EAAIrE,EAAGsE,GAE3B,OAAO,IAAO1H,UAAU,KAAmBD,EAD7B,Q,gCCpDlB,yEAsFO,MAAM4W,EAAiB,YAAG,CAAEC,gBAjBnC,SAAyB1Y,EAAGgN,EAAYnI,GACpC,MAAM5C,EAAK,YAAgBjC,EAAG,IAAK,kBACnC,IAAYiC,EAAGuB,MAAQ,EAAIwJ,EAAW3Q,QAAQ,IAAM,cAAc4F,EAAGuB,sCAAsCwJ,EAAW3Q,WACtH,IAAYwI,EAASxI,SAAW2Q,EAAW3Q,QAAQ,IAAM,qBAAqBwI,EAASxI,wCAAwC2Q,EAAW3Q,WAC1I,IAAY4F,EAAG7F,MAAM2T,QAAO,CAAC9K,EAAGC,EAAG5I,IAC3BA,EAAI,GAAKA,GAAK0Q,EAAW3Q,OAClB4I,IACDC,EAAIL,EAASvI,EAAI,GAAG,GAAKuI,EAASvI,EAAI,GAAG,IACvC0Q,EAAW1Q,EAAI,IACf,EAEL2I,IACR,IAAO,IAAM,4BAA4BhD,EAAG7F,MAAMkE,MAAM,oBAAoBuE,EAASiF,+CAA+CkD,EAAWlD,eAClJ,MAAMjI,EAAS,CAAE7B,EAAGiC,GACdyC,EAAQ,CAAEsI,aAAYnI,YAC5B,OAAO,IAAO/C,UAAU,KAAgBD,EAAQ6C,O,gCCpFpD,4DA0CO,SAAS2B,EAASyB,EAAQ1L,EAAOgG,GAEpC,GADA,YAAc0F,GACD,MAAT1L,GAAkC,IAAjBA,EAAMC,OACvB,MAAM,IAAI4E,MAAM,iDAEpB,MAAM8G,EAAgB,YAAWD,EAAQ1F,GACzC,GAA6B,IAAzB2F,EAAc1L,QAAyC,IAAzB0L,EAAc1L,OAC5C,MAAM,IAAI4E,MAAM,kEAEpB,GAA6B,IAAzB8G,EAAc1L,QAAyB,MAATD,EAC9B,MAAM,IAAI6E,MAAM,gFAGpB,OAAO,YAAW6G,EAAQ1L,EAAO2L,EAAe3F,K,gCCvDpD,kEA2CO,MAAM2E,EAAO,YAAG,CAAE4R,MANzB,SAAe3c,GACX,YAAuB,cAAhBA,EAAMoG,OAAuB,IAChC,8DAAWpG,EAAMoG,WACrB,MAAMP,EAAS,CAAE7F,SACjB,OAAO,IAAO8F,UAAU,KAAMD,O,gCCzClC,kEAwCO,MAAMmU,EAAO,YAAG,CAAE4C,MALzB,SAAe5c,GACX,MACM6F,EAAS,CAAE7F,MADF,YAAgBA,EAAO,QAAS,SAE/C,OAAO,IAAO8F,UAAU,KAAMD","file":"js/bundle~bundle~58c2b9c4.fe53ec28.js","sourcesContent":["/**\n * @license\n * Copyright 2017 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport * as util from '../util';\nexport function assertParamsValid(input, begin, size) {\n    const inputRank = input.shape.length;\n    util.assert(inputRank === begin.length, () => `Error in slice${inputRank}D: Length of begin ${begin} must ` +\n        `match the rank of the array (${inputRank}).`);\n    util.assert(inputRank === size.length, () => `Error in slice${inputRank}D: Length of size ${size} must ` +\n        `match the rank of the array (${inputRank}).`);\n    for (let i = 0; i < inputRank; ++i) {\n        util.assert(begin[i] + size[i] <= input.shape[i], () => `Error in slice${inputRank}D: begin[${i}] + size[${i}] ` +\n            `(${begin[i] + size[i]}) would overflow input.shape[${i}] (${input.shape[i]})`);\n    }\n}\n/** Converts a binary mask to an array of axes. Used in stridedSlice(). */\nexport function maskToAxes(mask) {\n    const axes = [];\n    let axis = 0;\n    while (mask > 0) {\n        if (mask & 1) {\n            axes.push(axis);\n        }\n        mask /= 2;\n        axis++;\n    }\n    return axes;\n}\n/** Computes the output shape given the strided slice params. */\nexport function computeOutShape(begin, end, strides) {\n    const size = [];\n    for (let axis = 0; axis < begin.length; axis++) {\n        size[axis] = Math.ceil((end[axis] - begin[axis]) / strides[axis]);\n    }\n    return size;\n}\n// Creates full selection at the elided dimensions. If the dimension matches\n// the ellipsis mask, override the current stride value. Otherwise, insert.\nexport function stridesWithElidedDims(strides, ellipsisInsertionIndex, numElidedAxes, inputShape) {\n    const newStrides = [...strides];\n    for (let i = newStrides.length; i < inputShape.length; i++) {\n        newStrides.push(1);\n    }\n    for (let i = 0; i < numElidedAxes; i++) {\n        if (i === 0) {\n            newStrides[ellipsisInsertionIndex] = 1;\n        }\n        else {\n            newStrides.splice(ellipsisInsertionIndex, 0 /* num elements to delete */, 1 /* element to add */);\n            newStrides.pop();\n        }\n    }\n    return newStrides;\n}\nfunction unnormalizeAxis(ellipsisInsertionIndex, numElidedAxes, normalizedAxis) {\n    if (normalizedAxis <= ellipsisInsertionIndex) {\n        return normalizedAxis;\n    }\n    return normalizedAxis - (numElidedAxes - 1);\n}\nfunction getElidedAxes(numElidedAxes, ellipsisInsertionIndex) {\n    const elidedAxes = [];\n    for (let i = 0; i < numElidedAxes; i++) {\n        elidedAxes.push(ellipsisInsertionIndex + i);\n    }\n    return elidedAxes;\n}\n// Normalize the start, end and strides.\nexport function getNormalizedAxes(inputShape, ellipsisAxes, numInterpolatedAxes, begin, end, strides, beginMask, endMask, ellipsisMask) {\n    const inputRank = inputShape.length;\n    let normalizedBegin = new Array(inputRank), normalizedEnd = new Array(inputRank), normalizedStrides = new Array(inputRank);\n    if (ellipsisAxes.length && numInterpolatedAxes > 0) {\n        const fullIndex = ellipsisAxes[0];\n        // The ellipsis applies to the masked index as well as any dimensions\n        // that are interpolated.\n        const numElidedAxes = numInterpolatedAxes + 1;\n        normalizedBegin = startIndicesWithElidedDims(beginMask, fullIndex, numElidedAxes, begin, inputShape);\n        normalizedEnd = stopIndicesWithElidedDims(endMask, fullIndex, numElidedAxes, end, inputShape);\n        normalizedStrides =\n            stridesWithElidedDims(strides, fullIndex, numElidedAxes, inputShape);\n    }\n    else {\n        for (let axis = 0; axis < inputRank; axis++) {\n            normalizedBegin[axis] = startForAxis(beginMask, begin, strides, inputShape, axis, ellipsisMask);\n            normalizedEnd[axis] =\n                stopForAxis(endMask, end, strides, inputShape, axis, ellipsisMask);\n            normalizedStrides[axis] = stridesForAxis(strides, axis, ellipsisMask);\n        }\n    }\n    return {\n        begin: normalizedBegin,\n        end: normalizedEnd,\n        strides: normalizedStrides\n    };\n}\n// Creates full selection at the elided dimensions. If the dimension matches\n// the ellipsis mask, override the current start value. Otherwise, insert.\nexport function startIndicesWithElidedDims(beginMask, ellipsisInsertionIndex, numElidedAxes, originalBegin, inputShape) {\n    const newIndices = [...inputShape];\n    const elidedAxes = getElidedAxes(numElidedAxes, ellipsisInsertionIndex);\n    for (let axis = 0; axis < newIndices.length; axis++) {\n        if (elidedAxes.indexOf(axis) > -1) {\n            newIndices[axis] = 0;\n        }\n        else {\n            const originalAxis = unnormalizeAxis(ellipsisInsertionIndex, numElidedAxes, axis);\n            let originalValue = originalBegin[originalAxis];\n            if (beginMask & 1 << originalAxis) {\n                originalValue = 0;\n            }\n            newIndices[axis] = originalValue;\n        }\n    }\n    return newIndices;\n}\n// Creates full selection at the elided dimensions. If the dimension matches\n// the ellipsis mask, override the current stop value. Otherwise, insert.\nexport function stopIndicesWithElidedDims(endMask, ellipsisInsertionIndex, numElidedAxes, originalEnd, inputShape) {\n    const newIndices = [...inputShape];\n    const elidedAxes = getElidedAxes(numElidedAxes, ellipsisInsertionIndex);\n    for (let axis = 0; axis < newIndices.length; axis++) {\n        if (elidedAxes.indexOf(axis) > -1) {\n            newIndices[axis] = Number.MAX_SAFE_INTEGER;\n        }\n        else {\n            const originalAxis = unnormalizeAxis(ellipsisInsertionIndex, numElidedAxes, axis);\n            let originalValue = originalEnd[originalAxis];\n            if (endMask & 1 << originalAxis) {\n                originalValue = Number.MAX_SAFE_INTEGER;\n            }\n            newIndices[axis] = originalValue;\n        }\n    }\n    for (let i = 0; i < newIndices.length; i++) {\n        // Handle negative indices\n        const axisSize = inputShape[i];\n        if (newIndices[i] < 0) {\n            newIndices[i] += axisSize;\n        }\n        newIndices[i] = util.clamp(0, newIndices[i], inputShape[i]);\n    }\n    return newIndices;\n}\nexport function stridesForAxis(strides, axis, ellipsisMask) {\n    let stride = strides[axis];\n    if (ellipsisMask & (1 << axis) || stride == null) {\n        stride = 1;\n    }\n    return stride;\n}\nexport function startForAxis(beginMask, startIndices, strides, inputShape, axis, ellipsisMask) {\n    // Begin with the specified index\n    let start = startIndices[axis];\n    const stride = strides[axis] || 1;\n    // Check the axis bit from right of masked axes, or the begin index is not set\n    // for the axis.\n    if (beginMask & 1 << axis || ellipsisMask & 1 << axis || start == null) {\n        if (stride > 0) {\n            // Forward iteration - use the first element. These values will get\n            // clamped below (Note: We could have set them to 0 and axis_size-1, but\n            // use lowest() and max() to maintain symmetry with StopForAxis())\n            start = Number.MIN_SAFE_INTEGER;\n        }\n        else {\n            // Backward iteration - use the last element.\n            start = Number.MAX_SAFE_INTEGER;\n        }\n    }\n    // Handle negative indices\n    const axisSize = inputShape[axis];\n    if (start < 0) {\n        start += axisSize;\n    }\n    // Clamping\n    start = util.clamp(0, start, axisSize - 1);\n    return start;\n}\nexport function stopForAxis(endMask, stopIndices, strides, inputShape, axis, ellipsisMask) {\n    // Begin with the specified index\n    let stop = stopIndices[axis];\n    const stride = strides[axis] || 1;\n    // Check the axis bit from right of masked axes, or if the stop index is not\n    // set for this axis.\n    if (endMask & (1 << axis) || ellipsisMask & (1 << axis) || stop == null) {\n        if (stride > 0) {\n            // Forward iteration - use the last element. These values will get\n            // clamped below\n            stop = Number.MAX_SAFE_INTEGER;\n        }\n        else {\n            // Backward iteration - use the first element.\n            stop = Number.MIN_SAFE_INTEGER;\n        }\n    }\n    // Handle negative indices\n    const axisSize = inputShape[axis];\n    if (stop < 0) {\n        stop += axisSize;\n    }\n    // Clamping\n    // Because the end index points one past the last element, we need slightly\n    // different clamping ranges depending on the direction.\n    if (stride > 0) {\n        // Forward iteration\n        stop = util.clamp(0, stop, axisSize);\n    }\n    else {\n        // Backward iteration\n        stop = util.clamp(-1, stop, axisSize - 1);\n    }\n    return stop;\n}\n/**\n * Returns true if the slice occupies a continous set of elements in the\n * 'flat' space.\n */\nexport function isSliceContinous(shape, begin, size) {\n    // Index of the first axis that has size > 1.\n    let firstNonOneAxis = size.length;\n    for (let i = 0; i < size.length; i++) {\n        if (size[i] > 1) {\n            firstNonOneAxis = i;\n            break;\n        }\n    }\n    for (let i = firstNonOneAxis + 1; i < size.length; i++) {\n        if (begin[i] > 0 || size[i] !== shape[i]) {\n            return false;\n        }\n    }\n    return true;\n}\nexport function computeFlatOffset(begin, strides) {\n    let flatOffset = begin.length > 0 ? begin[begin.length - 1] : 1;\n    for (let i = 0; i < begin.length - 1; i++) {\n        flatOffset += begin[i] * strides[i];\n    }\n    return flatOffset;\n}\nexport function parseSliceParams(x, begin, size) {\n    // The following logic allows for more ergonomic calls.\n    let begin_;\n    const xRank = x.shape.length;\n    if (typeof begin === 'number') {\n        begin_ = [begin, ...new Array(xRank - 1).fill(0)];\n    }\n    else if (begin.length < xRank) {\n        begin_ = begin.concat(new Array(xRank - begin.length).fill(0));\n    }\n    else {\n        begin_ = begin.slice();\n    }\n    begin_.forEach(d => {\n        util.assert(d !== -1, () => 'slice() does not support negative begin indexing.');\n    });\n    let size_;\n    if (size == null) {\n        size_ = new Array(xRank).fill(-1);\n    }\n    else if (typeof size === 'number') {\n        size_ = [size, ...new Array(xRank - 1).fill(-1)];\n    }\n    else if (size.length < xRank) {\n        size_ = size.concat(new Array(xRank - size.length).fill(-1));\n    }\n    else {\n        size_ = size;\n    }\n    size_ = size_.map((d, i) => {\n        if (d >= 0) {\n            return d;\n        }\n        else {\n            util.assert(d === -1, () => `Negative size values should be exactly -1 but got ` +\n                `${d} for the slice() size at index ${i}.`);\n            return x.shape[i] - begin_[i];\n        }\n    });\n    return [begin_, size_];\n}\nexport function sliceInfo(xShape, begin, end, strides, beginMask, endMask, ellipsisMask, newAxisMask, shrinkAxisMask) {\n    // make a copy because it may be modified further down.\n    let $begin = begin.slice();\n    let $end = end.slice();\n    let $strides = strides;\n    if (strides == null) {\n        $strides = new Array($begin.length);\n    }\n    const ellipsisAxes = maskToAxes(ellipsisMask);\n    if (ellipsisAxes.length > 1) {\n        throw new Error('Multiple ellipses in slice is not allowed.');\n    }\n    if (ellipsisMask !== 0 && newAxisMask !== 0) {\n        throw new Error('Using both ellipsisMask and newAxisMask is not yet supported.');\n    }\n    if (ellipsisMask !== 0 && shrinkAxisMask !== 0) {\n        throw new Error('Using both ellipsisMask and shrinkAxisMask is not yet supported.');\n    }\n    const numInterpolatedAxes = xShape.length - $begin.length;\n    // Expand the dims of x based on the newAxisMask.\n    const expandAxes = maskToAxes(newAxisMask);\n    const newShape = xShape.slice();\n    expandAxes.forEach(axis => {\n        $begin[axis] = 0;\n        $end[axis] = 1;\n        newShape.splice(axis, 0, 1);\n    });\n    const { begin: normalizedBegin, end: normalizedEnd, strides: normalizedStrides } = getNormalizedAxes(newShape, ellipsisAxes, numInterpolatedAxes, $begin, $end, $strides, beginMask, endMask, ellipsisMask);\n    $begin = normalizedBegin;\n    $end = normalizedEnd;\n    $strides = normalizedStrides;\n    const shrinkAxes = maskToAxes(shrinkAxisMask);\n    // Adjust the ends based on the shrink mask.\n    shrinkAxes.forEach(axis => {\n        $end[axis] = $begin[axis] + 1;\n        $strides[axis] = 1;\n    });\n    // Figure out the output shape.\n    const size = computeOutShape($begin, $end, $strides);\n    // Remove the axes based on shrinkMask.\n    const outShape = size.filter((_, axis) => shrinkAxes.indexOf(axis) === -1);\n    const nonStrided = $strides.every(v => v === 1);\n    return { nonStrided, $begin, $end, $strides, size, newShape, outShape };\n}\n//# sourceMappingURL=slice_util.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Sigmoid } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes sigmoid element-wise, `1 / (1 + exp(-x))`\n *\n * ```js\n * const x = tf.tensor1d([0, -1, 2, -3]);\n *\n * x.sigmoid().print();  // or tf.sigmoid(x)\n * ```\n * @param x The input tensor.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction sigmoid_(x) {\n    const $x = convertToTensor(x, 'x', 'sigmoid');\n    const inputs = { x: $x };\n    return ENGINE.runKernel(Sigmoid, inputs);\n}\nexport const sigmoid = op({ sigmoid_ });\n//# sourceMappingURL=sigmoid.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { convertToTensor } from '../tensor_util_env';\nimport { squeezeShape } from '../util';\nimport { op } from './operation';\nimport { reshape } from './reshape';\n/**\n * Removes dimensions of size 1 from the shape of a `tf.Tensor`.\n *\n * ```js\n * const x = tf.tensor([1, 2, 3, 4], [1, 1, 4]);\n * x.squeeze().print();\n * ```\n *\n * @param x The input tensor to be squeezed.\n * @param axis An optional list of numbers. If specified, only\n *     squeezes the dimensions listed. The dimension index starts at 0. It\n * is an error to squeeze a dimension that is not 1.\n *\n * @doc {heading: 'Tensors', subheading: 'Transformations'}\n */\nfunction squeeze_(x, axis) {\n    const $x = convertToTensor(x, 'x', 'squeeze');\n    return reshape($x, squeezeShape($x.shape, axis).newShape);\n}\nexport const squeeze = op({ squeeze_ });\n//# sourceMappingURL=squeeze.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../../engine';\nimport { FFT } from '../../kernel_names';\nimport { assert } from '../../util';\nimport { op } from '../operation';\n/**\n * Fast Fourier transform.\n *\n * Computes the 1-dimensional discrete Fourier transform over the inner-most\n * dimension of input.\n *\n * ```js\n * const real = tf.tensor1d([1, 2, 3]);\n * const imag = tf.tensor1d([1, 2, 3]);\n * const x = tf.complex(real, imag);\n *\n * x.fft().print();  // tf.spectral.fft(x).print();\n * ```\n * @param input The complex input to compute an fft over.\n *\n * @doc {heading: 'Operations', subheading: 'Spectral', namespace: 'spectral'}\n */\nfunction fft_(input) {\n    assert(input.dtype === 'complex64', () => `The dtype for tf.spectral.fft() must be complex64 ` +\n        `but got ${input.dtype}.`);\n    const inputs = { input };\n    return ENGINE.runKernel(FFT, inputs);\n}\nexport const fft = op({ fft_ });\n//# sourceMappingURL=fft.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { assert } from '../../util';\nimport { complex } from '../complex';\nimport { concat } from '../concat';\nimport { imag } from '../imag';\nimport { op } from '../operation';\nimport { real } from '../real';\nimport { reshape } from '../reshape';\nimport { slice } from '../slice';\nimport { split } from '../split';\nimport { zeros } from '../zeros';\nimport { zerosLike } from '../zeros_like';\nimport { fft } from './fft';\n/**\n * Real value input fast Fourier transform.\n *\n * Computes the 1-dimensional discrete Fourier transform over the\n * inner-most dimension of the real input.\n *\n * ```js\n * const real = tf.tensor1d([1, 2, 3]);\n *\n * real.rfft().print();\n * ```\n * @param input The real value input to compute an rfft over.\n *\n * @doc {heading: 'Operations', subheading: 'Spectral', namespace: 'spectral'}\n */\nfunction rfft_(input, fftLength) {\n    assert(input.dtype === 'float32', () => `The dtype for rfft() must be real value but got ${input.dtype}`);\n    let innerDimensionSize = input.shape[input.shape.length - 1];\n    const batch = input.size / innerDimensionSize;\n    let adjustedInput;\n    if (fftLength != null && fftLength < innerDimensionSize) {\n        // Need to crop\n        const begin = input.shape.map(v => 0);\n        const size = input.shape.map(v => v);\n        size[input.shape.length - 1] = fftLength;\n        adjustedInput = slice(input, begin, size);\n        innerDimensionSize = fftLength;\n    }\n    else if (fftLength != null && fftLength > innerDimensionSize) {\n        // Need to pad with zeros\n        const zerosShape = input.shape.map(v => v);\n        zerosShape[input.shape.length - 1] = fftLength - innerDimensionSize;\n        adjustedInput = concat([input, zeros(zerosShape)], input.shape.length - 1);\n        innerDimensionSize = fftLength;\n    }\n    else {\n        adjustedInput = input;\n    }\n    // Complement the input with zero imaginary numbers.\n    const zerosInput = zerosLike(adjustedInput);\n    const complexInput = reshape(complex(adjustedInput, zerosInput), [batch, innerDimensionSize]);\n    const ret = fft(complexInput);\n    // Exclude complex conjugations. These conjugations are put symmetrically.\n    const half = Math.floor(innerDimensionSize / 2) + 1;\n    const realValues = real(ret);\n    const imagValues = imag(ret);\n    const realComplexConjugate = split(realValues, [half, innerDimensionSize - half], realValues.shape.length - 1);\n    const imagComplexConjugate = split(imagValues, [half, innerDimensionSize - half], imagValues.shape.length - 1);\n    const outputShape = adjustedInput.shape.slice();\n    outputShape[adjustedInput.shape.length - 1] = half;\n    return reshape(complex(realComplexConjugate[0], imagComplexConjugate[0]), outputShape);\n}\nexport const rfft = op({ rfft_ });\n//# sourceMappingURL=rfft.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { convertToTensor } from '../tensor_util_env';\nimport { parseAxisParam } from '../util';\nimport { abs } from './abs';\nimport * as axis_util from './axis_util';\nimport { max } from './max';\nimport { min } from './min';\nimport { op } from './operation';\nimport { pow } from './pow';\nimport { reshape } from './reshape';\nimport { scalar } from './scalar';\nimport { sqrt } from './sqrt';\nimport { square } from './square';\nimport { sum } from './sum';\n/**\n * Computes the norm of scalar, vectors, and matrices.\n * This function can compute several different vector norms (the 1-norm, the\n * Euclidean or 2-norm, the inf-norm, and in general the p-norm for p > 0)\n * and matrix norms (Frobenius, 1-norm, and inf-norm).\n *\n * ```js\n * const x = tf.tensor1d([1, 2, 3, 4]);\n *\n * x.norm().print();  // or tf.norm(x)\n * ```\n *\n * @param x The input array.\n * @param ord Optional. Order of the norm. Supported norm types are\n * following:\n *\n *  | ord        | norm for matrices         | norm for vectors\n *  |------------|---------------------------|---------------------\n *  |'euclidean' |Frobenius norm             |2-norm\n *  |'fro'       |Frobenius norm\t           |\n *  |Infinity    |max(sum(abs(x), axis=1))   |max(abs(x))\n *  |-Infinity   |min(sum(abs(x), axis=1))   |min(abs(x))\n *  |1           |max(sum(abs(x), axis=0))   |sum(abs(x))\n *  |2           |                           |sum(abs(x)^2)^1/2*\n *\n * @param axis Optional. If axis is null (the default), the input is\n * considered a vector and a single vector norm is computed over the entire\n * set of values in the Tensor, i.e. norm(x, ord) is equivalent\n * to norm(x.reshape([-1]), ord). If axis is a integer, the input\n * is considered a batch of vectors, and axis determines the axis in x\n * over which to compute vector norms. If axis is a 2-tuple of integer it is\n * considered a batch of matrices and axis determines the axes in NDArray\n * over which to compute a matrix norm.\n * @param keepDims Optional. If true, the norm have the same dimensionality\n * as the input.\n *\n * @doc {heading: 'Operations', subheading: 'Matrices'}\n */\nfunction norm_(x, ord = 'euclidean', axis = null, keepDims = false) {\n    x = convertToTensor(x, 'x', 'norm');\n    const norm = normImpl(x, ord, axis);\n    let keepDimsShape = norm.shape;\n    if (keepDims) {\n        const axes = parseAxisParam(axis, x.shape);\n        keepDimsShape = axis_util.expandShapeToKeepDim(norm.shape, axes);\n    }\n    return reshape(norm, keepDimsShape);\n}\nfunction normImpl(x, p, axis = null) {\n    if (x.rank === 0) {\n        return abs(x);\n    }\n    // consider vector when no axis is specified\n    if (x.rank !== 1 && axis === null) {\n        return normImpl(reshape(x, [-1]), p, axis);\n    }\n    // vector\n    if (x.rank === 1 || typeof axis === 'number' ||\n        Array.isArray(axis) && axis.length === 1) {\n        if (p === 1) {\n            return sum(abs(x), axis);\n        }\n        if (p === Infinity) {\n            return max(abs(x), axis);\n        }\n        if (p === -Infinity) {\n            return min(abs(x), axis);\n        }\n        if (p === 'euclidean' || p === 2) {\n            // norm(x, 2) = sum(abs(xi) ^ 2) ^ 1/2\n            return sqrt(sum(pow(abs(x), scalar(2, 'int32')), axis));\n        }\n        throw new Error(`Error in norm: invalid ord value: ${p}`);\n    }\n    // matrix (assumption axis[0] < axis[1])\n    if (Array.isArray(axis) && axis.length === 2) {\n        if (p === 1) {\n            return max(sum(abs(x), axis[0]), axis[1] - 1);\n        }\n        if (p === Infinity) {\n            return max(sum(abs(x), axis[1]), axis[0]);\n        }\n        if (p === -Infinity) {\n            return min(sum(abs(x), axis[1]), axis[0]);\n        }\n        if (p === 'fro' || p === 'euclidean') {\n            // norm(x) = sqrt(sum(pow(x, 2)))\n            return sqrt(sum(square(x), axis));\n        }\n        throw new Error(`Error in norm: invalid ord value: ${p}`);\n    }\n    throw new Error(`Error in norm: invalid axis: ${axis}`);\n}\nexport const norm = op({ norm_ });\n//# sourceMappingURL=norm.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Relu6 } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes rectified linear 6 element-wise: `min(max(x, 0), 6)`.\n *\n * ```js\n * const x = tf.tensor1d([-1, 2, -3, 8]);\n *\n * x.relu6().print();  // or tf.relu6(x)\n * ```\n * @param x The input tensor. If the dtype is `bool`, the output dtype will be\n *     `int32'.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction relu6_(x) {\n    const $x = convertToTensor(x, 'x', 'relu6');\n    const inputs = { x: $x };\n    return ENGINE.runKernel(Relu6, inputs);\n}\nexport const relu6 = op({ relu6_ });\n//# sourceMappingURL=relu6.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Prelu } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes leaky rectified linear element-wise with parametric alphas.\n *\n * `x < 0 ? alpha * x : f(x) = x`\n *\n * ```js\n * const x = tf.tensor1d([-1, 2, -3, 4]);\n * const alpha = tf.scalar(0.1);\n *\n * x.prelu(alpha).print();  // or tf.prelu(x, alpha)\n * ```\n * @param x The input tensor.\n * @param alpha Scaling factor for negative values.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction prelu_(x, alpha) {\n    const $x = convertToTensor(x, 'x', 'prelu');\n    const $alpha = convertToTensor(alpha, 'alpha', 'prelu');\n    const inputs = { x: $x, alpha: $alpha };\n    return ENGINE.runKernel(Prelu, inputs);\n}\nexport const prelu = op({ prelu_ });\n//# sourceMappingURL=prelu.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { UnsortedSegmentSum } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { assert, isInt } from '../util';\nimport { op } from './operation';\n/**\n * Computes the sum along segments of a `tf.Tensor`.\n *\n * ```js\n * const x = tf.tensor1d([1, 2, 3, 4]);\n * const segmentIds = tf.tensor1d([1, 2, 0, 1], 'int32');\n * const numSegments = 3;\n *\n * x.unsortedSegmentSum(segmentIds, numSegments).print()\n * //or tf.unsortedSegmentSum(x, segmentIds, numSegments)\n * ```\n * @param x The `tf.Tensor` that will be summed along its segments.\n * @param segmentIds A `tf.Tensor1D` whose rank is equal to the rank of `x`'s\n * dimension along the `axis`.  Maps each element of `x` to a segment.\n * @param numSegments The number of distinct `segmentIds`.\n *\n * @doc {heading: 'Operations', subheading: 'Segment'}\n */\nfunction unsortedSegmentSum_(x, segmentIds, numSegments) {\n    const $x = convertToTensor(x, 'x', 'unsortedSegmentSum');\n    const $segmentIds = convertToTensor(segmentIds, 'segmentIds', 'unsortedSegmentSum', 'int32');\n    assert(isInt(numSegments), () => 'numSegments must be of dtype int');\n    const inputs = { x: $x, segmentIds: $segmentIds };\n    const attrs = { numSegments };\n    return ENGINE.runKernel(UnsortedSegmentSum, inputs, attrs);\n}\nexport const unsortedSegmentSum = op({ unsortedSegmentSum_ });\n//# sourceMappingURL=unsorted_segment_sum.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { PadV2 } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Pads a `tf.Tensor` with a given value and paddings.\n *\n * This operation implements `CONSTANT` mode. For `REFLECT` and `SYMMETRIC`,\n * refer to `tf.mirrorPad`\n *\n * Also available are stricter rank-specific methods with the same signature\n * as this method that assert that `paddings` is of given length.\n *   - `tf.pad1d`\n *   - `tf.pad2d`\n *   - `tf.pad3d`\n *   - `tf.pad4d`\n *\n * ```js\n * const x = tf.tensor1d([1, 2, 3, 4]);\n * x.pad([[1, 2]]).print();\n * ```\n * @param x The tensor to pad.\n * @param paddings An array of length `R` (the rank of the tensor), where\n * each element is a length-2 tuple of ints `[padBefore, padAfter]`,\n * specifying how much to pad along each dimension of the tensor.\n * @param constantValue The pad value to use. Defaults to 0.\n *\n * @doc {heading: 'Tensors', subheading: 'Transformations'}\n */\nfunction pad_(x, paddings, constantValue = 0) {\n    const $x = convertToTensor(x, 'x', 'pad');\n    if ($x.rank === 0) {\n        throw new Error('pad(scalar) is not defined. Pass non-scalar to pad');\n    }\n    const attrs = { paddings, constantValue };\n    const inputs = { x: $x };\n    return ENGINE.runKernel(PadV2, inputs, attrs);\n}\nexport const pad = op({ pad_ });\n//# sourceMappingURL=pad.js.map","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { tensor1d } from './tensor1d';\nexport function enclosingPowerOfTwo(value) {\n    // Return 2**N for integer N such that 2**N >= value.\n    return Math.floor(Math.pow(2, Math.ceil(Math.log(value) / Math.log(2.0))));\n}\nexport function cosineWindow(windowLength, a, b) {\n    const even = 1 - windowLength % 2;\n    const newValues = new Float32Array(windowLength);\n    for (let i = 0; i < windowLength; ++i) {\n        const cosArg = (2.0 * Math.PI * i) / (windowLength + even - 1);\n        newValues[i] = a - b * Math.cos(cosArg);\n    }\n    return tensor1d(newValues, 'float32');\n}\n//# sourceMappingURL=signal_ops_util.js.map","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { op } from '../operation';\nimport { cosineWindow } from '../signal_ops_util';\n/**\n * Generate a hamming window.\n *\n * See: https://en.wikipedia.org/wiki/Window_function#Hann_and_Hamming_windows\n *\n * ```js\n * tf.signal.hammingWindow(10).print();\n * ```\n * @param The length of window\n *\n * @doc {heading: 'Operations', subheading: 'Signal', namespace: 'signal'}\n */\nfunction hammingWindow_(windowLength) {\n    return cosineWindow(windowLength, 0.54, 0.46);\n}\nexport const hammingWindow = op({ hammingWindow_ });\n//# sourceMappingURL=hamming_window.js.map","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { op } from '../operation';\nimport { cosineWindow } from '../signal_ops_util';\n/**\n * Generate a Hann window.\n *\n * See: https://en.wikipedia.org/wiki/Window_function#Hann_and_Hamming_windows\n *\n * ```js\n * tf.signal.hannWindow(10).print();\n * ```\n * @param The length of window\n *\n * @doc {heading: 'Operations', subheading: 'Signal', namespace: 'signal'}\n */\nfunction hannWindow_(windowLength) {\n    return cosineWindow(windowLength, 0.5, 0.5);\n}\nexport const hannWindow = op({ hannWindow_ });\n//# sourceMappingURL=hann_window.js.map","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { concat } from '../concat';\nimport { fill } from '../fill';\nimport { op } from '../operation';\nimport { reshape } from '../reshape';\nimport { slice } from '../slice';\nimport { tensor2d } from '../tensor2d';\n/**\n * Expands input into frames of frameLength.\n * Slides a window size with frameStep.\n *\n * ```js\n * tf.signal.frame([1, 2, 3], 2, 1).print();\n * ```\n * @param signal The input tensor to be expanded\n * @param frameLength Length of each frame\n * @param frameStep The frame hop size in samples.\n * @param padEnd Whether to pad the end of signal with padValue.\n * @param padValue An number to use where the input signal does\n *     not exist when padEnd is True.\n *\n * @doc {heading: 'Operations', subheading: 'Signal', namespace: 'signal'}\n */\nfunction frame_(signal, frameLength, frameStep, padEnd = false, padValue = 0) {\n    let start = 0;\n    const output = [];\n    while (start + frameLength <= signal.size) {\n        output.push(slice(signal, start, frameLength));\n        start += frameStep;\n    }\n    if (padEnd) {\n        while (start < signal.size) {\n            const padLen = (start + frameLength) - signal.size;\n            const pad = concat([\n                slice(signal, start, frameLength - padLen), fill([padLen], padValue)\n            ]);\n            output.push(pad);\n            start += frameStep;\n        }\n    }\n    if (output.length === 0) {\n        return tensor2d([], [0, frameLength]);\n    }\n    return reshape(concat(output), [output.length, frameLength]);\n}\nexport const frame = op({ frame_ });\n//# sourceMappingURL=frame.js.map","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { concat } from '../concat';\nimport { mul } from '../mul';\nimport { op } from '../operation';\nimport { enclosingPowerOfTwo } from '../signal_ops_util';\nimport { slice } from '../slice';\nimport { rfft } from '../spectral/rfft';\nimport { frame } from './frame';\nimport { hannWindow } from './hann_window';\n/**\n * Computes the Short-time Fourier Transform of signals\n * See: https://en.wikipedia.org/wiki/Short-time_Fourier_transform\n *\n * ```js\n * const input = tf.tensor1d([1, 1, 1, 1, 1])\n * tf.signal.stft(input, 3, 1).print();\n * ```\n * @param signal 1-dimensional real value tensor.\n * @param frameLength The window length of samples.\n * @param frameStep The number of samples to step.\n * @param fftLength The size of the FFT to apply.\n * @param windowFn A callable that takes a window length and returns 1-d tensor.\n *\n * @doc {heading: 'Operations', subheading: 'Signal', namespace: 'signal'}\n */\nfunction stft_(signal, frameLength, frameStep, fftLength, windowFn = hannWindow) {\n    if (fftLength == null) {\n        fftLength = enclosingPowerOfTwo(frameLength);\n    }\n    const framedSignal = frame(signal, frameLength, frameStep);\n    const windowedSignal = mul(framedSignal, windowFn(frameLength));\n    const output = [];\n    for (let i = 0; i < framedSignal.shape[0]; i++) {\n        output.push(rfft(slice(windowedSignal, [i, 0], [1, frameLength]), fftLength));\n    }\n    return concat(output);\n}\nexport const stft = op({ stft_ });\n//# sourceMappingURL=stft.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n// Modularized ops.\nexport { abs } from './abs';\nexport { acos } from './acos';\nexport { acosh } from './acosh';\nexport { add } from './add';\nexport { addN } from './add_n';\nexport { all } from './all';\nexport { any } from './any';\nexport { argMax } from './arg_max';\nexport { argMin } from './arg_min';\nexport { asin } from './asin';\nexport { asinh } from './asinh';\nexport { atan } from './atan';\nexport { atan2 } from './atan2';\nexport { atanh } from './atanh';\nexport { avgPool } from './avg_pool';\nexport { avgPool3d } from './avg_pool_3d';\nexport { basicLSTMCell } from './basic_lstm_cell';\nexport { batchToSpaceND } from './batch_to_space_nd';\nexport { batchNorm } from './batchnorm';\nexport { batchNorm2d } from './batchnorm2d';\nexport { batchNorm3d } from './batchnorm3d';\nexport { batchNorm4d } from './batchnorm4d';\nexport { bincount } from './bincount';\nexport { broadcastTo } from './broadcast_to';\nexport { buffer } from './buffer';\nexport { cast } from './cast';\nexport { ceil } from './ceil';\nexport { clipByValue } from './clip_by_value';\nexport { clone } from './clone';\nexport { complex } from './complex';\nexport { concat } from './concat';\nexport { concat1d } from './concat_1d';\nexport { concat2d } from './concat_2d';\nexport { concat3d } from './concat_3d';\nexport { concat4d } from './concat_4d';\nexport { conv1d } from './conv1d';\nexport { conv2d } from './conv2d';\nexport { conv2dTranspose } from './conv2d_transpose';\nexport { conv3d } from './conv3d';\nexport { conv3dTranspose } from './conv3d_transpose';\nexport { cos } from './cos';\nexport { cosh } from './cosh';\nexport { cumsum } from './cumsum';\nexport { denseBincount } from './dense_bincount';\nexport { depthToSpace } from './depth_to_space';\nexport { depthwiseConv2d } from './depthwise_conv2d';\nexport { diag } from './diag';\nexport { dilation2d } from './dilation2d';\nexport { div } from './div';\nexport { divNoNan } from './div_no_nan';\nexport { dot } from './dot';\nexport { elu } from './elu';\nexport { equal } from './equal';\nexport { erf } from './erf';\nexport { exp } from './exp';\nexport { expandDims } from './expand_dims';\nexport { expm1 } from './expm1';\nexport { eye } from './eye';\nexport { fill } from './fill';\nexport { floor } from './floor';\nexport { floorDiv } from './floorDiv';\nexport { gather } from './gather';\nexport { greater } from './greater';\nexport { greaterEqual } from './greater_equal';\nexport { imag } from './imag';\nexport { isFinite } from './is_finite';\nexport { isInf } from './is_inf';\nexport { isNaN } from './is_nan';\nexport { leakyRelu } from './leaky_relu';\nexport { less } from './less';\nexport { lessEqual } from './less_equal';\nexport { linspace } from './linspace';\nexport { localResponseNormalization } from './local_response_normalization';\nexport { log } from './log';\nexport { log1p } from './log1p';\nexport { logSigmoid } from './log_sigmoid';\nexport { logSoftmax } from './log_softmax';\nexport { logSumExp } from './log_sum_exp';\nexport { logicalAnd } from './logical_and';\nexport { logicalNot } from './logical_not';\nexport { logicalOr } from './logical_or';\nexport { logicalXor } from './logical_xor';\nexport { matMul } from './mat_mul';\nexport { max } from './max';\nexport { maxPool } from './max_pool';\nexport { maxPool3d } from './max_pool_3d';\nexport { maxPoolWithArgmax } from './max_pool_with_argmax';\nexport { maximum } from './maximum';\nexport { mean } from './mean';\nexport { min } from './min';\nexport { minimum } from './minimum';\nexport { mirrorPad } from './mirror_pad';\nexport { mod } from './mod';\nexport { moments } from './moments';\nexport { mul } from './mul';\nexport { multiRNNCell } from './multi_rnn_cell';\nexport { multinomial } from './multinomial';\nexport { neg } from './neg';\nexport { notEqual } from './not_equal';\nexport { oneHot } from './one_hot';\nexport { ones } from './ones';\nexport { onesLike } from './ones_like';\nexport { outerProduct } from './outer_product';\nexport { pad } from './pad';\nexport { pad1d } from './pad1d';\nexport { pad2d } from './pad2d';\nexport { pad3d } from './pad3d';\nexport { pad4d } from './pad4d';\nexport { pool } from './pool';\nexport { pow } from './pow';\nexport { prelu } from './prelu';\nexport { print } from './print';\nexport { prod } from './prod';\nexport { rand } from './rand';\nexport { randomGamma } from './random_gamma';\nexport { randomNormal } from './random_normal';\nexport { randomUniform } from './random_uniform';\nexport { range } from './range';\nexport { real } from './real';\nexport { reciprocal } from './reciprocal';\nexport { relu } from './relu';\nexport { relu6 } from './relu6';\nexport { reshape } from './reshape';\nexport { reverse } from './reverse';\nexport { reverse1d } from './reverse_1d';\nexport { reverse2d } from './reverse_2d';\nexport { reverse3d } from './reverse_3d';\nexport { reverse4d } from './reverse_4d';\nexport { round } from './round';\nexport { rsqrt } from './rsqrt';\nexport { scalar } from './scalar';\nexport { selu } from './selu';\nexport { separableConv2d } from './separable_conv2d';\nexport { setdiff1dAsync } from './setdiff1d_async';\nexport { sigmoid } from './sigmoid';\nexport { sign } from './sign';\nexport { sin } from './sin';\nexport { sinh } from './sinh';\nexport { slice } from './slice';\nexport { slice1d } from './slice1d';\nexport { slice2d } from './slice2d';\nexport { slice3d } from './slice3d';\nexport { slice4d } from './slice4d';\nexport { softmax } from './softmax';\nexport { softplus } from './softplus';\nexport { spaceToBatchND } from './space_to_batch_nd';\nexport { fft } from './spectral/fft';\nexport { ifft } from './spectral/ifft';\nexport { irfft } from './spectral/irfft';\nexport { rfft } from './spectral/rfft';\nexport { split } from './split';\nexport { sqrt } from './sqrt';\nexport { square } from './square';\nexport { squaredDifference } from './squared_difference';\nexport { squeeze } from './squeeze';\nexport { stack } from './stack';\nexport { step } from './step';\nexport { stridedSlice } from './strided_slice';\nexport { sub } from './sub';\nexport { sum } from './sum';\nexport { tan } from './tan';\nexport { tanh } from './tanh';\nexport { tensor } from './tensor';\nexport { tensor1d } from './tensor1d';\nexport { tensor2d } from './tensor2d';\nexport { tensor3d } from './tensor3d';\nexport { tensor4d } from './tensor4d';\nexport { tensor5d } from './tensor5d';\nexport { tensor6d } from './tensor6d';\nexport { tile } from './tile';\nexport { topk } from './topk';\nexport { truncatedNormal } from './truncated_normal';\nexport { unique } from './unique';\nexport { unsortedSegmentSum } from './unsorted_segment_sum';\nexport { unstack } from './unstack';\nexport { variable } from './variable';\nexport { where } from './where';\nexport { whereAsync } from './where_async';\nexport { zeros } from './zeros';\nexport { zerosLike } from './zeros_like';\nexport * from './boolean_mask';\nexport * from './compare';\nexport * from './binary_ops';\nexport * from './transpose';\nexport * from './norm';\nexport * from './moving_average';\nexport * from './scatter_nd';\nexport * from './sparse_to_dense';\nexport * from './gather_nd';\nexport * from './dropout';\nexport * from './signal_ops_util';\nexport * from './in_top_k';\nexport { op, OP_SCOPE_SUFFIX } from './operation';\nimport { rfft } from './spectral/rfft';\nimport { fft } from './spectral/fft';\nimport { ifft } from './spectral/ifft';\nimport { irfft } from './spectral/irfft';\nconst spectral = {\n    fft,\n    ifft,\n    rfft,\n    irfft\n};\nimport * as fused from './fused_ops';\nimport { hammingWindow } from './signal/hamming_window';\nimport { hannWindow } from './signal/hann_window';\nimport { frame } from './signal/frame';\nimport { stft } from './signal/stft';\nconst signal = {\n    hammingWindow,\n    hannWindow,\n    frame,\n    stft,\n};\n// Image Ops namespace\nimport { cropAndResize } from './image/crop_and_resize';\nimport { flipLeftRight } from './image/flip_left_right';\nimport { rotateWithOffset } from './image/rotate_with_offset';\nimport { nonMaxSuppression } from './image/non_max_suppression';\nimport { nonMaxSuppressionAsync } from './image/non_max_suppression_async';\nimport { nonMaxSuppressionWithScore } from './image/non_max_suppression_with_score';\nimport { nonMaxSuppressionWithScoreAsync } from './image/non_max_suppression_with_score_async';\nimport { nonMaxSuppressionPadded } from './image/non_max_suppression_padded';\nimport { nonMaxSuppressionPaddedAsync } from './image/non_max_suppression_padded_async';\nimport { resizeBilinear } from './image/resize_bilinear';\nimport { resizeNearestNeighbor } from './image/resize_nearest_neighbor';\nconst image = {\n    flipLeftRight,\n    resizeNearestNeighbor,\n    resizeBilinear,\n    rotateWithOffset,\n    cropAndResize,\n    nonMaxSuppression,\n    nonMaxSuppressionAsync,\n    nonMaxSuppressionWithScore,\n    nonMaxSuppressionWithScoreAsync,\n    nonMaxSuppressionPadded,\n    nonMaxSuppressionPaddedAsync\n};\n// linalg namespace\nimport { bandPart } from './linalg/band_part';\nimport { gramSchmidt } from './linalg/gram_schmidt';\nimport { qr } from './linalg/qr';\nconst linalg = {\n    bandPart,\n    gramSchmidt,\n    qr\n};\n// losses namespace;\nimport { absoluteDifference } from './losses/absolute_difference';\nimport { computeWeightedLoss } from './losses/compute_weighted_loss';\nimport { cosineDistance } from './losses/cosine_distance';\nimport { hingeLoss } from './losses/hinge_loss';\nimport { huberLoss } from './losses/huber_loss';\nimport { logLoss } from './losses/log_loss';\nimport { meanSquaredError } from './losses/mean_squared_error';\nimport { sigmoidCrossEntropy } from './losses/sigmoid_cross_entropy';\nimport { softmaxCrossEntropy } from './losses/softmax_cross_entropy';\nconst losses = {\n    absoluteDifference,\n    computeWeightedLoss,\n    cosineDistance,\n    hingeLoss,\n    huberLoss,\n    logLoss,\n    meanSquaredError,\n    sigmoidCrossEntropy,\n    softmaxCrossEntropy\n};\n// Second level exports.\nexport { image, linalg, losses, spectral, fused, signal };\n//# sourceMappingURL=ops.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { inferShape } from '../tensor_util_env';\nimport { makeTensor } from './tensor_ops_util';\n/**\n * Creates a `tf.Tensor` with the provided values, shape and dtype.\n *\n * ```js\n * // Pass an array of values to create a vector.\n * tf.tensor([1, 2, 3, 4]).print();\n * ```\n *\n * ```js\n * // Pass a nested array of values to make a matrix or a higher\n * // dimensional tensor.\n * tf.tensor([[1, 2], [3, 4]]).print();\n * ```\n *\n * ```js\n * // Pass a flat array and specify a shape yourself.\n * tf.tensor([1, 2, 3, 4], [2, 2]).print();\n * ```\n *\n * @param values The values of the tensor. Can be nested array of numbers,\n *     or a flat array, or a `TypedArray`. If the values are strings,\n *     they will be encoded as utf-8 and kept as `Uint8Array[]`.\n * @param shape The shape of the tensor. Optional. If not provided,\n *   it is inferred from `values`.\n * @param dtype The data type.\n *\n * @doc {heading: 'Tensors', subheading: 'Creation'}\n */\nexport function tensor(values, shape, dtype) {\n    const inferredShape = inferShape(values, dtype);\n    return makeTensor(values, shape, inferredShape, dtype);\n}\n//# sourceMappingURL=tensor.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Sum } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { cast } from './cast';\nimport { op } from './operation';\n/**\n * Computes the sum of elements across dimensions of a `tf.Tensor`.\n *\n * Reduces the input along the dimensions given in `axes`. Unless `keepDims`\n * is true, the rank of the `tf.Tensor` is reduced by 1 for each entry in\n * `axes`. If `keepDims` is true, the reduced dimensions are retained with\n * length 1. If axes has no entries, all dimensions are reduced, and a\n * `tf.Tensor` with a single element is returned.\n *\n * ```js\n * const x = tf.tensor1d([1, 2, 3]);\n *\n * x.sum().print();  // or tf.sum(x)\n * ```\n *\n * ```js\n * const x = tf.tensor2d([1, 2, 3, 4], [2, 2]);\n *\n * const axis = 1;\n * x.sum(axis).print();  // or tf.sum(x, axis)\n * ```\n *\n * @param x The input tensor to compute the sum over. If the dtype is `bool`\n *   it will be converted to `int32` and the output dtype will be `int32`.\n * @param axis The dimension(s) to reduce. By default it reduces\n *     all dimensions.\n * @param keepDims If true, retains reduced dimensions with size 1.\n *\n * @doc {heading: 'Operations', subheading: 'Reduction'}\n */\nfunction sum_(x, axis = null, keepDims = false) {\n    let $x = convertToTensor(x, 'x', 'sum');\n    if ($x.dtype === 'bool') {\n        $x = cast($x, 'int32');\n    }\n    const inputs = { x: $x };\n    const attrs = { axis, keepDims };\n    return ENGINE.runKernel(Sum, inputs, attrs);\n}\nexport const sum = op({ sum_ });\n//# sourceMappingURL=sum.js.map","import { computeStrides, sizeFromShape } from '../util';\n/**\n * Check whether updates.shape = indices.shape[:batchDim] +\n * shape[sliceDim:]\n *\n * @param x The input tensor.\n */\nexport function validateUpdateShape(shape, indices, updates) {\n    const sliceDim = (indices.rank > 1) ? indices.shape[indices.rank - 1] : 1;\n    const batchDim = (indices.rank > 1) ? indices.rank - 1 : 1;\n    const shapeError = 'Must have updates.shape = indices.shape[:batchDim] + ' +\n        `shape[sliceDim:], got updates.shape: ${updates.shape}` +\n        `, indices.shape: ${indices.shape}, shape: ${shape}` +\n        `, sliceDim: ${sliceDim}, and batchDim: ${batchDim}.`;\n    if (updates.rank < batchDim) {\n        throw new Error(shapeError + ` update.rank < ${batchDim}. `);\n    }\n    if (shape.length < sliceDim + (updates.rank - batchDim)) {\n        throw new Error(shapeError +\n            ` Output shape length < ${sliceDim + (updates.rank - batchDim)}`);\n    }\n    if (updates.rank !== batchDim + shape.length - sliceDim) {\n        throw new Error(shapeError + ` update.rank != ${batchDim + shape.length - sliceDim}`);\n    }\n    for (let d = 0; d < batchDim; ++d) {\n        if (updates.shape[d] !== indices.shape[d]) {\n            throw new Error(shapeError +\n                ` updates.shape[${d}] (${updates.shape[d]}) != indices.shape[${d}] (${indices.shape[d]}).`);\n        }\n    }\n    for (let d = 0; d < updates.rank - batchDim; ++d) {\n        if (updates.shape[d + batchDim] !== shape[d + sliceDim]) {\n            throw new Error(shapeError +\n                ` updates.shape[${d + batchDim}] (${updates.shape[d + batchDim]}) != shape[${d + batchDim}] (${shape[d + batchDim]})`);\n        }\n    }\n}\n/**\n * Validate scatter nd inputs.\n *\n * @param update The tensor contains the update values.\n * @param indices The tensor contains the indices for the update values.\n * @param shape The shape of the output tensor.\n */\nexport function validateInput(updates, indices, shape) {\n    if (indices.rank < 1) {\n        throw new Error('tf.scatterND() expects the indices to be rank 1 or higher,' +\n            ` but the rank was ${indices.rank}.`);\n    }\n    if (updates.rank < 1) {\n        throw new Error('tf.scatterND() expects the updates to be rank 1 or higher,' +\n            ` but the rank was ${updates.rank}.`);\n    }\n    if (indices.dtype !== 'int32') {\n        throw new Error(`The dtype of 'indices' should be int32, but got dtype: ${indices.dtype}`);\n    }\n    if (shape.length < 1) {\n        throw new Error(`Output rank must be greater or equal to 1, but got shape: ${shape}`);\n    }\n    if (shape.length === 0) {\n        if (indices.size === 0) {\n            throw new Error(`Indices specified for empty output. indices shape: ${indices.shape}`);\n        }\n        if (updates.size === 0) {\n            throw new Error(`Updates specified for empty output. updates shape: ${updates.shape}`);\n        }\n    }\n    validateUpdateShape(shape, indices, updates);\n}\n/**\n * Calculate the shape information for the output.\n *\n * @param update The tensor contains the update values.\n * @param indices The tensor contains the indices for the update values.\n * @param shape The shape of the output tensor.\n *\n * @returns ScatterShapeInfo\n */\nexport function calculateShapes(updates, indices, shape) {\n    // Calculate the number of dimensions in indices\n    const indicesRank = indices.shape.length;\n    const sliceRank = (indicesRank > 1) ? indices.shape[indicesRank - 1] : 1;\n    // Calculate the number of elements that make up each slice of our updated\n    // tensor. This allows us to work with flattened tensors and copy over whole\n    // slices at a time.\n    const totalNd = shape.length;\n    let sliceSize = 1;\n    for (let i = sliceRank; i < totalNd; ++i) {\n        sliceSize *= shape[i];\n    }\n    const safeSliceDim = (sliceRank < 1) ? 1 : sliceRank;\n    const numUpdates = sizeFromShape(indices.shape) / safeSliceDim;\n    const strides = [...computeStrides(shape.slice(0, sliceRank)), 1];\n    const outputSize = sizeFromShape(shape);\n    return { sliceRank, numUpdates, sliceSize, strides, outputSize };\n}\n//# sourceMappingURL=scatter_nd_util.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Range } from '../kernel_names';\n/**\n * Creates a new `tf.Tensor1D` filled with the numbers in the range provided.\n *\n * The tensor is a is half-open interval meaning it includes start, but\n * excludes stop. Decrementing ranges and negative step values are also\n * supported.sv\n *\n *\n * ```js\n * tf.range(0, 9, 2).print();\n * ```\n *\n * @param start An integer start value\n * @param stop An integer stop value\n * @param step An integer increment (will default to 1 or -1)\n * @param dtype The data type of the output tensor. Defaults to 'float32'.\n *\n * @doc {heading: 'Tensors', subheading: 'Creation'}\n */\nexport function range(start, stop, step = 1, dtype = 'float32') {\n    if (step === 0) {\n        throw new Error('Cannot have a step of zero');\n    }\n    const attrs = { start, stop, step, dtype };\n    return ENGINE.runKernel(Range, {} /* inputs */, attrs);\n}\n//# sourceMappingURL=range.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nexport const SELU_SCALEALPHA = 1.7580993408473768599402175208123;\nexport const SELU_SCALE = 1.0507009873554804934193349852946;\n//# sourceMappingURL=selu_util.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Sub } from '../kernel_names';\nimport { makeTypesMatch } from '../tensor_util';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Subtracts two `tf.Tensor`s element-wise, A - B. Supports broadcasting.\n *\n * ```js\n * const a = tf.tensor1d([10, 20, 30, 40]);\n * const b = tf.tensor1d([1, 2, 3, 4]);\n *\n * a.sub(b).print();  // or tf.sub(a, b)\n * ```\n *\n * ```js\n * // Broadcast subtract a with b.\n * const a = tf.tensor1d([10, 20, 30, 40]);\n * const b = tf.scalar(5);\n *\n * a.sub(b).print();  // or tf.sub(a, b)\n * ```\n * @param a The first `tf.Tensor` to subtract from.\n * @param b The second `tf.Tensor` to be subtracted. Must have the same dtype as\n * `a`.\n *\n * @doc {heading: 'Operations', subheading: 'Arithmetic'}\n */\nfunction sub_(a, b) {\n    let $a = convertToTensor(a, 'a', 'sub');\n    let $b = convertToTensor(b, 'b', 'sub');\n    [$a, $b] = makeTypesMatch($a, $b);\n    const inputs = { a: $a, b: $b };\n    return ENGINE.runKernel(Sub, inputs);\n}\nexport const sub = op({ sub_ });\n//# sourceMappingURL=sub.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { isTypedArray } from '../util';\nimport { makeTensor } from './tensor_ops_util';\n/**\n * Creates rank-0 `tf.Tensor` (scalar) with the provided value and dtype.\n *\n * The same functionality can be achieved with `tf.tensor`, but in general\n * we recommend using `tf.scalar` as it makes the code more readable.\n *\n * ```js\n * tf.scalar(3.14).print();\n * ```\n *\n * @param value The value of the scalar.\n * @param dtype The data type.\n *\n * @doc {heading: 'Tensors', subheading: 'Creation'}\n */\nexport function scalar(value, dtype) {\n    if (((isTypedArray(value) && dtype !== 'string') || Array.isArray(value)) &&\n        dtype !== 'complex64') {\n        throw new Error('Error creating a new Scalar: value must be a primitive ' +\n            '(number|boolean|string)');\n    }\n    if (dtype === 'string' && isTypedArray(value) &&\n        !(value instanceof Uint8Array)) {\n        throw new Error('When making a scalar from encoded string, ' +\n            'the value must be `Uint8Array`.');\n    }\n    const shape = [];\n    const inferredShape = [];\n    return makeTensor(value, shape, inferredShape, dtype);\n}\n//# sourceMappingURL=scalar.js.map","/**\n * @license\n * Copyright 2020 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n/**\n * Prints information about the `tf.Tensor` including its data.\n *\n * ```js\n * const verbose = true;\n * tf.tensor2d([1, 2, 3, 4], [2, 2]).print(verbose);\n * ```\n * @param x The tensor to be printed.\n * @param verbose Whether to print verbose information about the ` Tensor`,\n * including dtype and size.\n *\n * @doc {heading: 'Tensors', subheading: 'Creation'}\n */\nexport function print(x, verbose = false) {\n    console.log(x.toString(verbose));\n}\n//# sourceMappingURL=print.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { complex } from '../complex';\nimport { concat } from '../concat';\nimport { imag } from '../imag';\nimport { mul } from '../mul';\nimport { op } from '../operation';\nimport { real } from '../real';\nimport { reshape } from '../reshape';\nimport { reverse } from '../reverse';\nimport { scalar } from '../scalar';\nimport { slice } from '../slice';\nimport { ifft } from './ifft';\n/**\n * Inversed real value input fast Fourier transform.\n *\n * Computes the 1-dimensional inversed discrete Fourier transform over the\n * inner-most dimension of the real input.\n *\n * ```js\n * const real = tf.tensor1d([1, 2, 3]);\n * const imag = tf.tensor1d([0, 0, 0]);\n * const x = tf.complex(real, imag);\n *\n * x.irfft().print();\n * ```\n * @param input The real value input to compute an irfft over.\n *\n * @doc {heading: 'Operations', subheading: 'Spectral', namespace: 'spectral'}\n */\nfunction irfft_(input) {\n    const innerDimensionSize = input.shape[input.shape.length - 1];\n    const batch = input.size / innerDimensionSize;\n    let ret;\n    if (innerDimensionSize <= 2) {\n        const complexInput = reshape(input, [batch, innerDimensionSize]);\n        ret = ifft(complexInput);\n    }\n    else {\n        // The length of unique components of the DFT of a real-valued signal\n        // is 2 * (input_len - 1)\n        const outputShape = [batch, 2 * (innerDimensionSize - 1)];\n        const realInput = reshape(real(input), [batch, innerDimensionSize]);\n        const imagInput = reshape(imag(input), [batch, innerDimensionSize]);\n        const realConjugate = reverse(slice(realInput, [0, 1], [batch, innerDimensionSize - 2]), 1);\n        const imagConjugate = mul(reverse(slice(imagInput, [0, 1], [batch, innerDimensionSize - 2]), 1), scalar(-1));\n        const r = concat([realInput, realConjugate], 1);\n        const i = concat([imagInput, imagConjugate], 1);\n        const complexInput = reshape(complex(r, i), [outputShape[0], outputShape[1]]);\n        ret = ifft(complexInput);\n    }\n    ret = real(ret);\n    // reshape the result if the input is 3D tensor.\n    if (input.rank === 3 && input.shape[0] !== 0) {\n        const temp = ret;\n        const batch = input.shape[0];\n        ret = reshape(ret, [batch, ret.shape[0] / batch, ret.shape[1]]);\n        temp.dispose();\n    }\n    return ret;\n}\nexport const irfft = op({ irfft_ });\n//# sourceMappingURL=irfft.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { inferShape } from '../tensor_util_env';\nimport { assertNonNull } from '../util';\nimport { makeTensor } from './tensor_ops_util';\n/**\n * Creates rank-3 `tf.Tensor` with the provided values, shape and dtype.\n *\n * The same functionality can be achieved with `tf.tensor`, but in general\n * we recommend using `tf.tensor3d` as it makes the code more readable.\n *\n *  ```js\n * // Pass a nested array.\n * tf.tensor3d([[[1], [2]], [[3], [4]]]).print();\n * ```\n * ```js\n * // Pass a flat array and specify a shape.\n * tf.tensor3d([1, 2, 3, 4], [2, 2, 1]).print();\n * ```\n *\n * @param values The values of the tensor. Can be nested array of numbers,\n *     or a flat array, or a `TypedArray`.\n * @param shape The shape of the tensor. If not provided,  it is inferred from\n *     `values`.\n * @param dtype The data type.\n *\n * @doc {heading: 'Tensors', subheading: 'Creation'}\n */\nexport function tensor3d(values, shape, dtype) {\n    assertNonNull(values);\n    if (shape != null && shape.length !== 3) {\n        throw new Error('tensor3d() requires shape to have three numbers');\n    }\n    const inferredShape = inferShape(values, dtype);\n    if (inferredShape.length !== 3 && inferredShape.length !== 1) {\n        throw new Error('tensor3d() requires values to be number[][][] or flat/TypedArray');\n    }\n    if (inferredShape.length === 1 && shape == null) {\n        throw new Error('tensor3d() requires shape to be provided when `values` ' +\n            'are a flat array');\n    }\n    return makeTensor(values, shape, inferredShape, dtype);\n}\n//# sourceMappingURL=tensor3d.js.map","/**\n * @license\n * Copyright 2017 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n/**\n * Inputs of size above this threshold will be parallelized by calling multiple\n * shader programs.\n */\nimport { nearestDivisor } from '../util';\nexport const PARALLELIZE_THRESHOLD = 30;\nexport function computeOptimalWindowSize(inSize) {\n    if (inSize <= PARALLELIZE_THRESHOLD) {\n        return inSize;\n    }\n    return nearestDivisor(inSize, Math.floor(Math.sqrt(inSize)));\n}\n//# sourceMappingURL=reduce_util.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Sin } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes sin of the input Tensor element-wise: `sin(x)`\n *\n * ```js\n * const x = tf.tensor1d([0, Math.PI / 2, Math.PI * 3 / 4]);\n *\n * x.sin().print();  // or tf.sin(x)\n * ```\n * @param x The input tensor.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction sin_(x) {\n    const $x = convertToTensor(x, 'x', 'sin');\n    const inputs = { x: $x };\n    return ENGINE.runKernel(Sin, inputs);\n}\nexport const sin = op({ sin_ });\n//# sourceMappingURL=sin.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Sinh } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes hyperbolic sin of the input `tf.Tensor` element-wise: `sinh(x)`\n *\n * ```js\n * const x = tf.tensor1d([0, 1, -1, .7]);\n *\n * x.sinh().print();  // or tf.sinh(x)\n * ```\n * @param x The input tensor.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction sinh_(x) {\n    const $x = convertToTensor(x, 'x', 'sinh');\n    const inputs = { x: $x };\n    return ENGINE.runKernel(Sinh, inputs);\n}\nexport const sinh = op({ sinh_ });\n//# sourceMappingURL=sinh.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Rsqrt } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes reciprocal of square root of the input `tf.Tensor` element-wise:\n * `y = 1 / sqrt(x)`\n *\n * ```js\n * const x = tf.tensor1d([1, 2, 4, -1]);\n *\n * x.rsqrt().print();  // or tf.rsqrt(x)\n * ```\n * @param x The input tensor.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction rsqrt_(x) {\n    const $x = convertToTensor(x, 'x', 'rsqrt');\n    const inputs = { x: $x };\n    return ENGINE.runKernel(Rsqrt, inputs);\n}\nexport const rsqrt = op({ rsqrt_ });\n//# sourceMappingURL=rsqrt.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Softplus } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes softplus of the input `tf.Tensor` element-wise: `log(exp(x) + 1)`\n *\n * ```js\n * const x = tf.tensor1d([0, 1, -1, .7]);\n *\n * x.softplus().print();  // or tf.softplus(x)\n * ```\n * @param x The input tensor.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction softplus_(x) {\n    const $x = convertToTensor(x, 'x', 'softplus');\n    const inputs = { x: $x };\n    return ENGINE.runKernel(Softplus, inputs);\n}\nexport const softplus = op({ softplus_ });\n//# sourceMappingURL=softplus.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { OneHot } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Creates a one-hot `tf.Tensor`. The locations represented by `indices` take\n * value `onValue` (defaults to 1), while all other locations take value\n * `offValue` (defaults to 0). If `indices` is rank `R`, the output has rank\n * `R+1` with the last axis of size `depth`.\n *\n * ```js\n * tf.oneHot(tf.tensor1d([0, 1], 'int32'), 3).print();\n * ```\n *\n * @param indices `tf.Tensor` of indices with dtype `int32`.\n * @param depth The depth of the one hot dimension.\n * @param onValue A number used to fill in the output when the index matches\n * the location.\n * @param offValue A number used to fill in the output when the index does\n *     not match the location.\n *\n * @doc {heading: 'Tensors', subheading: 'Creation'}\n */\nfunction oneHot_(indices, depth, onValue = 1, offValue = 0) {\n    if (depth < 2) {\n        throw new Error(`Error in oneHot: depth must be >=2, but it is ${depth}`);\n    }\n    const $indices = convertToTensor(indices, 'indices', 'oneHot', 'int32');\n    const inputs = { indices: $indices };\n    const attrs = { depth, onValue, offValue };\n    return ENGINE.runKernel(OneHot, inputs, attrs);\n}\nexport const oneHot = op({ oneHot_ });\n//# sourceMappingURL=one_hot.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { convertToTensor } from '../tensor_util_env';\nimport * as util from '../util';\nimport { avgPool } from './avg_pool';\nimport { batchToSpaceND } from './batch_to_space_nd';\nimport * as conv_util from './conv_util';\nimport { maxPool } from './max_pool';\nimport { op } from './operation';\nimport { reshape } from './reshape';\nimport { spaceToBatchND } from './space_to_batch_nd';\n/**\n * Performs an N-D pooling operation\n *\n * @param input The input tensor, of rank 4 or rank 3 of shape\n *     `[batch, height, width, inChannels]`. If rank 3, batch of 1 is assumed.\n * @param windowShape The filter size: `[filterHeight, filterWidth]`. If\n *     `filterSize` is a single number, then `filterHeight == filterWidth`.\n * @param poolingType The type of pooling, either 'max' or 'avg'.\n * @param pad The type of padding algorithm:\n *    - `same` and stride 1: output will be of same size as input,\n *       regardless of filter size.\n *    - `valid`: output will be smaller than input if filter is larger\n *       than 1x1.\n *    - For more info, see this guide:\n *     [https://www.tensorflow.org/api_guides/python/nn#Convolution](\n *         https://www.tensorflow.org/api_guides/python/nn#Convolution)\n * @param dilations The dilation rates: `[dilationHeight, dilationWidth]`\n *     in which we sample input values across the height and width dimensions\n *     in dilated pooling. Defaults to `[1, 1]`. If `dilationRate` is a single\n *     number, then `dilationHeight == dilationWidth`. If it is greater than\n *     1, then all values of `strides` must be 1.\n * @param strides The strides of the pooling: `[strideHeight, strideWidth]`. If\n *     `strides` is a single number, then `strideHeight == strideWidth`.\n *\n * @doc {heading: 'Operations', subheading: 'Convolution'}\n */\nfunction pool_(input, windowShape, poolingType, pad, dilations, strides) {\n    if (dilations == null) {\n        dilations = [1, 1];\n    }\n    if (strides == null) {\n        strides = 1;\n    }\n    if (pad === 0) {\n        pad = 'valid';\n    }\n    const $x = convertToTensor(input, 'x', 'maxPool');\n    let x4D = $x;\n    let reshapedTo4D = false;\n    if ($x.rank === 3) {\n        reshapedTo4D = true;\n        x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);\n    }\n    util.assert(conv_util.eitherStridesOrDilationsAreOne(strides, dilations), () => 'Error in pool: Either strides or dilations must be 1. ' +\n        `Got strides ${strides} and dilations '${dilations}'`);\n    const convInfo = conv_util.computePool2DInfo(x4D.shape, windowShape, strides, dilations, pad);\n    const dilation = [convInfo.dilationHeight, convInfo.dilationWidth];\n    // The following implementation does batchToSpace(pool(spaceToBatch(x)))\n    // whenever dilation > 1 since the TF kernels do not support dilation > 1.\n    // tslint:disable-next-line:max-line-length\n    // https://github.com/tensorflow/tensorflow/blob/50f6bb67dc98c9b74630b6047aae7a4f8a40fd02/tensorflow/python/ops/nn_ops.py#L1037\n    let basePadding;\n    if (pad === 'same') {\n        basePadding = withSpaceToBatchBasePaddings([convInfo.filterHeight, convInfo.filterWidth], dilation);\n    }\n    else {\n        basePadding = [[0, 0], [0, 0]];\n    }\n    const isDilationOne = dilation[0] === 1 && dilation[1] === 1;\n    const [adjustedPadding, adjustedCrops] = requiredSpaceToBatchPaddings([convInfo.inHeight, convInfo.inWidth], dilation, basePadding);\n    const convertedPad = isDilationOne ? pad : 'valid';\n    const convertedX = isDilationOne ? x4D : spaceToBatchND(x4D, dilation, adjustedPadding);\n    const forwardOp = poolingType === 'avg' ?\n        () => avgPool(convertedX, windowShape, strides, convertedPad) :\n        () => maxPool(convertedX, windowShape, strides, convertedPad);\n    const y = forwardOp();\n    const res = isDilationOne ? y : batchToSpaceND(y, dilation, adjustedCrops);\n    if (reshapedTo4D) {\n        return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);\n    }\n    return res;\n}\n// Helper function to compute crops and paddings for pool with dilation > 1.\n// tslint:disable-next-line:max-line-length\n// https://github.com/tensorflow/tensorflow/blob/50f6bb67dc98c9b74630b6047aae7a4f8a40fd02/tensorflow/python/ops/array_ops.py#L2184\nfunction requiredSpaceToBatchPaddings(inputShape, blockShape, basePadding) {\n    const padStart = basePadding.map(b => b[0]);\n    const origPadEnd = basePadding.map(b => b[1]);\n    const fullInputShape = inputShape.concat(padStart, origPadEnd);\n    const padEndExtra = blockShape.map((b, i) => (b - fullInputShape[i] % b) % b);\n    const padEnd = origPadEnd.map((s, i) => s + padEndExtra[i]);\n    const paddings = blockShape.map((_, i) => [padStart[i], padEnd[i]]);\n    const crops = blockShape.map((_, i) => [0, padEndExtra[i]]);\n    return [paddings, crops];\n}\n// Helper function to compute base paddings for pool with dilation > 1.\n// tslint:disable-next-line:max-line-length\n// https://github.com/tensorflow/tensorflow/blob/50f6bb67dc98c9b74630b6047aae7a4f8a40fd02/tensorflow/python/ops/nn_ops.py#L524\nfunction withSpaceToBatchBasePaddings(filterShape, dilation) {\n    // Spatial dimensions of the filters and the upsampled filters in which we\n    // introduce (rate - 1) zeros between consecutive filter values.\n    const dilatedFilterShape = filterShape.map((s, i) => {\n        return s + (s - 1) * (dilation[i] - 1);\n    });\n    const padExtraShape = dilatedFilterShape.map(s => s - 1);\n    // When padding is odd, we pad more at end, following the same\n    // convention as conv2d.\n    const padExtraStart = padExtraShape.map(s => Math.floor(s / 2));\n    const padExtraEnd = padExtraShape.map((s, i) => s - padExtraStart[i]);\n    return padExtraShape.map((_, i) => {\n        return [padExtraStart[i], padExtraEnd[i]];\n    });\n}\nexport const pool = op({ pool_ });\n//# sourceMappingURL=pool.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Prod } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { cast } from './cast';\nimport { op } from './operation';\n/**\n * Computes the product of elements across dimensions of a `tf.Tensor`.\n *\n * Reduces the input along the dimensions given in `axes`. Unless `keepDims`\n * is true, the rank of the `tf.Tensor` is reduced by 1 for each entry in\n * `axes`. If `keepDims` is true, the reduced dimensions are retained with\n * length 1. If `axes` has no entries, all dimensions are reduced, and a\n * `tf.Tensor` with a single element is returned.\n *\n * ```js\n * const x = tf.tensor1d([1, 2, 3]);\n *\n * x.prod().print();  // or tf.prod(x)\n * ```\n *\n * ```js\n * const x = tf.tensor2d([1, 2, 3, 4], [2, 2]);\n *\n * const axis = 1;\n * x.prod(axis).print();  // or tf.prod(x, axis)\n * ```\n *\n * @param x The input tensor to compute the product over. If the dtype is `bool`\n *   it will be converted to `int32` and the output dtype will be `int32`.\n * @param axis The dimension(s) to reduce. By default it reduces\n *     all dimensions.\n * @param keepDims If true, retains reduced dimensions with size 1.\n *\n * @doc {heading: 'Operations', subheading: 'Reduction'}\n */\nfunction prod_(x, axis = null, keepDims = false) {\n    let $x = convertToTensor(x, 'x', 'prod');\n    if ($x.dtype === 'bool') {\n        // bool is not an allowed type for the underlying kernel.\n        $x = cast($x, 'int32');\n    }\n    const inputs = { x: $x };\n    const attrs = { axis, keepDims };\n    return ENGINE.runKernel(Prod, inputs, attrs);\n}\nexport const prod = op({ prod_ });\n//# sourceMappingURL=prod.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Selu } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes scaled exponential linear element-wise.\n *\n * `x < 0 ? scale * alpha * (exp(x) - 1) : x`\n *\n * ```js\n * const x = tf.tensor1d([-1, 2, -3, 4]);\n *\n * x.selu().print();  // or tf.selu(x)\n * ```\n * @param x The input tensor.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction selu_(x) {\n    const $x = convertToTensor(x, 'x', 'selu');\n    const inputs = { x: $x };\n    return ENGINE.runKernel(Selu, inputs);\n}\nexport const selu = op({ selu_ });\n//# sourceMappingURL=selu.js.map","import { convertToTensor } from '../tensor_util_env';\nimport * as util from '../util';\nimport { conv2d } from './conv2d';\nimport { depthwiseConv2d } from './depthwise_conv2d';\nimport { op } from './operation';\nimport { reshape } from './reshape';\n/**\n * 2-D convolution with separable filters.\n *\n * Performs a depthwise convolution that acts separately on channels followed\n * by a pointwise convolution that mixes channels. Note that this is\n * separability between dimensions [1, 2] and 3, not spatial separability\n * between dimensions 1 and 2.\n *\n * See\n * [https://www.tensorflow.org/api_docs/python/tf/nn/separable_conv2d](\n *     https://www.tensorflow.org/api_docs/python/tf/nn/separable_conv2d)\n * for more details.\n *\n * @param x The input tensor, of rank 4 or rank 3, of shape\n *     `[batch, height, width, inChannels]`. If rank 3, batch of 1 is\n * assumed.\n * @param depthwiseFilter The depthwise filter tensor, rank 4, of shape\n *     `[filterHeight, filterWidth, inChannels, channelMultiplier]`. This is\n *     the filter used in the first step.\n * @param pointwiseFilter The pointwise filter tensor, rank 4, of shape\n *     `[1, 1, inChannels * channelMultiplier, outChannels]`. This is\n *     the filter used in the second step.\n * @param strides The strides of the convolution: `[strideHeight,\n * strideWidth]`. If strides is a single number, then `strideHeight ==\n * strideWidth`.\n * @param pad The type of padding algorithm.\n *   - `same` and stride 1: output will be of same size as input,\n *       regardless of filter size.\n *   - `valid`: output will be smaller than input if filter is larger\n *       than 1x1.\n *   - For more info, see this guide:\n *     [https://www.tensorflow.org/api_guides/python/nn#Convolution](\n *          https://www.tensorflow.org/api_guides/python/nn#Convolution)\n * @param dilations The dilation rates: `[dilationHeight, dilationWidth]`\n *     in which we sample input values across the height and width dimensions\n *     in atrous convolution. Defaults to `[1, 1]`. If `rate` is a single\n *     number, then `dilationHeight == dilationWidth`. If it is greater than\n *     1, then all values of `strides` must be 1.\n * @param dataFormat: An optional string from: \"NHWC\", \"NCHW\". Defaults to\n *     \"NHWC\". Specify the data format of the input and output data. With the\n *     default format \"NHWC\", the data is stored in the order of: [batch,\n *     height, width, channels]. Only \"NHWC\" is currently supported.\n *\n * @doc {heading: 'Operations', subheading: 'Convolution'}\n */\nfunction separableConv2d_(x, depthwiseFilter, pointwiseFilter, strides, pad, dilation = [1, 1], dataFormat = 'NHWC') {\n    const $x = convertToTensor(x, 'x', 'separableConv2d');\n    const $depthwiseFilter = convertToTensor(depthwiseFilter, 'depthwiseFilter', 'separableConv2d');\n    const $pointwiseFilter = convertToTensor(pointwiseFilter, 'pointwiseFilter', 'separableConv2d');\n    let x4D = $x;\n    let reshapedTo4D = false;\n    if ($x.rank === 3) {\n        reshapedTo4D = true;\n        x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);\n    }\n    if (dataFormat === 'NCHW') {\n        throw new Error('separableConv2d currently does not support dataFormat NCHW; only ' +\n            'NHWC is supported');\n    }\n    util.assert(x4D.rank === 4, () => `Error in separableConv2d: input must be rank 4, but got ` +\n        `rank ${x4D.rank}.`);\n    util.assert($depthwiseFilter.rank === 4, () => `Error in separableConv2d: depthwise filter must be rank 4, but ` +\n        `got rank ${$depthwiseFilter.rank}.`);\n    util.assert($pointwiseFilter.rank === 4, () => `Error in separableConv2d: pointwise filter must be rank 4, but ` +\n        `got rank ${$depthwiseFilter.rank}.`);\n    util.assert($pointwiseFilter.shape[0] === 1, () => `Error in separableConv2d: the first dimension of pointwise filter ` +\n        ` must be 1, but got ${$pointwiseFilter.shape[0]}.`);\n    util.assert($pointwiseFilter.shape[1] === 1, () => `Error in separableConv2d: the second dimension of pointwise ` +\n        `filter must be 1, but got ${$pointwiseFilter.shape[1]}.`);\n    const inChannels = $depthwiseFilter.shape[2];\n    const channelMultiplier = $depthwiseFilter.shape[3];\n    util.assert($pointwiseFilter.shape[2] === inChannels * channelMultiplier, () => `Error in separableConv2d: the third dimension of pointwise filter ` +\n        `must be ${inChannels * channelMultiplier}, ` +\n        `but got ${$pointwiseFilter.shape[2]}.`);\n    const depthwise = depthwiseConv2d(x4D, $depthwiseFilter, strides, pad, dataFormat, dilation);\n    const pointwiseStride = 1;\n    const res = conv2d(depthwise, $pointwiseFilter, pointwiseStride, 'valid', dataFormat);\n    if (reshapedTo4D) {\n        return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);\n    }\n    return res;\n}\nexport const separableConv2d = op({ separableConv2d_ });\n//# sourceMappingURL=separable_conv2d.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { TopK } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Finds the values and indices of the `k` largest entries along the last\n * dimension.\n *\n * If the input is a vector (rank=1), finds the k largest entries in the vector\n * and outputs their values and indices as vectors. Thus values[j] is the j-th\n * largest entry in input, and its index is indices[j].\n * For higher rank inputs, computes the top k entries along the last dimension.\n *\n * If two elements are equal, the lower-index element appears first.\n *\n * ```js\n * const a = tf.tensor2d([[1, 5], [4, 3]]);\n * const {values, indices} = tf.topk(a);\n * values.print();\n * indices.print();\n * ```\n * @param x 1-D or higher `tf.Tensor` with last dimension being at least `k`.\n * @param k Number of top elements to look for along the last dimension.\n * @param sorted If true, the resulting `k` elements will be sorted by the\n *     values in descending order.\n *\n * @doc {heading: 'Operations', subheading: 'Evaluation'}\n */\nfunction topk_(x, k = 1, sorted = true) {\n    const $x = convertToTensor(x, 'x', 'topk');\n    if ($x.rank === 0) {\n        throw new Error('topk() expects the input to be of rank 1 or higher');\n    }\n    const lastDim = $x.shape[$x.shape.length - 1];\n    if (k > lastDim) {\n        throw new Error(`'k' passed to topk() must be <= the last dimension (${lastDim}) ` +\n            `but got ${k}`);\n    }\n    const inputs = { x: $x };\n    const attrs = { k, sorted };\n    const [values, indices] = ENGINE.runKernel(TopK, inputs, attrs);\n    return { values, indices };\n}\nexport const topk = op({ topk_ });\n//# sourceMappingURL=topk.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Unique } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { assert } from '../util';\nimport { op } from './operation';\n/**\n * Finds unique elements along an axis of a tensor.\n *\n * It returns a tensor `values` containing all of the unique elements along the\n * `axis` of the given tensor `x` in the same order that they occur along the\n * `axis` in `x`; `x` does not need to be sorted. It also returns a tensor\n * `indices` the same size as the number of the elements in `x` along the `axis`\n * dimension. It contains the index in the unique output `values`.\n *\n * ```js\n * // A 1-D tensor\n * const a = tf.tensor1d([1, 1, 2, 4, 4, 4, 7, 8, 8]);\n * const {values, indices} = tf.unique(a);\n * values.print();   // [1, 2, 4, 7, 8,]\n * indices.print();  // [0, 0, 1, 2, 2, 2, 3, 4, 4]\n * ```\n *\n * ```js\n * // A 2-D tensor with axis=0\n * //\n * // 'a' is: [[1, 0, 0],\n * //          [1, 0, 0],\n * //          [2, 0, 0]]\n * const a = tf.tensor2d([[1, 0, 0], [1, 0, 0], [2, 0, 0]]);\n * const {values, indices} = tf.unique(a, 0)\n * values.print();   // [[1, 0, 0],\n *                   //  [2, 0, 0]]\n * indices.print();  // [0, 0, 1]\n * ```\n *\n * ```js\n * // A 2-D tensor with axis=1\n * //\n * // 'a' is: [[1, 0, 0],\n * //          [1, 0, 0],\n * //          [2, 0, 0]]\n * const a = tf.tensor2d([[1, 0, 0], [1, 0, 0], [2, 0, 0]]);\n * const {values, indices} = tf.unique(a, 1)\n * values.print();   // [[1, 0],\n *                   //  [1, 0],\n *                   //  [2, 0]]\n * indices.print();  // [0, 1, 1]\n * ```\n * @param x A tensor (int32, string, bool).\n * @param axis The axis of the tensor to find the unique elements.\n * @returns [uniqueElements, indices] (see above for details)\n *\n * @doc {heading: 'Operations', subheading: 'Evaluation'}\n */\nfunction unique_(x, axis = 0) {\n    const $x = convertToTensor(x, 'x', 'unique', 'string_or_numeric');\n    assert($x.rank > 0, () => 'The input tensor must be at least 1D');\n    const inputs = { x: $x };\n    const attrs = { axis };\n    const [values, indices] = ENGINE.runKernel(Unique, inputs, attrs);\n    return { values, indices };\n}\nexport const unique = op({ unique_ });\n//# sourceMappingURL=unique.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { ZerosLike } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Creates a `tf.Tensor` with all elements set to 0 with the same shape as the\n * given tensor.\n *\n * ```js\n * const x = tf.tensor([1, 2]);\n * tf.zerosLike(x).print();\n * ```\n *\n * @param x The tensor of required shape.\n *\n * @doc {heading: 'Tensors', subheading: 'Creation'}\n */\nfunction zerosLike_(x) {\n    const $x = convertToTensor(x, 'x', 'zerosLike');\n    const inputs = { x: $x };\n    return ENGINE.runKernel(ZerosLike, inputs);\n}\nexport const zerosLike = op({ zerosLike_ });\n//# sourceMappingURL=zeros_like.js.map","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes square of `x` element-wise: `x ^ 2`\n *\n * ```js\n * const x = tf.tensor1d([1, 2, Math.sqrt(2), -1]);\n *\n * x.square().print();  // or tf.square(x)\n * ```\n * @param x The input Tensor.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction square_(x) {\n    const $x = convertToTensor(x, 'x', 'square');\n    const attrs = {};\n    return ENGINE.runKernel('Square', { x: $x }, attrs);\n}\nexport const square = op({ square_ });\n//# sourceMappingURL=square.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Slice } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Extracts a slice from a `tf.Tensor` starting at coordinates `begin`\n * and is of size `size`.\n *\n * Also available are stricter rank-specific methods with the same signature\n * as this method that assert that `x` is of the given rank:\n *   - `tf.slice1d`\n *   - `tf.slice2d`\n *   - `tf.slice3d`\n *   - `tf.slice4d`\n *\n * ```js\n * const x = tf.tensor1d([1, 2, 3, 4]);\n *\n * x.slice([1], [2]).print();\n * ```\n *\n * ```js\n * const x = tf.tensor2d([1, 2, 3, 4], [2, 2]);\n *\n * x.slice([1, 0], [1, 2]).print();\n * ```\n * @param x The input `tf.Tensor` to slice from.\n * @param begin The coordinates to start the slice from. The length can be\n *     less than the rank of x - the rest of the axes will have implicit 0 as\n *     start. Can also be a single number, in which case it specifies the\n *     first axis.\n * @param size The size of the slice. The length can be less than the rank of\n *     x - the rest of the axes will have implicit -1. A value of -1 requests\n *     the rest of the dimensions in the axis. Can also be a single number,\n *     in which case it specifies the size of the first axis.\n *\n * @doc {heading: 'Tensors', subheading: 'Slicing and Joining'}\n */\nfunction slice_(x, begin, size) {\n    const $x = convertToTensor(x, 'x', 'slice', 'string_or_numeric');\n    if ($x.rank === 0) {\n        throw new Error('Slicing scalar is not possible');\n    }\n    const inputs = { x: $x };\n    const attrs = { begin, size };\n    return ENGINE.runKernel(Slice, inputs, attrs);\n}\nexport const slice = op({ slice_ });\n//# sourceMappingURL=slice.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n// Returns the image center in pixels.\nexport function getImageCenter(center, imageHeight, imageWidth) {\n    const centerX = imageWidth * (typeof center === 'number' ? center : center[0]);\n    const centerY = imageHeight * (typeof center === 'number' ? center : center[1]);\n    return [centerX, centerY];\n}\n//# sourceMappingURL=rotate_util.js.map","import { assert } from '../util';\n/**\n * Prepare the split size array. When the input is a number, the axis is evenly\n * divided among the split size. When the input contains the negative value, the\n * rest of the axis is allocated toward that.\n */\nexport function prepareSplitSize(x, numOrSizeSplits, axis = 0) {\n    let splitSizes = [];\n    if (typeof (numOrSizeSplits) === 'number') {\n        assert(x.shape[axis] % numOrSizeSplits === 0, () => 'Number of splits must evenly divide the axis.');\n        splitSizes =\n            new Array(numOrSizeSplits).fill(x.shape[axis] / numOrSizeSplits);\n    }\n    else {\n        const numOfNegs = numOrSizeSplits.reduce((count, value) => {\n            if (value === -1) {\n                count += 1;\n            }\n            return count;\n        }, 0);\n        assert(numOfNegs <= 1, () => 'There should be only one negative value in split array.');\n        const negIndex = numOrSizeSplits.indexOf(-1);\n        // Allow the number of split array to be -1, which indicates the rest\n        // of dimension is allocated to that split.\n        if (negIndex !== -1) {\n            const total = numOrSizeSplits.reduce((a, b) => b > 0 ? a + b : a);\n            numOrSizeSplits[negIndex] = x.shape[axis] - total;\n        }\n        assert(x.shape[axis] === numOrSizeSplits.reduce((a, b) => a + b), () => 'The sum of sizes must match the size of the axis dimension.');\n        splitSizes = numOrSizeSplits;\n    }\n    return splitSizes;\n}\n//# sourceMappingURL=split_util.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { nearestDivisor } from '../util';\nimport { PARALLELIZE_THRESHOLD } from './reduce_util';\nexport function segOpComputeOptimalWindowSize(inSize, numSegments) {\n    let done = false;\n    let res;\n    if (inSize <= PARALLELIZE_THRESHOLD) {\n        res = inSize;\n        done = true;\n    }\n    else {\n        res = nearestDivisor(inSize, Math.floor(Math.sqrt(inSize)));\n    }\n    while (!done) {\n        if (res > numSegments || res === inSize) {\n            done = true;\n        }\n        else {\n            res = nearestDivisor(inSize, res + 1);\n        }\n    }\n    return res;\n}\nexport function computeOutShape(aShape, axis, numSegments) {\n    const outShape = [];\n    const rank = aShape.length;\n    for (let dim = 0; dim < rank; dim++) {\n        if (dim !== axis) {\n            outShape.push(aShape[dim]);\n        }\n        else {\n            outShape.push(numSegments);\n        }\n    }\n    return outShape;\n}\nexport function collectGatherOpShapeInfo(x, indices, axis, batchDims) {\n    const indicesRank = indices.shape.length;\n    const xRank = x.shape.length;\n    if (batchDims !== 0) {\n        if (batchDims < -indicesRank || batchDims > indicesRank) {\n            throw new Error(`Expect batchDims in the range of [-${indicesRank}, ${indicesRank}], but got ${batchDims}`);\n        }\n    }\n    if (batchDims < 0) {\n        batchDims += indicesRank;\n    }\n    if (batchDims > xRank) {\n        throw new Error(`batchDims (${batchDims}) must be less than rank(x) (\n    ${xRank}).`);\n    }\n    if (axis < batchDims) {\n        throw new Error(`batchDims (${batchDims}) must be less than or equal to axis (${axis}).`);\n    }\n    for (let i = 0; i < batchDims; ++i) {\n        if (x.shape[i] !== indices.shape[i]) {\n            throw new Error(`x.shape[${i}]: ${x.shape[i]} should be equal to indices.shape[${i}]: ${indices.shape[i]}.`);\n        }\n    }\n    const dimSize = x.shape[axis];\n    const outputShape = [];\n    let batchSize = 1;\n    let outerSize = 1;\n    let sliceSize = 1;\n    for (let i = 0; i < batchDims; ++i) {\n        outputShape.push(x.shape[i]);\n        batchSize *= x.shape[i];\n    }\n    for (let i = batchDims; i < axis; i++) {\n        outputShape.push(x.shape[i]);\n        outerSize *= x.shape[i];\n    }\n    for (let i = batchDims; i < indicesRank; i++) {\n        outputShape.push(indices.shape[i]);\n    }\n    for (let i = axis + 1; i < xRank; i++) {\n        outputShape.push(x.shape[i]);\n        sliceSize *= x.shape[i];\n    }\n    return { batchSize, sliceSize, outerSize, dimSize, outputShape };\n}\n//# sourceMappingURL=segment_util.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { OnesLike } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Creates a `tf.Tensor` with all elements set to 1 with the same shape as the\n * given tensor.\n *\n * ```js\n * const x = tf.tensor([1, 2]);\n * tf.onesLike(x).print();\n * ```\n * @param x A tensor.\n *\n * @doc {heading: 'Tensors', subheading: 'Creation'}\n */\nfunction onesLike_(x) {\n    const $x = convertToTensor(x, 'x', 'onesLike');\n    const inputs = { x: $x };\n    return ENGINE.runKernel(OnesLike, inputs);\n}\nexport const onesLike = op({ onesLike_ });\n//# sourceMappingURL=ones_like.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Reciprocal } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes reciprocal of x element-wise: `1 / x`\n *\n * ```js\n * const x = tf.tensor1d([0, 1, 2]);\n *\n * x.reciprocal().print();  // or tf.reciprocal(x)\n * ```\n * @param x The input tensor.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction reciprocal_(x) {\n    const $x = convertToTensor(x, 'x', 'reciprocal');\n    const inputs = { x: $x };\n    return ENGINE.runKernel(Reciprocal, inputs);\n}\nexport const reciprocal = op({ reciprocal_ });\n//# sourceMappingURL=reciprocal.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { isPromise } from '../util';\nexport const OP_SCOPE_SUFFIX = '__op';\n/**\n * Used for wrapping functions that perform math operations on\n * Tensors. The function will be wrapped in a named scope that cleans all\n * memory usage after the function is done.\n */\nexport function op(f) {\n    const keys = Object.keys(f);\n    if (keys.length !== 1) {\n        throw new Error(`Please provide an object with a single key ` +\n            `(operation name) mapping to a function. Got an object with ` +\n            `${keys.length} keys.`);\n    }\n    let opName = keys[0];\n    const fn = f[opName];\n    // Strip the underscore from the end of the function name.\n    if (opName.endsWith('_')) {\n        opName = opName.substring(0, opName.length - 1);\n    }\n    // add an __op suffix to distinguish ops from kernels in tf.profile\n    opName = opName + OP_SCOPE_SUFFIX;\n    // tslint:disable-next-line:no-any\n    const f2 = (...args) => {\n        ENGINE.startScope(opName);\n        try {\n            const result = fn(...args);\n            if (isPromise(result)) {\n                console.error('Cannot return a Promise inside of tidy.');\n            }\n            ENGINE.endScope(result);\n            return result;\n        }\n        catch (ex) {\n            ENGINE.endScope(null);\n            throw ex;\n        }\n    };\n    Object.defineProperty(f2, 'name', { value: opName, configurable: true });\n    // tslint:disable-next-line:no-any\n    return f2;\n}\n//# sourceMappingURL=operation.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Round } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes round of input `tf.Tensor` element-wise: `round(x)`.\n * It implements banker's rounding.\n *\n * ```js\n * const x = tf.tensor1d([.6, 1.1, -3.3]);\n *\n * x.round().print();  // or tf.round(x)\n * ```\n * @param x The input tensor.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction round_(x) {\n    const $x = convertToTensor(x, 'x', 'round');\n    const inputs = { x: $x };\n    return ENGINE.runKernel(Round, inputs);\n}\nexport const round = op({ round_ });\n//# sourceMappingURL=round.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Sign } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Returns an element-wise indication of the sign of a number.\n *\n * ```js\n * const x = tf.tensor1d([.6, 1.1, -3.3, NaN, 0]);\n *\n * x.sign().print();  // or tf.sign(x)\n * ```\n * @param x The input Tensor.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction sign_(x) {\n    const $x = convertToTensor(x, 'x', 'sign');\n    const inputs = { x: $x };\n    return ENGINE.runKernel(Sign, inputs);\n}\nexport const sign = op({ sign_ });\n//# sourceMappingURL=sign.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Softmax } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes the softmax normalized vector given the logits.\n *\n * ```js\n * const a = tf.tensor1d([1, 2, 3]);\n *\n * a.softmax().print();  // or tf.softmax(a)\n * ```\n *\n * ```js\n * const a = tf.tensor2d([2, 4, 6, 1, 2, 3], [2, 3]);\n *\n * a.softmax().print();  // or tf.softmax(a)\n * ```\n *\n * @param logits The logits array.\n * @param dim The dimension softmax would be performed on. Defaults to `-1`\n *     which indicates the last dimension.\n *\n * @doc {heading: 'Operations', subheading: 'Normalization'}\n */\nfunction softmax_(logits, dim = -1) {\n    const $logits = convertToTensor(logits, 'logits', 'softmax', 'float32');\n    if (dim === -1) {\n        dim = $logits.rank - 1;\n    }\n    if (dim !== $logits.rank - 1) {\n        throw Error('Softmax along a non-last dimension is not yet supported. ' +\n            `Logits was rank ${$logits.rank} and dim was ${dim}`);\n    }\n    const inputs = { logits: $logits };\n    const attrs = { dim };\n    return ENGINE.runKernel(Softmax, inputs, attrs);\n}\nexport const softmax = op({ softmax_ });\n//# sourceMappingURL=softmax.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { StridedSlice } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Extracts a strided slice of a tensor.\n *\n * Roughly speaking, this op extracts a slice of size (end-begin)/stride from\n * the given input tensor (x). Starting at the location specified by begin the\n * slice continues by adding stride to the index until all dimensions are not\n * less than end. Note that a stride can be negative, which causes a reverse\n * slice.\n *\n * ```js\n * const t = tf.tensor3d([1, 1, 1 ,2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 6, 6, 6],\n *    [3, 2, 3]);\n * t.stridedSlice([1, 0, 0], [2, 1, 3], [1, 1, 1]).print()  // [[[3, 3, 3]]]\n * t.stridedSlice([1, 0, 0], [2, 2, 3], [1, 1, 1]).print()  // [[[3, 3, 3],\n *                                                     // [4, 4, 4]]]\n * t.stridedSlice([1, -1, 0], [2, -3, 3], [1, -1, 1]).print() // [[[4, 4, 4],\n *                                                     // [3, 3, 3]]]\n * ```\n *\n * @param x The tensor to stride slice.\n * @param begin The coordinates to start the slice from.\n * @param end: The coordinates to end the slice at.\n * @param strides: The size of the slice.\n * @param beginMask: If the ith bit of beginMask is set, begin[i] is ignored\n *      and the fullest possible range in that dimension is used instead.\n * @param endMask: If the ith bit of endMask is set, end[i] is ignored\n *      and the fullest possible range in that dimension is used instead.\n * @param shrinkAxisMask: a bitmask where bit i implies that\n * the ith specification should shrink the dimensionality. begin and end must\n * imply a slice of size 1 in the dimension.\n *\n * @doc {heading: 'Operations', subheading: 'Slicing and Joining'}\n */\nfunction stridedSlice_(x, begin, end, strides, beginMask = 0, endMask = 0, ellipsisMask = 0, newAxisMask = 0, shrinkAxisMask = 0) {\n    const $x = convertToTensor(x, 'x', 'stridedSlice');\n    const inputs = { x: $x };\n    const attrs = {\n        begin,\n        end,\n        strides,\n        beginMask,\n        endMask,\n        ellipsisMask,\n        newAxisMask,\n        shrinkAxisMask\n    };\n    return ENGINE.runKernel(StridedSlice, inputs, attrs);\n}\nexport const stridedSlice = op({ stridedSlice_ });\n//# sourceMappingURL=strided_slice.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Tan } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes tan of the input `tf.Tensor` element-wise, `tan(x)`\n *\n * ```js\n * const x = tf.tensor1d([0, Math.PI / 2, Math.PI * 3 / 4]);\n *\n * x.tan().print();  // or tf.tan(x)\n * ```\n * @param x The input tensor.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction tan_(x) {\n    const $x = convertToTensor(x, 'x', 'tan');\n    const inputs = { x: $x };\n    return ENGINE.runKernel(Tan, inputs);\n}\nexport const tan = op({ tan_ });\n//# sourceMappingURL=tan.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Tanh } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes hyperbolic tangent of the input `tf.Tensor` element-wise: `tanh(x)`\n *\n * ```js\n * const x = tf.tensor1d([0, 1, -1, 70]);\n *\n * x.tanh().print();  // or tf.tanh(x)\n * ```\n * @param x The input tensor.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction tanh_(x) {\n    const $x = convertToTensor(x, 'x', 'tanh');\n    const inputs = { x: $x };\n    return ENGINE.runKernel(Tanh, inputs);\n}\nexport const tanh = op({ tanh_ });\n//# sourceMappingURL=tanh.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Select } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { assert, assertShapesMatch } from '../util';\nimport { broadcastTo } from './broadcast_to';\nimport { assertAndGetBroadcastShape } from './broadcast_util';\nimport { op } from './operation';\n/**\n * Returns the elements, either `a` or `b` depending on the `condition`.\n *\n * If the condition is true, select from `a`, otherwise select from `b`.\n *\n * ```js\n * const cond = tf.tensor1d([false, false, true], 'bool');\n * const a = tf.tensor1d([1 , 2, 3]);\n * const b = tf.tensor1d([-1, -2, -3]);\n *\n * a.where(cond, b).print();\n * ```\n *\n * @param condition The input condition. Must be of dtype bool.\n * @param a If `condition` is rank 1, `a` may have a higher rank but\n *     its first dimension must match the size of `condition`.\n * @param b A tensor with the same dtype as `a` and with shape that is\n *     compatible with `a`.\n * @return A tensor with same dtype as `a` and `b`, and shape that is\n *     broadcastable from `a` and `b`.\n *\n * @doc {heading: 'Operations', subheading: 'Logical'}\n */\nfunction where_(condition, a, b) {\n    const $a = convertToTensor(a, 'a', 'where');\n    const $b = convertToTensor(b, 'b', 'where');\n    const $condition = convertToTensor(condition, 'condition', 'where', 'bool');\n    // TODO: move this logic to forward function when the broadcastTo op is\n    // implemented in WASM.\n    // Find the broadcastable shape for $a and $b.\n    const broadcastShape = assertAndGetBroadcastShape($a.shape, $b.shape);\n    const $broadcastedA = broadcastTo($a, broadcastShape);\n    const $broadcastedB = broadcastTo($b, broadcastShape);\n    if ($condition.rank === 1) {\n        // If condition rank is 1, then the first dimension must match the size of\n        // condition.\n        assert($condition.shape[0] === $a.shape[0], () => 'The first dimension of `a` must match the size of `condition`.');\n    }\n    if ($condition.rank !== 1) {\n        // A must have the same shape as condition.\n        assertShapesMatch($condition.shape, $broadcastedB.shape, 'Error in where: ');\n    }\n    const inputs = {\n        condition: $condition,\n        t: $broadcastedA,\n        e: $broadcastedB\n    };\n    return ENGINE.runKernel(Select, inputs);\n}\nexport const where = op({ where_ });\n//# sourceMappingURL=where.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Sqrt } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes square root of the input `tf.Tensor` element-wise: `y = sqrt(x)`\n *\n * ```js\n * const x = tf.tensor1d([1, 2, 4, -1]);\n *\n * x.sqrt().print();  // or tf.sqrt(x)\n * ```\n * @param x The input tensor.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction sqrt_(x) {\n    const $x = convertToTensor(x, 'x', 'sqrt');\n    const inputs = { x: $x };\n    return ENGINE.runKernel(Sqrt, inputs);\n}\nexport const sqrt = op({ sqrt_ });\n//# sourceMappingURL=sqrt.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Transpose } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport * as util from '../util';\nimport { op } from './operation';\n/**\n * Transposes the `tf.Tensor`. Permutes the dimensions according to `perm`.\n *\n * The returned `tf.Tensor`'s dimension `i` will correspond to the input\n * dimension `perm[i]`. If `perm` is not given, it is set to `[n-1...0]`,\n * where `n` is the rank of the input `tf.Tensor`. Hence by default, this\n * operation performs a regular matrix transpose on 2-D input `tf.Tensor`s.\n *\n * ```js\n * const a = tf.tensor2d([1, 2, 3, 4, 5, 6], [2, 3]);\n *\n * a.transpose().print();  // or tf.transpose(a)\n * ```\n *\n * @param x The tensor to transpose.\n * @param perm The permutation of the dimensions of a.\n *\n * @doc {heading: 'Operations', subheading: 'Matrices'}\n */\nfunction transpose_(x, perm) {\n    const $x = convertToTensor(x, 'x', 'transpose');\n    if (perm == null) {\n        perm = $x.shape.map((s, i) => i).reverse();\n    }\n    util.assert($x.rank === perm.length, () => `Error in transpose: rank of input ${$x.rank} ` +\n        `must match length of perm ${perm}.`);\n    perm.forEach(axis => {\n        util.assert(axis >= 0 && axis < $x.rank, () => `All entries in 'perm' must be between 0 and ${$x.rank - 1}` +\n            ` but got ${perm}`);\n    });\n    if ($x.rank <= 1) {\n        return $x.clone();\n    }\n    const inputs = { x: $x };\n    const attrs = { perm };\n    return ENGINE.runKernel(Transpose, inputs, attrs);\n}\nexport const transpose = op({ transpose_ });\n//# sourceMappingURL=transpose.js.map","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport '../flags';\nimport { env } from '../environment';\nimport { BrowserIndexedDB, BrowserIndexedDBManager } from '../io/indexed_db';\nimport { BrowserLocalStorage, BrowserLocalStorageManager } from '../io/local_storage';\nimport { ModelStoreManagerRegistry } from '../io/model_management';\nexport class PlatformBrowser {\n    fetch(path, init) {\n        return fetch(path, init);\n    }\n    now() {\n        return performance.now();\n    }\n    encode(text, encoding) {\n        if (encoding !== 'utf-8' && encoding !== 'utf8') {\n            throw new Error(`Browser's encoder only supports utf-8, but got ${encoding}`);\n        }\n        if (this.textEncoder == null) {\n            this.textEncoder = new TextEncoder();\n        }\n        return this.textEncoder.encode(text);\n    }\n    decode(bytes, encoding) {\n        return new TextDecoder(encoding).decode(bytes);\n    }\n}\nif (env().get('IS_BROWSER')) {\n    env().setPlatform('browser', new PlatformBrowser());\n    // Register LocalStorage IOHandler\n    try {\n        ModelStoreManagerRegistry.registerManager(BrowserLocalStorage.URL_SCHEME, new BrowserLocalStorageManager());\n    }\n    catch (err) {\n    }\n    // Register IndexedDB IOHandler\n    try {\n        ModelStoreManagerRegistry.registerManager(BrowserIndexedDB.URL_SCHEME, new BrowserIndexedDBManager());\n    }\n    catch (err) {\n    }\n}\n//# sourceMappingURL=platform_browser.js.map","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { env } from '../environment';\n// We are wrapping this within an object so it can be stubbed by Jasmine.\nexport const getNodeFetch = {\n    // tslint:disable-next-line:no-require-imports\n    importFetch: () => require('node-fetch')\n};\nlet systemFetch;\n// These getters and setters are for testing so we don't export a mutable\n// variable.\nexport function resetSystemFetch() {\n    systemFetch = null;\n}\nexport function setSystemFetch(fetchFn) {\n    systemFetch = fetchFn;\n}\nexport function getSystemFetch() {\n    return systemFetch;\n}\nexport class PlatformNode {\n    constructor() {\n        // tslint:disable-next-line:no-require-imports\n        this.util = require('util');\n        // According to the spec, the built-in encoder can do only UTF-8 encoding.\n        // https://developer.mozilla.org/en-US/docs/Web/API/TextEncoder/TextEncoder\n        this.textEncoder = new this.util.TextEncoder();\n    }\n    fetch(path, requestInits) {\n        if (env().global.fetch != null) {\n            return env().global.fetch(path, requestInits);\n        }\n        if (systemFetch == null) {\n            systemFetch = getNodeFetch.importFetch();\n        }\n        return systemFetch(path, requestInits);\n    }\n    now() {\n        const time = process.hrtime();\n        return time[0] * 1000 + time[1] / 1000000;\n    }\n    encode(text, encoding) {\n        if (encoding !== 'utf-8' && encoding !== 'utf8') {\n            throw new Error(`Node built-in encoder only supports utf-8, but got ${encoding}`);\n        }\n        return this.textEncoder.encode(text);\n    }\n    decode(bytes, encoding) {\n        if (bytes.length === 0) {\n            return '';\n        }\n        return new this.util.TextDecoder(encoding).decode(bytes);\n    }\n}\nif (env().get('IS_NODE')) {\n    env().setPlatform('node', new PlatformNode());\n}\n//# sourceMappingURL=platform_node.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Pack } from '../kernel_names';\nimport { convertToTensorArray } from '../tensor_util_env';\nimport * as util from '../util';\nimport { op } from './operation';\n/**\n * Stacks a list of rank-`R` `tf.Tensor`s into one rank-`(R+1)` `tf.Tensor`.\n *\n * ```js\n * const a = tf.tensor1d([1, 2]);\n * const b = tf.tensor1d([3, 4]);\n * const c = tf.tensor1d([5, 6]);\n * tf.stack([a, b, c]).print();\n * ```\n *\n * @param tensors A list of tensor objects with the same shape and dtype.\n * @param axis The axis to stack along. Defaults to 0 (the first dim).\n *\n * @doc {heading: 'Tensors', subheading: 'Slicing and Joining'}\n */\nfunction stack_(tensors, axis = 0) {\n    const $tensors = convertToTensorArray(tensors, 'tensors', 'stack', 'string_or_numeric');\n    util.assert($tensors.length >= 1, () => 'Pass at least one tensor to tf.stack');\n    if ($tensors.length > 0) {\n        util.assert(axis <= $tensors[0].rank, () => 'Axis must be <= rank of the tensor');\n    }\n    const inputs = $tensors;\n    const attrs = { axis };\n    return ENGINE.runKernel(Pack, inputs, attrs);\n}\nexport const stack = op({ stack_ });\n//# sourceMappingURL=stack.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { makeZerosTypedArray, sizeFromShape } from '../util';\nimport { complex } from './complex';\n/**\n * Creates a `tf.Tensor` with all elements set to 0.\n *\n * ```js\n * tf.zeros([2, 2]).print();\n * ```\n *\n * @param shape An array of integers defining the output tensor shape.\n * @param dtype The type of an element in the resulting tensor. Can\n *     be 'float32', 'int32' or 'bool'. Defaults to 'float'.\n *\n * @doc {heading: 'Tensors', subheading: 'Creation'}\n */\nexport function zeros(shape, dtype = 'float32') {\n    if (dtype === 'complex64') {\n        const real = zeros(shape, 'float32');\n        const imag = zeros(shape, 'float32');\n        return complex(real, imag);\n    }\n    const values = makeZerosTypedArray(sizeFromShape(shape), dtype);\n    return ENGINE.makeTensor(values, shape, dtype);\n}\n//# sourceMappingURL=zeros.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Pow } from '../kernel_names';\nimport { makeTypesMatch } from '../tensor_util';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes the power of one `tf.Tensor` to another. Supports broadcasting.\n *\n * Given a `tf.Tensor` x and a `tf.Tensor` y, this operation computes x^y for\n * corresponding elements in x and y. The result's dtype will be the upcasted\n * type of the `base` and `exp` dtypes.\n *\n * ```js\n * const a = tf.tensor([[2, 3], [4, 5]])\n * const b = tf.tensor([[1, 2], [3, 0]]).toInt();\n *\n * a.pow(b).print();  // or tf.pow(a, b)\n * ```\n *\n * ```js\n * const a = tf.tensor([[1, 2], [3, 4]])\n * const b = tf.tensor(2).toInt();\n *\n * a.pow(b).print();  // or tf.pow(a, b)\n * ```\n * We also expose `powStrict` which has the same signature as this op and\n * asserts that `base` and `exp` are the same shape (does not broadcast).\n *\n * @param base The base `tf.Tensor` to pow element-wise.\n * @param exp The exponent `tf.Tensor` to pow element-wise.\n *\n * @doc {heading: 'Operations', subheading: 'Arithmetic'}\n */\nfunction pow_(base, exp) {\n    let $base = convertToTensor(base, 'base', 'pow');\n    let $exp = convertToTensor(exp, 'exp', 'pow');\n    [$base, $exp] = makeTypesMatch($base, $exp);\n    const inputs = { a: $base, b: $exp };\n    return ENGINE.runKernel(Pow, inputs);\n}\nexport const pow = op({ pow_ });\n//# sourceMappingURL=pow.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport * as util from '../util';\nfunction nonMaxSuppSanityCheck(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma) {\n    if (iouThreshold == null) {\n        iouThreshold = 0.5;\n    }\n    if (scoreThreshold == null) {\n        scoreThreshold = Number.NEGATIVE_INFINITY;\n    }\n    if (softNmsSigma == null) {\n        softNmsSigma = 0.0;\n    }\n    const numBoxes = boxes.shape[0];\n    maxOutputSize = Math.min(maxOutputSize, numBoxes);\n    util.assert(0 <= iouThreshold && iouThreshold <= 1, () => `iouThreshold must be in [0, 1], but was '${iouThreshold}'`);\n    util.assert(boxes.rank === 2, () => `boxes must be a 2D tensor, but was of rank '${boxes.rank}'`);\n    util.assert(boxes.shape[1] === 4, () => `boxes must have 4 columns, but 2nd dimension was ${boxes.shape[1]}`);\n    util.assert(scores.rank === 1, () => 'scores must be a 1D tensor');\n    util.assert(scores.shape[0] === numBoxes, () => `scores has incompatible shape with boxes. Expected ${numBoxes}, ` +\n        `but was ${scores.shape[0]}`);\n    util.assert(0 <= softNmsSigma && softNmsSigma <= 1, () => `softNmsSigma must be in [0, 1], but was '${softNmsSigma}'`);\n    return { maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma };\n}\nexport { nonMaxSuppSanityCheck };\n//# sourceMappingURL=nonmax_util.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { inferShape } from '../tensor_util_env';\nimport { assertNonNull } from '../util';\nimport { makeTensor } from './tensor_ops_util';\n/**\n * Creates rank-1 `tf.Tensor` with the provided values, shape and dtype.\n *\n * The same functionality can be achieved with `tf.tensor`, but in general\n * we recommend using `tf.tensor1d` as it makes the code more readable.\n *\n * ```js\n * tf.tensor1d([1, 2, 3]).print();\n * ```\n *\n * @param values The values of the tensor. Can be array of numbers,\n *     or a `TypedArray`.\n * @param dtype The data type.\n *\n * @doc {heading: 'Tensors', subheading: 'Creation'}\n */\nexport function tensor1d(values, dtype) {\n    assertNonNull(values);\n    const inferredShape = inferShape(values, dtype);\n    if (inferredShape.length !== 1) {\n        throw new Error('tensor1d() requires values to be a flat/TypedArray');\n    }\n    const shape = null;\n    return makeTensor(values, shape, inferredShape, dtype);\n}\n//# sourceMappingURL=tensor1d.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { SplitV } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Splits a `tf.Tensor` into sub tensors.\n *\n * If `numOrSizeSplits` is a number, splits `x` along dimension `axis`\n * into `numOrSizeSplits` smaller tensors.\n * Requires that `numOrSizeSplits` evenly divides `x.shape[axis]`.\n *\n * If `numOrSizeSplits` is a number array, splits `x` into\n * `numOrSizeSplits.length` pieces. The shape of the `i`-th piece has the\n * same size as `x` except along dimension `axis` where the size is\n * `numOrSizeSplits[i]`.\n *\n * ```js\n * const x = tf.tensor2d([1, 2, 3, 4, 5, 6, 7, 8], [2, 4]);\n * const [a, b] = tf.split(x, 2, 1);\n * a.print();\n * b.print();\n *\n * const [c, d, e] = tf.split(x, [1, 2, 1], 1);\n * c.print();\n * d.print();\n * e.print();\n * ```\n *\n * @param x The input tensor to split.\n * @param numOrSizeSplits Either an integer indicating the number of\n * splits along the axis or an array of integers containing the sizes of\n * each output tensor along the axis. If a number then it must evenly divide\n * `x.shape[axis]`; otherwise the sum of sizes must match `x.shape[axis]`.\n * Can contain one -1 indicating that dimension is to be inferred.\n * @param axis The dimension along which to split. Defaults to 0 (the first\n * dim).\n *\n * @doc {heading: 'Tensors', subheading: 'Slicing and Joining'}\n */\nfunction split_(x, numOrSizeSplits, axis = 0) {\n    const $x = convertToTensor(x, 'x', 'split');\n    const inputs = { x: $x };\n    const attr = { numOrSizeSplits, axis };\n    return ENGINE.runKernel(SplitV, inputs, attr);\n}\nexport const split = op({ split_ });\n//# sourceMappingURL=split.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Unpack } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport * as util from '../util';\nimport { op } from './operation';\n/**\n * Unstacks a `tf.Tensor` of rank-`R` into a list of rank-`(R-1)` `tf.Tensor`s.\n *\n * ```js\n * const a = tf.tensor2d([1, 2, 3, 4], [2, 2]);\n *\n * tf.unstack(a).forEach(tensor => tensor.print());\n * ```\n *\n * @param x A tensor object.\n * @param axis The axis to unstack along. Defaults to 0 (the first dim).\n *\n * @doc {heading: 'Tensors', subheading: 'Slicing and Joining'}\n */\nfunction unstack_(x, axis = 0) {\n    const $x = convertToTensor(x, 'x', 'unstack', 'string_or_numeric');\n    util.assert(axis >= -$x.shape.length && axis < $x.shape.length, () => `Axis = ${axis} is not in [-${$x.shape.length}, ${$x.shape.length})`);\n    const inputs = { value: $x };\n    const attrs = { axis };\n    return ENGINE.runKernel(Unpack, inputs, attrs);\n}\nexport const unstack = op({ unstack_ });\n//# sourceMappingURL=unstack.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { makeOnesTypedArray, sizeFromShape } from '../util';\nimport { complex } from './complex';\nimport { zeros } from './zeros';\n/**\n * Creates a `tf.Tensor` with all elements set to 1.\n *\n * ```js\n * tf.ones([2, 2]).print();\n * ```\n *\n * @param shape An array of integers defining the output tensor shape.\n * @param dtype The type of an element in the resulting tensor. Defaults to\n *     'float'.\n *\n * @doc {heading: 'Tensors', subheading: 'Creation'}\n */\nexport function ones(shape, dtype = 'float32') {\n    if (dtype === 'complex64') {\n        const real = ones(shape, 'float32');\n        const imag = zeros(shape, 'float32');\n        return complex(real, imag);\n    }\n    const values = makeOnesTypedArray(sizeFromShape(shape), dtype);\n    return ENGINE.makeTensor(values, shape, dtype);\n}\n//# sourceMappingURL=ones.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Relu } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes rectified linear element-wise: `max(x, 0)`.\n *\n * ```js\n * const x = tf.tensor1d([-1, 2, -3, 4]);\n *\n * x.relu().print();  // or tf.relu(x)\n * ```\n * @param x The input tensor. If the dtype is `bool`, the output dtype will be\n *     `int32'.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction relu_(x) {\n    const $x = convertToTensor(x, 'x', 'relu');\n    const inputs = { x: $x };\n    return ENGINE.runKernel(Relu, inputs);\n}\nexport const relu = op({ relu_ });\n//# sourceMappingURL=relu.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Step } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes step of the input `tf.Tensor` element-wise: `x > 0 ? 1 : alpha * x`\n *\n * ```js\n * const x = tf.tensor1d([0, 2, -1, -3]);\n *\n * x.step(.5).print();  // or tf.step(x, .5)\n * ```\n * @param x The input tensor.\n * @param alpha The gradient when input is negative.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction step_(x, alpha = 0.0) {\n    const $x = convertToTensor(x, 'x', 'step');\n    const inputs = { x: $x };\n    const attrs = { alpha };\n    return ENGINE.runKernel(Step, inputs, attrs);\n}\nexport const step = op({ step_ });\n//# sourceMappingURL=step.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { assert, assertNonNegativeIntegerDimensions, flatten, inferDtype, isTypedArray, sizeFromShape, toTypedArray } from '../util';\n/** This is shared code across all tensor creation methods. */\nexport function makeTensor(values, shape, inferredShape, dtype) {\n    if (dtype == null) {\n        dtype = inferDtype(values);\n    }\n    if (dtype === 'complex64') {\n        throw new Error(`Cannot construct a complex64 tensor directly. ` +\n            `Please use tf.complex(real, imag).`);\n    }\n    if (!isTypedArray(values) && !Array.isArray(values) &&\n        typeof values !== 'number' && typeof values !== 'boolean' &&\n        typeof values !== 'string') {\n        throw new Error('values passed to tensor(values) must be a number/boolean/string or ' +\n            'an array of numbers/booleans/strings, or a TypedArray');\n    }\n    if (shape != null) {\n        assertNonNegativeIntegerDimensions(shape);\n        const providedSize = sizeFromShape(shape);\n        const inferredSize = sizeFromShape(inferredShape);\n        assert(providedSize === inferredSize, () => `Based on the provided shape, [${shape}], the tensor should have ` +\n            `${providedSize} values but has ${inferredSize}`);\n        for (let i = 0; i < inferredShape.length; ++i) {\n            const inferred = inferredShape[i];\n            const flatDimsDontMatch = i === inferredShape.length - 1 ?\n                inferred !== sizeFromShape(shape.slice(i)) :\n                true;\n            assert(inferredShape[i] === shape[i] || !flatDimsDontMatch, () => `Error creating a new Tensor. Inferred shape ` +\n                `(${inferredShape}) does not match the provided ` +\n                `shape (${shape}). `);\n        }\n    }\n    if (!isTypedArray(values) && !Array.isArray(values)) {\n        values = [values];\n    }\n    shape = shape || inferredShape;\n    values = dtype !== 'string' ?\n        toTypedArray(values, dtype) :\n        flatten(values, [], true);\n    return ENGINE.makeTensor(values, shape, dtype);\n}\n//# sourceMappingURL=tensor_ops_util.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Tile } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport * as util from '../util';\nimport { op } from './operation';\n/**\n * Construct a tensor by repeating it the number of times given by reps.\n *\n * This operation creates a new tensor by replicating `input` `reps`\n * times. The output tensor's i'th dimension has `input.shape[i] *\n * reps[i]` elements, and the values of `input` are replicated\n * `reps[i]` times along the i'th dimension. For example, tiling\n * `[a, b, c, d]` by `[2]` produces `[a, b, c, d, a, b, c, d]`.\n *\n * ```js\n * const a = tf.tensor1d([1, 2]);\n *\n * a.tile([2]).print();    // or a.tile([2])\n * ```\n *\n * ```js\n * const a = tf.tensor2d([1, 2, 3, 4], [2, 2]);\n *\n * a.tile([1, 2]).print();  // or a.tile([1, 2])\n * ```\n * @param x The tensor to tile.\n * @param reps Determines the number of replications per dimension.\n *\n * @doc {heading: 'Tensors', subheading: 'Slicing and Joining'}\n */\nfunction tile_(x, reps) {\n    const $x = convertToTensor(x, 'x', 'tile', 'string_or_numeric');\n    util.assert($x.rank === reps.length, () => `Error in transpose: rank of input ${$x.rank} ` +\n        `must match length of reps ${reps}.`);\n    const inputs = { x: $x };\n    const attrs = { reps };\n    return ENGINE.runKernel(Tile, inputs, attrs);\n}\nexport const tile = op({ tile_ });\n//# sourceMappingURL=tile.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Reshape } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Reshapes a `tf.Tensor` to a given shape.\n *\n * Given an input tensor, returns a new tensor with the same values as the\n * input tensor with shape `shape`.\n *\n * If one component of shape is the special value -1, the size of that\n * dimension is computed so that the total size remains constant. In\n * particular, a shape of [-1] flattens into 1-D. At most one component of\n * shape can be -1.\n *\n * If shape is 1-D or higher, then the operation returns a tensor with shape\n * shape filled with the values of tensor. In this case, the number of\n * elements implied by shape must be the same as the number of elements in\n * tensor.\n *\n * ```js\n * const x = tf.tensor1d([1, 2, 3, 4]);\n * x.reshape([2, 2]).print();\n * ```\n *\n * @param x The input tensor to be reshaped.\n * @param shape An array of integers defining the output tensor shape.\n *\n * @doc {heading: 'Tensors', subheading: 'Transformations'}\n */\nfunction reshape_(x, shape) {\n    const $x = convertToTensor(x, 'x', 'reshape', 'string_or_numeric');\n    const inputs = { x: $x };\n    const attrs = { shape };\n    return ENGINE.runKernel(Reshape, inputs, attrs);\n}\nexport const reshape = op({ reshape_ });\n//# sourceMappingURL=reshape.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Reverse } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Reverses a `tf.Tensor` along a specified axis.\n *\n * Also available are stricter rank-specific methods that assert that `x` is\n * of the given rank:\n *   - `tf.reverse1d`\n *   - `tf.reverse2d`\n *   - `tf.reverse3d`\n *   - `tf.reverse4d`\n *\n * Except `tf.reverse1d` (which does not have axis param), all methods have\n * same signature as this method.\n *\n * ```js\n * const x = tf.tensor1d([1, 2, 3, 4]);\n *\n * x.reverse().print();\n * ```\n *\n * ```js\n * const x = tf.tensor2d([1, 2, 3, 4], [2, 2]);\n *\n * const axis = 1;\n * x.reverse(axis).print();\n * ```\n * @param x The input tensor to be reversed.\n * @param axis The set of dimensions to reverse. Must be in the\n *     range [-rank(x), rank(x)). Defaults to all axes.\n *\n * @doc {heading: 'Tensors', subheading: 'Slicing and Joining'}\n */\nfunction reverse_(x, axis) {\n    const $x = convertToTensor(x, 'x', 'reverse');\n    const inputs = { x: $x };\n    const attrs = { dims: axis };\n    return ENGINE.runKernel(Reverse, inputs, attrs);\n}\nexport const reverse = op({ reverse_ });\n//# sourceMappingURL=reverse.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { NotEqual } from '../kernel_names';\nimport { makeTypesMatch } from '../tensor_util';\nimport { convertToTensor } from '../tensor_util_env';\nimport { assertAndGetBroadcastShape } from './broadcast_util';\nimport { op } from './operation';\n/**\n * Returns the truth value of (a != b) element-wise. Supports broadcasting.\n *\n * ```js\n * const a = tf.tensor1d([1, 2, 3]);\n * const b = tf.tensor1d([0, 2, 3]);\n *\n * a.notEqual(b).print();\n * ```\n * @param a The first input tensor.\n * @param b The second input tensor. Must have the same dtype as `a`.\n *\n * @doc {heading: 'Operations', subheading: 'Logical'}\n */\nfunction notEqual_(a, b) {\n    let $a = convertToTensor(a, 'a', 'notEqual');\n    let $b = convertToTensor(b, 'b', 'notEqual');\n    [$a, $b] = makeTypesMatch($a, $b);\n    assertAndGetBroadcastShape($a.shape, $b.shape);\n    const inputs = { a: $a, b: $b };\n    return ENGINE.runKernel(NotEqual, inputs);\n}\nexport const notEqual = op({ notEqual_ });\n//# sourceMappingURL=not_equal.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { SquaredDifference } from '../kernel_names';\nimport { makeTypesMatch } from '../tensor_util';\nimport { convertToTensor } from '../tensor_util_env';\nimport { assertAndGetBroadcastShape } from './broadcast_util';\nimport { op } from './operation';\n/**\n * Returns (a - b) * (a - b) element-wise.\n * Supports broadcasting.\n *\n * ```js\n * const a = tf.tensor1d([1, 4, 3, 16]);\n * const b = tf.tensor1d([1, 2, 9, 4]);\n *\n * a.squaredDifference(b).print();  // or tf.squaredDifference(a, b)\n * ```\n *\n * ```js\n * // Broadcast squared difference  a with b.\n * const a = tf.tensor1d([2, 4, 6, 8]);\n * const b = tf.scalar(5);\n *\n * a.squaredDifference(b).print();  // or tf.squaredDifference(a, b)\n * ```\n *\n * @param a The first tensor.\n * @param b The second tensor. Must have the same type as `a`.\n *\n * @doc {heading: 'Operations', subheading: 'Arithmetic'}\n */\nfunction squaredDifference_(a, b) {\n    let $a = convertToTensor(a, 'a', 'squaredDifference');\n    let $b = convertToTensor(b, 'b', 'squaredDifference');\n    [$a, $b] = makeTypesMatch($a, $b);\n    assertAndGetBroadcastShape($a.shape, $b.shape);\n    const inputs = { a: $a, b: $b };\n    const attrs = {};\n    return ENGINE.runKernel(SquaredDifference, inputs, attrs);\n}\nexport const squaredDifference = op({ squaredDifference_ });\n//# sourceMappingURL=squared_difference.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { SpaceToBatchND } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport * as util from '../util';\nimport { op } from './operation';\n/**\n * This operation divides \"spatial\" dimensions `[1, ..., M]` of the input into\n * a grid of blocks of shape `blockShape`, and interleaves these blocks with\n * the \"batch\" dimension (0) such that in the output, the spatial\n * dimensions `[1, ..., M]` correspond to the position within the grid,\n * and the batch dimension combines both the position within a spatial block\n * and the original batch position. Prior to division into blocks,\n * the spatial dimensions of the input are optionally zero padded\n * according to `paddings`. See below for a precise description.\n *\n * ```js\n * const x = tf.tensor4d([1, 2, 3, 4], [1, 2, 2, 1]);\n * const blockShape = [2, 2];\n * const paddings = [[0, 0], [0, 0]];\n *\n * x.spaceToBatchND(blockShape, paddings).print();\n * ```\n *\n * @param x A `tf.Tensor`. N-D with `x.shape` = `[batch] + spatialShape +\n * remainingShape`, where spatialShape has `M` dimensions.\n * @param blockShape A 1-D array. Must have shape `[M]`, all values must\n * be >= 1.\n * @param paddings A 2-D array. Must have shape `[M, 2]`, all values must be >=\n *     0. `paddings[i] = [padStart, padEnd]` specifies the amount to zero-pad\n * from input dimension `i + 1`, which corresponds to spatial dimension `i`. It\n * is required that\n * `(inputShape[i + 1] + padStart + padEnd) % blockShape[i] === 0`\n *\n * This operation is equivalent to the following steps:\n *\n * 1. Zero-pad the start and end of dimensions `[1, ..., M]` of the input\n * according to `paddings` to produce `padded` of shape paddedShape.\n *\n * 2. Reshape `padded` to `reshapedPadded` of shape:\n * `[batch] + [paddedShape[1] / blockShape[0], blockShape[0], ...,\n * paddedShape[M] / blockShape[M-1], blockShape[M-1]] + remainingShape`\n *\n * 3. Permute dimensions of `reshapedPadded` to produce `permutedReshapedPadded`\n * of shape: `blockShape + [batch] + [paddedShape[1] / blockShape[0], ...,\n * paddedShape[M] / blockShape[M-1]] + remainingShape`\n *\n * 4. Reshape `permutedReshapedPadded` to flatten `blockShape` into the\n * batch dimension, producing an output tensor of shape:\n * `[batch * prod(blockShape)] + [paddedShape[1] / blockShape[0], ...,\n * paddedShape[M] / blockShape[M-1]] + remainingShape`\n *\n * @doc {heading: 'Tensors', subheading: 'Transformations'}\n */\nfunction spaceToBatchND_(x, blockShape, paddings) {\n    const $x = convertToTensor(x, 'x', 'spaceToBatchND');\n    util.assert($x.rank >= 1 + blockShape.length, () => `input rank ${$x.rank} should be > than [blockShape] ${blockShape.length}`);\n    util.assert(paddings.length === blockShape.length, () => `paddings.shape[0] ${paddings.length} must be equal to [blockShape] ${blockShape.length}`);\n    util.assert($x.shape.reduce((a, b, i) => {\n        if (i > 0 && i <= blockShape.length) {\n            return a &&\n                ((b + paddings[i - 1][0] + paddings[i - 1][1]) %\n                    blockShape[i - 1] ===\n                    0);\n        }\n        return a;\n    }, true), () => `input spatial dimensions ${$x.shape.slice(1)} with paddings ${paddings.toString()} must be divisible by blockShapes ${blockShape.toString()}`);\n    const inputs = { x: $x };\n    const attrs = { blockShape, paddings };\n    return ENGINE.runKernel(SpaceToBatchND, inputs, attrs);\n}\nexport const spaceToBatchND = op({ spaceToBatchND_ });\n//# sourceMappingURL=space_to_batch_nd.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { inferShape } from '../tensor_util_env';\nimport { assertNonNull } from '../util';\nimport { makeTensor } from './tensor_ops_util';\n/**\n * Creates rank-2 `tf.Tensor` with the provided values, shape and dtype.\n *\n * The same functionality can be achieved with `tf.tensor`, but in general\n * we recommend using `tf.tensor2d` as it makes the code more readable.\n *\n *  ```js\n * // Pass a nested array.\n * tf.tensor2d([[1, 2], [3, 4]]).print();\n * ```\n * ```js\n * // Pass a flat array and specify a shape.\n * tf.tensor2d([1, 2, 3, 4], [2, 2]).print();\n * ```\n *\n * @param values The values of the tensor. Can be nested array of numbers,\n *     or a flat array, or a `TypedArray`.\n * @param shape The shape of the tensor. If not provided, it is inferred from\n *     `values`.\n * @param dtype The data type.\n *\n * @doc {heading: 'Tensors', subheading: 'Creation'}\n */\nexport function tensor2d(values, shape, dtype) {\n    assertNonNull(values);\n    if (shape != null && shape.length !== 2) {\n        throw new Error('tensor2d() requires shape to have two numbers');\n    }\n    const inferredShape = inferShape(values, dtype);\n    if (inferredShape.length !== 2 && inferredShape.length !== 1) {\n        throw new Error('tensor2d() requires values to be number[][] or flat/TypedArray');\n    }\n    if (inferredShape.length === 1 && shape == null) {\n        throw new Error('tensor2d() requires shape to be provided when `values` ' +\n            'are a flat/TypedArray');\n    }\n    return makeTensor(values, shape, inferredShape, dtype);\n}\n//# sourceMappingURL=tensor2d.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../../engine';\nimport { IFFT } from '../../kernel_names';\nimport { assert } from '../../util';\nimport { op } from '../operation';\n/**\n * Inverse fast Fourier transform.\n *\n * Computes the inverse 1-dimensional discrete Fourier transform over the\n * inner-most dimension of input.\n *\n * ```js\n * const real = tf.tensor1d([1, 2, 3]);\n * const imag = tf.tensor1d([1, 2, 3]);\n * const x = tf.complex(real, imag);\n *\n * x.ifft().print();  // tf.spectral.ifft(x).print();\n * ```\n * @param input The complex input to compute an ifft over.\n *\n * @doc {heading: 'Operations', subheading: 'Spectral', namespace: 'spectral'}\n */\nfunction ifft_(input) {\n    assert(input.dtype === 'complex64', () => `The dtype for tf.spectral.ifft() must be complex64 ` +\n        `but got ${input.dtype}.`);\n    const inputs = { input };\n    return ENGINE.runKernel(IFFT, inputs);\n}\nexport const ifft = op({ ifft_ });\n//# sourceMappingURL=ifft.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Real } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Returns the real part of a complex (or real) tensor.\n *\n * Given a tensor input, this operation returns a tensor of type float that is\n * the real part of each element in input considered as a complex number.\n *\n * If the input is real, it simply makes a clone.\n *\n * ```js\n * const x = tf.complex([-2.25, 3.25], [4.75, 5.75]);\n * tf.real(x).print();\n * ```\n *\n * @doc {heading: 'Tensors', subheading: 'Creation'}\n */\nfunction real_(input) {\n    const $input = convertToTensor(input, 'input', 'real');\n    const inputs = { input: $input };\n    return ENGINE.runKernel(Real, inputs);\n}\nexport const real = op({ real_ });\n//# sourceMappingURL=real.js.map"],"sourceRoot":""}