{"version":3,"sources":["webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/cast.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/broadcast_to.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/broadcast_util.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/elu.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/cumsum.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/cos.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/avg_pool.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/conv2d_backprop_input.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/conv2d_backprop_filter.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/concat_util.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/conv_util.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/eye.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/div.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/cosh.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/all.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/any.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/arg_max.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/axis_util.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/arg_min.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/atan2.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/conv1d.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/conv2d_transpose.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/depth_to_space.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/dilation2d.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/div_no_nan.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/dot.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/batchnorm.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/batchnorm_util.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/depthwise_conv2d_native_backprop_input.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/depthwise_conv2d_native_backprop_filter.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/add.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/concat_2d.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/browser.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/array_ops_util.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/erf_util.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/log.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/acos.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/acosh.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/binary_ops.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/asin.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/asinh.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/atan.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/atanh.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/ceil.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/clip_by_value.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/compare.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/erf.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/expm1.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/concat.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/avg_pool_3d_backprop.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/avg_pool_backprop.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/conv3d_backprop_input.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/conv3d_backprop_filter.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/exp.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/abs.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/expand_dims.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/complex.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/conv2d.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/clone.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/depthwise_conv2d.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/equal.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/buffer.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/batch_to_space_nd.js"],"names":["cast","cast_","x","dtype","$x","Error","inputs","attrs","runKernelFunc","backend","broadcastTo","broadcastTo_","shape","input","xShape","some","d","length","rank","newShape","slice","unshift","inputShape","reps","Array","from","i","map","n","filter","tile","getBroadcastDims","inShape","outShape","inRank","dims","dim","a","getReductionAxes","result","inDim","outAxis","outDim","assertAndGetBroadcastShape","shapeA","shapeB","l","Math","max","b","elu","elu_","save","y","cumsum","cumsum_","axis","exclusive","reverse","permutation","permutedX","permutedAxis","value","reversePermutation","cos","cos_","res","avgPool","avgPool_","filterSize","strides","pad","dimRoundingMode","x4D","reshapedTo4D","convInfo","filterWidth","filterHeight","clone","conv2DBackpropInput","conv2DBackpropInput_","dy","dataFormat","xShape4D","dy4D","inDepth","outDepth","$dataFormat","conv2dDerInput","conv2DBackpropFilter","conv2DBackpropFilter_","filterShape","conv2dDerFilter","assertParamsConsistent","shapes","forEach","firstShape","r","computeOutShape","outputShape","computeDilation2DInfo","dilations","computeConv2DInfo","convertConv2DDataFormat","computePool2DInfo","roundingMode","parseTupleParam","computePool3DInfo","filterDepth","parse3TupleParam","computeConv3DInfo","depthwise","batchSize","inHeight","inWidth","inChannels","filterChannels","strideHeight","strideWidth","dilationHeight","dilationWidth","effectiveFilterHeight","getEffectiveFilterSize","effectiveFilterWidth","padInfo","outHeight","outWidth","top","bottom","left","right","type","fieldSize","stride","zeroPad","computeDefaultPad","inputRows","inputCols","outputRows","conditionalRound","outputCols","computeOutputShape2D","ceil","padAlongHeight","padAlongWidth","floor","getPadAndOutInfo","outChannels","strideDepth","dilationDepth","effectiveFilterDepth","front","back","inputDepth","outputDepths","computeOutputShape4D","padAlongDepth","get3DPadAndOutInfo","dilation","effectiveFieldSize","param","round","tupleValuesAreOne","dimA","dimB","dimC","eitherStridesOrDilationsAreOne","eye","eye_","numRows","numColumns","batchShape","buff","set","out","toTensor","div","div_","$a","$b","realDivide","cosh","cosh_","all","all_","keepDims","origAxes","axes","permutedAxes","any","any_","argMax","argMax_","axesAreInnerMostDims","combineLocations","outputLoc","reduceLoc","loc","outIdx","reduceIdx","indexOf","push","computeOutAndReduceShapes","aShape","expandShapeToKeepDim","assertAxesAreInnerMostDims","msg","getAxesPermutation","getUndoAxesPermutation","sort","getInnerMostAxes","numAxes","argMin","argMin_","atan2","atan2_","conv1d","conv1d_","$filter","x3D","reshapedTo3D","filter4D","input4D","conv2dTranspose","conv2dTranspose_","depthToSpace","depthToSpace_","blockSize","inputHeight","inputWidth","dilation2d","dilation2d_","runKernel","divNoNan","divNoNan_","divResult","zeros","bEqualsZero","dot","dot_","t1","t2","$t1","$t2","t1Inner","size","t2Inner","t12D","t22D","t1t2","as1DOr4D","reshape","batchNorm","batchNorm_","mean","variance","offset","scale","varianceEpsilon","$mean","$variance","$scale","$offset","util","xAs4D","depthwiseConv2dNativeBackpropInput","depthwiseConv2dNativeBackpropInput_","depthwiseConv2DDerInput","depthwiseConv2dNativeBackpropFilter","depthwiseConv2dNativeBackpropFilter_","depthwiseConv2DDerFilter","add","add_","concat2d","concat2d_","tensors","fromPixels2DContext","async","toPixels","img","canvas","$img","originalImgTensor","dispose","height","width","depth","data","multiplier","bytes","Uint8ClampedArray","rgba","j","ctx","getContext","imageData","ImageData","putImageData","fromPixels","fromPixels_","pixels","numChannels","isPixelData","isImageData","isVideo","isImage","isCanvasLike","Uint8Array","HTMLVideoElement","HTMLImageElement","constructor","name","HAVE_CURRENT_DATA_READY_STATE","readyState","backendName","videoWidth","videoHeight","vals","values","getImageData","document","createElement","drawImage","Int32Array","numPixels","channel","getReshaped","blockShape","prod","batchToSpace","reshaped","concat","spatialLength","getPermuted","reshapedRank","blockShapeRank","permuted","permutedBeforeBatch","permutedAfterBatch","getReshapedPermuted","reshapedPermuted","getSliceBeginCoords","crops","sliceBeginCoords","getSliceSize","uncroppedShape","sliceSize","ERF_P","ERF_A1","ERF_A2","ERF_A3","ERF_A4","ERF_A5","warn","getBool","console","log","acos","acos_","acosh","acosh_","addStrict","addStrict_","divStrict","divStrict_","maximumStrict","maximumStrict_","minimumStrict","minimumStrict_","modStrict","modStrict_","mulStrict","mulStrict_","powStrict","powStrict_","base","exp","squaredDifferenceStrict","squaredDifferenceStrict_","subStrict","subStrict_","asin","asin_","asinh","asinh_","atan","atan_","atanh","atanh_","ceil_","clipByValue","clipByValue_","clipValueMin","clipValueMax","clip","equalStrict","equalStrict_","greaterEqualStrict","greaterEqualStrict_","greaterStrict","greaterStrict_","lessEqualStrict","lessEqualStrict_","lessStrict","lessStrict_","notEqualStrict","notEqualStrict_","erf","erf_","expm1","expm1_","concat_","$tensors","tensor","$axis","t","attr","avgPool3dBackprop","avgPool3dBackprop_","$dy","$input","dy5D","input5D","reshapedTo5D","avgPoolBackprop","avgPoolBackprop_","conv3DBackpropInput","conv3DBackpropInput_","xShape5D","conv3dDerInput","conv3DBackpropFilter","conv3DBackpropFilter_","x5D","conv3dDerFilter","exp_","abs","abs_","complexAbs","expandDims","expandDims_","splice","complex","complex_","real","imag","$real","$imag","conv2d","conv2d_","clone_","makeTensorFromDataId","dataId","depthwiseConv2d","depthwiseConv2d_","depthwiseConv2D","equal","equal_","buffer","batchToSpaceND","batchToSpaceND_","reduce","join"],"mappings":";sJAAA,yEA+CO,MAAMA,EAAO,YAAG,CAAEC,MAdzB,SAAeC,EAAGC,GACd,MAAMC,EAAK,YAAgBF,EAAG,IAAK,QAEnC,IAAK,eAAkBC,GACnB,MAAM,IAAIE,MAAM,mCAAmCF,KAEvD,GAAc,WAAVA,GAAmC,WAAbC,EAAGD,OACf,WAAVA,GAAmC,WAAbC,EAAGD,MACzB,MAAM,IAAIE,MAAM,yCAEpB,MAAMC,EAAS,CAAEJ,EAAGE,GACdG,EAAQ,CAAEJ,SAChB,OAAO,IAAOK,eAAcC,GAAWA,EAAQT,KAAKI,EAAID,IAAQG,EAAQ,KAAiB,IAAMC,O,iCC7CnG,iFAuEO,MAAMG,EAAc,YAAG,CAAEC,aAnChC,SAAsBT,EAAGU,GACrB,IAAIC,EAAQ,YAAgBX,EAAG,cAAe,KAC9C,MAAMY,EAASD,EAAMD,MACrB,GAAIA,EAAMG,MAAKC,KAAOA,EAAI,IAAMA,EAAI,GAAM,IACtC,MAAM,IAAIX,MAAM,2CAA2CO,OAE/D,GAAIA,EAAMK,OAASJ,EAAMK,KACrB,MAAM,IAAIb,MAAM,+BAA+BO,EAAMK,uBAAuBJ,EAAMK,SAEtF,GAAIN,EAAMK,OAASJ,EAAMK,KAAM,CAC3B,MAAMC,EAAWN,EAAMD,MAAMQ,QAC7B,KAAOD,EAASF,OAASL,EAAMK,QAC3BE,EAASE,QAAQ,GAErBR,EAAQ,YAAQA,EAAOM,GAE3B,MAAMG,EAAaT,EAAMD,MACnBW,EAAOC,MAAMC,KAAKb,GACxB,IAAK,IAAIc,EAAId,EAAMK,OAAS,EAAGS,GAAK,EAAGA,IACnC,GAAIJ,EAAWI,KAAOd,EAAMc,GACxBH,EAAKG,GAAK,OAET,GAAuB,IAAnBb,EAAMD,MAAMc,GACjB,MAAM,IAAIrB,MAAM,mBAAmBS,8BAAmCF,OAI9E,GAAoB,IADPW,EAAKI,KAAI,CAACC,EAAGF,IAAME,EAAI,EAAIF,GAAK,IAAGG,QAAOH,GAAKA,GAAK,IACxDT,OACL,OAAO,YAAMJ,GAEjB,MACMP,EAAS,CAAEJ,EAAGW,GACdN,EAAQ,CAAEK,QAAOU,cACvB,OAAO,IAAOd,eAHGC,GAAYA,EAAQqB,KAAKjB,EAAOU,IAGZjB,EAAQ,KAAiB,IAAaC,O,gCC5CxE,SAASwB,EAAiBC,EAASC,GACtC,MAAMC,EAASF,EAAQf,OACjBkB,EAAO,GACb,IAAK,IAAIT,EAAI,EAAGA,EAAIQ,EAAQR,IAAK,CAC7B,MAAMU,EAAMF,EAAS,EAAIR,EACnBW,EAAIL,EAAQI,IAAQ,GAChBH,EAASA,EAAShB,OAAS,EAAIS,IAAM,GACvC,GAAW,IAANW,GACTF,EAAKd,QAAQe,GAGrB,OAAOD,EAMJ,SAASG,EAAiBN,EAASC,GACtC,MAAMM,EAAS,GACf,IAAK,IAAIb,EAAI,EAAGA,EAAIO,EAAShB,OAAQS,IAAK,CACtC,MAAMc,EAAQR,EAAQA,EAAQf,OAASS,EAAI,GACrCe,EAAUR,EAAShB,OAASS,EAAI,EAChCgB,EAAST,EAASQ,IACX,MAATD,GAA4B,IAAVA,GAAeE,EAAS,IAC1CH,EAAOlB,QAAQoB,GAGvB,OAAOF,EAEJ,SAASI,EAA2BC,EAAQC,GAC/C,MAAMN,EAAS,GACTO,EAAIC,KAAKC,IAAIJ,EAAO3B,OAAQ4B,EAAO5B,QACzC,IAAK,IAAIS,EAAI,EAAGA,EAAIoB,EAAGpB,IAAK,CACxB,IAAIW,EAAIO,EAAOA,EAAO3B,OAASS,EAAI,GAC1B,MAALW,IACAA,EAAI,GAER,IAAIY,EAAIJ,EAAOA,EAAO5B,OAASS,EAAI,GAInC,GAHS,MAALuB,IACAA,EAAI,GAEE,IAANZ,EACAE,EAAOlB,QAAQ4B,QAEd,GAAU,IAANA,EACLV,EAAOlB,QAAQgB,OAEd,IAAIA,IAAMY,EAAG,CAGd,MAAM5C,MADF,wDAAGuC,SAAcC,MAIrBN,EAAOlB,QAAQgB,IAGvB,OAAOE,EAjFX,uG,iCCAA,kEA0CO,MAAMW,EAAM,YAAG,CAAEC,KAVxB,SAAcjD,GACV,MAAME,EAAK,YAAgBF,EAAG,IAAK,OAM7BI,EAAS,CAAEJ,EAAGE,GACpB,OAAO,IAAOI,eANE,CAACC,EAAS2C,KACtB,MAAMC,EAAI5C,EAAQyC,IAAI9C,GAEtB,OADAgD,EAAK,CAACC,IACCA,IAG0B/C,EAAQ,KAAiB,S,iCCxClE,kFAkEO,MAAMgD,EAAS,YAAG,CAAEC,QArB3B,SAAiBrD,EAAGsD,EAAO,EAAGC,GAAY,EAAOC,GAAU,GACvD,MAAMtD,EAAK,YAAgBF,EAAG,IAAK,UAgB7BI,EAAS,CAAEJ,EAAGE,GACdG,EAAQ,CAAEiD,OAAMC,YAAWC,WACjC,OAAO,IAAOlD,eAjBE,CAACC,EAAS2C,KACtB,MAAMO,EAAc,YAAmB,CAACH,GAAOpD,EAAGc,MAClD,IAAI0C,EAAYxD,EACG,MAAfuD,IACAC,EAAY,YAAUxD,EAAIuD,IAE9B,MAAME,EAAe,YAAiB,EAAGzD,EAAGc,MAAM,GAClD,IAAI4C,EAAQrD,EAAQ6C,OAAOM,EAAWC,EAAcJ,EAAWC,GAE/D,GADAN,EAAK,CAAChD,IACa,MAAfuD,EAAqB,CACrB,MAAMI,EAAqB,YAAuBJ,GAClDG,EAAQ,YAAUA,EAAOC,GAE7B,OAAOD,IAI0BxD,EAAQ,KAAiB,IAAQC,O,iCChE1E,kEAyCO,MAAMyD,EAAM,YAAG,CAAEC,KATxB,SAAc/D,GACV,MAAME,EAAK,YAAgBF,EAAG,IAAK,OAC7BI,EAAS,CAAEJ,EAAGE,GACpB,OAAO,IAAOI,eAAc,CAACC,EAAS2C,KAClC,MAAMc,EAAMzD,EAAQuD,IAAI5D,GAExB,OADAgD,EAAK,CAAChD,IACC8D,IACR5D,EAAQ,KAAiB,S,iCCvChC,gGA+EO,MAAM6D,EAAU,YAAG,CAAEC,SAlC5B,SAAkBlE,EAAGmE,EAAYC,EAASC,EAAKC,GAC3C,MAAMpE,EAAK,YAAgBF,EAAG,IAAK,UAAW,WAE9C,SAAY,IAAyCoE,EADnC,IACwD,IACtE,wEAAeA,wBACnB,IAAIG,EAAMrE,EACNsE,GAAe,EACH,IAAZtE,EAAGc,OACHwD,GAAe,EACfD,EAAM,YAAQrE,EAAI,CAAC,EAAGA,EAAGQ,MAAM,GAAIR,EAAGQ,MAAM,GAAIR,EAAGQ,MAAM,MAE7D,SAAyB,IAAb6D,EAAIvD,MAAY,IAAM,mDAAmDuD,EAAIvD,UAClE,MAAnBsD,GACA,SAAY,QAAWD,IAAM,IACzB,wEAAmBC,iBAA+BD,OAE1D,MASMjE,EAAS,CAAEJ,EAAGuE,GACdlE,EAAQ,CAAE8D,aAAYC,UAASC,MAAKC,mBAC1C,IAAIN,EAAM,IAAO1D,eAXD,CAACC,EAAS2C,KACtB,MAAMuB,EAAW,IAA4BF,EAAI7D,MAAOyD,EAAYC,EAAS,EAAmBC,EAAKC,GAErG,OADApB,EAAK,CAACqB,IACuB,IAAzBE,EAASC,aAA+C,IAA1BD,EAASE,cACvC,cAAiBF,EAAS3C,QAAS2C,EAAS1C,UACrCwC,EAAIK,QAERrE,EAAQ0D,QAAQM,EAAKE,KAIQrE,EAAQ,KAAiB,IAASC,GAE1E,OADA2D,EAAM,YAAKA,EAAK9D,EAAGD,OACfuE,EACO,YAAQR,EAAK,CAACA,EAAItD,MAAM,GAAIsD,EAAItD,MAAM,GAAIsD,EAAItD,MAAM,KAExDsD,M,iCC7EX,iFA0FO,MAAMa,EAAsB,YAAG,CAAEC,qBA3CxC,SAA8BlE,EAAQmE,EAAIpD,EAAQyC,EAASC,EAAKW,EAAa,OAAQV,GACjF,SAAY1D,EAAOG,SAAWgE,EAAG/D,MAAM,IACnC,sBAAIJ,EAAOG,2BAA2BgE,EAAG/D,qBAC7C,IAAIiE,EAAWrE,EACXsE,EAAOH,EACPP,GAAe,EACH,IAAZO,EAAG/D,OACHwD,GAAe,EACfU,EAAO,YAAQH,EAAI,CAAC,EAAGA,EAAGrE,MAAM,GAAIqE,EAAGrE,MAAM,GAAIqE,EAAGrE,MAAM,KAC1DuE,EAAW,CAAC,EAAGrE,EAAO,GAAIA,EAAO,GAAIA,EAAO,KAEhD,SAAgC,IAApBqE,EAASlE,QAAc,IAC/B,qEAAGkE,EAASlE,YAChB,SAA0B,IAAdmE,EAAKlE,MAAY,IACzB,4DAAQkE,EAAKlE,SACjB,SAA4B,IAAhBW,EAAOX,MAAY,IAC3B,gEAAQW,EAAOX,SACnB,MAAMmE,EAAyB,SAAfH,EAAwBC,EAAS,GAAKA,EAAS,GACzDG,EAA0B,SAAfJ,EAAwBE,EAAKxE,MAAM,GAAKwE,EAAKxE,MAAM,GACpE,SAAYyE,IAAYxD,EAAOjB,MAAM,IAAI,IAAM,4CAA4CyE,wCACvDxD,EAAOjB,MAAM,QACjD,SAAY0E,IAAazD,EAAOjB,MAAM,IAAI,IAAM,6CAA6C0E,yCACxDzD,EAAOjB,MAAM,QAC3B,MAAnB4D,GACA,SAAY,QAAWD,IAAM,IACzB,+EAAmBC,iBAA+BD,OAE1D,MAQMjE,EAAS,CAAE2E,GAAIG,EAAMvD,UACrBtB,EAAQ,CAAE+D,UAASC,MAAKW,aAAYV,kBAAiBlD,WAAY6D,GACjEjB,EAAM,IAAO1D,eAVH,CAACC,EAAS2C,KACtB,MACMmC,EAAc,IAAkCL,GAChDP,EAAW,IAA4BQ,EAAUtD,EAAOjB,MAAO0D,EAFnD,EAEuEC,EAAKC,GAAiB,EAAOe,GAChHrB,EAAMzD,EAAQ+E,eAAeJ,EAAMvD,EAAQ8C,GAEjD,OADAvB,EAAK,CAACgC,EAAMvD,IACLqC,IAI+B5D,EAAQ,KAAiB,IAAqBC,GACxF,OAAImE,EACO,YAAQR,EAAK,CAACA,EAAItD,MAAM,GAAIsD,EAAItD,MAAM,GAAIsD,EAAItD,MAAM,KAExDsD,M,iCCxFX,iFA+EO,MAAMuB,EAAuB,YAAG,CAAEC,sBAnCzC,SAA+BxF,EAAG+E,EAAIU,EAAarB,EAASC,EAAKW,EAAa,OAAQV,GAClF,IAAIC,EAAMvE,EACK,IAAXA,EAAEgB,OACFuD,EAAM,YAAQvE,EAAG,CAAC,EAAGA,EAAEU,MAAM,GAAIV,EAAEU,MAAM,GAAIV,EAAEU,MAAM,MAEzD,IAAIwE,EAAOH,EACO,IAAdG,EAAKlE,OACLkE,EAAO,YAAQH,EAAI,CAAC,EAAGA,EAAGrE,MAAM,GAAIqE,EAAGrE,MAAM,GAAIqE,EAAGrE,MAAM,MAE9D,SAAyB,IAAb6D,EAAIvD,MAAY,IACxB,iEAAGuD,EAAI7D,WACX,SAA0B,IAAdwE,EAAKlE,MAAY,IACzB,8DAAGkE,EAAKxE,WACZ,SAAmC,IAAvB+E,EAAY1E,QAAc,IAClC,mEAAG0E,OACP,MAAMN,EAAyB,SAAfH,EAAwBT,EAAI7D,MAAM,GAAK6D,EAAI7D,MAAM,GAC3D0E,EAA0B,SAAfJ,EAAwBE,EAAKxE,MAAM,GAAKwE,EAAKxE,MAAM,GACpE,SAAYyE,IAAYM,EAAY,IAAI,IAAM,4CAA4CN,wCACtDM,EAAY,QAChD,SAAYL,IAAaK,EAAY,IAAI,IAAM,0CAA0CL,0CACnDK,EAAY,SAC3B,MAAnBnB,GACA,SAAY,QAAWD,IAAM,IACzB,gFAAmBC,iBAA+BD,OAE1D,MAMMjE,EAAS,CAAEJ,EAAGuE,EAAKQ,GAAIG,GACvB7E,EAAQ,CAAE+D,UAASC,MAAKW,aAAYV,mBAC1C,OAAO,IAAOhE,eAREC,IACZ,MACM8E,EAAc,IAAkCL,GAChDP,EAAW,IAA4BF,EAAI7D,MAAO+E,EAAarB,EAFnD,EAEuEC,EAAKC,GAAiB,EAAOe,GACtH,OAAO9E,EAAQmF,gBAAgBnB,EAAKW,EAAMT,KAITrE,EAAQ,KAAM,IAAsBC,O,iCC7E7E,+EAiBO,SAASsF,EAAuBC,EAAQtC,GAC3C,MAAMtC,EAAO4E,EAAO,GAAG7E,OACvB6E,EAAOC,SAAQ,CAACnF,EAAOc,KACnB,SAAYd,EAAMK,SAAWC,GAAM,IAAM,kBAAkBA,uBAA0BQ,gDACrDR,UAEpC,SAAYsC,GAAQ,GAAKA,EAAOtC,GAAM,IAAM,kBAAkBA,kCAAqCA,EAAO,OAC1G,MAAM8E,EAAaF,EAAO,GAC1BA,EAAOC,SAAQ,CAACnF,EAAOc,KACnB,IAAK,IAAIuE,EAAI,EAAGA,EAAI/E,EAAM+E,IACtB,SAAaA,IAAMzC,GAAU5C,EAAMqF,KAAOD,EAAWC,IAAK,IAAM,kBAAkB/E,wBAA2BQ,OAAOd,4CACvEoF,sCACNtE,UAI5C,SAASwE,EAAgBJ,EAAQtC,GACpC,MAAM2C,EAAcL,EAAO,GAAG1E,QAC9B,IAAK,IAAIM,EAAI,EAAGA,EAAIoE,EAAO7E,OAAQS,IAC/ByE,EAAY3C,IAASsC,EAAOpE,GAAG8B,GAEnC,OAAO2C,I,gCCtCX,6TAyCO,SAASC,EAAsB9E,EAAYqE,EAAarB,EAASC,EAAKW,EAAa,OAAQmB,GAQ9F,OAAOC,EAAkBhF,EAFJ,IAAIqE,EADHrE,EAAW,IAGkBgD,EAAS+B,EAAW9B,EAAK,KAAyB,KADjFgC,EAAwBrB,IAGzC,SAASsB,EAAkBxE,EAASqC,EAAYC,EAAS+B,EAAW9B,EAAKkC,EAAcvB,EAAa,gBACvG,MAAOL,EAAcD,GAAe8B,EAAgBrC,GACpD,IAAIsB,EACJ,GAAmB,iBAAfT,EACAS,EAAc,CAACd,EAAcD,EAAa5C,EAAQ,GAAIA,EAAQ,QAE7D,IAAmB,kBAAfkD,EAIL,MAAM,IAAI7E,MAAM,sBAAsB6E,KAHtCS,EAAc,CAACd,EAAcD,EAAa5C,EAAQ,GAAIA,EAAQ,IAKlE,OAAOsE,EAAkBtE,EAAS2D,EAAarB,EAAS+B,EAAW9B,EAAKkC,GAAc,EAAOvB,GAK1F,SAASyB,EAAkB3E,EAASqC,EAAYC,EAAS+B,EAAW9B,EAAKkC,EAAcvB,EAAa,SACvG,MAAO0B,EAAa/B,EAAcD,GAAeiC,EAAiBxC,GAClE,IAAIsB,EACAJ,EACJ,GAAmB,UAAfL,EACAK,EAAc,eACdI,EACI,CAACiB,EAAa/B,EAAcD,EAAa5C,EAAQ,GAAIA,EAAQ,QAEhE,IAAmB,UAAfkD,EAML,MAAM,IAAI7E,MAAM,sBAAsB6E,KALtCK,EAAc,gBACdI,EACI,CAACiB,EAAa/B,EAAcD,EAAa5C,EAAQ,GAAIA,EAAQ,IAKrE,OAAO8E,EAAkB9E,EAAS2D,EAAarB,EAAS+B,EAAW9B,GAAK,EAAOgB,EAAakB,GAMzF,SAASH,EAAkBtE,EAAS2D,EAAarB,EAAS+B,EAAW9B,EAAKkC,EAAcM,GAAY,EAAO7B,EAAa,gBAC3H,IAAK8B,EAAWC,EAAUC,EAASC,GAAc,EAAE,GAAI,GAAI,GAAI,GAC/D,GAAmB,iBAAfjC,GACC8B,EAAWC,EAAUC,EAASC,GAAcnF,MAE5C,IAAmB,kBAAfkD,EAIL,MAAM,IAAI7E,MAAM,sBAAsB6E,MAHrC8B,EAAWG,EAAYF,EAAUC,GAAWlF,EAKjD,MAAO6C,EAAcD,EAAa,CAAEwC,GAAkBzB,GAC/C0B,EAAcC,GAAeZ,EAAgBpC,IAC7CiD,EAAgBC,GAAiBd,EAAgBL,GAClDoB,EAAwBC,EAAuB7C,EAAc0C,GAC7DI,EAAuBD,EAAuB9C,EAAa4C,IAC3D,QAAEI,EAAO,UAAEC,EAAS,SAAEC,GA4JhC,SAA0BvD,EAAK0C,EAAUC,EAASG,EAAcC,EAAazC,EAAcD,EAAa6B,EAAcvB,GAClH,IAAI0C,EACAC,EACAC,EACJ,GAAmB,iBAARvD,EAAkB,CAEzBqD,EAAU,CAAEG,IAAKxD,EAAKyD,OAAQzD,EAAK0D,KAAM1D,EAAK2D,MAAO3D,EAAK4D,KADjC,IAAR5D,EAAa,QAAU,UAExC,MAAMtC,EAxEd,SAA8BD,EAASoG,EAAWC,EAAQC,EAAS7B,GAChD,MAAX6B,IACAA,EAAUC,EAAkBvG,EAASoG,EAAWC,IAEpD,MAAMG,EAAYxG,EAAQ,GACpByG,EAAYzG,EAAQ,GACpB0G,EAAaC,GAAkBH,EAAYJ,EAAY,EAAIE,GAAWD,EAAS,EAAG5B,GACxF,SAAY,QAAWiC,IAAa,IAAM,yBAAyBA,wEAEnE,MAAME,EAAaD,GAAkBF,EAAYL,EAAY,EAAIE,GAAWD,EAAS,EAAG5B,GAGxF,OAFA,SAAY,QAAWmC,IAAa,IAAM,4BAA4BA,wEAE/D,CAACF,EAAYE,GA4DCC,CAAqB,CAAC5B,EAAUC,GAAUrC,EAAcwC,EAAc9C,EAAKkC,GAC5FoB,EAAY5F,EAAS,GACrB6F,EAAW7F,EAAS,QAEnB,GAAY,SAARsC,EAAgB,CACrBsD,EAAY9E,KAAK+F,KAAK7B,EAAWI,GACjCS,EAAW/E,KAAK+F,KAAK5B,EAAUI,GAC/B,MAAMyB,EAAiBhG,KAAKC,IAAI,GAAI6E,EAAY,GAAKR,EAAexC,EAAeoC,GAC7E+B,EAAgBjG,KAAKC,IAAI,GAAI8E,EAAW,GAAKR,EAAc1C,EAAcsC,GACzEa,EAAMhF,KAAKkG,MAAMF,EAAiB,GAClCf,EAASe,EAAiBhB,EAC1BE,EAAOlF,KAAKkG,MAAMD,EAAgB,GAExCpB,EAAU,CAAEG,MAAKC,SAAQC,OAAMC,MADjBc,EAAgBf,EACQE,KAAM,aAE3C,GAAY,UAAR5D,EACLqD,EAAU,CAAEG,IAAK,EAAGC,OAAQ,EAAGC,KAAM,EAAGC,MAAO,EAAGC,KAAM,SACxDN,EAAY9E,KAAK+F,MAAM7B,EAAWpC,EAAe,GAAKwC,GACtDS,EAAW/E,KAAK+F,MAAM5B,EAAUtC,EAAc,GAAK0C,OAElD,IAAmB,iBAAR/C,EAaZ,MAAMlE,MAAM,8BAA8BkE,KAbZ,CAC9B,MAAMwD,EAAqB,iBAAf7C,EAAgCX,EAAI,GAAG,GAAKA,EAAI,GAAG,GACzDyD,EAAwB,iBAAf9C,EAAgCX,EAAI,GAAG,GAAKA,EAAI,GAAG,GAC5D0D,EAAsB,iBAAf/C,EAAgCX,EAAI,GAAG,GAAKA,EAAI,GAAG,GAC1D2D,EAAuB,iBAAfhD,EAAgCX,EAAI,GAAG,GAAKA,EAAI,GAAG,GAIjEqD,EAAU,CAAEG,MAAKC,SAAQC,OAAMC,QAAOC,KAHb,IAARJ,GAAwB,IAAXC,GAAyB,IAATC,GAAwB,IAAVC,EACxD,QACA,YAEJL,EAAYc,GAAkB1B,EAAWpC,EAAekD,EAAMC,GAAUX,EAAe,EAAGZ,GAC1FqB,EAAWa,GAAkBzB,EAAUtC,EAAcqD,EAAOC,GAASZ,EAAc,EAAGb,IAK1F,MAAO,CAAEmB,UAASC,YAAWC,YAtMYoB,CAAiB3E,EAAK0C,EAAUC,EAASG,EAAcC,EAAaG,EAAuBE,EAAsBlB,EAAcvB,GAClKiE,EAAcpC,EAAYK,EAAiBD,EAAaC,EAC9D,IAAInF,EAOJ,MANmB,kBAAfiD,EACAjD,EAAW,CAAC+E,EAAWmC,EAAatB,EAAWC,GAE3B,iBAAf5C,IACLjD,EAAW,CAAC+E,EAAWa,EAAWC,EAAUqB,IAEzC,CACHnC,YACA9B,aACA+B,WACAC,UACAC,aACAU,YACAC,WACAqB,cACAvB,UACAP,eACAC,cACAzC,eACAD,cACA6C,wBACAE,uBACAJ,iBACAC,gBACAxF,UACAC,WACA0D,eAOD,SAASmB,EAAkB9E,EAAS2D,EAAarB,EAAS+B,EAAW9B,EAAKwC,GAAY,EAAO7B,EAAa,eAAgBuB,GAC7H,IAAKO,EAAW3B,EAAS4B,EAAUC,EAASC,GAAc,EAAE,GAAI,GAAI,GAAI,GAAI,GAC5E,GAAmB,iBAAfjC,GACC8B,EAAW3B,EAAS4B,EAAUC,EAASC,GAAcnF,MAErD,IAAmB,kBAAfkD,EAIL,MAAM,IAAI7E,MAAM,sBAAsB6E,MAHrC8B,EAAWG,EAAY9B,EAAS4B,EAAUC,GAAWlF,EAK1D,MAAO4E,EAAa/B,EAAcD,EAAa,CAAEwC,GAAkBzB,GAC5DyD,EAAa/B,EAAcC,GAAeT,EAAiBvC,IAC3D+E,EAAe9B,EAAgBC,GAAiBX,EAAiBR,GAClEiD,EAAuB5B,EAAuBd,EAAayC,GAC3D5B,EAAwBC,EAAuB7C,EAAc0C,GAC7DI,EAAuBD,EAAuB9C,EAAa4C,IAC3D,QAAEI,EAAO,SAAEtC,EAAQ,UAAEuC,EAAS,SAAEC,GAmJ1C,SAA4BvD,EAAKc,EAAS4B,EAAUC,EAASkC,EAAa/B,EAAcC,EAAaV,EAAa/B,EAAcD,EAAa6B,GACzI,IAAImB,EACAtC,EACAuC,EACAC,EACJ,GAAmB,iBAARvD,EAAkB,CAEzBqD,EAAU,CACNG,IAAKxD,EACLyD,OAAQzD,EACR0D,KAAM1D,EACN2D,MAAO3D,EACPgF,MAAOhF,EACPiF,KAAMjF,EACN4D,KARqB,IAAR5D,EAAa,QAAU,UAUxC,MAAMtC,EA/Gd,SAA8BD,EAASoG,EAAWe,EAAad,EAAQC,EAAS7B,GAC7D,MAAX6B,IACAA,EAAUC,EAAkBvG,EAASoG,EAAWC,IAEpD,MAAMoB,EAAazH,EAAQ,GACrBwG,EAAYxG,EAAQ,GACpByG,EAAYzG,EAAQ,GACpB0H,EAAef,GAAkBc,EAAarB,EAAY,EAAIE,GAAWD,EAAS,EAAG5B,GAC3F,SAAY,QAAWiD,IAAe,IAAM,2BAA2BA,wEAEvE,MAAMhB,EAAaC,GAAkBH,EAAYJ,EAAY,EAAIE,GAAWD,EAAS,EAAG5B,GACxF,SAAY,QAAWiC,IAAa,IAAM,yBAAyBA,wEAEnE,MAAME,EAAaD,GAAkBF,EAAYL,EAAY,EAAIE,GAAWD,EAAS,EAAG5B,GAGxF,OAFA,SAAY,QAAWmC,IAAa,IAAM,4BAA4BA,wEAE/D,CAACc,EAAchB,EAAYE,EAAYO,GA+FzBQ,CAAqB,CAACtE,EAAS4B,EAAUC,EAAS,GAAIN,EAAa,EAAGwC,EAAa7E,EAAKkC,GACzGnB,EAAWrD,EAAS,GACpB4F,EAAY5F,EAAS,GACrB6F,EAAW7F,EAAS,QAEnB,GAAY,SAARsC,EAAgB,CACrBe,EAAWvC,KAAK+F,KAAKzD,EAAU+D,GAC/BvB,EAAY9E,KAAK+F,KAAK7B,EAAWI,GACjCS,EAAW/E,KAAK+F,KAAK5B,EAAUI,GAC/B,MAAMsC,GAAiBtE,EAAW,GAAK8D,EAAcxC,EAAcvB,EAC7D0D,GAAkBlB,EAAY,GAAKR,EAAexC,EAAeoC,EACjE+B,GAAiBlB,EAAW,GAAKR,EAAc1C,EAAcsC,EAC7DqC,EAAQxG,KAAKkG,MAAMW,EAAgB,GACnCJ,EAAOI,EAAgBL,EACvBxB,EAAMhF,KAAKkG,MAAMF,EAAiB,GAClCf,EAASe,EAAiBhB,EAC1BE,EAAOlF,KAAKkG,MAAMD,EAAgB,GAExCpB,EAAU,CAAEG,MAAKC,SAAQC,OAAMC,MADjBc,EAAgBf,EACQsB,QAAOC,OAAMrB,KAAM,YAExD,IAAY,UAAR5D,EAeL,MAAMlE,MAAM,8BAA8BkE,KAd1CqD,EAAU,CACNG,IAAK,EACLC,OAAQ,EACRC,KAAM,EACNC,MAAO,EACPqB,MAAO,EACPC,KAAM,EACNrB,KAAM,SAEV7C,EAAWvC,KAAK+F,MAAMzD,EAAUuB,EAAc,GAAKwC,GACnDvB,EAAY9E,KAAK+F,MAAM7B,EAAWpC,EAAe,GAAKwC,GACtDS,EAAW/E,KAAK+F,MAAM5B,EAAUtC,EAAc,GAAK0C,GAKvD,MAAO,CAAEM,UAAStC,WAAUuC,YAAWC,YAxMY+B,CAAmBtF,EAAKc,EAAS4B,EAAUC,EAASkC,EAAa/B,EAAcC,EAAagC,EAAsB7B,EAAuBE,EAAsBlB,GAC5M0C,EAAcpC,EAAYK,EAAiBD,EAAaC,EAC9D,IAAInF,EAOJ,MANmB,kBAAfiD,EACAjD,EAAW,CAAC+E,EAAWmC,EAAa7D,EAAUuC,EAAWC,GAErC,iBAAf5C,IACLjD,EAAW,CAAC+E,EAAW1B,EAAUuC,EAAWC,EAAUqB,IAEnD,CACHnC,YACA9B,aACAG,UACA4B,WACAC,UACAC,aACA7B,WACAuC,YACAC,WACAqB,cACAvB,UACAwB,cACA/B,eACAC,cACAV,cACA/B,eACAD,cACA0E,uBACA7B,wBACAE,uBACA0B,gBACA9B,iBACAC,gBACAxF,UACAC,WACA0D,eAmCD,SAAS4C,EAAkBjH,EAAY8G,EAAWC,EAAQyB,EAAW,GACxE,MAAMC,EAAqBrC,EAAuBU,EAAW0B,GAC7D,OAAO/G,KAAKkG,OAAO3H,EAAW,IAAM+G,EAAS,GAAKA,EAAS0B,GAAsB,GAErF,SAASrD,EAAgBsD,GACrB,MAAqB,iBAAVA,EACA,CAACA,EAAOA,EAAOA,GAEL,IAAjBA,EAAM/I,OACC,CAAC+I,EAAM,GAAIA,EAAM,GAAI,GAEzBA,EAEX,SAASnD,EAAiBmD,GACtB,MAAwB,iBAAVA,EAAqB,CAACA,EAAOA,EAAOA,GAASA,EAa/D,SAAStC,EAAuBrD,EAAYyF,GACxC,OAAIA,GAAY,EACLzF,EAEJA,GAAcA,EAAa,IAAMyF,EAAW,GA0GvD,SAASnB,EAAiB7E,EAAO2C,GAC7B,IAAKA,EACD,OAAO3C,EAEX,OAAQ2C,GACJ,IAAK,QAED,OAAO1D,KAAKkH,MAAMnG,GACtB,IAAK,OAED,OAAOf,KAAK+F,KAAKhF,GACrB,IAAK,QACD,OAAOf,KAAKkG,MAAMnF,GACtB,QACI,MAAM,IAAIzD,MAAM,wBAAwBoG,MAG7C,SAASyD,EAAkBF,GAC9B,MAAOG,EAAMC,EAAMC,GAAQ3D,EAAgBsD,GAC3C,OAAgB,IAATG,GAAuB,IAATC,GAAuB,IAATC,EAEhC,SAASC,EAA+BhG,EAAS+B,GACpD,OAAO6D,EAAkB5F,IAAY4F,EAAkB7D,GASpD,SAASE,EAAwBrB,GACpC,GAAmB,SAAfA,EACA,MAAO,eAEN,GAAmB,SAAfA,EACL,MAAO,gBAGP,MAAM,IAAI7E,MAAM,sBAAsB6E,O,iCCtZ9C,4EAqEO,MAAMqF,EAAM,YAAG,CAAEC,KAlCxB,SAAcC,EAASC,EAAYC,EAAYxK,EAAQ,WACjC,MAAduK,IACAA,EAAaD,GAEjB,MAAMG,EAAO,YAAO,CAACH,EAASC,GAAavK,GACrCyB,EAAI6I,GAAWC,EAAaD,EAAUC,EAC5C,IAAK,IAAIhJ,EAAI,EAAGA,EAAIE,IAAKF,EACrBkJ,EAAKC,IAAI,EAAGnJ,EAAGA,GAEnB,MAAMoJ,EAAM,YAAQF,EAAKG,WAAY,CAACN,EAASC,IAC/C,GAAkB,MAAdC,EACA,OAAOG,EAGP,GAA0B,IAAtBH,EAAW1J,OACX,OAAO,YAAK,YAAW6J,EAAK,GAAI,CAACH,EAAW,GAAI,EAAG,IAElD,GAA0B,IAAtBA,EAAW1J,OAEhB,OAAO,YAAK,YAAW,YAAW6J,EAAK,GAAI,GAAI,CAACH,EAAW,GAAIA,EAAW,GAAI,EAAG,IAEhF,GAA0B,IAAtBA,EAAW1J,OAEhB,OAAO,YAAK,YAAW,YAAW,YAAW6J,EAAK,GAAI,GAAI,GAAI,CAC1DH,EAAW,GAAIA,EAAW,GAAIA,EAAW,GAAI,EAAG,IAIpD,MAAM,IAAItK,MAEN,qEAA6BsK,EAAW1J,gB,gCCjExD,mFA8DO,MAAM+J,EAAM,YAAG,CAAEC,KAhBxB,SAAc5I,EAAGY,GACb,IAAIiI,EAAK,YAAgB7I,EAAG,IAAK,OAC7B8I,EAAK,YAAgBlI,EAAG,IAAK,OAEjC,IADCiI,EAAIC,GAAM,YAAeD,EAAIC,GACb,UAAbD,EAAG/K,OAAkC,UAAbgL,EAAGhL,MAC3B,OAAO,YAAS+K,EAAIC,GAExB,MAKM7K,EAAS,CAAE+B,EAAG6I,EAAIjI,EAAGkI,GAE3B,OAAO,IAAO3K,eAPE,CAACC,EAAS2C,KACtB,MAAMc,EAAMzD,EAAQ2K,WAAWF,EAAIC,GAEnC,OADA/H,EAAK,CAAC8H,EAAIC,IACHjH,IAI0B5D,EAAQ,KAAqB,IADpD,Q,iCC3DlB,kEAyCO,MAAM+K,EAAO,YAAG,CAAEC,MATzB,SAAepL,GACX,MAAME,EAAK,YAAgBF,EAAG,IAAK,QAC7BI,EAAS,CAAEJ,EAAGE,GACpB,OAAO,IAAOI,eAAc,CAACC,EAAS2C,KAClC,MAAMc,EAAMzD,EAAQ4K,KAAKjL,GAEzB,OADAgD,EAAK,CAAChD,IACC8D,IACR5D,EAAQ,KAAiB,S,iCCvChC,gGA0EO,MAAMiL,EAAM,YAAG,CAAEC,KArBxB,SAActL,EAAGsD,EAAO,KAAMiI,GAAW,GACrC,IAAIrL,EAAK,YAAgBF,EAAG,IAAK,MAAO,QACxC,MAeMI,EAAS,CAAEJ,EAAGE,GACdG,EAAQ,CAAEiD,OAAMiI,YACtB,OAAO,IAAOjL,eAjBGC,IACb,MAAMiL,EAAW,yBAAelI,EAAMpD,EAAGQ,OACzC,IAAI+K,EAAOD,EACX,MAAME,EAAe,YAAmBD,EAAMvL,EAAGc,MAC7B,MAAhB0K,IACAxL,EAAK,YAAUA,EAAIwL,GACnBD,EAAO,YAAiBA,EAAK1K,OAAQb,EAAGc,OAE5C,MAAMgD,EAAMzD,EAAQ8K,IAAInL,EAAIuL,GAC5B,GAAIF,EAAU,CACV,MAAMtK,EAAW,YAAqB+C,EAAItD,MAAO8K,GACjD,OAAO,YAAQxH,EAAK/C,GAExB,OAAO+C,IAI0B5D,EAAQ,KAAiB,IAAKC,O,iCCxEvE,gGA2EO,MAAMsL,EAAM,YAAG,CAAEC,KAtBxB,SAAc5L,EAAGsD,EAAO,KAAMiI,GAAW,GACrC,IAAIrL,EAAK,YAAgBF,EAAG,IAAK,MAAO,QACxC,MAeMI,EAAS,CAAEJ,EAAGE,GACdG,EAAQ,CAAEiD,OAAMiI,YACtB,OAAO,IAAOjL,eAjBGC,IACb,MAAMiL,EAAW,yBAAelI,EAAMpD,EAAGQ,OACzC,IAAI+K,EAAOD,EACX,MAAME,EAAe,YAAmBD,EAAMvL,EAAGc,MAC7B,MAAhB0K,IACAxL,EAAK,YAAUA,EAAIwL,GACnBD,EAAO,YAAiBA,EAAK1K,OAAQb,EAAGc,OAE5C,MAAMgD,EAAMzD,EAAQoL,IAAIzL,EAAIuL,GAC5B,GAAIF,EAAU,CACV,MAAMtK,EAAW,YAAqB+C,EAAItD,MAAO8K,GACjD,OAAO,YAAQxH,EAAK/C,GAExB,OAAO+C,IAI0B5D,EAAQ,KAAiB,IAAKC,O,iCCxEvE,yFA+DO,MAAMwL,EAAS,YAAG,CAAEC,QAhB3B,SAAiB9L,EAAGsD,EAAO,GACvB,IAAIpD,EAAK,YAAgBF,EAAG,IAAK,UACjC,MAUMI,EAAS,CAAEJ,EAAGE,GACdG,EAAQ,CAAEiD,QAChB,OAAO,IAAOhD,eAZE,CAACC,EAAS2C,KACtBA,EAAK,CAAChD,IACN,IAAIuL,EAAO,iBAAoBnI,EAAMpD,EAAGQ,OACxC,MAAMgL,EAAe,IAA6BD,EAAMvL,EAAGc,MAK3D,OAJoB,MAAhB0K,IACAxL,EAAK,YAAUA,EAAIwL,GACnBD,EAAO,IAA2BA,EAAK1K,OAAQb,EAAGc,OAE/CT,EAAQsL,OAAO3L,EAAIuL,EAAK,MAIErL,EAAQ,KAAiB,IAAQC,O,gCC7D1E,2RAqBO,SAAS0L,EAAqBN,EAAMzK,GACvC,IAAK,IAAIQ,EAAI,EAAGA,EAAIiK,EAAK1K,SAAUS,EAC/B,GAAIiK,EAAKA,EAAK1K,OAASS,EAAI,KAAOR,EAAO,EAAIQ,EACzC,OAAO,EAGf,OAAO,EAEJ,SAASwK,EAAiBC,EAAWC,EAAWT,GACnD,MAAMzK,EAAOiL,EAAUlL,OAASmL,EAAUnL,OACpCoL,EAAM,GACZ,IAAIC,EAAS,EACTC,EAAY,EAChB,IAAK,IAAInK,EAAM,EAAGA,EAAMlB,EAAMkB,KACC,IAAvBuJ,EAAKa,QAAQpK,GACbiK,EAAII,KAAKN,EAAUG,MAGnBD,EAAII,KAAKL,EAAUG,MAG3B,OAAOF,EAEJ,SAASK,EAA0BC,EAAQhB,GAC9C,MAAM1J,EAAW,GACXf,EAAOyL,EAAO1L,OACpB,IAAK,IAAImB,EAAM,EAAGA,EAAMlB,EAAMkB,KACC,IAAvBuJ,EAAKa,QAAQpK,IACbH,EAASwK,KAAKE,EAAOvK,IAI7B,MAAO,CAACH,EADY0J,EAAKhK,KAAIS,GAAOuK,EAAOvK,MAGxC,SAASwK,EAAqBhM,EAAO+K,GAExC,OAAOO,EAAiBtL,EADD+K,EAAKhK,KAAIzB,GAAK,IACUyL,GAE5C,SAASkB,EAA2BC,EAAKnB,EAAMzK,GAClD,SAAY+K,EAAqBN,EAAMzK,IAAO,IAAM,GAAG4L,qDACvCnB,cAAiBzK,aAO9B,SAAS6L,EAAmBpB,EAAMzK,GACrC,GAAI+K,EAAqBN,EAAMzK,GAC3B,OAAO,KAEX,MAAMqB,EAAS,GACf,IAAK,IAAIb,EAAI,EAAGA,EAAIR,IAAQQ,GACC,IAArBiK,EAAKa,QAAQ9K,IACba,EAAOkK,KAAK/K,GAIpB,OADAiK,EAAK5F,SAAQvC,GAAQjB,EAAOkK,KAAKjJ,KAC1BjB,EAGJ,SAASyK,EAAuBrB,GACnC,OAAOA,EAAKhK,KAAI,CAAC6B,EAAM9B,IAAM,CAACA,EAAG8B,KAC5ByJ,MAAK,CAAC5K,EAAGY,IAAMZ,EAAE,GAAKY,EAAE,KACxBtB,KAAIzB,GAAKA,EAAE,KAEb,SAASgN,EAAiBC,EAASjM,GACtC,MAAMgD,EAAM,GACZ,IAAK,IAAIxC,EAAIR,EAAOiM,EAASzL,EAAIR,IAAQQ,EACrCwC,EAAIuI,KAAK/K,GAEb,OAAOwC,I,iCC5FX,yFAkEO,MAAMkJ,EAAS,YAAG,CAAEC,QAnB3B,SAAiBnN,EAAGsD,EAAO,GACvB,IAAIpD,EAAK,YAAgBF,EAAG,IAAK,UACjC,MAaMI,EAAS,CAAEJ,EAAGE,GACdG,EAAQ,CAAEiD,QAChB,OAAO,IAAOhD,eAfE,CAACC,EAAS2C,KACtBA,EAAK,CAAChD,IACM,MAARoD,IACAA,EAAO,GAEX,IAAImI,EAAO,iBAAoBnI,EAAMpD,EAAGQ,OACxC,MAAMgL,EAAe,IAA6BD,EAAMvL,EAAGc,MAK3D,OAJoB,MAAhB0K,IACAxL,EAAK,YAAUA,EAAIwL,GACnBD,EAAO,IAA2BA,EAAK1K,OAAQb,EAAGc,OAE/CT,EAAQ2M,OAAOhN,EAAIuL,EAAK,MAIErL,EAAQ,KAAiB,IAAQC,O,iCChE1E,0EAiDO,MAAM+M,EAAQ,YAAG,CAAEC,OAZ1B,SAAgBlL,EAAGY,GACf,IAAIiI,EAAK,YAAgB7I,EAAG,IAAK,SAC7B8I,EAAK,YAAgBlI,EAAG,IAAK,UAChCiI,EAAIC,GAAM,YAAeD,EAAIC,GAC9B,MAKM7K,EAAS,CAAE+B,EAAG6I,EAAIjI,EAAGkI,GAC3B,OAAO,IAAO3K,eANE,CAACC,EAAS2C,KACtB,MAAMc,EAAMzD,EAAQ6M,MAAMpC,EAAIC,GAE9B,OADA/H,EAAK,CAAC8H,EAAIC,IACHjH,IAG0B5D,EAAQ,KAAqB,S,iCC/CtE,kFAmEO,MAAMkN,EAAS,YAAG,CAAEC,QAhC3B,SAAiBvN,EAAG2B,EAAQwG,EAAQ9D,EAAKW,EAAa,MAAO4E,EAAW,EAAGtF,GACvE,MAAMpE,EAAK,YAAgBF,EAAG,IAAK,UAC7BwN,EAAU,YAAgB7L,EAAQ,SAAU,UAClD,IAAI8L,EAAMvN,EACNwN,GAAe,EACH,IAAZxN,EAAGc,OACH0M,GAAe,EACfD,EAAM,YAAQvN,EAAI,CAAC,EAAGA,EAAGQ,MAAM,GAAIR,EAAGQ,MAAM,MAEhD,SAAyB,IAAb+M,EAAIzM,MAAY,IAAM,uDAAuDyM,EAAIzM,UAC7F,SAA6B,IAAjBwM,EAAQxM,MAAY,IAC5B,wDAAGwM,EAAQxM,UACQ,MAAnBsD,GACA,SAAY,QAAWD,IAAM,IACzB,uEAAmBC,iBAA+BD,OAE1D,SAAYoJ,EAAI/M,MAAM,KAAO8M,EAAQ9M,MAAM,IAAI,IAAM,oCAAoC+M,EAAI/M,MAAM,yCACrE8M,EAAQ9M,MAAM,QAC5C,SAAY,IAAyCyH,EAAQyB,IAAW,IACpE,oEAAczB,mBAAwByB,OAC1C,SAA2B,QAAf5E,GAAsB,IAAM,sCAAsCA,2CAC9E,MAAM2I,EAAW,YAAQH,EAAS,CAAC,EAAGA,EAAQ9M,MAAM,GAAI8M,EAAQ9M,MAAM,GAAI8M,EAAQ9M,MAAM,KAClFkN,EAAU,YAAQH,EAAK,CAACA,EAAI/M,MAAM,GAAI,EAAG+M,EAAI/M,MAAM,GAAI+M,EAAI/M,MAAM,KACjE0D,EAAU,CAAC,EAAG+D,GACdhC,EAAY,CAAC,EAAGyD,GAEhB5F,EAAM,YAAO4J,EAASD,EAAUvJ,EAASC,EADtB,OAC6C8B,EAAW7B,GACjF,OAAIoJ,EACO,YAAQ1J,EAAK,CAACA,EAAItD,MAAM,GAAIsD,EAAItD,MAAM,KAE1C,YAAQsD,EAAK,CAACA,EAAItD,MAAM,GAAIsD,EAAItD,MAAM,GAAIsD,EAAItD,MAAM,S,iCCjE/D,6DA6BO,MAAMmN,EAAkB,YAAG,CAAEC,iBALpC,SAA0B9N,EAAG2B,EAAQsE,EAAa7B,EAASC,EAAKC,GAC5D,MAAMpE,EAAK,YAAgBF,EAAG,IAAK,mBAC7BwN,EAAU,YAAgB7L,EAAQ,SAAU,mBAClD,OAAO,YAAoBsE,EAAa/F,EAAIsN,EAASpJ,EAASC,EAAK,OAAQC,O,iCC3B/E,yEA2EO,MAAMyJ,EAAe,YAAG,CAAEC,cAjBjC,SAAuBhO,EAAGiO,EAAWjJ,EAAa,QAC9C,MAAM9E,EAAK,YAAgBF,EAAG,IAAK,gBAC7BkO,EAA8B,SAAflJ,EAAyB9E,EAAGQ,MAAM,GAAKR,EAAGQ,MAAM,GAC/DyN,EAA6B,SAAfnJ,EAAyB9E,EAAGQ,MAAM,GAAKR,EAAGQ,MAAM,GAC9D6I,EAA6B,SAAfvE,EAAyB9E,EAAGQ,MAAM,GAAKR,EAAGQ,MAAM,GACpE,SAAYwN,EAAcD,GAAa,GAAG,IAAM,oEAC9CC,SAAmBD,6CACnB/N,EAAGQ,UACL,SAAYyN,EAAaF,GAAa,GAAG,IAAM,oEAC7CE,SAAkBF,gDACd/N,EAAGQ,UACT,SAAa6I,GAAc0E,EAAYA,IAAe,GAAI,IAAM,8CAA8CA,EAAYA,YAAoB1E,uCAAgDrJ,EAAGQ,UACjM,MACMN,EAAS,CAAEJ,EAAGE,GACdG,EAAQ,CAAE4N,YAAWjJ,cAC3B,OAAO,IAAO1E,eAHEC,GAAWA,EAAQwN,aAAa7N,EAAI+N,EAAWjJ,IAG1B5E,EAAQ,KAAqB,IAAcC,O,iCCzEpF,gFA4EO,MAAM+N,EAAa,YAAG,CAAEC,YAvB/B,SAAqBrO,EAAG2B,EAAQyC,EAASC,EAAK8B,EAAY,CAAC,EAAG,GAAInB,EAAa,QAC3E,MAAM9E,EAAK,YAAgBF,EAAG,IAAK,cAC7BwN,EAAU,YAAgB7L,EAAQ,SAAU,cAClD,SAAwB,IAAZzB,EAAGc,MAA0B,IAAZd,EAAGc,MAAY,IACxC,gEAAGd,EAAGc,UACV,SAA6B,IAAjBwM,EAAQxM,MAAY,IAC5B,4DAAGwM,EAAQxM,UACf,SAA2B,SAAfgE,GAAuB,IAC/B,gFAAyBA,MAC7B,IAAIT,EAAMrE,EACNsE,GAAe,EACH,IAAZtE,EAAGc,OACHuD,EAAM,YAAQrE,EAAI,CAAC,EAAGA,EAAGQ,MAAM,GAAIR,EAAGQ,MAAM,GAAIR,EAAGQ,MAAM,KACzD8D,GAAe,GAEnB,MAAMpE,EAAS,CAAEJ,EAAGuE,EAAK5C,OAAQ6L,GAC3BnN,EAAQ,CAAE+D,UAASC,MAAK8B,aACxBnC,EAAM,IAAOsK,UAAU,IAAYlO,EAAQC,GACjD,OAAImE,EACO,YAAQR,EAAK,CAACA,EAAItD,MAAM,GAAIsD,EAAItD,MAAM,GAAIsD,EAAItD,MAAM,KAExDsD,M,iCC1EX,4FA+DO,MAAMuK,EAAW,YAAG,CAAEC,UAV7B,SAAmBrM,EAAGY,GAElB,IAAIiI,EAAK,YAAgB7I,EAAG,IAAK,OAC7B8I,EAAK,YAAgBlI,EAAG,IAAK,QAChCiI,EAAIC,GAAM,YAAeD,EAAIC,GAC9B,MAAMwD,EAAY,YAAIzD,EAAIC,GACpByD,EAAQ,YAAUD,GAClBE,EAAc,YAAM1D,EAAIyD,GAC9B,OAAO,YAAMC,EAAaD,EAAOD,O,iCC7DrC,0EAsEO,MAAMG,EAAM,YAAG,CAAEC,KAhCxB,SAAcC,EAAIC,GACd,MAAMC,EAAM,YAAgBF,EAAI,KAAM,OAChCG,EAAM,YAAgBF,EAAI,KAAM,OACtC,WAA0B,IAAbC,EAAIhO,MAA2B,IAAbgO,EAAIhO,MAA6B,IAAbiO,EAAIjO,MAA2B,IAAbiO,EAAIjO,OAAa,IAClF,+DAAGgO,EAAIhO,YAAYiO,EAAIjO,UAC3B,MAAMkO,EAAwB,IAAbF,EAAIhO,KAAagO,EAAIG,KAAOH,EAAItO,MAAM,GACjD0O,EAAwB,IAAbH,EAAIjO,KAAaiO,EAAIE,KAAOF,EAAIvO,MAAM,GAGvD,GAFA,SAAYwO,IAAYE,GAAS,IAC7B,gEAAGF,SAAeE,OACL,IAAbJ,EAAIhO,MAA2B,IAAbiO,EAAIjO,KAAY,CAClC,MAAMqO,EAAO,YAAQL,EAAK,CAAC,GAAI,IACzBM,EAAO,YAAQL,EAAK,EAAE,EAAG,IACzBM,EAAO,YAAOF,EAAMC,GAC1B,OAAO,YAAQC,EAAM,IAEpB,GAAiB,IAAbP,EAAIhO,MAA2B,IAAbiO,EAAIjO,KAAY,CACvC,MAAMqO,EAAO,YAAQL,EAAK,CAAC,GAAI,IACzBM,EAAO,YAAQL,EAAK,CAACA,EAAIvO,MAAM,GAAIuO,EAAIvO,MAAM,KAC7C6O,EAAO,YAAOF,EAAMC,GAC1B,OAAO,YAAQC,EAAM,CAACA,EAAKJ,OAE1B,GAAiB,IAAbH,EAAIhO,MAA2B,IAAbiO,EAAIjO,KAAY,CACvC,MAAMsO,EAAO,YAAQL,EAAK,EAAE,EAAG,IACzBM,EAAO,YAAOP,EAAKM,GACzB,OAAO,YAAQC,EAAM,CAACA,EAAKJ,OAE1B,CACD,MAAMG,EAAO,YAAQL,EAAK,CAACA,EAAIvO,MAAM,GAAIuO,EAAIvO,MAAM,KAEnD,OADa,YAAOsO,EAAKM,Q,qHCoBjC,SAASE,EAASxP,GACd,OAAS,MAALA,EACO,KAEI,IAAXA,EAAEgB,KAEK,OAAAyO,EAAA,GAAQzP,EAAG,CAACA,EAAEmP,OAEL,IAAXnP,EAAEgB,KACAhB,EAES,IAAXA,EAAEgB,KAEA,OAAAyO,EAAA,GAAQzP,EAAG,CAAC,EAAG,EAAGA,EAAEU,MAAM,GAAIV,EAAEU,MAAM,KAE7B,IAAXV,EAAEgB,KAEA,OAAAyO,EAAA,GAAQzP,EAAG,CAAC,EAAGA,EAAEU,MAAM,GAAIV,EAAEU,MAAM,GAAIV,EAAEU,MAAM,KAEnDV,EAEJ,MAAM0P,EAAY,YAAG,CAAEC,WA1D9B,SAAoB3P,EAAG4P,EAAMC,EAAUC,EAAQC,EAAOC,GAC3B,MAAnBA,IACAA,EAAkB,MAEtB,MAAM9P,EAAK,YAAgBF,EAAG,IAAK,aAC7BiQ,EAAQ,YAAgBL,EAAM,OAAQ,aACtCM,EAAY,YAAgBL,EAAU,WAAY,aACxD,IAAIM,EAIAC,EAHS,MAATL,IACAI,EAAS,YAAgBJ,EAAO,QAAS,cAG/B,MAAVD,IACAM,EAAU,YAAgBN,EAAQ,SAAU,cAEhDO,EAAA,OAAYJ,EAAMjP,OAASkP,EAAUlP,MAAM,IAAM,iFAEjDqP,EAAA,OAAuB,MAAXD,GAAmBH,EAAMjP,OAASoP,EAAQpP,MAAM,IAAM,+EAElEqP,EAAA,OAAsB,MAAVF,GAAkBF,EAAMjP,OAASmP,EAAOnP,MAAM,IAAM,8EAEhE,MAAMuD,ECrEH,SAAevE,GAClB,IAAIuE,EAaJ,OAXIA,EADW,IAAXvE,EAAEgB,MAAyB,IAAXhB,EAAEgB,KACZ,OAAAyO,EAAA,GAAQzP,EAAG,CAAC,EAAG,EAAG,EAAGA,EAAEmP,OAEb,IAAXnP,EAAEgB,KACD,OAAAyO,EAAA,GAAQzP,EAAG,CAAC,EAAG,EAAGA,EAAEU,MAAM,GAAIV,EAAEU,MAAM,KAE5B,IAAXV,EAAEgB,KACD,OAAAyO,EAAA,GAAQzP,EAAG,CAAC,EAAGA,EAAEU,MAAM,GAAIV,EAAEU,MAAM,GAAIV,EAAEU,MAAM,KAG/CV,EAEHuE,EDuDK+L,CAAMpQ,GAKZE,EAAS,CACXJ,EAAGuE,EACHwL,MAAOI,EACPL,OAAQM,EACRR,KAAMK,EACNJ,SAAUK,GAER7P,EAAQ,CAAE2P,mBACVhM,EAAM,IAAO1D,eAZH,CAACC,EAAS2C,KACtBA,EAAK,CAACqB,EAAK0L,EAAOC,EAAWC,IACtB5P,EAAQmP,UAAUnL,EAAKiL,EAASS,GAAQT,EAASU,GAAYV,EAASY,GAAUZ,EAASW,GAASH,KAUnE5P,EAAQ,KAAqB,KAAgBC,GACvF,OAAO,OAAAoP,EAAA,GAAQzL,EAAK9D,EAAGQ,W,iCEpF3B,kEAmCO,MAAM6P,EAAqC,YAAG,CAAEC,oCAfvD,SAA6C5P,EAAQmE,EAAIpD,EAAQ8C,GAC7D,IAAIS,EAAOH,EACPP,GAAe,EACH,IAAZO,EAAG/D,OACHwD,GAAe,EACfU,EAAO,YAAQH,EAAI,CAAC,EAAGA,EAAGrE,MAAM,GAAIqE,EAAGrE,MAAM,GAAIqE,EAAGrE,MAAM,MAE9D,MACMN,EAAS,CAAE2E,GAAIG,GACflB,EAAM,IAAO1D,eAFHC,GAAWA,EAAQkQ,wBAAwBvL,EAAMvD,EAAQ8C,IAE/BrE,EAAQ,KAAM,KACxD,OAAIoE,EACO,YAAQR,EAAK,CAACA,EAAItD,MAAM,GAAIsD,EAAItD,MAAM,GAAIsD,EAAItD,MAAM,KAExDsD,M,iCCjCX,kEAiCO,MAAM0M,EAAsC,YAAG,CAAEC,qCAbxD,SAA8C3Q,EAAG+E,EAAIU,EAAahB,GAC9D,IAAIF,EAAMvE,EACK,IAAXA,EAAEgB,OACFuD,EAAM,YAAQvE,EAAG,CAAC,EAAGA,EAAEU,MAAM,GAAIV,EAAEU,MAAM,GAAIV,EAAEU,MAAM,MAEzD,IAAIwE,EAAOH,EACO,IAAdG,EAAKlE,OACLkE,EAAO,YAAQH,EAAI,CAAC,EAAGA,EAAGrE,MAAM,GAAIqE,EAAGrE,MAAM,GAAIqE,EAAGrE,MAAM,MAE9D,MACMN,EAAS,CAAEJ,EAAGuE,EAAKQ,GAAIG,GAC7B,OAAO,IAAO5E,eAFEC,GAAWA,EAAQqQ,yBAAyBrM,EAAKW,EAAMT,IAElCrE,EAAQ,KAAM,S,gCC/BvD,0EAwDO,MAAMyQ,EAAM,YAAG,CAAEC,KAZxB,SAAc3O,EAAGY,GACb,IAAIiI,EAAK,YAAgB7I,EAAG,IAAK,OAC7B8I,EAAK,YAAgBlI,EAAG,IAAK,QAChCiI,EAAIC,GAAM,YAAeD,EAAIC,GAC9B,MAKM7K,EAAS,CAAE+B,EAAG6I,EAAIjI,EAAGkI,GAC3B,OAAO,IAAO3K,eANE,CAACC,EAAS2C,KACtB,MAAMc,EAAMzD,EAAQsQ,IAAI7F,EAAIC,GAE5B,OADA/H,EAAK,CAAC8H,EAAIC,IACHjH,IAG0B5D,EAAQ,KAAqB,S,iCCtDtE,qDAgCO,MAAM2Q,EAAW,YAAG,CAAEC,UAH7B,SAAmBC,EAAS3N,GACxB,OAAO,YAAO2N,EAAS3N,O,iCC9B3B,2JAwBA,IAAI4N,EA0IGC,eAAeC,EAASC,EAAKC,GAChC,IAAIC,EAAO,YAAgBF,EAAK,MAAO,YACvC,KAAMA,aAAe,KAAS,CAE1B,MAAMG,EAAoBD,EAC1BA,EAAO,YAAKC,EAAmB,SAC/BA,EAAkBC,UAEtB,GAAkB,IAAdF,EAAKvQ,MAA4B,IAAduQ,EAAKvQ,KACxB,MAAM,IAAIb,MAAM,wDAAwDoR,EAAKvQ,SAEjF,MAAO0Q,EAAQC,GAASJ,EAAK7Q,MAAMQ,MAAM,EAAG,GACtC0Q,EAAsB,IAAdL,EAAKvQ,KAAa,EAAIuQ,EAAK7Q,MAAM,GAC/C,GAAIkR,EAAQ,GAAe,IAAVA,EACb,MAAM,IAAIzR,MACN,0DAAqByR,KAE7B,GAAmB,YAAfL,EAAKtR,OAAsC,UAAfsR,EAAKtR,MACjC,MAAM,IAAIE,MAAM,kCAAkCoR,EAAKtR,+CAG3D,MAAM4R,QAAaN,EAAKM,OAClBC,EAA4B,YAAfP,EAAKtR,MAAsB,IAAM,EAC9C8R,EAAQ,IAAIC,kBAAkBL,EAAQD,EAAS,GACrD,IAAK,IAAIlQ,EAAI,EAAGA,EAAIkQ,EAASC,IAASnQ,EAAG,CACrC,MAAMyQ,EAAO,CAAC,EAAG,EAAG,EAAG,KACvB,IAAK,IAAInR,EAAI,EAAGA,EAAI8Q,EAAO9Q,IAAK,CAC5B,MAAM8C,EAAQiO,EAAKrQ,EAAIoQ,EAAQ9Q,GAC/B,GAAmB,YAAfyQ,EAAKtR,OACL,GAAI2D,EAAQ,GAAKA,EAAQ,EACrB,MAAM,IAAIzD,MACN,mFAAiCyD,WAGxC,GAAmB,UAAf2N,EAAKtR,QACN2D,EAAQ,GAAKA,EAAQ,KACrB,MAAM,IAAIzD,MACN,mFAAmCyD,MAGjC,IAAVgO,GACAK,EAAK,GAAKrO,EAAQkO,EAClBG,EAAK,GAAKrO,EAAQkO,EAClBG,EAAK,GAAKrO,EAAQkO,GAGlBG,EAAKnR,GAAK8C,EAAQkO,EAG1B,MAAMI,EAAQ,EAAJ1Q,EACVuQ,EAAMG,EAAI,GAAKrP,KAAKkH,MAAMkI,EAAK,IAC/BF,EAAMG,EAAI,GAAKrP,KAAKkH,MAAMkI,EAAK,IAC/BF,EAAMG,EAAI,GAAKrP,KAAKkH,MAAMkI,EAAK,IAC/BF,EAAMG,EAAI,GAAKrP,KAAKkH,MAAMkI,EAAK,IAEnC,GAAc,MAAVX,EAAgB,CAChBA,EAAOK,MAAQA,EACfL,EAAOI,OAASA,EAChB,MAAMS,EAAMb,EAAOc,WAAW,MACxBC,EAAY,IAAIC,UAAUP,EAAOJ,EAAOD,GAC9CS,EAAII,aAAaF,EAAW,EAAG,GAKnC,OAHId,IAASF,GACTE,EAAKE,UAEFM,EAEJ,MAAMS,EAAa,YAAG,CAAEC,YArL/B,SAAqBC,EAAQC,EAAc,GAEvC,GAAIA,EAAc,EACd,MAAM,IAAIxS,MAAM,kEAEpB,GAAc,MAAVuS,EACA,MAAM,IAAIvS,MAAM,4DAEpB,IAAIyS,GAAc,EACdC,GAAc,EACdC,GAAU,EACVC,GAAU,EACVC,GAAe,EACnB,GAAIN,EAAOb,gBAAgBoB,WACvBL,GAAc,OAEb,GAA2B,oBAAhB,WAA+BF,aAAkBJ,UAC7DO,GAAc,OAEb,GAAkC,oBAAvB,kBACZH,aAAkBQ,iBAClBJ,GAAU,OAET,GAAkC,oBAAvB,kBACZJ,aAAkBS,iBAClBJ,GAAU,MAGT,IAAyB,MAArBL,EAAON,WAIZ,MAAM,IAAIjS,MAIN,qPAAWuS,EAAOU,YAAYC,QAPlCL,GAAe,EASnB,GAAIF,EAAS,CACT,MAAMQ,EAAgC,EACtC,GAAIR,GACAJ,EAAOa,WACHD,EACJ,MAAM,IAAInT,MAAM,yGAOxB,GAAc,MADC,YAAU,KAAY,IAAOqT,aACxB,CAChB,MAAMpT,EAAS,CAAEsS,UACXrS,EAAQ,CAAEsS,eAChB,OAAO,IAAOrE,UAAU,KAAYlO,EAAQC,GAEhD,MAAOsR,EAAOD,GAAUoB,EACpB,CACIJ,EAAOe,WACPf,EAAOgB,aAEX,CAAChB,EAAOf,MAAOe,EAAOhB,QAC1B,IAAIiC,EAkBAC,EACJ,GAlBIZ,EACAW,EAEIjB,EAAON,WAAW,MAAMyB,aAAa,EAAG,EAAGlC,EAAOD,GAAQG,KAEzDgB,GAAeD,EACpBe,EAAOjB,EAAOb,MAETkB,GAAWD,KACW,MAAvB5B,IACAA,EAAsB4C,SAASC,cAAc,UAAU3B,WAAW,OAEtElB,EAAoBI,OAAOK,MAAQA,EACnCT,EAAoBI,OAAOI,OAASA,EACpCR,EAAoB8C,UAAUtB,EAAQ,EAAG,EAAGf,EAAOD,GACnDiC,EAAOzC,EAAoB2C,aAAa,EAAG,EAAGlC,EAAOD,GAAQG,MAG7C,IAAhBc,EACAiB,EAAS,IAAIK,WAAWN,OAEvB,CACD,MAAMO,EAAYvC,EAAQD,EAC1BkC,EAAS,IAAIK,WAAWC,EAAYvB,GACpC,IAAK,IAAInR,EAAI,EAAGA,EAAI0S,EAAW1S,IAC3B,IAAK,IAAI2S,EAAU,EAAGA,EAAUxB,IAAewB,EAC3CP,EAAOpS,EAAImR,EAAcwB,GAAWR,EAAS,EAAJnS,EAAQ2S,GAI7D,MAAMpS,EAAW,CAAC2P,EAAQC,EAAOgB,GACjC,OAAO,YAASiB,EAAQ7R,EAAU,a,iCCrH/B,SAASqS,EAAYhT,EAAYiT,EAAYC,EAAMC,GAAe,GACrE,IAAIC,EAAW,GACf,GAAID,EACAC,EAAWA,EAASC,OAAOJ,EAAWnT,MAAM,IAC5CsT,EAASjI,KAAKnL,EAAW,GAAKkT,GAC9BE,EAAWA,EAASC,OAAOrT,EAAWF,MAAM,QAE3C,CACDsT,EAAWA,EAASC,OAAOrT,EAAW,IACtC,MAAMsT,EAAgBL,EAAWtT,OACjC,IAAK,IAAIS,EAAI,EAAGA,EAAIkT,IAAiBlT,EACjCgT,EACIA,EAASC,OAAO,CAACrT,EAAWI,EAAI,GAAK6S,EAAW7S,GAAI6S,EAAW7S,KAEvEgT,EAAWA,EAASC,OAAOrT,EAAWF,MAAMwT,EAAgB,IAEhE,OAAOF,EAWJ,SAASG,EAAYC,EAAcC,EAAgBN,GAAe,GACrE,MAAMO,EAAW,GACjB,GAAIP,EAAc,CACdO,EAASvI,KAAKsI,GACd,IAAK,IAAIrT,EAAIqT,EAAiB,EAAGrT,EAAIoT,IAAgBpT,EAC7CA,GAAK,EAAIqT,GACTC,EAASvI,KAAK/K,GACdsT,EAASvI,KAAK/K,GAAKqT,EAAiB,KAGpCC,EAASvI,KAAK/K,OAIrB,CACD,MAAMuT,EAAsB,GACtBC,EAAqB,GAC3B,IAAK,IAAIxT,EAAI,EAAGA,EAAIoT,IAAgBpT,EAC5BA,GAAsB,EAAjBqT,EAAqB,GAAKrT,EAAI,GAAM,EACzCwT,EAAmBzI,KAAK/K,GAGxBuT,EAAoBxI,KAAK/K,GAGjCsT,EAASvI,QAAQwI,GACjBD,EAASvI,KAAK,GACduI,EAASvI,QAAQyI,GAErB,OAAOF,EAWJ,SAASG,EAAoB7T,EAAYiT,EAAYC,EAAMC,GAAe,GAC7E,MAAMW,EAAmB,GACrBX,EACAW,EAAiB3I,KAAKnL,EAAW,GAAKkT,GAGtCY,EAAiB3I,KAAKnL,EAAW,GAAKkT,GAE1C,IAAK,IAAI9S,EAAI,EAAGA,EAAIJ,EAAWL,SAAUS,EACjCA,GAAK6S,EAAWtT,OACZwT,EACAW,EAAiB3I,KAAK8H,EAAW7S,EAAI,GAAKJ,EAAWI,IAGrD0T,EAAiB3I,KAAKnL,EAAWI,GAAK6S,EAAW7S,EAAI,IAIzD0T,EAAiB3I,KAAKnL,EAAWI,IAGzC,OAAO0T,EAMJ,SAASC,EAAoBC,EAAOf,GACvC,MAAMgB,EAAmB,CAAC,GAC1B,IAAK,IAAI7T,EAAI,EAAGA,EAAI6S,IAAc7S,EAC9B6T,EAAiB9I,KAAK6I,EAAM5T,GAAG,IAEnC,OAAO6T,EAaJ,SAASC,EAAaC,EAAgBH,EAAOf,GAChD,MAAMmB,EAAYD,EAAerU,MAAM,EAAG,GAC1C,IAAK,IAAIM,EAAI,EAAGA,EAAI6S,IAAc7S,EAC9BgU,EAAUjJ,KAAKgJ,EAAe/T,EAAI,GAAK4T,EAAM5T,GAAG,GAAK4T,EAAM5T,GAAG,IAElE,OAAOgU,EA7IX,2K,iCCAA,4MAgBO,MAAMC,EAAQ,SACRC,EAAS,WACTC,GAAU,WACVC,EAAS,YACTC,GAAU,YACVC,EAAS,a,iCCrBtB,gFAiBO,SAASC,KAAQnJ,GACf,cAAMoJ,QAAQ,YACfC,QAAQF,QAAQnJ,GAGjB,SAASsJ,KAAOtJ,GACd,cAAMoJ,QAAQ,YACfC,QAAQC,OAAOtJ,K,iCCxBvB,kEAwCO,MAAMuJ,EAAO,YAAG,CAAEC,MATzB,SAAepW,GACX,MAAME,EAAK,YAAgBF,EAAG,IAAK,QAC7BI,EAAS,CAAEJ,EAAGE,GACpB,OAAO,IAAOI,eAAc,CAACC,EAAS2C,KAClC,MAAMc,EAAMzD,EAAQ4V,KAAKjW,GAEzB,OADAgD,EAAK,CAAChD,IACC8D,IACR5D,EAAQ,KAAiB,S,iCCtChC,kEA0CO,MAAMiW,EAAQ,YAAG,CAAEC,OAT1B,SAAgBtW,GACZ,MAAME,EAAK,YAAgBF,EAAG,IAAK,SAC7BI,EAAS,CAAEJ,EAAGE,GACpB,OAAO,IAAOI,eAAc,CAACC,EAAS2C,KAClC,MAAMc,EAAMzD,EAAQ8V,MAAMnW,GAE1B,OADAgD,EAAK,CAAChD,IACC8D,IACR5D,EAAQ,KAAiB,S,iCCxChC,2ZAoLO,MAAMmW,EAAY,YAAG,CAAEC,WA9I9B,SAAoBrU,EAAGY,GACnB,YAAgB,6EAEhB,MAAMiI,EAAK,YAAgB7I,EAAG,IAAK,aAC7B8I,EAAK,YAAgBlI,EAAG,IAAK,aAEnC,OADA,oBAAuBiI,EAAGtK,MAAOuK,EAAGvK,MAAO,wBACpC,YAAIsK,EAAIC,MAyINwL,EAAY,YAAG,CAAEC,WA3E9B,SAAoBvU,EAAGY,GACnB,YAAgB,6EAEhB,MAAMiI,EAAK,YAAgB7I,EAAG,IAAK,OAC7B8I,EAAK,YAAgBlI,EAAG,IAAK,OAEnC,OADA,oBAAuBiI,EAAGtK,MAAOuK,EAAGvK,MAAO,2BACpC,YAAIsK,EAAIC,MAsEN0L,EAAgB,YAAG,CAAEC,eA5BlC,SAAwBzU,EAAGY,GACvB,YAAgB,6EAEhB,MAAMiI,EAAK,YAAgB7I,EAAG,IAAK,iBAC7B8I,EAAK,YAAgBlI,EAAG,IAAK,iBAEnC,OADA,oBAAuBiI,EAAGtK,MAAOuK,EAAGvK,MAAO,4BACpC,YAAQsK,EAAIC,MAuBV4L,EAAgB,YAAG,CAAEC,eA7ClC,SAAwB3U,EAAGY,GACvB,YAAgB,6EAEhB,MAAMiI,EAAK,YAAgB7I,EAAG,IAAK,iBAC7B8I,EAAK,YAAgBlI,EAAG,IAAK,iBAEnC,OADA,oBAAuBiI,EAAGtK,MAAOuK,EAAGvK,MAAO,4BACpC,YAAQsK,EAAIC,MAwCV8L,EAAY,YAAG,CAAEC,WA9D9B,SAAoB7U,EAAGY,GACnB,YAAgB,6EAEhB,MAAMiI,EAAK,YAAgB7I,EAAG,IAAK,aAC7B8I,EAAK,YAAgBlI,EAAG,IAAK,aAEnC,OADA,oBAAuBiI,EAAGtK,MAAOuK,EAAGvK,MAAO,wBACpC,YAAIsK,EAAIC,MAyDNgM,EAAY,YAAG,CAAEC,WA/F9B,SAAoB/U,EAAGY,GACnB,YAAgB,6EAEhB,MAAMiI,EAAK,YAAgB7I,EAAG,IAAK,OAC7B8I,EAAK,YAAgBlI,EAAG,IAAK,OAEnC,OADA,oBAAuBiI,EAAGtK,MAAOuK,EAAGvK,MAAO,6BACpC,YAAIsK,EAAIC,MA0FNkM,EAAY,YAAG,CAAEC,WAhH9B,SAAoBC,EAAMC,GAItB,OAHA,YAAgB,6EAEhB,oBAAuBD,EAAK3W,MAAO4W,EAAI5W,MAAO,wBACvC,YAAI2W,EAAMC,MA6GRC,EAA0B,YAAG,CAAEC,yBAf5C,SAAkCrV,EAAGY,GACjC,YAAgB,6EAEhB,MAAMiI,EAAK,YAAgB7I,EAAG,IAAK,2BAC7B8I,EAAK,YAAgBlI,EAAG,IAAK,2BAEnC,OADA,oBAAuBiI,EAAGtK,MAAOuK,EAAGvK,MAAO,sCACpC,YAAkBsK,EAAIC,MAUpBwM,EAAY,YAAG,CAAEC,WApI9B,SAAoBvV,EAAGY,GACnB,YAAgB,6EAEhB,MAAMiI,EAAK,YAAgB7I,EAAG,IAAK,aAC7B8I,EAAK,YAAgBlI,EAAG,IAAK,aAEnC,OADA,oBAAuBiI,EAAGtK,MAAOuK,EAAGvK,MAAO,wBACpC,YAAIsK,EAAIC,O,iCC9DnB,kEAwCO,MAAM0M,EAAO,YAAG,CAAEC,MATzB,SAAe5X,GACX,MAAME,EAAK,YAAgBF,EAAG,IAAK,QAC7BI,EAAS,CAAEJ,EAAGE,GACpB,OAAO,IAAOI,eAAc,CAACC,EAAS2C,KAClC,MAAMc,EAAMzD,EAAQoX,KAAKzX,GAEzB,OADAgD,EAAK,CAAChD,IACC8D,IACR5D,EAAQ,KAAiB,S,iCCtChC,kEA0CO,MAAMyX,EAAQ,YAAG,CAAEC,OAT1B,SAAgB9X,GACZ,MAAME,EAAK,YAAgBF,EAAG,IAAK,SAC7BI,EAAS,CAAEJ,EAAGE,GACpB,OAAO,IAAOI,eAAc,CAACC,EAAS2C,KAClC,MAAMc,EAAMzD,EAAQsX,MAAM3X,GAE1B,OADAgD,EAAK,CAAChD,IACC8D,IACR5D,EAAQ,KAAiB,S,iCCxChC,kEAyCO,MAAM2X,EAAO,YAAG,CAAEC,MATzB,SAAehY,GACX,MAAME,EAAK,YAAgBF,EAAG,IAAK,QAC7BI,EAAS,CAAEJ,EAAGE,GACpB,OAAO,IAAOI,eAAc,CAACC,EAAS2C,KAClC,MAAMc,EAAMzD,EAAQwX,KAAK7X,GAEzB,OADAgD,EAAK,CAAChD,IACC8D,IACR5D,EAAQ,KAAiB,S,iCCvChC,kEA0CO,MAAM6X,EAAQ,YAAG,CAAEC,OAT1B,SAAgBlY,GACZ,MAAME,EAAK,YAAgBF,EAAG,IAAK,SAC7BI,EAAS,CAAEJ,EAAGE,GACpB,OAAO,IAAOI,eAAc,CAACC,EAAS2C,KAClC,MAAMc,EAAMzD,EAAQ0X,MAAM/X,GAE1B,OADAgD,EAAK,CAAChD,IACC8D,IACR5D,EAAQ,KAAiB,S,iCCxChC,kEAqCO,MAAMwI,EAAO,YAAG,CAAEuP,MALzB,SAAenY,GACX,MAAME,EAAK,YAAgBF,EAAG,IAAK,QAC7BI,EAAS,CAAEJ,EAAGE,GACpB,OAAO,IAAOI,eAAcC,GAAWA,EAAQqI,KAAK1I,IAAKE,EAAQ,KAAiB,S,iCCnCtF,yEA+CO,MAAMgY,EAAc,YAAG,CAAEC,aAZhC,SAAsBrY,EAAGsY,EAAcC,GACnC,MAAMrY,EAAK,YAAgBF,EAAG,IAAK,eACnC,SAAasY,GAAgBC,GAAe,IAAM,uBAAuBD,yCACvCC,QAClC,MAAMnY,EAAS,CAAEJ,EAAGE,GACdG,EAAQ,CAAEiY,eAAcC,gBAC9B,OAAO,IAAOjY,eAAc,CAACC,EAAS2C,KAClC,MAAMc,EAAMzD,EAAQiY,KAAKtY,EAAIoY,EAAcC,GAE3C,OADArV,EAAK,CAAChD,IACC8D,IACR5D,EAAQ,KAAiB,IAAaC,O,iCC7C7C,6RA4FO,MAAMoY,EAAc,YAAG,CAAEC,aAhChC,SAAsBvW,EAAGY,GACrB,YAAgB,6EAEhB,MAAMiI,EAAK,YAAgB7I,EAAG,IAAK,eAC7B8I,EAAK,YAAgBlI,EAAG,IAAK,eAEnC,OADA,4BAAkBiI,EAAGtK,MAAOuK,EAAGvK,MAAO,0BAC/B,YAAMsK,EAAIC,MA2BR0N,EAAqB,YAAG,CAAEC,oBATvC,SAA6BzW,EAAGY,GAC5B,YAAgB,6EAEhB,MAAMiI,EAAK,YAAgB7I,EAAG,IAAK,sBAC7B8I,EAAK,YAAgBlI,EAAG,IAAK,sBAEnC,OADA,4BAAkBiI,EAAGtK,MAAOuK,EAAGvK,MAAO,iCAC/B,YAAasK,EAAIC,MAIf4N,EAAgB,YAAG,CAAEC,eAlBlC,SAAwB3W,EAAGY,GACvB,YAAgB,6EAEhB,MAAMiI,EAAK,YAAgB7I,EAAG,IAAK,iBAC7B8I,EAAK,YAAgBlI,EAAG,IAAK,iBAEnC,OADA,4BAAkBiI,EAAGtK,MAAOuK,EAAGvK,MAAO,4BAC/B,YAAQsK,EAAIC,MAaV8N,EAAkB,YAAG,CAAEC,iBA3BpC,SAA0B7W,EAAGY,GACzB,YAAgB,6EAEhB,MAAMiI,EAAK,YAAgB7I,EAAG,IAAK,mBAC7B8I,EAAK,YAAgBlI,EAAG,IAAK,mBAEnC,OADA,4BAAkBiI,EAAGtK,MAAOuK,EAAGvK,MAAO,8BAC/B,YAAUsK,EAAIC,MAsBZgO,EAAa,YAAG,CAAEC,YA5C/B,SAAqB/W,EAAGY,GACpB,YAAgB,6EAEhB,MAAMiI,EAAK,YAAgB7I,EAAG,IAAK,cAC7B8I,EAAK,YAAgBlI,EAAG,IAAK,cAEnC,OADA,4BAAkBiI,EAAGtK,MAAOuK,EAAGvK,MAAO,yBAC/B,YAAKsK,EAAIC,MAuCPkO,EAAiB,YAAG,CAAEC,gBA9DnC,SAAyBjX,EAAGY,GACxB,YAAgB,6EAEhB,MAAMiI,EAAK,YAAgB7I,EAAG,IAAK,kBAC7B8I,EAAK,YAAgBlI,EAAG,IAAK,kBAEnC,OADA,4BAAkBiI,EAAGtK,MAAOuK,EAAGvK,MAAO,6BAC/B,YAASsK,EAAIC,O,iCCzCxB,iFAgDO,MAAMoO,EAAM,YAAG,CAAEC,KAbxB,SAActZ,GACV,IAAIE,EAAK,YAAgBF,EAAG,IAAK,OACjC,SAAyB,UAAbE,EAAGD,OAAkC,YAAbC,EAAGD,OAAqB,IAAM,8CACjD,UAAbC,EAAGD,QACHC,EAAK,YAAKA,EAAI,YAElB,MAAME,EAAS,CAAEJ,EAAGE,GACpB,OAAO,IAAOI,eAAc,CAACC,EAAS2C,KAClC,MAAMc,EAAMzD,EAAQ8Y,IAAInZ,GAExB,OADAgD,EAAK,CAAChD,IACC8D,IACR5D,EAAQ,KAAiB,S,iCC9ChC,kEA0CO,MAAMmZ,EAAQ,YAAG,CAAEC,OAT1B,SAAgBxZ,GACZ,MAAME,EAAK,YAAgBF,EAAG,IAAK,SAC7BI,EAAS,CAAEJ,EAAGE,GACpB,OAAO,IAAOI,eAAc,CAACC,EAAS2C,KAClC,MAAMc,EAAMzD,EAAQgZ,MAAMrZ,GAE1B,OADAgD,EAAK,CAAChD,IACC8D,IACR5D,EAAQ,KAAiB,S,gCCxChC,0FA+FO,MAAMqU,EAAS,YAAG,CAAEgF,QAhC3B,SAAiBxI,EAAS3N,EAAO,GAC7B,iBAAO2N,EAAQlQ,QAAU,GAAG,IAAM,uCAClC,IAAI2Y,EAAW,YAAqBzI,EAAS,UAAW,UAC9B,cAAtByI,EAAS,GAAGzZ,OACZyZ,EAAS7T,SAAQ8T,IACb,GAAqB,cAAjBA,EAAO1Z,MACP,MAAM,IAAIE,MAAM,4EACTwZ,EAAO1Z,cAI1B,MAAM2Z,EAAQ,yBAAetW,EAAMoW,EAAS,GAAGhZ,OAAO,GAChDqB,EAAW,YAAgB2X,EAASjY,KAAIoY,GAAKA,EAAEnZ,QAAQkZ,GAC7D,GAAgC,IAA5B,wBAAc7X,GACd,OAAO,YAAO,GAAIA,GAItB,GADA2X,EAAWA,EAAS/X,QAAOkY,GAAKA,EAAE1K,KAAO,IACjB,IAApBuK,EAAS3Y,OACT,OAAO2Y,EAAS,GAEpB,MAAM9T,EAAS8T,EAASjY,KAAIoY,GAAKA,EAAEnZ,QACnC,YAAuBkF,EAAQgU,GAC/B,MAKMxZ,EAASsZ,EACTI,EAAO,CAAExW,QACf,OAAO,IAAOhD,eAPE,CAACC,EAAS2C,KACtB,MAAMc,EAAMzD,EAAQkU,OAAOiF,EAAUE,GAErC,OADA1W,EAAKwW,GACE1V,IAI0B5D,EAAQ,KAAiB,IAAQ0Z,O,iCC7F1E,wFAuFO,MAAMC,EAAoB,YAAG,CAAEC,mBAnCtC,SAA4BjV,EAAIpE,EAAOwD,EAAYC,EAAS+B,EAAY,CAAC,EAAG,EAAG,GAAI9B,EAAKC,GACpF,MAAM2V,EAAM,YAAgBlV,EAAI,KAAM,qBAChCmV,EAAS,YAAgBvZ,EAAO,QAAS,qBAC/C,IAAIwZ,EAAOF,EACPG,EAAUF,EACVG,GAAe,EACC,IAAhBH,EAAOlZ,OACPqZ,GAAe,EACfF,EAAO,YAAQF,EAAK,CAAC,EAAGA,EAAIvZ,MAAM,GAAIuZ,EAAIvZ,MAAM,GAAIuZ,EAAIvZ,MAAM,GAAIuZ,EAAIvZ,MAAM,KAC5E0Z,EAAU,YAAQF,EAAQ,CACtB,EAAGA,EAAOxZ,MAAM,GAAIwZ,EAAOxZ,MAAM,GAAIwZ,EAAOxZ,MAAM,GAAIwZ,EAAOxZ,MAAM,MAG3E,SAA0B,IAAdyZ,EAAKnZ,MAAY,IACzB,8DAAGmZ,EAAKnZ,UACZ,SAA6B,IAAjBoZ,EAAQpZ,MAAY,IAC5B,iEAAGoZ,EAAQpZ,UACf,SAAY,IAAyCoD,EAAS+B,IAAY,IACtE,kFAA0B/B,oBAA0B+B,OACjC,MAAnB7B,GACA,SAAY,QAAWD,IAAM,IACzB,kFAA0BC,iBAA+BD,OAEjE,MAIMjE,EAAS,CAAE2E,GAAIoV,EAAMxZ,MAAOyZ,GAC5B/Z,EAAQ,CAAE8D,aAAYC,UAAS+B,YAAW9B,MAAKC,mBAC/CN,EAAM,IAAO1D,eANHC,IACZ,MAAMkE,EAAW,IAA4B2V,EAAQ1Z,MAAOyD,EAAYC,EAAS+B,EAAW9B,EAAKC,GACjG,OAAO/D,EAAQwZ,kBAAkBI,EAAMC,EAAS3V,KAIVrE,EAAQ,KAAiB,IAAmBC,GACtF,OAAIga,EACO,YAAQrW,EAAK,CAACA,EAAItD,MAAM,GAAIsD,EAAItD,MAAM,GAAIsD,EAAItD,MAAM,GAAIsD,EAAItD,MAAM,KAEtEsD,M,iCCrFX,wFAoEO,MAAMsW,EAAkB,YAAG,CAAEC,iBA7BpC,SAA0BxV,EAAIpE,EAAOwD,EAAYC,EAASC,GACtD,MAAM4V,EAAM,YAAgBlV,EAAI,KAAM,mBAChCmV,EAAS,YAAgBvZ,EAAO,QAAS,mBAC/C,SAAYuZ,EAAOlZ,OAASiZ,EAAIjZ,MAAM,IAAM,kBAAkBkZ,EAAOlZ,oCAAoCiZ,EAAIjZ,UAC7G,IAAI4M,EAAUsM,EACVhV,EAAO+U,EACPzV,GAAe,EACC,IAAhB0V,EAAOlZ,OACPwD,GAAe,EACfoJ,EACI,YAAQsM,EAAQ,CAAC,EAAGA,EAAOxZ,MAAM,GAAIwZ,EAAOxZ,MAAM,GAAIwZ,EAAOxZ,MAAM,KACvEwE,EAAO,YAAQ+U,EAAK,CAAC,EAAGA,EAAIvZ,MAAM,GAAIuZ,EAAIvZ,MAAM,GAAIuZ,EAAIvZ,MAAM,MAElE,SAA0B,IAAdwE,EAAKlE,MAAY,IACzB,4DAAGkE,EAAKlE,UACZ,SAA6B,IAAjB4M,EAAQ5M,MAAY,IAC5B,+DAAG4M,EAAQ5M,UACf,MAIMZ,EAAS,CAAE2E,GAAIG,EAAMvE,MAAOiN,GAC5BvN,EAAQ,CAAE8D,aAAYC,UAASC,OAC/BL,EAAM,IAAO1D,eANHC,IACZ,MAAMkE,EAAW,IAA4BmJ,EAAQlN,MAAOyD,EAAYC,EAAS,EAAmBC,GACpG,OAAO9D,EAAQ+Z,gBAAgBpV,EAAM0I,EAASnJ,KAIRrE,EAAQ,KAAM,IAAiBC,GACzE,OAAImE,EACO,YAAQR,EAAK,CAACA,EAAItD,MAAM,GAAIsD,EAAItD,MAAM,GAAIsD,EAAItD,MAAM,KAExDsD,M,iCClEX,iFA4EO,MAAMwW,EAAsB,YAAG,CAAEC,qBApCxC,SAA8B7Z,EAAQmE,EAAIpD,EAAQyC,EAASC,GACvD,SAAYzD,EAAOG,SAAWgE,EAAG/D,MAAM,IACnC,sBAAIJ,EAAOG,2BAA2BgE,EAAG/D,qBAC7C,IAAI0Z,EAAW9Z,EACXuZ,EAAOpV,EACPsV,GAAe,EACH,IAAZtV,EAAG/D,OACHqZ,GAAe,EACfF,EAAO,YAAQpV,EAAI,CAAC,EAAGA,EAAGrE,MAAM,GAAIqE,EAAGrE,MAAM,GAAIqE,EAAGrE,MAAM,GAAIqE,EAAGrE,MAAM,KACvEga,EAAW,CAAC,EAAG9Z,EAAO,GAAIA,EAAO,GAAIA,EAAO,GAAIA,EAAO,KAE3D,MAAMuE,EAAUuV,EAAS,GACnBtV,EAAW+U,EAAKzZ,MAAM,GAC5B,SAAgC,IAApBga,EAAS3Z,QAAc,IAC/B,qEAAG2Z,EAAS3Z,YAChB,SAA0B,IAAdoZ,EAAKnZ,MAAY,IACzB,4DAAQmZ,EAAKnZ,SACjB,SAA4B,IAAhBW,EAAOX,MAAY,IAC3B,gEAAQW,EAAOX,SACnB,SAAYmE,IAAYxD,EAAOjB,MAAM,IAAI,IAAM,4CAA4CyE,wCACvDxD,EAAOjB,MAAM,QACjD,SAAY0E,IAAazD,EAAOjB,MAAM,IAAI,IAAM,6CAA6C0E,yCACxDzD,EAAOjB,MAAM,QAClD,MAKMN,EAAS,CAAE2E,GAAIoV,GACf9Z,EAAQ,CAAEgE,OACVL,EAAM,IAAO1D,eAPHC,IACZ,MACMkE,EAAW,IAA4BiW,EAAU/Y,EAAOjB,MAAO0D,EADnD,EACuEC,GACzF,OAAO9D,EAAQoa,eAAeR,EAAMxY,EAAQ8C,KAINrE,EAAQ,KAAM,IAAuBC,GAC/E,OAAIga,EACO,YAAQrW,EAAK,CAACA,EAAItD,MAAM,GAAIsD,EAAItD,MAAM,GAAIsD,EAAItD,MAAM,GAAIsD,EAAItD,MAAM,KAEtEsD,M,iCC1EX,iFAkEO,MAAM4W,EAAuB,YAAG,CAAEC,sBA5BzC,SAA+B7a,EAAG+E,EAAIU,EAAarB,EAASC,GACxD,IAAIyW,EAAM9a,EACK,IAAXA,EAAEgB,OACF8Z,EAAM,YAAQ9a,EAAG,CAAC,EAAGA,EAAEU,MAAM,GAAIV,EAAEU,MAAM,GAAIV,EAAEU,MAAM,GAAIV,EAAEU,MAAM,MAErE,IAAIyZ,EAAOpV,EACO,IAAdoV,EAAKnZ,OACLmZ,EAAO,YAAQpV,EAAI,CAAC,EAAGA,EAAGrE,MAAM,GAAIqE,EAAGrE,MAAM,GAAIqE,EAAGrE,MAAM,GAAIqE,EAAGrE,MAAM,MAE3E,SAAyB,IAAboa,EAAI9Z,MAAY,IACxB,iEAAG8Z,EAAIpa,WACX,SAA0B,IAAdyZ,EAAKnZ,MAAY,IACzB,8DAAGmZ,EAAKzZ,WACZ,SAAmC,IAAvB+E,EAAY1E,QAAc,IAClC,mEAAG0E,OACP,SAAYqV,EAAIpa,MAAM,KAAO+E,EAAY,IAAI,IAAM,4CAA4CqV,EAAIpa,MAAM,yCACrE+E,EAAY,QAChD,SAAY0U,EAAKzZ,MAAM,KAAO+E,EAAY,IAAI,IAAM,0CAA0C0U,EAAKzZ,MAAM,2CACnE+E,EAAY,SAClD,MAKMrF,EAAS,CAAEJ,EAAG8a,EAAK3X,EAAGgX,GACtB9Z,EAAQ,CAAE+D,UAASC,OACzB,OAAO,IAAO/D,eAPEC,IACZ,MACMkE,EAAW,IAA4BqW,EAAIpa,MAAO+E,EAAarB,EADnD,EACuEC,GACzF,OAAO9D,EAAQwa,gBAAgBD,EAAKX,EAAM1V,KAITrE,EAAQ,KAAM,IAAwBC,O,gCChE/E,kEAyCO,MAAMiX,EAAM,YAAG,CAAE0D,KATxB,SAAchb,GACV,MAAME,EAAK,YAAgBF,EAAG,IAAK,OAC7BI,EAAS,CAAEJ,EAAGE,GACpB,OAAO,IAAOI,eAAc,CAACC,EAAS2C,KAClC,MAAMc,EAAMzD,EAAQ+W,IAAIpX,GAExB,OADAgD,EAAK,CAACc,IACCA,IACR5D,EAAQ,KAAiB,S,gCCvChC,kEA2CO,MAAM6a,EAAM,YAAG,CAAEC,KAXxB,SAAclb,GACV,MAAME,EAAK,YAAgBF,EAAG,IAAK,OAC7BI,EAAS,CAAEJ,EAAGE,GACpB,OAAO,IAAOI,eAAc,CAACC,EAAS2C,KAClCA,EAAK,CAAChD,IACW,cAAbA,EAAGD,MACIM,EAAQ4a,WAAWjb,GAEvBK,EAAQ0a,IAAI/a,KACpBE,EAAQ,KAAiB,S,gCCzChC,kEAiDO,MAAMgb,EAAa,YAAG,CAAEC,YAb/B,SAAqBrb,EAAGsD,EAAO,GAC3B,MACMpD,EAAK,YAAgBF,EAAG,IAAK,aADnB,MAEhB,SAAYsD,GAAQpD,EAAGc,MAAM,IAAM,uCACnC,MAAMC,EAAWf,EAAGQ,MAAMQ,QAO1B,OANIoC,EAAO,IAEP,WAAcpD,EAAGc,KAAO,IAAMsC,GAAM,IAAM,mCAAmCpD,EAAGc,KAAO,OAAOd,EAAGc,UACjGsC,EAAOpD,EAAGc,KAAOsC,EAAO,GAE5BrC,EAASqa,OAAOhY,EAAM,EAAG,GAClB,YAAQpD,EAAIe,O,gCC/CvB,yEAoDO,MAAMsa,EAAU,YAAG,CAAEC,SAX5B,SAAkBC,EAAMC,GACpB,MAAMC,EAAQ,YAAgBF,EAAM,OAAQ,WACtCG,EAAQ,YAAgBF,EAAM,OAAQ,WAC5C,oBAAuBC,EAAMjb,MAAOkb,EAAMlb,MAAO,yBAAyBib,EAAMjb,aAAakb,EAAMlb,8CAEnG,MAGMN,EAAS,CAAEqb,KAAME,EAAOD,KAAME,GACpC,OAAO,IAAOtb,eAJGC,GACNA,EAAQgb,QAAQI,EAAOC,IAGGxb,EAAQ,KAAqB,S,gCClDtE,wFA4FO,MAAMyb,EAAS,YAAG,CAAEC,QApC3B,SAAiB9b,EAAG2B,EAAQyC,EAASC,EAAKW,EAAa,OAAQmB,EAAY,CAAC,EAAG,GAAI7B,GAC/E,MAAMpE,EAAK,YAAgBF,EAAG,IAAK,UAC7BwN,EAAU,YAAgB7L,EAAQ,SAAU,UAClD,IAAI4C,EAAMrE,EACNsE,GAAe,EACH,IAAZtE,EAAGc,OACHwD,GAAe,EACfD,EAAM,YAAQrE,EAAI,CAAC,EAAGA,EAAGQ,MAAM,GAAIR,EAAGQ,MAAM,GAAIR,EAAGQ,MAAM,MAE7D,SAAyB,IAAb6D,EAAIvD,MAAY,IAAM,uDAAuDuD,EAAIvD,UAC7F,SAA6B,IAAjBwM,EAAQxM,MAAY,IAC5B,wDAAGwM,EAAQxM,UACQ,MAAnBsD,GACA,SAAY,QAAWD,IAAM,IACzB,uEAAmBC,iBAA+BD,OAE1D,MAAMc,EAAyB,SAAfH,EAAwBT,EAAI7D,MAAM,GAAK6D,EAAI7D,MAAM,GACjE,SAAYyE,IAAYqI,EAAQ9M,MAAM,IAAI,IAAM,oCAAoCyE,wCACtDqI,EAAQ9M,MAAM,QAC5C,SAAY,IAAyC0D,EAAS+B,IAAY,IACtE,uEAAe/B,oBAA0B+B,OAC7C,MAOM/F,EAAS,CAAEJ,EAAGuE,EAAK5C,OAAQ6L,GAC3BnN,EAAQ,CAAE+D,UAASC,MAAKW,aAAYmB,YAAW7B,mBAC/CN,EAAM,IAAO1D,eATH,CAACC,EAAS2C,KACtB,MAAMmC,EAAc,IAAkCL,GAChDP,EAAW,IAA4BF,EAAI7D,MAAO8M,EAAQ9M,MAAO0D,EAAS+B,EAAW9B,EAAKC,GAAiB,EAAOe,GAClHrB,EAAMzD,EAAQsb,OAAOtX,EAAKiJ,EAAS/I,GAEzC,OADAvB,EAAK,CAACqB,EAAKiJ,IACJxJ,IAI+B5D,EAAQ,KAAiB,IAAQC,GAC3E,OAAImE,EACO,YAAQR,EAAK,CAACA,EAAItD,MAAM,GAAIsD,EAAItD,MAAM,GAAIsD,EAAItD,MAAM,KAExDsD,M,gCC1FX,kEA0CO,MAAMY,EAAQ,YAAG,CAAEmX,OAR1B,SAAgB/b,GACZ,MAAME,EAAK,YAAgBF,EAAG,IAAK,QAAS,MAEtCI,EAAS,CAAEJ,EAAGE,GAGpB,OAAO,IAAOI,eAJE,IAAM,IAAO0b,qBAAqB9b,EAAG+b,OAAQ/b,EAAGQ,MAAOR,EAAGD,QAIrCG,EAAQ,KAAiB,U,gCCxClE,wFA4GO,MAAM8b,EAAkB,YAAG,CAAEC,iBAvCpC,SAA0Bnc,EAAG2B,EAAQyC,EAASC,EAAKW,EAAa,OAAQmB,EAAY,CAAC,EAAG,GAAI7B,GACxF,MAAMpE,EAAK,YAAgBF,EAAG,IAAK,mBAC7BwN,EAAU,YAAgB7L,EAAQ,SAAU,mBAClD,IAAI4C,EAAMrE,EACNsE,GAAe,EACH,IAAZtE,EAAGc,OACHwD,GAAe,EACfD,EAAM,YAAQrE,EAAI,CAAC,EAAGA,EAAGQ,MAAM,GAAIR,EAAGQ,MAAM,GAAIR,EAAGQ,MAAM,MAE7D,SAAyB,IAAb6D,EAAIvD,MAAY,IACxB,gEAAQuD,EAAIvD,UAChB,SAA6B,IAAjBwM,EAAQxM,MAAY,IAC5B,iEAAGwM,EAAQxM,UACf,SAAYuD,EAAI7D,MAAM,KAAO8M,EAAQ9M,MAAM,IAAI,IAC3C,uDAAI6D,EAAI7D,MAAM,qDACJ8M,EAAQ9M,MAAM,QACL,MAAnB4D,GACA,SAAY,QAAWD,IAAM,IACzB,gFAAmBC,iBAA+BD,OAE1D,MAWMjE,EAAS,CAAEJ,EAAGuE,EAAK5C,OAAQ6L,GAC3BnN,EAAQ,CAAE+D,UAASC,MAAKW,aAAYmB,YAAW7B,mBAC/CN,EAAM,IAAO1D,eAbH,CAACC,EAAS2C,KACL,MAAbiD,IACAA,EAAY,CAAC,EAAG,IAEpB,SAAY,IAAyC/B,EAAS+B,IAAY,IACtE,gFAAkB/B,oBAA0B+B,OAChD,MAAM1B,EAAW,IAA4BF,EAAI7D,MAAO8M,EAAQ9M,MAAO0D,EAAS+B,EAAW9B,EAAKC,GAAiB,GAC3GN,EAAMzD,EAAQ6b,gBAAgB7X,EAAKiJ,EAAS/I,GAElD,OADAvB,EAAK,CAACqB,EAAKiJ,IACJxJ,IAI+B5D,EAAQ,KAAiB,IAAuBC,GAC1F,OAAImE,EACO,YAAQR,EAAK,CAACA,EAAItD,MAAM,GAAIsD,EAAItD,MAAM,GAAIsD,EAAItD,MAAM,KAExDsD,M,gCC1GX,kFA8CO,MAAMqY,EAAQ,YAAG,CAAEC,OAT1B,SAAgBna,EAAGY,GACf,IAAIiI,EAAK,YAAgB7I,EAAG,IAAK,SAC7B8I,EAAK,YAAgBlI,EAAG,IAAK,UAChCiI,EAAIC,GAAM,YAAeD,EAAIC,GAC9B,YAA2BD,EAAGtK,MAAOuK,EAAGvK,OACxC,MACMN,EAAS,CAAE+B,EAAG6I,EAAIjI,EAAGkI,GAC3B,OAAO,IAAO3K,eAFEC,GAAWA,EAAQ8b,MAAMrR,EAAIC,IAER7K,EAAQ,KAAM,S,gCC5CvD,oDA4CO,SAASmc,EAAO7b,EAAOT,EAAQ,UAAW2T,GAG7C,OAFA3T,EAAQA,GAAS,UACjB,qCAAwCS,GACjC,IAAI,IAAaA,EAAOT,EAAO2T,K,gCC/C1C,yEAmFO,MAAM4I,EAAiB,YAAG,CAAEC,gBAdnC,SAAyBzc,EAAGqU,EAAYe,GACpC,MAAMlV,EAAK,YAAgBF,EAAG,IAAK,kBAC7BsU,EAAOD,EAAWqI,QAAO,CAACva,EAAGY,IAAMZ,EAAIY,IAC7C,SAAY7C,EAAGc,MAAQ,EAAIqT,EAAWtT,QAAQ,IAAM,iBAAiBb,EAAGc,+CAA+CqT,EAAWtT,WAClI,SAAYqU,EAAMrU,SAAWsT,EAAWtT,QAAQ,IAAM,mBAAmBqU,EAAMrU,oDAAoDsT,EAAWtT,WAC9I,SAAYb,EAAGQ,MAAM,GAAK4T,GAAS,GAAG,IAAM,yBAAyBpU,EAAGQ,MAAM,wEAC5C2T,EAAWsI,KAAK,cAAcrI,MAChE,MAGMlU,EAAS,CAAEJ,EAAGE,GACdG,EAAQ,CAAEgU,aAAYe,SAC5B,OAAO,IAAO9U,eALEC,GACLA,EAAQic,eAAetc,EAAImU,EAAYe,IAIbhV,EAAQ,KAAqB,IAAgBC","file":"js/bundle~bundle~a1212309.0178786a.js","sourcesContent":["/**\n * @license\n * Copyright 2020 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Cast } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport * as util from '../util';\nimport { op } from './operation';\n/**\n * Casts a `tf.Tensor` to a new dtype.\n *\n * ```js\n * const x = tf.tensor1d([1.5, 2.5, 3]);\n * tf.cast(x, 'int32').print();\n * ```\n * @param x The input tensor to be casted.\n * @param dtype The dtype to cast the input tensor to.\n *\n * @doc {heading: 'Tensors', subheading: 'Transformations'}\n */\nfunction cast_(x, dtype) {\n    const $x = convertToTensor(x, 'x', 'cast');\n    // Sanity checks.\n    if (!util.isValidDtype(dtype)) {\n        throw new Error(`Failed to cast to unknown dtype ${dtype}`);\n    }\n    if (dtype === 'string' && $x.dtype !== 'string' ||\n        dtype !== 'string' && $x.dtype === 'string') {\n        throw new Error('Only strings can be casted to strings');\n    }\n    const inputs = { x: $x };\n    const attrs = { dtype };\n    return ENGINE.runKernelFunc(backend => backend.cast($x, dtype), inputs, null /* grad */, Cast, attrs);\n}\nexport const cast = op({ cast_ });\n//# sourceMappingURL=cast.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { BroadcastTo } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { clone } from './clone';\nimport { op } from './operation';\nimport { reshape } from './reshape';\n/**\n * Broadcast an array to a compatible shape NumPy-style.\n *\n * The tensor's shape is compared to the broadcast shape from end to beginning.\n * Ones are prepended to the tensor's shape until is has the same length as\n * the broadcast shape. If input.shape[i]==shape[i], the (i+1)-th axis is\n * already broadcast-compatible. If input.shape[i]==1 and shape[i]==N, then\n * the input tensor is tiled N times along that axis (using tf.tile).\n *\n * @param input The tensor that is to be broadcasted.\n * @param shape The input is to be broadcast to this shape.\n *\n * @doc {heading: 'Tensors', subheading: 'Transformations'}\n */\nfunction broadcastTo_(x, shape) {\n    let input = convertToTensor(x, 'broadcastTo', 'x');\n    const xShape = input.shape;\n    if (shape.some(d => !(d > 0) || d % 1 !== 0)) {\n        throw new Error(`broadcastTo(): Invalid broadcast shape [${shape}].`);\n    }\n    if (shape.length < input.rank) {\n        throw new Error(`broadcastTo(): shape.length=${shape.length} < input.rank=${input.rank}.`);\n    }\n    if (shape.length > input.rank) {\n        const newShape = input.shape.slice();\n        while (newShape.length < shape.length) {\n            newShape.unshift(1);\n        }\n        input = reshape(input, newShape);\n    }\n    const inputShape = input.shape;\n    const reps = Array.from(shape);\n    for (let i = shape.length - 1; i >= 0; i--) {\n        if (inputShape[i] === shape[i]) {\n            reps[i] = 1;\n        }\n        else if (input.shape[i] !== 1) {\n            throw new Error(`broadcastTo(): [${xShape}] cannot be broadcast to [${shape}].`);\n        }\n    }\n    const axes = reps.map((n, i) => n > 1 ? i : -1).filter(i => i >= 0);\n    if (axes.length === 0) {\n        return clone(input);\n    }\n    const forward = (backend) => backend.tile(input, reps);\n    const inputs = { x: input };\n    const attrs = { shape, inputShape };\n    return ENGINE.runKernelFunc(forward, inputs, null /* grad */, BroadcastTo, attrs);\n}\nexport const broadcastTo = op({ broadcastTo_ });\n//# sourceMappingURL=broadcast_to.js.map","/**\n * @license\n * Copyright 2017 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n/**\n * Returns the dimensions in the input shape that are broadcasted to\n * produce the provided output shape.\n *\n * The returned dimensions are 0-indexed and sorted. An example:\n * inShape = [4, 1, 3]\n * outShape = [5, 4, 3, 3]\n * result = [1]. Dimension 1 (2nd dimension of input) gets broadcasted 1 => 3.\n */\nexport function getBroadcastDims(inShape, outShape) {\n    const inRank = inShape.length;\n    const dims = [];\n    for (let i = 0; i < inRank; i++) {\n        const dim = inRank - 1 - i;\n        const a = inShape[dim] || 1;\n        const b = outShape[outShape.length - 1 - i] || 1;\n        if (b > 1 && a === 1) {\n            dims.unshift(dim);\n        }\n    }\n    return dims;\n}\n/**\n * Returns the axes in the output space that should be reduced to produce\n * the input space.\n */\nexport function getReductionAxes(inShape, outShape) {\n    const result = [];\n    for (let i = 0; i < outShape.length; i++) {\n        const inDim = inShape[inShape.length - i - 1];\n        const outAxis = outShape.length - i - 1;\n        const outDim = outShape[outAxis];\n        if (inDim == null || (inDim === 1 && outDim > 1)) {\n            result.unshift(outAxis);\n        }\n    }\n    return result;\n}\nexport function assertAndGetBroadcastShape(shapeA, shapeB) {\n    const result = [];\n    const l = Math.max(shapeA.length, shapeB.length);\n    for (let i = 0; i < l; i++) {\n        let a = shapeA[shapeA.length - i - 1];\n        if (a == null) {\n            a = 1;\n        }\n        let b = shapeB[shapeB.length - i - 1];\n        if (b == null) {\n            b = 1;\n        }\n        if (a === 1) {\n            result.unshift(b);\n        }\n        else if (b === 1) {\n            result.unshift(a);\n        }\n        else if (a !== b) {\n            const errMsg = `Operands could not be broadcast together with shapes ` +\n                `${shapeA} and ${shapeB}.`;\n            throw Error(errMsg);\n        }\n        else {\n            result.unshift(a);\n        }\n    }\n    return result;\n}\n//# sourceMappingURL=broadcast_util.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Elu } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes exponential linear element-wise: `x > 0 ? e ^ x - 1 : 0`.\n *\n * ```js\n * const x = tf.tensor1d([-1, 1, -3, 2]);\n *\n * x.elu().print();  // or tf.elu(x)\n * ```\n * @param x The input tensor.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction elu_(x) {\n    const $x = convertToTensor(x, 'x', 'elu');\n    const forward = (backend, save) => {\n        const y = backend.elu($x);\n        save([y]);\n        return y;\n    };\n    const inputs = { x: $x };\n    return ENGINE.runKernelFunc(forward, inputs, null /* grad */, Elu);\n}\nexport const elu = op({ elu_ });\n//# sourceMappingURL=elu.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Cumsum } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { getAxesPermutation, getInnerMostAxes, getUndoAxesPermutation } from './axis_util';\nimport { op } from './operation';\nimport { transpose } from './transpose';\n/**\n * Computes the cumulative sum of a `tf.Tensor` along `axis`.\n *\n * ```js\n * const x = tf.tensor([1, 2, 3, 4]);\n * x.cumsum().print();\n * ```\n * ```js\n * const x = tf.tensor([[1, 2], [3, 4]]);\n * x.cumsum().print();\n * ```\n *\n * @param x The input tensor to be summed.\n * @param axis The axis along which to sum. Optional. Defaults to 0.\n * @param exclusive Whether to perform exclusive cumulative sum. Optional.\n *     Defaults to false. If set to true then the sum of each tensor entry\n *     does not include its own value, but only the values previous to it\n *     along the specified axis.\n * @param reverse Whether to sum in the opposite direction. Optional.\n *     Defaults to false.\n *\n * @doc {heading: 'Operations', subheading: 'Scan'}\n */\nfunction cumsum_(x, axis = 0, exclusive = false, reverse = false) {\n    const $x = convertToTensor(x, 'x', 'cumsum');\n    const forward = (backend, save) => {\n        const permutation = getAxesPermutation([axis], $x.rank);\n        let permutedX = $x;\n        if (permutation != null) {\n            permutedX = transpose($x, permutation);\n        }\n        const permutedAxis = getInnerMostAxes(1, $x.rank)[0];\n        let value = backend.cumsum(permutedX, permutedAxis, exclusive, reverse);\n        save([$x]);\n        if (permutation != null) {\n            const reversePermutation = getUndoAxesPermutation(permutation);\n            value = transpose(value, reversePermutation);\n        }\n        return value;\n    };\n    const inputs = { x: $x };\n    const attrs = { axis, exclusive, reverse };\n    return ENGINE.runKernelFunc(forward, inputs, null /* grad */, Cumsum, attrs);\n}\nexport const cumsum = op({ cumsum_ });\n//# sourceMappingURL=cumsum.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Cos } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes cos of the input `tf.Tensor` element-wise: `cos(x)`\n *\n * ```js\n * const x = tf.tensor1d([0, Math.PI / 2, Math.PI * 3 / 4]);\n *\n * x.cos().print();  // or tf.cos(x)\n * ```\n * @param x The input tensor.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction cos_(x) {\n    const $x = convertToTensor(x, 'x', 'cos');\n    const inputs = { x: $x };\n    return ENGINE.runKernelFunc((backend, save) => {\n        const res = backend.cos($x);\n        save([$x]);\n        return res;\n    }, inputs, null /* grad */, Cos);\n}\nexport const cos = op({ cos_ });\n//# sourceMappingURL=cos.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { AvgPool } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport * as util from '../util';\nimport { cast } from './cast';\nimport * as conv_util from './conv_util';\nimport { op } from './operation';\nimport { reshape } from './reshape';\n/**\n * Computes the 2D average pooling of an image.\n *\n * @param x The input tensor, of rank 4 or rank 3 of shape\n *     `[batch, height, width, inChannels]`. If rank 3, batch of 1 is assumed.\n * @param filterSize The filter size: `[filterHeight, filterWidth]`. If\n *     `filterSize` is a single number, then `filterHeight == filterWidth`.\n * @param strides The strides of the pooling: `[strideHeight, strideWidth]`. If\n *     `strides` is a single number, then `strideHeight == strideWidth`.\n * @param pad The type of padding algorithm:\n *    - `same` and stride 1: output will be of same size as input,\n *       regardless of filter size.\n *    - `valid`: output will be smaller than input if filter is larger\n *       than 1x1.\n *    - For more info, see this guide:\n *     [https://www.tensorflow.org/api_guides/python/nn#Convolution](\n *         https://www.tensorflow.org/api_guides/python/nn#Convolution)\n * @param dimRoundingMode The rounding mode used when computing output\n *     dimensions if pad is a number. If none is provided, it will not round\n *     and error if the output is of fractional size.\n */\nfunction avgPool_(x, filterSize, strides, pad, dimRoundingMode) {\n    const $x = convertToTensor(x, 'x', 'avgPool', 'float32');\n    const dilations = 1;\n    util.assert(conv_util.eitherStridesOrDilationsAreOne(strides, dilations), () => 'Error in avgPool: Either strides or dilations must be 1. ' +\n        `Got strides ${strides} and dilations '${dilations}'`);\n    let x4D = $x;\n    let reshapedTo4D = false;\n    if ($x.rank === 3) {\n        reshapedTo4D = true;\n        x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);\n    }\n    util.assert(x4D.rank === 4, () => `Error in avgPool: x must be rank 4 but got rank ${x4D.rank}.`);\n    if (dimRoundingMode != null) {\n        util.assert(util.isInt(pad), () => `Error in avgPool: pad must be an integer when using, ` +\n            `dimRoundingMode ${dimRoundingMode} but got pad ${pad}.`);\n    }\n    const forward = (backend, save) => {\n        const convInfo = conv_util.computePool2DInfo(x4D.shape, filterSize, strides, 1 /* dilations */, pad, dimRoundingMode);\n        save([x4D]);\n        if (convInfo.filterWidth === 1 && convInfo.filterHeight === 1 &&\n            util.arraysEqual(convInfo.inShape, convInfo.outShape)) {\n            return x4D.clone();\n        }\n        return backend.avgPool(x4D, convInfo);\n    };\n    const inputs = { x: x4D };\n    const attrs = { filterSize, strides, pad, dimRoundingMode };\n    let res = ENGINE.runKernelFunc(forward, inputs, null /* grad */, AvgPool, attrs);\n    res = cast(res, $x.dtype);\n    if (reshapedTo4D) {\n        return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);\n    }\n    return res;\n}\nexport const avgPool = op({ avgPool_ });\n//# sourceMappingURL=avg_pool.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Conv2DBackpropInput } from '../kernel_names';\nimport * as util from '../util';\nimport * as conv_util from './conv_util';\nimport { op } from './operation';\nimport { reshape } from './reshape';\n/**\n * Computes the derivative of the input of a 2D convolution.\n *\n * @param xShape The shape of the input: [batch, height, width, inDepth].\n * If length of 3, batch of 1 is assumed.\n * @param dy The derivative of the output, of rank 4 or rank 3 of shape\n *   `[batch, outHeight, outWidth, outDepth]`. If rank 3, batch of 1 is\n * assumed.\n * @param filter The filter, rank 4, of shape\n *     `[filterHeight, filterWidth, inDepth, outDepth]`.\n * @param strides The strides of the convolution: `[strideHeight,\n * strideWidth]`.\n * @param pad The type of padding algorithm used:\n *    - `same` and stride 1: output will be of same size as input,\n *       regardless of filter size.\n *    - `valid`: output will be smaller than input if filter is larger\n *       than 1x1.\n * @param dataFormat: An optional string from: \"NHWC\", \"NCHW\". Defaults to\n *     \"NHWC\". Specify the data format of the input and output data. With the\n *     default format \"NHWC\", the data is stored in the order of: [batch,\n *     height, width, channels].\n * @param dimRoundingMode The rounding mode used when computing output\n *     dimensions if pad is a number. If none is provided, it will not round\n *     and error if the output is of fractional size.\n */\nfunction conv2DBackpropInput_(xShape, dy, filter, strides, pad, dataFormat = 'NHWC', dimRoundingMode) {\n    util.assert(xShape.length === dy.rank, () => `Length of inShape ` +\n        `(${xShape.length}) and rank of dy (${dy.rank}) must match`);\n    let xShape4D = xShape;\n    let dy4D = dy;\n    let reshapedTo4D = false;\n    if (dy.rank === 3) {\n        reshapedTo4D = true;\n        dy4D = reshape(dy, [1, dy.shape[0], dy.shape[1], dy.shape[2]]);\n        xShape4D = [1, xShape[0], xShape[1], xShape[2]];\n    }\n    util.assert(xShape4D.length === 4, () => `Error in conv2dDerInput: inShape must be length 4, but got length ` +\n        `${xShape4D.length}.`);\n    util.assert(dy4D.rank === 4, () => `Error in conv2dDerInput: dy must be rank 4, but got ` +\n        `rank ${dy4D.rank}`);\n    util.assert(filter.rank === 4, () => `Error in conv2dDerInput: filter must be rank 4, but got ` +\n        `rank ${filter.rank}`);\n    const inDepth = dataFormat === 'NHWC' ? xShape4D[3] : xShape4D[1];\n    const outDepth = dataFormat === 'NHWC' ? dy4D.shape[3] : dy4D.shape[1];\n    util.assert(inDepth === filter.shape[2], () => `Error in conv2dDerInput: depth of input (${inDepth}) must ` +\n        `match input depth for filter ${filter.shape[2]}.`);\n    util.assert(outDepth === filter.shape[3], () => `Error in conv2dDerInput: depth of output (${outDepth}) must ` +\n        `match output depth for filter ${filter.shape[3]}.`);\n    if (dimRoundingMode != null) {\n        util.assert(util.isInt(pad), () => `Error in conv2dDerInput: pad must be an integer when using, ` +\n            `dimRoundingMode ${dimRoundingMode} but got pad ${pad}.`);\n    }\n    const forward = (backend, save) => {\n        const dilations = 1;\n        const $dataFormat = conv_util.convertConv2DDataFormat(dataFormat);\n        const convInfo = conv_util.computeConv2DInfo(xShape4D, filter.shape, strides, dilations, pad, dimRoundingMode, false, $dataFormat);\n        const res = backend.conv2dDerInput(dy4D, filter, convInfo);\n        save([dy4D, filter]);\n        return res;\n    };\n    const inputs = { dy: dy4D, filter };\n    const attrs = { strides, pad, dataFormat, dimRoundingMode, inputShape: xShape4D };\n    const res = ENGINE.runKernelFunc(forward, inputs, null /* grad */, Conv2DBackpropInput, attrs);\n    if (reshapedTo4D) {\n        return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);\n    }\n    return res;\n}\nexport const conv2DBackpropInput = op({ conv2DBackpropInput_ });\n//# sourceMappingURL=conv2d_backprop_input.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Conv2DBackpropFilter } from '../kernel_names';\nimport * as util from '../util';\nimport * as conv_util from './conv_util';\nimport { op } from './operation';\nimport { reshape } from './reshape';\n/**\n * Computes the derivative of the filter of a 2D convolution.\n *\n * @param x The input tensor, of rank 4 or rank 3 of shape\n *     [batch, height, width, inChannels]. If rank 3, batch of 1 is assumed.\n * @param dy The dy image, of rank 4 or rank 3, of shape\n *     [batch, height, width, outDepth]. If rank 3, batch of 1 is assumed.\n * @param filterShape The shape of the filter, length 4,\n *     [filterHeight, filterWidth, inDepth, outDepth].\n * @param strides The strides of the convolution: [strideHeight,\n * strideWidth].\n * @param pad A string from: 'same', 'valid'. The type of padding algorithm\n *     used in the forward prop of the op.\n * @param dataFormat: An optional string from: \"NHWC\", \"NCHW\". Defaults to\n *     \"NHWC\". Specify the data format of the input and output data. With the\n *     default format \"NHWC\", the data is stored in the order of: [batch,\n *     height, width, channels].\n * @param dimRoundingMode A string from: 'ceil', 'round', 'floor'. The\n *     rounding mode used when computing output dimensions if pad is a\n *     number. If none is provided, it will not round and error if the output\n *     is of fractional size.\n */\nfunction conv2DBackpropFilter_(x, dy, filterShape, strides, pad, dataFormat = 'NHWC', dimRoundingMode) {\n    let x4D = x;\n    if (x.rank === 3) {\n        x4D = reshape(x, [1, x.shape[0], x.shape[1], x.shape[2]]);\n    }\n    let dy4D = dy;\n    if (dy4D.rank === 3) {\n        dy4D = reshape(dy, [1, dy.shape[0], dy.shape[1], dy.shape[2]]);\n    }\n    util.assert(x4D.rank === 4, () => `Error in conv2dDerFilter: input must be rank 4, but got shape ` +\n        `${x4D.shape}.`);\n    util.assert(dy4D.rank === 4, () => `Error in conv2dDerFilter: dy must be rank 4, but got shape ` +\n        `${dy4D.shape}.`);\n    util.assert(filterShape.length === 4, () => `Error in conv2dDerFilter: filterShape must be length 4, but got ` +\n        `${filterShape}.`);\n    const inDepth = dataFormat === 'NHWC' ? x4D.shape[3] : x4D.shape[1];\n    const outDepth = dataFormat === 'NHWC' ? dy4D.shape[3] : dy4D.shape[1];\n    util.assert(inDepth === filterShape[2], () => `Error in conv2dDerFilter: depth of input ${inDepth}) must ` +\n        `match input depth in filter (${filterShape[2]}.`);\n    util.assert(outDepth === filterShape[3], () => `Error in conv2dDerFilter: depth of dy (${outDepth}) must ` +\n        `match output depth for filter (${filterShape[3]}).`);\n    if (dimRoundingMode != null) {\n        util.assert(util.isInt(pad), () => `Error in conv2dDerFilter: pad must be an integer when using, ` +\n            `dimRoundingMode ${dimRoundingMode} but got pad ${pad}.`);\n    }\n    const forward = backend => {\n        const dilations = 1;\n        const $dataFormat = conv_util.convertConv2DDataFormat(dataFormat);\n        const convInfo = conv_util.computeConv2DInfo(x4D.shape, filterShape, strides, dilations, pad, dimRoundingMode, false, $dataFormat);\n        return backend.conv2dDerFilter(x4D, dy4D, convInfo);\n    };\n    const inputs = { x: x4D, dy: dy4D };\n    const attrs = { strides, pad, dataFormat, dimRoundingMode };\n    return ENGINE.runKernelFunc(forward, inputs, null, Conv2DBackpropFilter, attrs);\n}\nexport const conv2DBackpropFilter = op({ conv2DBackpropFilter_ });\n//# sourceMappingURL=conv2d_backprop_filter.js.map","/**\n * @license\n * Copyright 2017 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport * as util from '../util';\nexport function assertParamsConsistent(shapes, axis) {\n    const rank = shapes[0].length;\n    shapes.forEach((shape, i) => {\n        util.assert(shape.length === rank, () => `Error in concat${rank}D: rank of tensors[${i}] must be the same ` +\n            `as the rank of the rest (${rank})`);\n    });\n    util.assert(axis >= 0 && axis < rank, () => `Error in concat${rank}D: axis must be between 0 and ${rank - 1}.`);\n    const firstShape = shapes[0];\n    shapes.forEach((shape, i) => {\n        for (let r = 0; r < rank; r++) {\n            util.assert((r === axis) || (shape[r] === firstShape[r]), () => `Error in concat${rank}D: Shape of tensors[${i}] (${shape}) ` +\n                `does not match the shape of the rest (${firstShape}) ` +\n                `along the non-concatenated axis ${i}.`);\n        }\n    });\n}\nexport function computeOutShape(shapes, axis) {\n    const outputShape = shapes[0].slice();\n    for (let i = 1; i < shapes.length; i++) {\n        outputShape[axis] += shapes[i][axis];\n    }\n    return outputShape;\n}\n//# sourceMappingURL=concat_util.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport * as util from '../util';\n/**\n *\n * @param inputShape Input tensor shape is of the following dimensions:\n *     `[batch, height, width, inChannels]`.\n * @param filterShape The filter shape is of the following dimensions:\n *     `[filterHeight, filterWidth, depth]`.\n * @param strides The strides of the sliding window for each dimension of the\n *     input tensor: `[strideHeight, strideWidth]`.\n *     If `strides` is a single number,\n *     then `strideHeight == strideWidth`.\n * @param pad The type of padding algorithm.\n *    - `same` and stride 1: output will be of same size as input,\n *       regardless of filter size.\n *    - `valid`: output will be smaller than input if filter is larger\n *       than 1*1x1.\n *    - For more info, see this guide:\n *     [https://www.tensorflow.org/api_guides/python/nn#Convolution](\n *          https://www.tensorflow.org/api_guides/python/nn#Convolution)\n * @param dataFormat The data format of the input and output data.\n *     Defaults to 'NHWC'.\n * @param dilations The dilation rates: `[dilationHeight, dilationWidth]`.\n *     Defaults to `[1, 1]`. If `dilations` is a single number, then\n *     `dilationHeight == dilationWidth`.\n */\nexport function computeDilation2DInfo(inputShape, filterShape, strides, pad, dataFormat = 'NHWC', dilations) {\n    // `computerConv2DInfo` require filterShape to be in the dimension of:\n    // `[filterHeight, filterWidth, depth, outDepth]`, dilation2d doesn't have\n    // outDepth, it should have the same depth as the input.\n    // Input shape: [batch, height, width, inChannels]\n    const inputChannels = inputShape[3];\n    const $filterShape = [...filterShape, inputChannels];\n    const $dataFormat = convertConv2DDataFormat(dataFormat);\n    return computeConv2DInfo(inputShape, $filterShape, strides, dilations, pad, null /* roundingMode */, null /* depthWise */, $dataFormat);\n}\nexport function computePool2DInfo(inShape, filterSize, strides, dilations, pad, roundingMode, dataFormat = 'channelsLast') {\n    const [filterHeight, filterWidth] = parseTupleParam(filterSize);\n    let filterShape;\n    if (dataFormat === 'channelsLast') {\n        filterShape = [filterHeight, filterWidth, inShape[3], inShape[3]];\n    }\n    else if (dataFormat === 'channelsFirst') {\n        filterShape = [filterHeight, filterWidth, inShape[1], inShape[1]];\n    }\n    else {\n        throw new Error(`Unknown dataFormat ${dataFormat}`);\n    }\n    return computeConv2DInfo(inShape, filterShape, strides, dilations, pad, roundingMode, false, dataFormat);\n}\n/**\n * Computes the information for a forward pass of a pooling3D operation.\n */\nexport function computePool3DInfo(inShape, filterSize, strides, dilations, pad, roundingMode, dataFormat = 'NDHWC') {\n    const [filterDepth, filterHeight, filterWidth] = parse3TupleParam(filterSize);\n    let filterShape;\n    let $dataFormat;\n    if (dataFormat === 'NDHWC') {\n        $dataFormat = 'channelsLast';\n        filterShape =\n            [filterDepth, filterHeight, filterWidth, inShape[4], inShape[4]];\n    }\n    else if (dataFormat === 'NCDHW') {\n        $dataFormat = 'channelsFirst';\n        filterShape =\n            [filterDepth, filterHeight, filterWidth, inShape[1], inShape[1]];\n    }\n    else {\n        throw new Error(`Unknown dataFormat ${dataFormat}`);\n    }\n    return computeConv3DInfo(inShape, filterShape, strides, dilations, pad, false, $dataFormat, roundingMode);\n}\n/**\n * Computes the information for a forward pass of a convolution/pooling\n * operation.\n */\nexport function computeConv2DInfo(inShape, filterShape, strides, dilations, pad, roundingMode, depthwise = false, dataFormat = 'channelsLast') {\n    let [batchSize, inHeight, inWidth, inChannels] = [-1, -1, -1, -1];\n    if (dataFormat === 'channelsLast') {\n        [batchSize, inHeight, inWidth, inChannels] = inShape;\n    }\n    else if (dataFormat === 'channelsFirst') {\n        [batchSize, inChannels, inHeight, inWidth] = inShape;\n    }\n    else {\n        throw new Error(`Unknown dataFormat ${dataFormat}`);\n    }\n    const [filterHeight, filterWidth, , filterChannels] = filterShape;\n    const [strideHeight, strideWidth] = parseTupleParam(strides);\n    const [dilationHeight, dilationWidth] = parseTupleParam(dilations);\n    const effectiveFilterHeight = getEffectiveFilterSize(filterHeight, dilationHeight);\n    const effectiveFilterWidth = getEffectiveFilterSize(filterWidth, dilationWidth);\n    const { padInfo, outHeight, outWidth } = getPadAndOutInfo(pad, inHeight, inWidth, strideHeight, strideWidth, effectiveFilterHeight, effectiveFilterWidth, roundingMode, dataFormat);\n    const outChannels = depthwise ? filterChannels * inChannels : filterChannels;\n    let outShape;\n    if (dataFormat === 'channelsFirst') {\n        outShape = [batchSize, outChannels, outHeight, outWidth];\n    }\n    else if (dataFormat === 'channelsLast') {\n        outShape = [batchSize, outHeight, outWidth, outChannels];\n    }\n    return {\n        batchSize,\n        dataFormat,\n        inHeight,\n        inWidth,\n        inChannels,\n        outHeight,\n        outWidth,\n        outChannels,\n        padInfo,\n        strideHeight,\n        strideWidth,\n        filterHeight,\n        filterWidth,\n        effectiveFilterHeight,\n        effectiveFilterWidth,\n        dilationHeight,\n        dilationWidth,\n        inShape,\n        outShape,\n        filterShape\n    };\n}\n/**\n * Computes the information for a forward pass of a 3D convolution/pooling\n * operation.\n */\nexport function computeConv3DInfo(inShape, filterShape, strides, dilations, pad, depthwise = false, dataFormat = 'channelsLast', roundingMode) {\n    let [batchSize, inDepth, inHeight, inWidth, inChannels] = [-1, -1, -1, -1, -1];\n    if (dataFormat === 'channelsLast') {\n        [batchSize, inDepth, inHeight, inWidth, inChannels] = inShape;\n    }\n    else if (dataFormat === 'channelsFirst') {\n        [batchSize, inChannels, inDepth, inHeight, inWidth] = inShape;\n    }\n    else {\n        throw new Error(`Unknown dataFormat ${dataFormat}`);\n    }\n    const [filterDepth, filterHeight, filterWidth, , filterChannels] = filterShape;\n    const [strideDepth, strideHeight, strideWidth] = parse3TupleParam(strides);\n    const [dilationDepth, dilationHeight, dilationWidth] = parse3TupleParam(dilations);\n    const effectiveFilterDepth = getEffectiveFilterSize(filterDepth, dilationDepth);\n    const effectiveFilterHeight = getEffectiveFilterSize(filterHeight, dilationHeight);\n    const effectiveFilterWidth = getEffectiveFilterSize(filterWidth, dilationWidth);\n    const { padInfo, outDepth, outHeight, outWidth } = get3DPadAndOutInfo(pad, inDepth, inHeight, inWidth, strideDepth, strideHeight, strideWidth, effectiveFilterDepth, effectiveFilterHeight, effectiveFilterWidth, roundingMode);\n    const outChannels = depthwise ? filterChannels * inChannels : filterChannels;\n    let outShape;\n    if (dataFormat === 'channelsFirst') {\n        outShape = [batchSize, outChannels, outDepth, outHeight, outWidth];\n    }\n    else if (dataFormat === 'channelsLast') {\n        outShape = [batchSize, outDepth, outHeight, outWidth, outChannels];\n    }\n    return {\n        batchSize,\n        dataFormat,\n        inDepth,\n        inHeight,\n        inWidth,\n        inChannels,\n        outDepth,\n        outHeight,\n        outWidth,\n        outChannels,\n        padInfo,\n        strideDepth,\n        strideHeight,\n        strideWidth,\n        filterDepth,\n        filterHeight,\n        filterWidth,\n        effectiveFilterDepth,\n        effectiveFilterHeight,\n        effectiveFilterWidth,\n        dilationDepth,\n        dilationHeight,\n        dilationWidth,\n        inShape,\n        outShape,\n        filterShape\n    };\n}\nfunction computeOutputShape2D(inShape, fieldSize, stride, zeroPad, roundingMode) {\n    if (zeroPad == null) {\n        zeroPad = computeDefaultPad(inShape, fieldSize, stride);\n    }\n    const inputRows = inShape[0];\n    const inputCols = inShape[1];\n    const outputRows = conditionalRound((inputRows - fieldSize + 2 * zeroPad) / stride + 1, roundingMode);\n    util.assert(util.isInt(outputRows), () => `The output # of rows (${outputRows}) must be an integer. ` +\n        `Change the stride and/or zero pad parameters`);\n    const outputCols = conditionalRound((inputCols - fieldSize + 2 * zeroPad) / stride + 1, roundingMode);\n    util.assert(util.isInt(outputCols), () => `The output # of columns (${outputCols}) must be an integer. ` +\n        `Change the stride and/or zero pad parameters`);\n    return [outputRows, outputCols];\n}\nfunction computeOutputShape4D(inShape, fieldSize, outChannels, stride, zeroPad, roundingMode) {\n    if (zeroPad == null) {\n        zeroPad = computeDefaultPad(inShape, fieldSize, stride);\n    }\n    const inputDepth = inShape[0];\n    const inputRows = inShape[1];\n    const inputCols = inShape[2];\n    const outputDepths = conditionalRound((inputDepth - fieldSize + 2 * zeroPad) / stride + 1, roundingMode);\n    util.assert(util.isInt(outputDepths), () => `The output # of depths (${outputDepths}) must be an integer. ` +\n        `Change the stride and/or zero pad parameters`);\n    const outputRows = conditionalRound((inputRows - fieldSize + 2 * zeroPad) / stride + 1, roundingMode);\n    util.assert(util.isInt(outputRows), () => `The output # of rows (${outputRows}) must be an integer. ` +\n        `Change the stride and/or zero pad parameters`);\n    const outputCols = conditionalRound((inputCols - fieldSize + 2 * zeroPad) / stride + 1, roundingMode);\n    util.assert(util.isInt(outputCols), () => `The output # of columns (${outputCols}) must be an integer. ` +\n        `Change the stride and/or zero pad parameters`);\n    return [outputDepths, outputRows, outputCols, outChannels];\n}\nexport function computeDefaultPad(inputShape, fieldSize, stride, dilation = 1) {\n    const effectiveFieldSize = getEffectiveFilterSize(fieldSize, dilation);\n    return Math.floor((inputShape[0] * (stride - 1) - stride + effectiveFieldSize) / 2);\n}\nfunction parseTupleParam(param) {\n    if (typeof param === 'number') {\n        return [param, param, param];\n    }\n    if (param.length === 2) {\n        return [param[0], param[1], 1];\n    }\n    return param;\n}\nfunction parse3TupleParam(param) {\n    return typeof param === 'number' ? [param, param, param] : param;\n}\n/* See https://www.tensorflow.org/api_docs/python/tf/nn/atrous_conv2d\n * Atrous convolution is equivalent to standard convolution with upsampled\n * filters with effective_filter_height =\n * filter_height + (filter_height - 1) * (dilation - 1)\n * and effective_filter_width =\n * filter_width + (filter_width - 1) * (dilation - 1),\n * produced by inserting dilation - 1 zeros along consecutive elements across\n * the filters' spatial dimensions.\n * When there is a dilation, this converts a filter dimension to the\n * effective filter dimension, so it can be used in a standard convolution.\n */\nfunction getEffectiveFilterSize(filterSize, dilation) {\n    if (dilation <= 1) {\n        return filterSize;\n    }\n    return filterSize + (filterSize - 1) * (dilation - 1);\n}\nfunction getPadAndOutInfo(pad, inHeight, inWidth, strideHeight, strideWidth, filterHeight, filterWidth, roundingMode, dataFormat) {\n    let padInfo;\n    let outHeight;\n    let outWidth;\n    if (typeof pad === 'number') {\n        const padType = (pad === 0) ? 'VALID' : 'NUMBER';\n        padInfo = { top: pad, bottom: pad, left: pad, right: pad, type: padType };\n        const outShape = computeOutputShape2D([inHeight, inWidth], filterHeight, strideHeight, pad, roundingMode);\n        outHeight = outShape[0];\n        outWidth = outShape[1];\n    }\n    else if (pad === 'same') {\n        outHeight = Math.ceil(inHeight / strideHeight);\n        outWidth = Math.ceil(inWidth / strideWidth);\n        const padAlongHeight = Math.max(0, (outHeight - 1) * strideHeight + filterHeight - inHeight);\n        const padAlongWidth = Math.max(0, (outWidth - 1) * strideWidth + filterWidth - inWidth);\n        const top = Math.floor(padAlongHeight / 2);\n        const bottom = padAlongHeight - top;\n        const left = Math.floor(padAlongWidth / 2);\n        const right = padAlongWidth - left;\n        padInfo = { top, bottom, left, right, type: 'SAME' };\n    }\n    else if (pad === 'valid') {\n        padInfo = { top: 0, bottom: 0, left: 0, right: 0, type: 'VALID' };\n        outHeight = Math.ceil((inHeight - filterHeight + 1) / strideHeight);\n        outWidth = Math.ceil((inWidth - filterWidth + 1) / strideWidth);\n    }\n    else if (typeof pad === 'object') {\n        const top = dataFormat === 'channelsLast' ? pad[1][0] : pad[2][0];\n        const bottom = dataFormat === 'channelsLast' ? pad[1][1] : pad[2][1];\n        const left = dataFormat === 'channelsLast' ? pad[2][0] : pad[3][0];\n        const right = dataFormat === 'channelsLast' ? pad[2][1] : pad[3][1];\n        const padType = (top === 0 && bottom === 0 && left === 0 && right === 0) ?\n            'VALID' :\n            'EXPLICIT';\n        padInfo = { top, bottom, left, right, type: padType };\n        outHeight = conditionalRound((inHeight - filterHeight + top + bottom) / strideHeight + 1, roundingMode);\n        outWidth = conditionalRound((inWidth - filterWidth + left + right) / strideWidth + 1, roundingMode);\n    }\n    else {\n        throw Error(`Unknown padding parameter: ${pad}`);\n    }\n    return { padInfo, outHeight, outWidth };\n}\nfunction get3DPadAndOutInfo(pad, inDepth, inHeight, inWidth, strideDepth, strideHeight, strideWidth, filterDepth, filterHeight, filterWidth, roundingMode) {\n    let padInfo;\n    let outDepth;\n    let outHeight;\n    let outWidth;\n    if (typeof pad === 'number') {\n        const padType = (pad === 0) ? 'VALID' : 'NUMBER';\n        padInfo = {\n            top: pad,\n            bottom: pad,\n            left: pad,\n            right: pad,\n            front: pad,\n            back: pad,\n            type: padType\n        };\n        const outShape = computeOutputShape4D([inDepth, inHeight, inWidth, 1], filterDepth, 1, strideDepth, pad, roundingMode);\n        outDepth = outShape[0];\n        outHeight = outShape[1];\n        outWidth = outShape[2];\n    }\n    else if (pad === 'same') {\n        outDepth = Math.ceil(inDepth / strideDepth);\n        outHeight = Math.ceil(inHeight / strideHeight);\n        outWidth = Math.ceil(inWidth / strideWidth);\n        const padAlongDepth = (outDepth - 1) * strideDepth + filterDepth - inDepth;\n        const padAlongHeight = (outHeight - 1) * strideHeight + filterHeight - inHeight;\n        const padAlongWidth = (outWidth - 1) * strideWidth + filterWidth - inWidth;\n        const front = Math.floor(padAlongDepth / 2);\n        const back = padAlongDepth - front;\n        const top = Math.floor(padAlongHeight / 2);\n        const bottom = padAlongHeight - top;\n        const left = Math.floor(padAlongWidth / 2);\n        const right = padAlongWidth - left;\n        padInfo = { top, bottom, left, right, front, back, type: 'SAME' };\n    }\n    else if (pad === 'valid') {\n        padInfo = {\n            top: 0,\n            bottom: 0,\n            left: 0,\n            right: 0,\n            front: 0,\n            back: 0,\n            type: 'VALID'\n        };\n        outDepth = Math.ceil((inDepth - filterDepth + 1) / strideDepth);\n        outHeight = Math.ceil((inHeight - filterHeight + 1) / strideHeight);\n        outWidth = Math.ceil((inWidth - filterWidth + 1) / strideWidth);\n    }\n    else {\n        throw Error(`Unknown padding parameter: ${pad}`);\n    }\n    return { padInfo, outDepth, outHeight, outWidth };\n}\n/**\n * Rounds a value depending on the rounding mode\n * @param value\n * @param roundingMode\n */\nfunction conditionalRound(value, roundingMode) {\n    if (!roundingMode) {\n        return value;\n    }\n    switch (roundingMode) {\n        case 'round':\n            // used for Caffe Conv\n            return Math.round(value);\n        case 'ceil':\n            // used for Caffe Pool\n            return Math.ceil(value);\n        case 'floor':\n            return Math.floor(value);\n        default:\n            throw new Error(`Unknown roundingMode ${roundingMode}`);\n    }\n}\nexport function tupleValuesAreOne(param) {\n    const [dimA, dimB, dimC] = parseTupleParam(param);\n    return dimA === 1 && dimB === 1 && dimC === 1;\n}\nexport function eitherStridesOrDilationsAreOne(strides, dilations) {\n    return tupleValuesAreOne(strides) || tupleValuesAreOne(dilations);\n}\n/**\n * Convert Conv2D dataFormat from 'NHWC'|'NCHW' to\n *    'channelsLast'|'channelsFirst'\n * @param dataFormat in 'NHWC'|'NCHW' mode\n * @return dataFormat in 'channelsLast'|'channelsFirst' mode\n * @throws unknown dataFormat\n */\nexport function convertConv2DDataFormat(dataFormat) {\n    if (dataFormat === 'NHWC') {\n        return 'channelsLast';\n    }\n    else if (dataFormat === 'NCHW') {\n        return 'channelsFirst';\n    }\n    else {\n        throw new Error(`Unknown dataFormat ${dataFormat}`);\n    }\n}\n//# sourceMappingURL=conv_util.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { buffer } from './buffer';\nimport { expandDims } from './expand_dims';\nimport { op } from './operation';\nimport { reshape } from './reshape';\nimport { tile } from './tile';\n/**\n * Create an identity matrix.\n *\n * @param numRows Number of rows.\n * @param numColumns Number of columns. Defaults to `numRows`.\n * @param batchShape If provided, will add the batch shape to the beginning\n *   of the shape of the returned `tf.Tensor` by repeating the identity\n *   matrix.\n * @param dtype Data type.\n * @returns Identity matrix of the specified size and data type, possibly\n *   with batch repetition if `batchShape` is specified.\n *\n * @doc {heading: 'Tensors', subheading: 'Creation'}\n */\nfunction eye_(numRows, numColumns, batchShape, dtype = 'float32') {\n    if (numColumns == null) {\n        numColumns = numRows;\n    }\n    const buff = buffer([numRows, numColumns], dtype);\n    const n = numRows <= numColumns ? numRows : numColumns;\n    for (let i = 0; i < n; ++i) {\n        buff.set(1, i, i);\n    }\n    const out = reshape(buff.toTensor(), [numRows, numColumns]);\n    if (batchShape == null) {\n        return out;\n    }\n    else {\n        if (batchShape.length === 1) {\n            return tile(expandDims(out, 0), [batchShape[0], 1, 1]);\n        }\n        else if (batchShape.length === 2) {\n            // tslint:disable-next-line:no-unnecessary-type-assertion\n            return tile(expandDims(expandDims(out, 0), 0), [batchShape[0], batchShape[1], 1, 1]);\n        }\n        else if (batchShape.length === 3) {\n            // tslint:disable-next-line:no-unnecessary-type-assertion\n            return tile(expandDims(expandDims(expandDims(out, 0), 0), 0), [\n                batchShape[0], batchShape[1], batchShape[2], 1, 1\n            ]);\n        }\n        else {\n            throw new Error(`eye() currently supports only 1D and 2D ` +\n                // tslint:disable-next-line:no-any\n                `batchShapes, but received ${batchShape.length}D.`);\n        }\n    }\n}\nexport const eye = op({ eye_ });\n//# sourceMappingURL=eye.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Div } from '../kernel_names';\nimport { makeTypesMatch } from '../tensor_util';\nimport { convertToTensor } from '../tensor_util_env';\nimport { floorDiv } from './floorDiv';\nimport { op } from './operation';\n/**\n * Divides two `tf.Tensor`s element-wise, A / B. Supports broadcasting.\n *\n * ```js\n * const a = tf.tensor1d([1, 4, 9, 16]);\n * const b = tf.tensor1d([1, 2, 3, 4]);\n *\n * a.div(b).print();  // or tf.div(a, b)\n * ```\n *\n * ```js\n * // Broadcast div a with b.\n * const a = tf.tensor1d([2, 4, 6, 8]);\n * const b = tf.scalar(2);\n *\n * a.div(b).print();  // or tf.div(a, b)\n * ```\n *\n * @param a The first tensor as the numerator.\n * @param b The second tensor as the denominator. Must have the same dtype as\n * `a`.\n *\n * @doc {heading: 'Operations', subheading: 'Arithmetic'}\n */\nfunction div_(a, b) {\n    let $a = convertToTensor(a, 'a', 'div');\n    let $b = convertToTensor(b, 'b', 'div');\n    [$a, $b] = makeTypesMatch($a, $b);\n    if ($a.dtype === 'int32' && $b.dtype === 'int32') {\n        return floorDiv($a, $b);\n    }\n    const forward = (backend, save) => {\n        const res = backend.realDivide($a, $b);\n        save([$a, $b]);\n        return res;\n    };\n    const inputs = { a: $a, b: $b };\n    const attrs = {};\n    return ENGINE.runKernelFunc(forward, inputs, null /* gradient */, Div, attrs);\n}\nexport const div = op({ div_ });\n//# sourceMappingURL=div.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Cosh } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes hyperbolic cos of the input `tf.Tensor` element-wise: `cosh(x)`\n *\n * ```js\n * const x = tf.tensor1d([0, 1, -1, .7]);\n *\n * x.cosh().print();  // or tf.cosh(x)\n * ```\n * @param x The input tensor.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction cosh_(x) {\n    const $x = convertToTensor(x, 'x', 'cosh');\n    const inputs = { x: $x };\n    return ENGINE.runKernelFunc((backend, save) => {\n        const res = backend.cosh($x);\n        save([$x]);\n        return res;\n    }, inputs, null /* grad */, Cosh);\n}\nexport const cosh = op({ cosh_ });\n//# sourceMappingURL=cosh.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { All } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { parseAxisParam } from '../util';\nimport { expandShapeToKeepDim, getAxesPermutation, getInnerMostAxes } from './axis_util';\nimport { op } from './operation';\nimport { reshape } from './reshape';\nimport { transpose } from './transpose';\n/**\n * Computes the logical and of elements across dimensions of a `tf.Tensor`.\n *\n * Reduces the input along the dimensions given in `axes`. Unless `keepDims`\n * is true, the rank of the `tf.Tensor` is reduced by 1 for each entry in\n * `axes`. If `keepDims` is true, the reduced dimensions are retained with\n * length 1. If `axes` has no entries, all dimensions are reduced, and an\n * `tf.Tensor` with a single element is returned.\n *\n * ```js\n * const x = tf.tensor1d([1, 1, 1], 'bool');\n *\n * x.all().print();  // or tf.all(x)\n * ```\n *\n * ```js\n * const x = tf.tensor2d([1, 1, 0, 0], [2, 2], 'bool');\n *\n * const axis = 1;\n * x.all(axis).print();  // or tf.all(x, axis)\n * ```\n *\n * @param x The input tensor. Must be of dtype bool.\n * @param axis The dimension(s) to reduce. By default it reduces\n *     all dimensions.\n * @param keepDims If true, retains reduced dimensions with size 1.\n *\n * @doc {heading: 'Operations', subheading: 'Reduction'}\n */\nfunction all_(x, axis = null, keepDims = false) {\n    let $x = convertToTensor(x, 'x', 'all', 'bool');\n    const forward = (backend) => {\n        const origAxes = parseAxisParam(axis, $x.shape);\n        let axes = origAxes;\n        const permutedAxes = getAxesPermutation(axes, $x.rank);\n        if (permutedAxes != null) {\n            $x = transpose($x, permutedAxes);\n            axes = getInnerMostAxes(axes.length, $x.rank);\n        }\n        const res = backend.all($x, axes);\n        if (keepDims) {\n            const newShape = expandShapeToKeepDim(res.shape, origAxes);\n            return reshape(res, newShape);\n        }\n        return res;\n    };\n    const inputs = { x: $x };\n    const attrs = { axis, keepDims };\n    return ENGINE.runKernelFunc(forward, inputs, null /* grad */, All, attrs);\n}\nexport const all = op({ all_ });\n//# sourceMappingURL=all.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Any } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { parseAxisParam } from '../util';\nimport { expandShapeToKeepDim, getAxesPermutation, getInnerMostAxes } from './axis_util';\nimport { op } from './operation';\nimport { reshape } from './reshape';\nimport { transpose } from './transpose';\n/**\n * Computes the logical or of elements across dimensions of a `tf.Tensor`.\n *\n * Reduces the input along the dimensions given in `axes`. Unless `keepDims`\n * is true, the rank of the `tf.Tensor` is reduced by 1 for each entry in\n * `axes`. If `keepDims` is true, the reduced dimensions are retained with\n * length 1. If `axes` has no entries, all dimensions are reduced, and an\n * `tf.Tensor` with a single element is returned.\n *\n * ```js\n * const x = tf.tensor1d([1, 1, 1], 'bool');\n *\n * x.any().print();  // or tf.any(x)\n * ```\n *\n * ```js\n * const x = tf.tensor2d([1, 1, 0, 0], [2, 2], 'bool');\n *\n * const axis = 1;\n * x.any(axis).print();  // or tf.any(x, axis)\n * ```\n *\n * @param x The input tensor. Must be of dtype bool.\n * @param axis The dimension(s) to reduce. By default it reduces\n *     all dimensions.\n * @param keepDims If true, retains reduced dimensions with size 1.\n *\n * @doc {heading: 'Operations', subheading: 'Reduction'}\n */\nfunction any_(x, axis = null, keepDims = false) {\n    let $x = convertToTensor(x, 'x', 'any', 'bool');\n    const forward = (backend) => {\n        const origAxes = parseAxisParam(axis, $x.shape);\n        let axes = origAxes;\n        const permutedAxes = getAxesPermutation(axes, $x.rank);\n        if (permutedAxes != null) {\n            $x = transpose($x, permutedAxes);\n            axes = getInnerMostAxes(axes.length, $x.rank);\n        }\n        const res = backend.any($x, axes);\n        if (keepDims) {\n            const newShape = expandShapeToKeepDim(res.shape, origAxes);\n            return reshape(res, newShape);\n        }\n        return res;\n    };\n    const inputs = { x: $x };\n    const attrs = { axis, keepDims };\n    return ENGINE.runKernelFunc(forward, inputs, null /* grad */, Any, attrs);\n}\n// tslint:disable-next-line:variable-name\nexport const any = op({ any_ });\n//# sourceMappingURL=any.js.map","/**\n * @license\n * Copyright 2020 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { ArgMax } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport * as util from '../util';\nimport * as axis_util from './axis_util';\nimport { op } from './operation';\nimport { transpose } from './transpose';\n/**\n * Returns the indices of the maximum values along an `axis`.\n *\n * The result has the same shape as `input` with the dimension along `axis`\n * removed.\n *\n * ```js\n * const x = tf.tensor1d([1, 2, 3]);\n *\n * x.argMax().print();  // or tf.argMax(x)\n * ```\n *\n * ```js\n * const x = tf.tensor2d([1, 2, 4, 3], [2, 2]);\n *\n * const axis = 1;\n * x.argMax(axis).print();  // or tf.argMax(x, axis)\n * ```\n *\n * @param x The input tensor.\n * @param axis The dimension to reduce. Defaults to 0 (outer-most dimension).\n *\n * @doc {heading: 'Operations', subheading: 'Reduction'}\n */\nfunction argMax_(x, axis = 0) {\n    let $x = convertToTensor(x, 'x', 'argMax');\n    const forward = (backend, save) => {\n        save([$x]);\n        let axes = util.parseAxisParam(axis, $x.shape);\n        const permutedAxes = axis_util.getAxesPermutation(axes, $x.rank);\n        if (permutedAxes != null) {\n            $x = transpose($x, permutedAxes);\n            axes = axis_util.getInnerMostAxes(axes.length, $x.rank);\n        }\n        return backend.argMax($x, axes[0]);\n    };\n    const inputs = { x: $x };\n    const attrs = { axis };\n    return ENGINE.runKernelFunc(forward, inputs, null /* grad */, ArgMax, attrs);\n}\nexport const argMax = op({ argMax_ });\n//# sourceMappingURL=arg_max.js.map","/**\n * @license\n * Copyright 2017 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport * as util from '../util';\n/**\n * Returns true if the axis specifies the inner most dimensions of the\n * array.\n */\nexport function axesAreInnerMostDims(axes, rank) {\n    for (let i = 0; i < axes.length; ++i) {\n        if (axes[axes.length - i - 1] !== rank - 1 - i) {\n            return false;\n        }\n    }\n    return true;\n}\nexport function combineLocations(outputLoc, reduceLoc, axes) {\n    const rank = outputLoc.length + reduceLoc.length;\n    const loc = [];\n    let outIdx = 0;\n    let reduceIdx = 0;\n    for (let dim = 0; dim < rank; dim++) {\n        if (axes.indexOf(dim) === -1) {\n            loc.push(outputLoc[outIdx++]);\n        }\n        else {\n            loc.push(reduceLoc[reduceIdx++]);\n        }\n    }\n    return loc;\n}\nexport function computeOutAndReduceShapes(aShape, axes) {\n    const outShape = [];\n    const rank = aShape.length;\n    for (let dim = 0; dim < rank; dim++) {\n        if (axes.indexOf(dim) === -1) {\n            outShape.push(aShape[dim]);\n        }\n    }\n    const reduceShape = axes.map(dim => aShape[dim]);\n    return [outShape, reduceShape];\n}\nexport function expandShapeToKeepDim(shape, axes) {\n    const reduceSubShape = axes.map(x => 1);\n    return combineLocations(shape, reduceSubShape, axes);\n}\nexport function assertAxesAreInnerMostDims(msg, axes, rank) {\n    util.assert(axesAreInnerMostDims(axes, rank), () => `${msg} supports only inner-most axes for now. ` +\n        `Got axes ${axes} and rank-${rank} input.`);\n}\n/**\n * Returns the axes permutation to be used with `tf.transpose`, if such\n * permutation is necessary. Otherwise it returns null. This method is used by\n * operations that operate only on inner-most axes.\n */\nexport function getAxesPermutation(axes, rank) {\n    if (axesAreInnerMostDims(axes, rank)) {\n        return null;\n    }\n    const result = [];\n    for (let i = 0; i < rank; ++i) {\n        if (axes.indexOf(i) === -1) {\n            result.push(i);\n        }\n    }\n    axes.forEach(axis => result.push(axis));\n    return result;\n}\n/** Returns the axes permutation that undoes the original permutation. */\nexport function getUndoAxesPermutation(axes) {\n    return axes.map((axis, i) => [i, axis])\n        .sort((a, b) => a[1] - b[1])\n        .map(x => x[0]);\n}\nexport function getInnerMostAxes(numAxes, rank) {\n    const res = [];\n    for (let i = rank - numAxes; i < rank; ++i) {\n        res.push(i);\n    }\n    return res;\n}\n//# sourceMappingURL=axis_util.js.map","/**\n * @license\n * Copyright 2020 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { ArgMin } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport * as util from '../util';\nimport * as axis_util from './axis_util';\nimport { op } from './operation';\nimport { transpose } from './transpose';\n/**\n * Returns the indices of the minimum values along an `axis`.\n *\n * The result has the same shape as `input` with the dimension along `axis`\n * removed.\n *\n * ```js\n * const x = tf.tensor1d([1, 2, 3]);\n *\n * x.argMin().print();  // or tf.argMin(x)\n * ```\n *\n * ```js\n * const x = tf.tensor2d([1, 2, 4, 3], [2, 2]);\n *\n * const axis = 1;\n * x.argMin(axis).print();  // or tf.argMin(x, axis)\n * ```\n *\n * @param x The input tensor.\n * @param axis The dimension to reduce. Defaults to 0 (outer-most dimension).\n *\n * @doc {heading: 'Operations', subheading: 'Reduction'}\n */\nfunction argMin_(x, axis = 0) {\n    let $x = convertToTensor(x, 'x', 'argMin');\n    const forward = (backend, save) => {\n        save([$x]);\n        if (axis == null) {\n            axis = 0;\n        }\n        let axes = util.parseAxisParam(axis, $x.shape);\n        const permutedAxes = axis_util.getAxesPermutation(axes, $x.rank);\n        if (permutedAxes != null) {\n            $x = transpose($x, permutedAxes);\n            axes = axis_util.getInnerMostAxes(axes.length, $x.rank);\n        }\n        return backend.argMin($x, axes[0]);\n    };\n    const inputs = { x: $x };\n    const attrs = { axis };\n    return ENGINE.runKernelFunc(forward, inputs, null /* grad */, ArgMin, attrs);\n}\nexport const argMin = op({ argMin_ });\n//# sourceMappingURL=arg_min.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Atan2 } from '../kernel_names';\nimport { makeTypesMatch } from '../tensor_util';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes arctangent of `tf.Tensor`s a / b element-wise: `atan2(a, b)`.\n * Supports broadcasting.\n *\n * ```js\n * const a = tf.tensor1d([1.0, 1.0, -1.0, .7]);\n * const b = tf.tensor1d([2.0, 13.0, 3.5, .21]);\n *\n * tf.atan2(a, b).print()\n * ```\n *\n * @param a The first tensor.\n * @param b The second tensor. Must have the same dtype as `a`.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction atan2_(a, b) {\n    let $a = convertToTensor(a, 'a', 'atan2');\n    let $b = convertToTensor(b, 'b', 'atan2');\n    [$a, $b] = makeTypesMatch($a, $b);\n    const forward = (backend, save) => {\n        const res = backend.atan2($a, $b);\n        save([$a, $b]);\n        return res;\n    };\n    const inputs = { a: $a, b: $b };\n    return ENGINE.runKernelFunc(forward, inputs, null /* gradient */, Atan2);\n}\nexport const atan2 = op({ atan2_ });\n//# sourceMappingURL=atan2.js.map","import { convertToTensor } from '../tensor_util_env';\nimport * as util from '../util';\nimport { conv2d } from './conv2d';\nimport * as conv_util from './conv_util';\nimport { op } from './operation';\nimport { reshape } from './reshape';\n/**\n * Computes a 1D convolution over the input x.\n *\n * @param x The input tensor, of rank 3 or rank 2, of shape\n *     `[batch, width, inChannels]`. If rank 2, batch of 1 is assumed.\n * @param filter The filter, rank 3, of shape\n *     `[filterWidth, inDepth, outDepth]`.\n * @param stride The number of entries by which the filter is moved right at\n *     each step.\n * @param pad The type of padding algorithm.\n *    - `same` and stride 1: output will be of same size as input,\n *       regardless of filter size.\n *    - `valid`: output will be smaller than input if filter is larger\n *       than 1x1.\n *   - For more info, see this guide:\n *     [https://www.tensorflow.org/api_guides/python/nn#Convolution](\n *          https://www.tensorflow.org/api_guides/python/nn#Convolution)\n * @param dataFormat An optional string from \"NWC\", \"NCW\". Defaults to \"NWC\",\n *     the data is stored in the order of [batch, in_width, in_channels]. Only\n *     \"NWC\" is currently supported.\n * @param dilation The dilation rate in which we sample input values in\n *     atrous convolution. Defaults to `1`. If it is greater than 1, then\n *     stride must be `1`.\n * @param dimRoundingMode The rounding mode used when computing output\n *     dimensions if pad is a number. If none is provided, it will not round\n *     and error if the output is of fractional size.\n *\n * @doc {heading: 'Operations', subheading: 'Convolution'}\n */\nfunction conv1d_(x, filter, stride, pad, dataFormat = 'NWC', dilation = 1, dimRoundingMode) {\n    const $x = convertToTensor(x, 'x', 'conv1d');\n    const $filter = convertToTensor(filter, 'filter', 'conv1d');\n    let x3D = $x;\n    let reshapedTo3D = false;\n    if ($x.rank === 2) {\n        reshapedTo3D = true;\n        x3D = reshape($x, [1, $x.shape[0], $x.shape[1]]);\n    }\n    util.assert(x3D.rank === 3, () => `Error in conv1d: input must be rank 3, but got rank ${x3D.rank}.`);\n    util.assert($filter.rank === 3, () => `Error in conv1d: filter must be rank 3, but got rank ` +\n        `${$filter.rank}.`);\n    if (dimRoundingMode != null) {\n        util.assert(util.isInt(pad), () => `Error in conv1d: pad must be an integer when using, ` +\n            `dimRoundingMode ${dimRoundingMode} but got pad ${pad}.`);\n    }\n    util.assert(x3D.shape[2] === $filter.shape[1], () => `Error in conv1d: depth of input (${x3D.shape[2]}) must match ` +\n        `input depth for filter ${$filter.shape[1]}.`);\n    util.assert(conv_util.eitherStridesOrDilationsAreOne(stride, dilation), () => 'Error in conv1D: Either stride or dilation must be 1. ' +\n        `Got stride ${stride} and dilation '${dilation}'`);\n    util.assert(dataFormat === 'NWC', () => `Error in conv1d: got dataFormat of ${dataFormat} but only NWC is currently supported.`);\n    const filter4D = reshape($filter, [1, $filter.shape[0], $filter.shape[1], $filter.shape[2]]);\n    const input4D = reshape(x3D, [x3D.shape[0], 1, x3D.shape[1], x3D.shape[2]]);\n    const strides = [1, stride];\n    const dilations = [1, dilation];\n    const conv2dDataFormat = 'NHWC';\n    const res = conv2d(input4D, filter4D, strides, pad, conv2dDataFormat, dilations, dimRoundingMode);\n    if (reshapedTo3D) {\n        return reshape(res, [res.shape[2], res.shape[3]]);\n    }\n    return reshape(res, [res.shape[0], res.shape[2], res.shape[3]]);\n}\nexport const conv1d = op({ conv1d_ });\n//# sourceMappingURL=conv1d.js.map","import { convertToTensor } from '../tensor_util_env';\nimport { conv2DBackpropInput } from './conv2d_backprop_input';\nimport { op } from './operation';\n/**\n * Computes the transposed 2D convolution of an image, also known as a\n * deconvolution.\n *\n * @param x The input image, of rank 4 or rank 3, of shape\n *   `[batch, height, width, inDepth]`. If rank 3, batch of 1 is assumed.\n * @param filter The filter, rank 4, of shape\n *     `[filterHeight, filterWidth, outDepth, inDepth]`.\n *     `inDepth` must match `inDepth` in `x`.\n * @param outputShape Output shape, of rank 4 or rank 3:\n *     `[batch, height, width, outDepth]`. If rank 3, batch of 1 is assumed.\n * @param strides The strides of the original convolution:\n *     `[strideHeight, strideWidth]`.\n * @param pad  The type of padding algorithm used in the non-transpose version\n *    of the op.\n * @param dimRoundingMode The rounding mode used when computing output\n *    dimensions if pad is a number. If none is provided, it will not round\n *    and error if the output is of fractional size.\n *\n * @doc {heading: 'Operations', subheading: 'Convolution'}\n */\nfunction conv2dTranspose_(x, filter, outputShape, strides, pad, dimRoundingMode) {\n    const $x = convertToTensor(x, 'x', 'conv2dTranspose');\n    const $filter = convertToTensor(filter, 'filter', 'conv2dTranspose');\n    return conv2DBackpropInput(outputShape, $x, $filter, strides, pad, 'NHWC', dimRoundingMode);\n}\nexport const conv2dTranspose = op({ conv2dTranspose_ });\n//# sourceMappingURL=conv2d_transpose.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { DepthToSpace } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport * as util from '../util';\nimport { op } from './operation';\n/**\n * Rearranges data from depth into blocks of spatial data. More specifically,\n * this op outputs a copy of the input tensor where values from the `depth`\n * dimension are moved in spatial blocks to the `height` and `width` dimensions.\n * The attr `blockSize` indicates the input block size and how the data is\n * moved.\n *\n *  - Chunks of data of size `blockSize * blockSize` from depth are rearranged\n * into non-overlapping blocks of size `blockSize x blockSize`\n *\n *  - The width the output tensor is `inputWidth * blockSize`, whereas the\n * height is `inputHeight * blockSize`\n *\n *  - The Y, X coordinates within each block of the output image are determined\n * by the high order component of the input channel index\n *\n *  - The depth of the input tensor must be divisible by `blockSize *\n * blockSize`\n *\n * The `dataFormat` attr specifies the layout of the input and output tensors\n * with the following options: \"NHWC\": [ `batch, height, width, channels` ]\n * \"NCHW\": [ `batch, channels, height, width` ]\n *\n * ```js\n * const x = tf.tensor4d([1, 2, 3, 4], [1, 1, 1, 4]);\n * const blockSize = 2;\n * const dataFormat = \"NHWC\";\n *\n * tf.depthToSpace(x, blockSize, dataFormat).print();\n * ```\n *\n * @param x The input tensor of rank 4\n * @param blockSIze  An `int` that is `>= 2`. The size of the spatial block\n * @param dataFormat An optional string from: \"NHWC\", \"NCHW\". Defaults to \"NHWC\"\n *\n * @doc {heading: 'Tensors', subheading: 'Transformations'}\n */\nfunction depthToSpace_(x, blockSize, dataFormat = 'NHWC') {\n    const $x = convertToTensor(x, 'x', 'depthToSpace');\n    const inputHeight = (dataFormat === 'NHWC') ? $x.shape[1] : $x.shape[2];\n    const inputWidth = (dataFormat === 'NHWC') ? $x.shape[2] : $x.shape[3];\n    const inputDepth = (dataFormat === 'NHWC') ? $x.shape[3] : $x.shape[1];\n    util.assert(inputHeight * blockSize >= 0, () => `Negative dimension size caused by overflow when multiplying\n    ${inputHeight} and ${blockSize}  for depthToSpace with input shape\n    ${$x.shape}`);\n    util.assert(inputWidth * blockSize >= 0, () => `Negative dimension size caused by overflow when multiplying\n    ${inputWidth} and ${blockSize} for depthToSpace with input shape\n        ${$x.shape}`);\n    util.assert((inputDepth % (blockSize * blockSize) === 0), () => `Dimension size must be evenly divisible by ${blockSize * blockSize} but is ${inputDepth} for depthToSpace with input shape ${$x.shape}`);\n    const forward = backend => backend.depthToSpace($x, blockSize, dataFormat);\n    const inputs = { x: $x };\n    const attrs = { blockSize, dataFormat };\n    return ENGINE.runKernelFunc(forward, inputs, null /* gradient */, DepthToSpace, attrs);\n}\nexport const depthToSpace = op({ depthToSpace_ });\n//# sourceMappingURL=depth_to_space.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Dilation2D } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport * as util from '../util';\nimport { op } from './operation';\nimport { reshape } from './reshape';\n/**\n * Computes the grayscale dilation over the input `x`.\n *\n * @param x The input tensor, rank 3 or rank 4 of shape\n *     `[batch, height, width, inChannels]`. If rank 3, batch of 1 is assumed.\n * @param filter The filter tensor, rank 3, of shape\n *     `[filterHeight, filterWidth, depth]`.\n * @param strides The strides of the sliding window for each dimension of the\n *     input tensor: `[strideHeight, strideWidth]`.\n *     If `strides` is a single number,\n *     then `strideHeight == strideWidth`.\n * @param pad The type of padding algorithm.\n *    - `same` and stride 1: output will be of same size as input,\n *       regardless of filter size.\n *    - `valid`: output will be smaller than input if filter is larger\n *       than 1*1x1.\n *    - For more info, see this guide:\n *     [https://www.tensorflow.org/api_guides/python/nn#Convolution](\n *          https://www.tensorflow.org/api_guides/python/nn#Convolution)\n * @param dataFormat Specify the data format of the input and output data.\n *      Defaults to 'NHWC'. Only 'NHWC' is currently supported. With the\n *      default format \"NHWC\", the data is stored in the order of: [batch,\n *      height, width, channels].\n * @param dilations The dilation rates: `[dilationHeight, dilationWidth]`\n *     in which we sample input values across the height and width dimensions\n *     for atrous morphological dilation. Defaults to `[1, 1]`. If `dilations`\n *     is a single number, then `dilationHeight == dilationWidth`. If it is\n *     greater than 1, then all values of `strides` must be 1.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction dilation2d_(x, filter, strides, pad, dilations = [1, 1], dataFormat = 'NHWC') {\n    const $x = convertToTensor(x, 'x', 'dilation2d');\n    const $filter = convertToTensor(filter, 'filter', 'dilation2d');\n    util.assert($x.rank === 3 || $x.rank === 4, () => `Error in dilation2d: input must be rank 3 or 4, but got rank ` +\n        `${$x.rank}.`);\n    util.assert($filter.rank === 3, () => `Error in dilation2d: filter must be rank 3, but got rank ` +\n        `${$filter.rank}.`);\n    util.assert(dataFormat === 'NHWC', () => `Error in dilation2d: Only NHWC is currently supported, ` +\n        `but got dataFormat of ${dataFormat}`);\n    let x4D = $x;\n    let reshapedTo4D = false;\n    if ($x.rank === 3) {\n        x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);\n        reshapedTo4D = true;\n    }\n    const inputs = { x: x4D, filter: $filter };\n    const attrs = { strides, pad, dilations };\n    const res = ENGINE.runKernel(Dilation2D, inputs, attrs);\n    if (reshapedTo4D) {\n        return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);\n    }\n    return res;\n}\nexport const dilation2d = op({ dilation2d_ });\n//# sourceMappingURL=dilation2d.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { makeTypesMatch } from '../tensor_util';\nimport { convertToTensor } from '../tensor_util_env';\nimport { div } from './div';\nimport { equal } from './equal';\nimport { op } from './operation';\nimport { where } from './where';\nimport { zerosLike } from './zeros_like';\n/**\n * Divides two `tf.Tensor`s element-wise, A / B. Supports broadcasting. Return 0\n * if denominator is 0.\n *\n *\n * ```js\n * const a = tf.tensor1d([1, 4, 9, 16]);\n * const b = tf.tensor1d([1, 2, 3, 4]);\n * const c = tf.tensor1d([0, 0, 0, 0]);\n *\n * a.divNoNan(b).print();  // or tf.divNoNan(a, b)\n * a.divNoNan(c).print();  // or tf.divNoNan(a, c)\n * ```\n *\n * ```js\n * // Broadcast div a with b.\n * const a = tf.tensor1d([2, 4, 6, 8]);\n * const b = tf.scalar(2);\n * const c = tf.scalar(0);\n *\n * a.divNoNan(b).print();  // or tf.divNoNan(a, b)\n * a.divNoNan(c).print();  // or tf.divNoNan(a, c)\n * ```\n *\n * @param a The first tensor as the numerator.\n * @param b The second tensor as the denominator. Must have the same dtype as\n * `a`.\n *\n * @doc {heading: 'Operations', subheading: 'Arithmetic'}\n */\nfunction divNoNan_(a, b) {\n    // TODO: Make this into its own kernel.\n    let $a = convertToTensor(a, 'a', 'div');\n    let $b = convertToTensor(b, 'b', 'div');\n    [$a, $b] = makeTypesMatch($a, $b);\n    const divResult = div($a, $b);\n    const zeros = zerosLike(divResult);\n    const bEqualsZero = equal($b, zeros);\n    return where(bEqualsZero, zeros, divResult);\n}\nexport const divNoNan = op({ divNoNan_ });\n//# sourceMappingURL=div_no_nan.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { convertToTensor } from '../tensor_util_env';\nimport * as util from '../util';\nimport { matMul } from './mat_mul';\nimport { op } from './operation';\nimport { reshape } from './reshape';\n/**\n * Computes the dot product of two matrices and/or vectors, `t1` and `t2`.\n *\n * ```js\n * const a = tf.tensor1d([1, 2]);\n * const b = tf.tensor2d([[1, 2], [3, 4]]);\n * const c = tf.tensor2d([[1, 2, 3], [4, 5, 6]]);\n *\n * a.dot(b).print();  // or tf.dot(a, b)\n * b.dot(a).print();\n * b.dot(c).print();\n * ```\n * @param t1 The first tensor in the dot operation.\n * @param t2 The second tensor in the dot operation.\n *\n * @doc {heading: 'Operations', subheading: 'Matrices'}\n */\nfunction dot_(t1, t2) {\n    const $t1 = convertToTensor(t1, 't1', 'dot');\n    const $t2 = convertToTensor(t2, 't2', 'dot');\n    util.assert(($t1.rank === 1 || $t1.rank === 2) && ($t2.rank === 1 || $t2.rank === 2), () => `Error in dot: inputs must all be rank 1 or 2, but got ranks ` +\n        `${$t1.rank} and ${$t2.rank}.`);\n    const t1Inner = ($t1.rank === 1 ? $t1.size : $t1.shape[1]);\n    const t2Inner = ($t2.rank === 1 ? $t2.size : $t2.shape[0]);\n    util.assert(t1Inner === t2Inner, () => `Error in dot: inner dimensions of inputs must match, but got ` +\n        `${t1Inner} and ${t2Inner}.`);\n    if ($t1.rank === 1 && $t2.rank === 1) {\n        const t12D = reshape($t1, [1, -1]);\n        const t22D = reshape($t2, [-1, 1]);\n        const t1t2 = matMul(t12D, t22D);\n        return reshape(t1t2, []);\n    }\n    else if ($t1.rank === 1 && $t2.rank === 2) {\n        const t12D = reshape($t1, [1, -1]);\n        const t22D = reshape($t2, [$t2.shape[0], $t2.shape[1]]);\n        const t1t2 = matMul(t12D, t22D);\n        return reshape(t1t2, [t1t2.size]);\n    }\n    else if ($t1.rank === 2 && $t2.rank === 1) {\n        const t22D = reshape($t2, [-1, 1]);\n        const t1t2 = matMul($t1, t22D);\n        return reshape(t1t2, [t1t2.size]);\n    }\n    else {\n        const t22D = reshape($t2, [$t2.shape[0], $t2.shape[1]]);\n        const t1t2 = matMul($t1, t22D);\n        return t1t2;\n    }\n}\nexport const dot = op({ dot_ });\n//# sourceMappingURL=dot.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { FusedBatchNorm } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport * as util from '../util';\nimport { xAs4D } from './batchnorm_util';\nimport { op } from './operation';\nimport { reshape } from './reshape';\n/**\n * Batch normalization.\n *\n * As described in\n * [http://arxiv.org/abs/1502.03167](http://arxiv.org/abs/1502.03167).\n *\n * Mean, variance, scale, and offset can be of two shapes:\n *   - The same shape as the input.\n *   - In the common case, the depth dimension is the last dimension of x, so\n *     the values would be an `tf.Tensor1D` of shape [depth].\n *\n * Also available are stricter rank-specific methods with the same signature\n * as this method that assert that parameters passed are of given rank\n *   - `tf.batchNorm2d`\n *   - `tf.batchNorm3d`\n *   - `tf.batchNorm4d`\n *\n * @param x The input Tensor.\n * @param mean A mean Tensor.\n * @param variance A variance Tensor.\n * @param offset An offset Tensor.\n * @param scale A scale Tensor.\n * @param varianceEpsilon A small float number to avoid dividing by 0.\n *\n * @doc {heading: 'Operations', subheading: 'Normalization'}\n */\nfunction batchNorm_(x, mean, variance, offset, scale, varianceEpsilon) {\n    if (varianceEpsilon == null) {\n        varianceEpsilon = 0.001;\n    }\n    const $x = convertToTensor(x, 'x', 'batchNorm');\n    const $mean = convertToTensor(mean, 'mean', 'batchNorm');\n    const $variance = convertToTensor(variance, 'variance', 'batchNorm');\n    let $scale;\n    if (scale != null) {\n        $scale = convertToTensor(scale, 'scale', 'batchNorm');\n    }\n    let $offset;\n    if (offset != null) {\n        $offset = convertToTensor(offset, 'offset', 'batchNorm');\n    }\n    util.assert($mean.rank === $variance.rank, () => 'Batch normalization gradient requires mean and variance to have ' +\n        'equal ranks.');\n    util.assert($offset == null || $mean.rank === $offset.rank, () => 'Batch normalization gradient requires mean and offset to have ' +\n        'equal ranks.');\n    util.assert($scale == null || $mean.rank === $scale.rank, () => 'Batch normalization gradient requires mean and scale to have ' +\n        'equal ranks.');\n    const x4D = xAs4D($x);\n    const forward = (backend, save) => {\n        save([x4D, $mean, $variance, $scale]);\n        return backend.batchNorm(x4D, as1DOr4D($mean), as1DOr4D($variance), as1DOr4D($offset), as1DOr4D($scale), varianceEpsilon);\n    };\n    const inputs = {\n        x: x4D,\n        scale: $scale,\n        offset: $offset,\n        mean: $mean,\n        variance: $variance\n    };\n    const attrs = { varianceEpsilon };\n    const res = ENGINE.runKernelFunc(forward, inputs, null /* gradient */, FusedBatchNorm, attrs);\n    return reshape(res, $x.shape);\n}\nfunction as1DOr4D(x) {\n    if (x == null) {\n        return null;\n    }\n    if (x.rank === 0) {\n        // tslint:disable-next-line:no-unnecessary-type-assertion\n        return reshape(x, [x.size]);\n    }\n    else if (x.rank === 1) {\n        return x;\n    }\n    else if (x.rank === 2) {\n        // tslint:disable-next-line:no-unnecessary-type-assertion\n        return reshape(x, [1, 1, x.shape[0], x.shape[1]]);\n    }\n    else if (x.rank === 3) {\n        // tslint:disable-next-line:no-unnecessary-type-assertion\n        return reshape(x, [1, x.shape[0], x.shape[1], x.shape[2]]);\n    }\n    return x;\n}\nexport const batchNorm = op({ batchNorm_ });\n//# sourceMappingURL=batchnorm.js.map","import { reshape } from './reshape';\nexport function xAs4D(x) {\n    let x4D;\n    if (x.rank === 0 || x.rank === 1) {\n        x4D = reshape(x, [1, 1, 1, x.size]);\n    }\n    else if (x.rank === 2) {\n        x4D = reshape(x, [1, 1, x.shape[0], x.shape[1]]);\n    }\n    else if (x.rank === 3) {\n        x4D = reshape(x, [1, x.shape[0], x.shape[1], x.shape[2]]);\n    }\n    else {\n        x4D = x;\n    }\n    return x4D;\n}\n//# sourceMappingURL=batchnorm_util.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { DepthwiseConv2dNativeBackpropInput } from '../kernel_names';\nimport { op } from './operation';\nimport { reshape } from './reshape';\nfunction depthwiseConv2dNativeBackpropInput_(xShape, dy, filter, convInfo) {\n    let dy4D = dy;\n    let reshapedTo4D = false;\n    if (dy.rank === 3) {\n        reshapedTo4D = true;\n        dy4D = reshape(dy, [1, dy.shape[0], dy.shape[1], dy.shape[2]]);\n    }\n    const forward = backend => backend.depthwiseConv2DDerInput(dy4D, filter, convInfo);\n    const inputs = { dy: dy4D };\n    const res = ENGINE.runKernelFunc(forward, inputs, null, DepthwiseConv2dNativeBackpropInput);\n    if (reshapedTo4D) {\n        return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);\n    }\n    return res;\n}\nexport const depthwiseConv2dNativeBackpropInput = op({ depthwiseConv2dNativeBackpropInput_ });\n//# sourceMappingURL=depthwise_conv2d_native_backprop_input.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { DepthwiseConv2dNativeBackpropFilter } from '../kernel_names';\nimport { op } from './operation';\nimport { reshape } from './reshape';\nfunction depthwiseConv2dNativeBackpropFilter_(x, dy, filterShape, convInfo) {\n    let x4D = x;\n    if (x.rank === 3) {\n        x4D = reshape(x, [1, x.shape[0], x.shape[1], x.shape[2]]);\n    }\n    let dy4D = dy;\n    if (dy4D.rank === 3) {\n        dy4D = reshape(dy, [1, dy.shape[0], dy.shape[1], dy.shape[2]]);\n    }\n    const forward = backend => backend.depthwiseConv2DDerFilter(x4D, dy4D, convInfo);\n    const inputs = { x: x4D, dy: dy4D };\n    return ENGINE.runKernelFunc(forward, inputs, null, DepthwiseConv2dNativeBackpropFilter);\n}\nexport const depthwiseConv2dNativeBackpropFilter = op({ depthwiseConv2dNativeBackpropFilter_ });\n//# sourceMappingURL=depthwise_conv2d_native_backprop_filter.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Add } from '../kernel_names';\nimport { makeTypesMatch } from '../tensor_util';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Adds two `tf.Tensor`s element-wise, A + B. Supports broadcasting.\n *\n *\n * ```js\n * const a = tf.tensor1d([1, 2, 3, 4]);\n * const b = tf.tensor1d([10, 20, 30, 40]);\n *\n * a.add(b).print();  // or tf.add(a, b)\n * ```\n *\n * ```js\n * // Broadcast add a with b.\n * const a = tf.scalar(5);\n * const b = tf.tensor1d([10, 20, 30, 40]);\n *\n * a.add(b).print();  // or tf.add(a, b)\n * ```\n * @param a The first `tf.Tensor` to add.\n * @param b The second `tf.Tensor` to add. Must have the same type as `a`.\n *\n * @doc {heading: 'Operations', subheading: 'Arithmetic'}\n */\nfunction add_(a, b) {\n    let $a = convertToTensor(a, 'a', 'add');\n    let $b = convertToTensor(b, 'b', 'add');\n    [$a, $b] = makeTypesMatch($a, $b);\n    const forward = (backend, save) => {\n        const res = backend.add($a, $b);\n        save([$a, $b]);\n        return res;\n    };\n    const inputs = { a: $a, b: $b };\n    return ENGINE.runKernelFunc(forward, inputs, null /* gradient */, Add);\n}\nexport const add = op({ add_ });\n//# sourceMappingURL=add.js.map","import { concat } from './concat';\nimport { op } from './operation';\n/**\n * Concatenates a list of`tf.Tensor2D`s along an axis. See `concat` for details.\n *\n * For example, if:\n * A: shape(2, 3) = | r1, g1, b1 |\n *                  | r2, g2, b2 |\n *\n * B: shape(2, 3) = | r3, g3, b3 |\n *                  | r4, g4, b4 |\n *\n * C = tf.concat2d([A, B], axis)\n *\n * if axis = 0:\n * C: shape(4, 3) = | r1, g1, b1 |\n *                  | r2, g2, b2 |\n *                  | r3, g3, b3 |\n *                  | r4, g4, b4 |\n *\n * if axis = 1:\n * C = shape(2, 6) = | r1, g1, b1, r3, g3, b3 |\n *                   | r2, g2, b2, r4, g4, b4 |\n *\n *\n * @param tensors A list of `tf.Tensor`s to concatenate.\n * @param axis The axis to concatenate along.\n * @return The concatenated array.\n */\nfunction concat2d_(tensors, axis) {\n    return concat(tensors, axis);\n}\nexport const concat2d = op({ concat2d_ });\n//# sourceMappingURL=concat_2d.js.map","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { FromPixels } from '../kernel_names';\nimport { getKernel } from '../kernel_registry';\nimport { Tensor } from '../tensor';\nimport { convertToTensor } from '../tensor_util_env';\nimport { cast } from './cast';\nimport { op } from './operation';\nimport { tensor3d } from './tensor3d';\nlet fromPixels2DContext;\n/**\n * Creates a `tf.Tensor` from an image.\n *\n * ```js\n * const image = new ImageData(1, 1);\n * image.data[0] = 100;\n * image.data[1] = 150;\n * image.data[2] = 200;\n * image.data[3] = 255;\n *\n * tf.browser.fromPixels(image).print();\n * ```\n *\n * @param pixels The input image to construct the tensor from. The\n * supported image types are all 4-channel. You can also pass in an image\n * object with following attributes:\n * `{data: Uint8Array; width: number; height: number}`\n * @param numChannels The number of channels of the output tensor. A\n * numChannels value less than 4 allows you to ignore channels. Defaults to\n * 3 (ignores alpha channel of input image).\n *\n * @doc {heading: 'Browser', namespace: 'browser', ignoreCI: true}\n */\nfunction fromPixels_(pixels, numChannels = 3) {\n    // Sanity checks.\n    if (numChannels > 4) {\n        throw new Error('Cannot construct Tensor with more than 4 channels from pixels.');\n    }\n    if (pixels == null) {\n        throw new Error('pixels passed to tf.browser.fromPixels() can not be null');\n    }\n    let isPixelData = false;\n    let isImageData = false;\n    let isVideo = false;\n    let isImage = false;\n    let isCanvasLike = false;\n    if (pixels.data instanceof Uint8Array) {\n        isPixelData = true;\n    }\n    else if (typeof (ImageData) !== 'undefined' && pixels instanceof ImageData) {\n        isImageData = true;\n    }\n    else if (typeof (HTMLVideoElement) !== 'undefined' &&\n        pixels instanceof HTMLVideoElement) {\n        isVideo = true;\n    }\n    else if (typeof (HTMLImageElement) !== 'undefined' &&\n        pixels instanceof HTMLImageElement) {\n        isImage = true;\n        // tslint:disable-next-line: no-any\n    }\n    else if (pixels.getContext != null) {\n        isCanvasLike = true;\n    }\n    else {\n        throw new Error('pixels passed to tf.browser.fromPixels() must be either an ' +\n            `HTMLVideoElement, HTMLImageElement, HTMLCanvasElement, ImageData ` +\n            `in browser, or OffscreenCanvas, ImageData in webworker` +\n            ` or {data: Uint32Array, width: number, height: number}, ` +\n            `but was ${pixels.constructor.name}`);\n    }\n    if (isVideo) {\n        const HAVE_CURRENT_DATA_READY_STATE = 2;\n        if (isVideo &&\n            pixels.readyState <\n                HAVE_CURRENT_DATA_READY_STATE) {\n            throw new Error('The video element has not loaded data yet. Please wait for ' +\n                '`loadeddata` event on the <video> element.');\n        }\n    }\n    // If the current backend has 'FromPixels' registered, it has a more\n    // efficient way of handling pixel uploads, so we call that.\n    const kernel = getKernel(FromPixels, ENGINE.backendName);\n    if (kernel != null) {\n        const inputs = { pixels };\n        const attrs = { numChannels };\n        return ENGINE.runKernel(FromPixels, inputs, attrs);\n    }\n    const [width, height] = isVideo ?\n        [\n            pixels.videoWidth,\n            pixels.videoHeight\n        ] :\n        [pixels.width, pixels.height];\n    let vals;\n    if (isCanvasLike) {\n        vals =\n            // tslint:disable-next-line:no-any\n            pixels.getContext('2d').getImageData(0, 0, width, height).data;\n    }\n    else if (isImageData || isPixelData) {\n        vals = pixels.data;\n    }\n    else if (isImage || isVideo) {\n        if (fromPixels2DContext == null) {\n            fromPixels2DContext = document.createElement('canvas').getContext('2d');\n        }\n        fromPixels2DContext.canvas.width = width;\n        fromPixels2DContext.canvas.height = height;\n        fromPixels2DContext.drawImage(pixels, 0, 0, width, height);\n        vals = fromPixels2DContext.getImageData(0, 0, width, height).data;\n    }\n    let values;\n    if (numChannels === 4) {\n        values = new Int32Array(vals);\n    }\n    else {\n        const numPixels = width * height;\n        values = new Int32Array(numPixels * numChannels);\n        for (let i = 0; i < numPixels; i++) {\n            for (let channel = 0; channel < numChannels; ++channel) {\n                values[i * numChannels + channel] = vals[i * 4 + channel];\n            }\n        }\n    }\n    const outShape = [height, width, numChannels];\n    return tensor3d(values, outShape, 'int32');\n}\n/**\n * Draws a `tf.Tensor` of pixel values to a byte array or optionally a\n * canvas.\n *\n * When the dtype of the input is 'float32', we assume values in the range\n * [0-1]. Otherwise, when input is 'int32', we assume values in the range\n * [0-255].\n *\n * Returns a promise that resolves when the canvas has been drawn to.\n *\n * @param img A rank-2 or rank-3 tensor. If rank-2, draws grayscale. If\n *     rank-3, must have depth of 1, 3 or 4. When depth of 1, draws\n * grayscale. When depth of 3, we draw with the first three components of\n * the depth dimension corresponding to r, g, b and alpha = 1. When depth of\n * 4, all four components of the depth dimension correspond to r, g, b, a.\n * @param canvas The canvas to draw to.\n *\n * @doc {heading: 'Browser', namespace: 'browser'}\n */\nexport async function toPixels(img, canvas) {\n    let $img = convertToTensor(img, 'img', 'toPixels');\n    if (!(img instanceof Tensor)) {\n        // Assume int32 if user passed a native array.\n        const originalImgTensor = $img;\n        $img = cast(originalImgTensor, 'int32');\n        originalImgTensor.dispose();\n    }\n    if ($img.rank !== 2 && $img.rank !== 3) {\n        throw new Error(`toPixels only supports rank 2 or 3 tensors, got rank ${$img.rank}.`);\n    }\n    const [height, width] = $img.shape.slice(0, 2);\n    const depth = $img.rank === 2 ? 1 : $img.shape[2];\n    if (depth > 4 || depth === 2) {\n        throw new Error(`toPixels only supports depth of size ` +\n            `1, 3 or 4 but got ${depth}`);\n    }\n    if ($img.dtype !== 'float32' && $img.dtype !== 'int32') {\n        throw new Error(`Unsupported type for toPixels: ${$img.dtype}.` +\n            ` Please use float32 or int32 tensors.`);\n    }\n    const data = await $img.data();\n    const multiplier = $img.dtype === 'float32' ? 255 : 1;\n    const bytes = new Uint8ClampedArray(width * height * 4);\n    for (let i = 0; i < height * width; ++i) {\n        const rgba = [0, 0, 0, 255];\n        for (let d = 0; d < depth; d++) {\n            const value = data[i * depth + d];\n            if ($img.dtype === 'float32') {\n                if (value < 0 || value > 1) {\n                    throw new Error(`Tensor values for a float32 Tensor must be in the ` +\n                        `range [0 - 1] but encountered ${value}.`);\n                }\n            }\n            else if ($img.dtype === 'int32') {\n                if (value < 0 || value > 255) {\n                    throw new Error(`Tensor values for a int32 Tensor must be in the ` +\n                        `range [0 - 255] but encountered ${value}.`);\n                }\n            }\n            if (depth === 1) {\n                rgba[0] = value * multiplier;\n                rgba[1] = value * multiplier;\n                rgba[2] = value * multiplier;\n            }\n            else {\n                rgba[d] = value * multiplier;\n            }\n        }\n        const j = i * 4;\n        bytes[j + 0] = Math.round(rgba[0]);\n        bytes[j + 1] = Math.round(rgba[1]);\n        bytes[j + 2] = Math.round(rgba[2]);\n        bytes[j + 3] = Math.round(rgba[3]);\n    }\n    if (canvas != null) {\n        canvas.width = width;\n        canvas.height = height;\n        const ctx = canvas.getContext('2d');\n        const imageData = new ImageData(bytes, width, height);\n        ctx.putImageData(imageData, 0, 0);\n    }\n    if ($img !== img) {\n        $img.dispose();\n    }\n    return bytes;\n}\nexport const fromPixels = op({ fromPixels_ });\n//# sourceMappingURL=browser.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n/**\n * Gets the new shape of the input Tensor after it's been reshaped\n * to:\n * [blockShape[0], ..., blockShape[M-1], batch / prod(blockShape),\n * inputShape[1], ..., inputShape[N-1]]\n *\n * See step 1: https://www.tensorflow.org/api_docs/python/tf/batch_to_space_nd\n */\nexport function getReshaped(inputShape, blockShape, prod, batchToSpace = true) {\n    let reshaped = [];\n    if (batchToSpace) {\n        reshaped = reshaped.concat(blockShape.slice(0));\n        reshaped.push(inputShape[0] / prod);\n        reshaped = reshaped.concat(inputShape.slice(1));\n    }\n    else {\n        reshaped = reshaped.concat(inputShape[0]);\n        const spatialLength = blockShape.length;\n        for (let i = 0; i < spatialLength; ++i) {\n            reshaped =\n                reshaped.concat([inputShape[i + 1] / blockShape[i], blockShape[i]]);\n        }\n        reshaped = reshaped.concat(inputShape.slice(spatialLength + 1));\n    }\n    return reshaped;\n}\n/**\n * Gets the permutation that will transpose the dimensions of the\n * reshaped tensor to shape:\n *\n * [batch / prod(block_shape),inputShape[1], blockShape[0], ...,\n * inputShape[M], blockShape[M-1],inputShape[M+1], ..., inputShape[N-1]]\n *\n * see step 2: https://www.tensorflow.org/api_docs/python/tf/batch_to_space_nd\n */\nexport function getPermuted(reshapedRank, blockShapeRank, batchToSpace = true) {\n    const permuted = [];\n    if (batchToSpace) {\n        permuted.push(blockShapeRank);\n        for (let i = blockShapeRank + 1; i < reshapedRank; ++i) {\n            if (i <= 2 * blockShapeRank) {\n                permuted.push(i);\n                permuted.push(i - (blockShapeRank + 1));\n            }\n            else {\n                permuted.push(i);\n            }\n        }\n    }\n    else {\n        const permutedBeforeBatch = [];\n        const permutedAfterBatch = [];\n        for (let i = 1; i < reshapedRank; ++i) {\n            if (i >= blockShapeRank * 2 + 1 || i % 2 === 1) {\n                permutedAfterBatch.push(i);\n            }\n            else {\n                permutedBeforeBatch.push(i);\n            }\n        }\n        permuted.push(...permutedBeforeBatch);\n        permuted.push(0);\n        permuted.push(...permutedAfterBatch);\n    }\n    return permuted;\n}\n/**\n * Gets the shape of the reshaped and permuted input Tensor before any cropping\n * is applied.  The new shape will be:\n *\n * [batch / prod(blockShape),inputShape[1] * blockShape[0], ...,\n * inputShape[M] * blockShape[M-1],inputShape[M+1], ..., inputShape[N-1]]\n *\n * See step 3: https://www.tensorflow.org/api_docs/python/tf/batch_to_space_nd\n */\nexport function getReshapedPermuted(inputShape, blockShape, prod, batchToSpace = true) {\n    const reshapedPermuted = [];\n    if (batchToSpace) {\n        reshapedPermuted.push(inputShape[0] / prod);\n    }\n    else {\n        reshapedPermuted.push(inputShape[0] * prod);\n    }\n    for (let i = 1; i < inputShape.length; ++i) {\n        if (i <= blockShape.length) {\n            if (batchToSpace) {\n                reshapedPermuted.push(blockShape[i - 1] * inputShape[i]);\n            }\n            else {\n                reshapedPermuted.push(inputShape[i] / blockShape[i - 1]);\n            }\n        }\n        else {\n            reshapedPermuted.push(inputShape[i]);\n        }\n    }\n    return reshapedPermuted;\n}\n/**\n * Converts the crops argument into the beginning coordinates of a slice\n * operation.\n */\nexport function getSliceBeginCoords(crops, blockShape) {\n    const sliceBeginCoords = [0];\n    for (let i = 0; i < blockShape; ++i) {\n        sliceBeginCoords.push(crops[i][0]);\n    }\n    return sliceBeginCoords;\n}\n/**\n * Converts the crops argument into the size of a slice operation.  When\n * combined with getSliceBeginCoords this function allows the reshaped and\n * permuted Tensor to be cropped to its final output shape of:\n *\n * inputShape[1] * blockShape[0] - crops[0,0] - crops[0,1], ...,\n * inputShape[M] * blockShape[M-1] -crops[M-1,0] -\n * crops[M-1,1],inputShape[M+1], ..., inputShape[N-1]]\n *\n * See step 4: https://www.tensorflow.org/api_docs/python/tf/batch_to_space_nd\n */\nexport function getSliceSize(uncroppedShape, crops, blockShape) {\n    const sliceSize = uncroppedShape.slice(0, 1);\n    for (let i = 0; i < blockShape; ++i) {\n        sliceSize.push(uncroppedShape[i + 1] - crops[i][0] - crops[i][1]);\n    }\n    return sliceSize;\n}\n//# sourceMappingURL=array_ops_util.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nexport const ERF_P = 0.3275911;\nexport const ERF_A1 = 0.254829592;\nexport const ERF_A2 = -0.284496736;\nexport const ERF_A3 = 1.421413741;\nexport const ERF_A4 = -1.453152027;\nexport const ERF_A5 = 1.061405429;\n//# sourceMappingURL=erf_util.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { env } from './environment';\nexport function warn(...msg) {\n    if (!env().getBool('IS_TEST')) {\n        console.warn(...msg);\n    }\n}\nexport function log(...msg) {\n    if (!env().getBool('IS_TEST')) {\n        console.log(...msg);\n    }\n}\n//# sourceMappingURL=log.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Acos } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes acos of the input `tf.Tensor` element-wise: `acos(x)`\n *\n * ```js\n * const x = tf.tensor1d([0, 1, -1, .7]);\n *\n * x.acos().print();  // or tf.acos(x)\n * ```\n * @param x The input tensor.\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction acos_(x) {\n    const $x = convertToTensor(x, 'x', 'acos');\n    const inputs = { x: $x };\n    return ENGINE.runKernelFunc((backend, save) => {\n        const res = backend.acos($x);\n        save([$x]);\n        return res;\n    }, inputs, null /* grad */, Acos);\n}\nexport const acos = op({ acos_ });\n//# sourceMappingURL=acos.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Acosh } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes the inverse hyperbolic cos of the input `tf.Tensor` element-wise:\n * `acosh(x)`\n *\n * ```js\n * const x = tf.tensor1d([10, 1, 3, 5.7]);\n *\n * x.acosh().print();  // or tf.acosh(x)\n * ```\n * @param x The input tensor.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction acosh_(x) {\n    const $x = convertToTensor(x, 'x', 'acosh');\n    const inputs = { x: $x };\n    return ENGINE.runKernelFunc((backend, save) => {\n        const res = backend.acosh($x);\n        save([$x]);\n        return res;\n    }, inputs, null /* grad */, Acosh);\n}\nexport const acosh = op({ acosh_ });\n//# sourceMappingURL=acosh.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { deprecationWarn } from '../globals';\nimport { convertToTensor } from '../tensor_util_env';\nimport * as util from '../util';\nimport { add } from './add';\nimport { div } from './div';\nimport { maximum } from './maximum';\nimport { minimum } from './minimum';\nimport { mod } from './mod';\nimport { mul } from './mul';\nimport { op } from './operation';\nimport { pow } from './pow';\nimport { squaredDifference } from './squared_difference';\nimport { sub } from './sub';\n/**\n * @deprecated\n * Adds two `tf.Tensor`s element-wise, A + B.\n *\n * Inputs must be the same shape. For broadcasting support, use add() instead.\n *\n * @param a The first Tensor to add element-wise.\n * @param b The second Tensor to add element-wise.\n */\nfunction addStrict_(a, b) {\n    deprecationWarn('strict variants of ops have been deprecated ' +\n        'and will be removed in future');\n    const $a = convertToTensor(a, 'a', 'addStrict');\n    const $b = convertToTensor(b, 'b', 'addStrict');\n    util.assertShapesMatch($a.shape, $b.shape, 'Error in addStrict: ');\n    return add($a, $b);\n}\n/**\n * @deprecated\n * Subtracts two `tf.Tensor`s element-wise, A - B. Inputs must\n * be the same shape.\n *\n * For broadcasting support, use `tf.sub` instead.\n *\n * @param a The first Tensor to subtract element-wise.\n * @param b The second Tensor to subtract element-wise.\n */\nfunction subStrict_(a, b) {\n    deprecationWarn('strict variants of ops have been deprecated ' +\n        'and will be removed in future');\n    const $a = convertToTensor(a, 'a', 'subStrict');\n    const $b = convertToTensor(b, 'b', 'subStrict');\n    util.assertShapesMatch($a.shape, $b.shape, 'Error in subStrict: ');\n    return sub($a, $b);\n}\n/**\n * @deprecated\n * Computes the power of one `tf.Tensor` to another. Inputs must\n * be the same shape.\n *\n * For broadcasting support, use `tf.pow` instead.\n *\n * @param base The base tensor to pow element-wise.\n * @param exp The exponent tensor to pow element-wise.\n */\nfunction powStrict_(base, exp) {\n    deprecationWarn('strict variants of ops have been deprecated ' +\n        'and will be removed in future');\n    util.assertShapesMatch(base.shape, exp.shape, 'Error in powStrict: ');\n    return pow(base, exp);\n}\n/**\n * @deprecated\n * Multiplies two `tf.Tensor`s element-wise, A * B.\n *\n * Inputs must be the same shape. For broadcasting support, use `tf.mul`.\n *\n * @param a The first tensor to multiply.\n * @param b The first tensor to multiply. Must have the same\n *    dtype as `a`.\n */\nfunction mulStrict_(a, b) {\n    deprecationWarn('strict variants of ops have been deprecated ' +\n        'and will be removed in future');\n    const $a = convertToTensor(a, 'a', 'mul');\n    const $b = convertToTensor(b, 'b', 'mul');\n    util.assertShapesMatch($a.shape, $b.shape, 'Error in multiplyStrict: ');\n    return mul($a, $b);\n}\n/**\n * @deprecated\n * Divides two `tf.Tensor`s element-wise, A / B. Inputs must\n * be the same shape.\n *\n * @param a The first tensor as the numerator for element-wise division.\n * @param b The second tensor as the denominator for element-wise division.\n */\nfunction divStrict_(a, b) {\n    deprecationWarn('strict variants of ops have been deprecated ' +\n        'and will be removed in future');\n    const $a = convertToTensor(a, 'a', 'div');\n    const $b = convertToTensor(b, 'b', 'div');\n    util.assertShapesMatch($a.shape, $b.shape, 'Error in divideStrict: ');\n    return div($a, $b);\n}\n/**\n * @deprecated\n * Returns the mod of a and b (`a < b ? a : b`) element-wise. Inputs must\n * be the same shape. For broadcasting support, use mod().\n *\n * @param a The first tensor.\n * @param b The second tensor. Must have the same dtype as `a`.\n */\nfunction modStrict_(a, b) {\n    deprecationWarn('strict variants of ops have been deprecated ' +\n        'and will be removed in future');\n    const $a = convertToTensor(a, 'a', 'modStrict');\n    const $b = convertToTensor(b, 'b', 'modStrict');\n    util.assertShapesMatch($a.shape, $b.shape, 'Error in modStrict: ');\n    return mod($a, $b);\n}\n/**\n * @deprecated\n * Returns the min of a and b (`a < b ? a : b`) element-wise. Inputs must\n * be the same shape. For broadcasting support, use minimum().\n *\n * @param a The first tensor.\n * @param b The second tensor. Must have the same dtype as `a`.\n */\nfunction minimumStrict_(a, b) {\n    deprecationWarn('strict variants of ops have been deprecated ' +\n        'and will be removed in future');\n    const $a = convertToTensor(a, 'a', 'minimumStrict');\n    const $b = convertToTensor(b, 'b', 'minimumStrict');\n    util.assertShapesMatch($a.shape, $b.shape, 'Error in minimumStrict: ');\n    return minimum($a, $b);\n}\n/**\n * @deprecated\n * Returns the max of a and b (`a > b ? a : b`) element-wise. Inputs must\n * be the same shape. For broadcasting support, use maximum().\n *\n * @param a The first tensor.\n * @param b The second tensor. Must have the same dtype as `a`.\n */\nfunction maximumStrict_(a, b) {\n    deprecationWarn('strict variants of ops have been deprecated ' +\n        'and will be removed in future');\n    const $a = convertToTensor(a, 'a', 'maximumStrict');\n    const $b = convertToTensor(b, 'b', 'maximumStrict');\n    util.assertShapesMatch($a.shape, $b.shape, 'Error in maximumStrict: ');\n    return maximum($a, $b);\n}\n/**\n * @deprecated\n * Returns (a - b) * (a - b) element-wise.\n *\n * Inputs must be the same shape. For broadcasting support, use\n * `tf.squaredDifference` instead.\n *\n * @param a The first tensor.\n * @param b The second tensor. Must have the same type as `a`.\n */\nfunction squaredDifferenceStrict_(a, b) {\n    deprecationWarn('strict variants of ops have been deprecated ' +\n        'and will be removed in future');\n    const $a = convertToTensor(a, 'a', 'squaredDifferenceStrict');\n    const $b = convertToTensor(b, 'b', 'squaredDifferenceStrict');\n    util.assertShapesMatch($a.shape, $b.shape, 'Error in squaredDifferenceStrict: ');\n    return squaredDifference($a, $b);\n}\nexport const addStrict = op({ addStrict_ });\nexport const divStrict = op({ divStrict_ });\nexport const maximumStrict = op({ maximumStrict_ });\nexport const minimumStrict = op({ minimumStrict_ });\nexport const modStrict = op({ modStrict_ });\nexport const mulStrict = op({ mulStrict_ });\nexport const powStrict = op({ powStrict_ });\nexport const squaredDifferenceStrict = op({ squaredDifferenceStrict_ });\nexport const subStrict = op({ subStrict_ });\n//# sourceMappingURL=binary_ops.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Asin } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes asin of the input `tf.Tensor` element-wise: `asin(x)`\n *\n * ```js\n * const x = tf.tensor1d([0, 1, -1, .7]);\n *\n * x.asin().print();  // or tf.asin(x)\n * ```\n * @param x The input tensor.\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction asin_(x) {\n    const $x = convertToTensor(x, 'x', 'asin');\n    const inputs = { x: $x };\n    return ENGINE.runKernelFunc((backend, save) => {\n        const res = backend.asin($x);\n        save([$x]);\n        return res;\n    }, inputs, null /* grad */, Asin);\n}\nexport const asin = op({ asin_ });\n//# sourceMappingURL=asin.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Asinh } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes inverse hyperbolic sin of the input `tf.Tensor` element-wise:\n * `asinh(x)`\n *\n * ```js\n * const x = tf.tensor1d([0, 1, -1, .7]);\n *\n * x.asinh().print();  // or tf.asinh(x)\n * ```\n * @param x The input tensor.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction asinh_(x) {\n    const $x = convertToTensor(x, 'x', 'asinh');\n    const inputs = { x: $x };\n    return ENGINE.runKernelFunc((backend, save) => {\n        const res = backend.asinh($x);\n        save([$x]);\n        return res;\n    }, inputs, null /* grad */, Asinh);\n}\nexport const asinh = op({ asinh_ });\n//# sourceMappingURL=asinh.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Atan } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes atan of the input `tf.Tensor` element-wise: `atan(x)`\n *\n * ```js\n * const x = tf.tensor1d([0, 1, -1, .7]);\n *\n * x.atan().print();  // or tf.atan(x)\n * ```\n * @param x The input tensor.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction atan_(x) {\n    const $x = convertToTensor(x, 'x', 'atan');\n    const inputs = { x: $x };\n    return ENGINE.runKernelFunc((backend, save) => {\n        const res = backend.atan($x);\n        save([$x]);\n        return res;\n    }, inputs, null /* grad */, Atan);\n}\nexport const atan = op({ atan_ });\n//# sourceMappingURL=atan.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Atanh } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes inverse hyperbolic tan of the input `tf.Tensor` element-wise:\n * `atanh(x)`\n *\n * ```js\n * const x = tf.tensor1d([0, .1, -.1, .7]);\n *\n * x.atanh().print();  // or tf.atanh(x)\n * ```\n * @param x The input tensor.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction atanh_(x) {\n    const $x = convertToTensor(x, 'x', 'atanh');\n    const inputs = { x: $x };\n    return ENGINE.runKernelFunc((backend, save) => {\n        const res = backend.atanh($x);\n        save([$x]);\n        return res;\n    }, inputs, null /* grad */, Atanh);\n}\nexport const atanh = op({ atanh_ });\n//# sourceMappingURL=atanh.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Ceil } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes ceiling of input `tf.Tensor` element-wise: `ceil(x)`\n *\n * ```js\n * const x = tf.tensor1d([.6, 1.1, -3.3]);\n *\n * x.ceil().print();  // or tf.ceil(x)\n * ```\n * @param x The input Tensor.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction ceil_(x) {\n    const $x = convertToTensor(x, 'x', 'ceil');\n    const inputs = { x: $x };\n    return ENGINE.runKernelFunc(backend => backend.ceil($x), inputs, null /* grad */, Ceil);\n}\nexport const ceil = op({ ceil_ });\n//# sourceMappingURL=ceil.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { ClipByValue } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport * as util from '../util';\nimport { op } from './operation';\n/**\n * Clips values element-wise. `max(min(x, clipValueMax), clipValueMin)`\n *\n * ```js\n * const x = tf.tensor1d([-1, 2, -3, 4]);\n *\n * x.clipByValue(-2, 3).print();  // or tf.clipByValue(x, -2, 3)\n * ```\n * @param x The input tensor.\n * @param clipValueMin Lower-bound of range to be clipped to.\n * @param clipValueMax Upper-bound of range to be clipped to.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction clipByValue_(x, clipValueMin, clipValueMax) {\n    const $x = convertToTensor(x, 'x', 'clipByValue');\n    util.assert((clipValueMin <= clipValueMax), () => `Error in clip: min (${clipValueMin}) must be ` +\n        `less than or equal to max (${clipValueMax}).`);\n    const inputs = { x: $x };\n    const attrs = { clipValueMin, clipValueMax };\n    return ENGINE.runKernelFunc((backend, save) => {\n        const res = backend.clip($x, clipValueMin, clipValueMax);\n        save([$x]);\n        return res;\n    }, inputs, null /* grad */, ClipByValue, attrs);\n}\nexport const clipByValue = op({ clipByValue_ });\n//# sourceMappingURL=clip_by_value.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { deprecationWarn } from '../globals';\nimport { convertToTensor } from '../tensor_util_env';\nimport { assertShapesMatch } from '../util';\nimport { equal } from './equal';\nimport { greater } from './greater';\nimport { greaterEqual } from './greater_equal';\nimport { less } from './less';\nimport { lessEqual } from './less_equal';\nimport { notEqual } from './not_equal';\nimport { op } from './operation';\n/**\n * @deprecated\n * Strict version of `tf.notEqual` that forces `a` and `b` to be of the same\n * shape.\n *\n * @param a The first input tensor.\n * @param b The second input tensor. Must have the same shape and dtype as\n *     `a`.\n */\nfunction notEqualStrict_(a, b) {\n    deprecationWarn('strict variants of ops have been deprecated ' +\n        'and will be removed in future');\n    const $a = convertToTensor(a, 'a', 'notEqualStrict');\n    const $b = convertToTensor(b, 'b', 'notEqualStrict');\n    assertShapesMatch($a.shape, $b.shape, 'Error in notEqualStrict: ');\n    return notEqual($a, $b);\n}\n/**\n * @deprecated\n * Strict version of `tf.less` that forces `a` and `b` to be of the same\n * shape.\n *\n * @param a The first input tensor.\n * @param b The second input tensor. Must have the same shape and dtype as\n *     `a`.\n */\nfunction lessStrict_(a, b) {\n    deprecationWarn('strict variants of ops have been deprecated ' +\n        'and will be removed in future');\n    const $a = convertToTensor(a, 'a', 'lessStrict');\n    const $b = convertToTensor(b, 'b', 'lessStrict');\n    assertShapesMatch($a.shape, $b.shape, 'Error in lessStrict: ');\n    return less($a, $b);\n}\nfunction equalStrict_(a, b) {\n    deprecationWarn('strict variants of ops have been deprecated ' +\n        'and will be removed in future');\n    const $a = convertToTensor(a, 'a', 'equalStrict');\n    const $b = convertToTensor(b, 'b', 'equalStrict');\n    assertShapesMatch($a.shape, $b.shape, 'Error in equalStrict: ');\n    return equal($a, $b);\n}\nfunction lessEqualStrict_(a, b) {\n    deprecationWarn('strict variants of ops have been deprecated ' +\n        'and will be removed in future');\n    const $a = convertToTensor(a, 'a', 'lessEqualStrict');\n    const $b = convertToTensor(b, 'b', 'lessEqualStrict');\n    assertShapesMatch($a.shape, $b.shape, 'Error in lessEqualStrict: ');\n    return lessEqual($a, $b);\n}\nfunction greaterStrict_(a, b) {\n    deprecationWarn('strict variants of ops have been deprecated ' +\n        'and will be removed in future');\n    const $a = convertToTensor(a, 'a', 'greaterStrict');\n    const $b = convertToTensor(b, 'b', 'greaterStrict');\n    assertShapesMatch($a.shape, $b.shape, 'Error in greaterStrict: ');\n    return greater($a, $b);\n}\nfunction greaterEqualStrict_(a, b) {\n    deprecationWarn('strict variants of ops have been deprecated ' +\n        'and will be removed in future');\n    const $a = convertToTensor(a, 'a', 'greaterEqualStrict');\n    const $b = convertToTensor(b, 'b', 'greaterEqualStrict');\n    assertShapesMatch($a.shape, $b.shape, 'Error in greaterEqualStrict: ');\n    return greaterEqual($a, $b);\n}\nexport const equalStrict = op({ equalStrict_ });\nexport const greaterEqualStrict = op({ greaterEqualStrict_ });\nexport const greaterStrict = op({ greaterStrict_ });\nexport const lessEqualStrict = op({ lessEqualStrict_ });\nexport const lessStrict = op({ lessStrict_ });\nexport const notEqualStrict = op({ notEqualStrict_ });\n//# sourceMappingURL=compare.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Erf } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport * as util from '../util';\nimport { cast } from './cast';\nimport { op } from './operation';\n/**\n * Computes gause error function of the input `tf.Tensor` element-wise:\n * `erf(x)`\n *\n * ```js\n * const x = tf.tensor1d([0, .1, -.1, .7]);\n *\n * x.erf().print(); // or tf.erf(x);\n * ```\n * @param x The input tensor.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction erf_(x) {\n    let $x = convertToTensor(x, 'x', 'erf');\n    util.assert($x.dtype === 'int32' || $x.dtype === 'float32', () => 'Input dtype must be `int32` or `float32`.');\n    if ($x.dtype === 'int32') {\n        $x = cast($x, 'float32');\n    }\n    const inputs = { x: $x };\n    return ENGINE.runKernelFunc((backend, save) => {\n        const res = backend.erf($x);\n        save([$x]);\n        return res;\n    }, inputs, null /* grad */, Erf);\n}\nexport const erf = op({ erf_ });\n//# sourceMappingURL=erf.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Expm1 } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes exponential of the input `tf.Tensor` minus one element-wise.\n * `e ^ x - 1`\n *\n * ```js\n * const x = tf.tensor1d([1, 2, -3]);\n *\n * x.expm1().print();  // or tf.expm1(x)\n * ```\n * @param x The input tensor.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction expm1_(x) {\n    const $x = convertToTensor(x, 'x', 'expm1');\n    const inputs = { x: $x };\n    return ENGINE.runKernelFunc((backend, save) => {\n        const res = backend.expm1($x);\n        save([$x]);\n        return res;\n    }, inputs, null /* grad */, Expm1);\n}\nexport const expm1 = op({ expm1_ });\n//# sourceMappingURL=expm1.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Concat } from '../kernel_names';\nimport { convertToTensorArray } from '../tensor_util_env';\nimport { assert, parseAxisParam, sizeFromShape } from '../util';\nimport { assertParamsConsistent, computeOutShape } from './concat_util';\nimport { op } from './operation';\nimport { tensor } from './tensor';\n/**\n * Concatenates a list of `tf.Tensor`s along a given axis.\n *\n * The tensors ranks and types must match, and their sizes must match in all\n * dimensions except `axis`.\n *\n * Also available are stricter rank-specific methods that assert that\n * `tensors` are of the given rank:\n *   - `tf.concat1d`\n *   - `tf.concat2d`\n *   - `tf.concat3d`\n *   - `tf.concat4d`\n *\n * Except `tf.concat1d` (which does not have axis param), all methods have\n * same signature as this method.\n *\n * ```js\n * const a = tf.tensor1d([1, 2]);\n * const b = tf.tensor1d([3, 4]);\n * a.concat(b).print();  // or a.concat(b)\n * ```\n *\n * ```js\n * const a = tf.tensor1d([1, 2]);\n * const b = tf.tensor1d([3, 4]);\n * const c = tf.tensor1d([5, 6]);\n * tf.concat([a, b, c]).print();\n * ```\n *\n * ```js\n * const a = tf.tensor2d([[1, 2], [10, 20]]);\n * const b = tf.tensor2d([[3, 4], [30, 40]]);\n * const axis = 1;\n * tf.concat([a, b], axis).print();\n * ```\n * @param tensors A list of tensors to concatenate.\n * @param axis The axis to concate along. Defaults to 0 (the first dim).\n *\n * @doc {heading: 'Tensors', subheading: 'Slicing and Joining'}\n */\nfunction concat_(tensors, axis = 0) {\n    assert(tensors.length >= 1, () => 'Pass at least one tensor to concat');\n    let $tensors = convertToTensorArray(tensors, 'tensors', 'concat');\n    if ($tensors[0].dtype === 'complex64') {\n        $tensors.forEach(tensor => {\n            if (tensor.dtype !== 'complex64') {\n                throw new Error(`Cannot concatenate complex64 tensors with a tensor\n          with dtype ${tensor.dtype}. `);\n            }\n        });\n    }\n    const $axis = parseAxisParam(axis, $tensors[0].shape)[0];\n    const outShape = computeOutShape($tensors.map(t => t.shape), $axis);\n    if (sizeFromShape(outShape) === 0) {\n        return tensor([], outShape);\n    }\n    // Keep only non-empty tensors (ignore tensors with 0 in their shape).\n    $tensors = $tensors.filter(t => t.size > 0);\n    if ($tensors.length === 1) {\n        return $tensors[0];\n    }\n    const shapes = $tensors.map(t => t.shape);\n    assertParamsConsistent(shapes, $axis);\n    const forward = (backend, save) => {\n        const res = backend.concat($tensors, $axis);\n        save($tensors);\n        return res;\n    };\n    const inputs = $tensors;\n    const attr = { axis };\n    return ENGINE.runKernelFunc(forward, inputs, null /* grad */, Concat, attr);\n}\nexport const concat = op({ concat_ });\n//# sourceMappingURL=concat.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { AvgPool3DBackprop } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport * as util from '../util';\nimport * as conv_util from './conv_util';\nimport { op } from './operation';\nimport { reshape } from './reshape';\n/**\n * Computes the backprop of a 3d avg pool.\n *\n * @param dy The dy error, of rank 5 of shape\n *     [batchSize, depth, height, width, channels].\n * assumed.\n * @param input The original input image, of rank 5 or rank4 of shape\n *     [batchSize, depth, height, width, channels].\n * @param filterSize The filter size:\n *     `[filterDepth, filterHeight, filterWidth]`.\n *     `filterSize` is a single number,\n *     then `filterDepth == filterHeight == filterWidth`.\n * @param strides The strides of the pooling:\n *     `[strideDepth, strideHeight, strideWidth]`. If\n *     `strides` is a single number, then `strideHeight == strideWidth`.\n * @param dilations Deprecated, this field will be gone in v3.0.0. The dilation\n *     rates: `[dilationDepth, dilationHeight, dilationWidth]`\n *     in which we sample input values across the depth, height and width\n *     dimensions in dilated pooling.\n *     Defaults to `[1, 1, 1]`. If `dilations` is a single number,\n *     then `dilationDepth == dilationHeight == dilationWidth`.\n *     If it is greater than 1, then all values of `strides` must be 1.\n * @param pad A string from: 'same', 'valid'. The type of padding algorithm\n *     used in the forward prop of the op.\n * @param dimRoundingMode A string from: 'ceil', 'round', 'floor'. The\n *     rounding mode used when computing output dimensions if pad is a\n *     number. If none is provided, it will not round and error if the output\n *     is of fractional size.\n */\nfunction avgPool3dBackprop_(dy, input, filterSize, strides, dilations = [1, 1, 1], pad, dimRoundingMode) {\n    const $dy = convertToTensor(dy, 'dy', 'avgPool3dBackprop');\n    const $input = convertToTensor(input, 'input', 'avgPool3dBackprop');\n    let dy5D = $dy;\n    let input5D = $input;\n    let reshapedTo5D = false;\n    if ($input.rank === 4) {\n        reshapedTo5D = true;\n        dy5D = reshape($dy, [1, $dy.shape[0], $dy.shape[1], $dy.shape[2], $dy.shape[3]]);\n        input5D = reshape($input, [\n            1, $input.shape[0], $input.shape[1], $input.shape[2], $input.shape[3]\n        ]);\n    }\n    util.assert(dy5D.rank === 5, () => `Error in avgPool3dBackprop: dy must be rank 5 but got rank ` +\n        `${dy5D.rank}.`);\n    util.assert(input5D.rank === 5, () => `Error in avgPool3dBackprop: input must be rank 5 but got rank ` +\n        `${input5D.rank}.`);\n    util.assert(conv_util.eitherStridesOrDilationsAreOne(strides, dilations), () => 'Error in avgPool3dBackprop: Either strides or dilations ' +\n        `must be 1. Got strides ${strides} and dilations '${dilations}'`);\n    if (dimRoundingMode != null) {\n        util.assert(util.isInt(pad), () => `Error in maxPool3dBackprop: pad must be an integer when ` +\n            `using, dimRoundingMode ${dimRoundingMode} but got pad ${pad}.`);\n    }\n    const forward = backend => {\n        const convInfo = conv_util.computePool3DInfo(input5D.shape, filterSize, strides, dilations, pad, dimRoundingMode);\n        return backend.avgPool3dBackprop(dy5D, input5D, convInfo);\n    };\n    const inputs = { dy: dy5D, input: input5D };\n    const attrs = { filterSize, strides, dilations, pad, dimRoundingMode };\n    const res = ENGINE.runKernelFunc(forward, inputs, null /* grad */, AvgPool3DBackprop, attrs);\n    if (reshapedTo5D) {\n        return reshape(res, [res.shape[1], res.shape[2], res.shape[3], res.shape[4]]);\n    }\n    return res;\n}\nexport const avgPool3dBackprop = op({ avgPool3dBackprop_ });\n//# sourceMappingURL=avg_pool_3d_backprop.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { AvgPoolBackprop } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport * as util from '../util';\nimport * as conv_util from './conv_util';\nimport { op } from './operation';\nimport { reshape } from './reshape';\n/**\n * Computes the backprop of an 2D avg pool.\n *\n * @param dy The dy error, of rank 4 or rank 3 of shape\n *     [batchSize, height, width, channels]. If rank 3, batch of 1 is\n * assumed.\n * @param input The input image, of rank 4 or rank 3 of shape\n *     [batchSize, height, width, channels]. If rank 3, batch of 1 is\n * assumed.\n * @param filterSize The filter size: `[filterHeight, filterWidth]`. If\n *     `filterSize` is a single number, then `filterHeight == filterWidth`.\n * @param strides The strides of the pooling: `[strideHeight, strideWidth]`. If\n *     `strides` is a single number, then `strideHeight == strideWidth`.\n * @param pad A string from: 'same', 'valid'. The type of padding algorithm\n *     used in the forward prop of the op.\n */\nfunction avgPoolBackprop_(dy, input, filterSize, strides, pad) {\n    const $dy = convertToTensor(dy, 'dy', 'avgPoolBackprop');\n    const $input = convertToTensor(input, 'input', 'avgPoolBackprop');\n    util.assert($input.rank === $dy.rank, () => `Rank of input (${$input.rank}) does not match rank of dy (${$dy.rank})`);\n    let input4D = $input;\n    let dy4D = $dy;\n    let reshapedTo4D = false;\n    if ($input.rank === 3) {\n        reshapedTo4D = true;\n        input4D =\n            reshape($input, [1, $input.shape[0], $input.shape[1], $input.shape[2]]);\n        dy4D = reshape($dy, [1, $dy.shape[0], $dy.shape[1], $dy.shape[2]]);\n    }\n    util.assert(dy4D.rank === 4, () => `Error in avgPoolBackprop: dy must be rank 4 but got rank ` +\n        `${dy4D.rank}.`);\n    util.assert(input4D.rank === 4, () => `Error in avgPoolBackprop: input must be rank 4 but got rank ` +\n        `${input4D.rank}.`);\n    const forward = backend => {\n        const convInfo = conv_util.computePool2DInfo(input4D.shape, filterSize, strides, 1 /* dilations */, pad);\n        return backend.avgPoolBackprop(dy4D, input4D, convInfo);\n    };\n    const inputs = { dy: dy4D, input: input4D };\n    const attrs = { filterSize, strides, pad };\n    const res = ENGINE.runKernelFunc(forward, inputs, null, AvgPoolBackprop, attrs);\n    if (reshapedTo4D) {\n        return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);\n    }\n    return res;\n}\nexport const avgPoolBackprop = op({ avgPoolBackprop_ });\n//# sourceMappingURL=avg_pool_backprop.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Conv3DBackpropInputV2 } from '../kernel_names';\nimport * as util from '../util';\nimport * as conv_util from './conv_util';\nimport { op } from './operation';\nimport { reshape } from './reshape';\n/**\n * Computes the derivative of the input of a 3D convolution.\n *\n * @param xShape The shape of the input: [batch, depth, height, width,\n * in_channels]. If length of 4, batch of 1 is assumed.\n * @param dy The derivative of the output, of rank 5 or rank 4 of shape\n *   `[batch, outDepth, outHeight, outWidth, in_channels]`.\n * If rank 4, batch of 1 is assumed.\n * @param filter The filter, rank 5, of shape\n *     `[filterDepth, filterHeight, filterWidth, inDepth, outDepth]`.\n * @param strides The strides of the convolution: `[strideDepth, strideHeight,\n * strideWidth]`.\n * @param pad The type of padding algorithm used:\n *    - `same` and stride 1: output will be of same size as input,\n *       regardless of filter size.\n *    - `valid`: output will be smaller than input if filter is larger\n *       than 1x1.\n */\nfunction conv3DBackpropInput_(xShape, dy, filter, strides, pad) {\n    util.assert(xShape.length === dy.rank, () => `Length of inShape ` +\n        `(${xShape.length}) and rank of dy (${dy.rank}) must match`);\n    let xShape5D = xShape;\n    let dy5D = dy;\n    let reshapedTo5D = false;\n    if (dy.rank === 4) {\n        reshapedTo5D = true;\n        dy5D = reshape(dy, [1, dy.shape[0], dy.shape[1], dy.shape[2], dy.shape[3]]);\n        xShape5D = [1, xShape[0], xShape[1], xShape[2], xShape[3]];\n    }\n    const inDepth = xShape5D[4];\n    const outDepth = dy5D.shape[4];\n    util.assert(xShape5D.length === 5, () => `Error in conv3dDerInput: inShape must be length 5, but got length ` +\n        `${xShape5D.length}.`);\n    util.assert(dy5D.rank === 5, () => `Error in conv3dDerInput: dy must be rank 5, but got ` +\n        `rank ${dy5D.rank}`);\n    util.assert(filter.rank === 5, () => `Error in conv3dDerInput: filter must be rank 5, but got ` +\n        `rank ${filter.rank}`);\n    util.assert(inDepth === filter.shape[3], () => `Error in conv3dDerInput: depth of input (${inDepth}) must ` +\n        `match input depth for filter ${filter.shape[3]}.`);\n    util.assert(outDepth === filter.shape[4], () => `Error in conv3dDerInput: depth of output (${outDepth}) must ` +\n        `match output depth for filter ${filter.shape[4]}.`);\n    const forward = backend => {\n        const dilations = 1;\n        const convInfo = conv_util.computeConv3DInfo(xShape5D, filter.shape, strides, dilations, pad);\n        return backend.conv3dDerInput(dy5D, filter, convInfo);\n    };\n    const inputs = { dy: dy5D };\n    const attrs = { pad };\n    const res = ENGINE.runKernelFunc(forward, inputs, null, Conv3DBackpropInputV2, attrs);\n    if (reshapedTo5D) {\n        return reshape(res, [res.shape[1], res.shape[2], res.shape[3], res.shape[4]]);\n    }\n    return res;\n}\nexport const conv3DBackpropInput = op({ conv3DBackpropInput_ });\n//# sourceMappingURL=conv3d_backprop_input.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Conv3DBackpropFilterV2 } from '../kernel_names';\nimport * as util from '../util';\nimport * as conv_util from './conv_util';\nimport { op } from './operation';\nimport { reshape } from './reshape';\n/**\n * Computes the derivative of the filter of a 3D convolution.\n *\n * @param x The input tensor, of rank 5 or rank 4 of shape\n *     [batch, depth, height, width, inChannels]. If rank 4, batch of 1 is\n *     assumed.\n * @param dy The dy image, of rank 5 or rank 4, of shape\n *     [batch, depth, height, width, outDepth]. If rank 4, batch of 1 is\n *     assumed.\n * @param filterShape The shape of the filter, length 5,\n *     [filterDepth, filterHeight, filterWidth, inDepth, outDepth].\n * @param strides The strides of the convolution: [strideDepth, strideHeight,\n * strideWidth].\n * @param pad A string from: 'same', 'valid'. The type of padding algorithm\n *     used in the forward prop of the op.\n */\nfunction conv3DBackpropFilter_(x, dy, filterShape, strides, pad) {\n    let x5D = x;\n    if (x.rank === 4) {\n        x5D = reshape(x, [1, x.shape[0], x.shape[1], x.shape[2], x.shape[3]]);\n    }\n    let dy5D = dy;\n    if (dy5D.rank === 4) {\n        dy5D = reshape(dy, [1, dy.shape[0], dy.shape[1], dy.shape[2], dy.shape[3]]);\n    }\n    util.assert(x5D.rank === 5, () => `Error in conv3dDerFilter: input must be rank 5, but got shape ` +\n        `${x5D.shape}.`);\n    util.assert(dy5D.rank === 5, () => `Error in conv3dDerFilter: dy must be rank 5, but got shape ` +\n        `${dy5D.shape}.`);\n    util.assert(filterShape.length === 5, () => `Error in conv3dDerFilter: filterShape must be length 5, but got ` +\n        `${filterShape}.`);\n    util.assert(x5D.shape[4] === filterShape[3], () => `Error in conv3dDerFilter: depth of input ${x5D.shape[4]}) must ` +\n        `match input depth in filter (${filterShape[3]}.`);\n    util.assert(dy5D.shape[4] === filterShape[4], () => `Error in conv3dDerFilter: depth of dy (${dy5D.shape[4]}) must ` +\n        `match output depth for filter (${filterShape[4]}).`);\n    const forward = backend => {\n        const dilations = 1;\n        const convInfo = conv_util.computeConv3DInfo(x5D.shape, filterShape, strides, dilations, pad);\n        return backend.conv3dDerFilter(x5D, dy5D, convInfo);\n    };\n    const inputs = { x: x5D, y: dy5D };\n    const attrs = { strides, pad };\n    return ENGINE.runKernelFunc(forward, inputs, null, Conv3DBackpropFilterV2, attrs);\n}\nexport const conv3DBackpropFilter = op({ conv3DBackpropFilter_ });\n//# sourceMappingURL=conv3d_backprop_filter.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Exp } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes exponential of the input `tf.Tensor` element-wise. `e ^ x`\n *\n * ```js\n * const x = tf.tensor1d([1, 2, -3]);\n *\n * x.exp().print();  // or tf.exp(x)\n * ```\n * @param x The input tensor.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction exp_(x) {\n    const $x = convertToTensor(x, 'x', 'exp');\n    const inputs = { x: $x };\n    return ENGINE.runKernelFunc((backend, save) => {\n        const res = backend.exp($x);\n        save([res]);\n        return res;\n    }, inputs, null /* grad */, Exp);\n}\nexport const exp = op({ exp_ });\n//# sourceMappingURL=exp.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Abs } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes absolute value element-wise: `abs(x)`\n *\n * ```js\n * const x = tf.tensor1d([-1, 2, -3, 4]);\n *\n * x.abs().print();  // or tf.abs(x)\n * ```\n * @param x The input `tf.Tensor`.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction abs_(x) {\n    const $x = convertToTensor(x, 'x', 'abs');\n    const inputs = { x: $x };\n    return ENGINE.runKernelFunc((backend, save) => {\n        save([$x]);\n        if ($x.dtype === 'complex64') {\n            return backend.complexAbs($x);\n        }\n        return backend.abs($x);\n    }, inputs, null /* grad */, Abs);\n}\nexport const abs = op({ abs_ });\n//# sourceMappingURL=abs.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { convertToTensor } from '../tensor_util_env';\nimport * as util from '../util';\nimport { op } from './operation';\nimport { reshape } from './reshape';\n/**\n * Returns a `tf.Tensor` that has expanded rank, by inserting a dimension\n * into the tensor's shape.\n *\n * ```js\n * const x = tf.tensor1d([1, 2, 3, 4]);\n * const axis = 1;\n * x.expandDims(axis).print();\n * ```\n *\n * @param x The input tensor whose dimensions to be expanded.\n * @param axis The dimension index at which to insert shape of `1`. Defaults\n *     to 0 (the first dimension).\n *\n * @doc {heading: 'Tensors', subheading: 'Transformations'}\n */\nfunction expandDims_(x, axis = 0) {\n    const parseAs = null;\n    const $x = convertToTensor(x, 'x', 'expandDims', parseAs);\n    util.assert(axis <= $x.rank, () => 'Axis must be <= rank of the tensor');\n    const newShape = $x.shape.slice();\n    if (axis < 0) {\n        // Negative value is counted from the tail of rank.\n        util.assert(-($x.rank + 1) <= axis, () => `Axis must be in the interval [${-($x.rank + 1)}, ${$x.rank}]`);\n        axis = $x.rank + axis + 1;\n    }\n    newShape.splice(axis, 0, 1);\n    return reshape($x, newShape);\n}\nexport const expandDims = op({ expandDims_ });\n//# sourceMappingURL=expand_dims.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Complex } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport * as util from '../util';\nimport { op } from './operation';\n/**\n * Converts two real numbers to a complex number.\n *\n * Given a tensor `real` representing the real part of a complex number, and a\n * tensor `imag` representing the imaginary part of a complex number, this\n * operation returns complex numbers elementwise of the form [r0, i0, r1, i1],\n * where r represents the real part and i represents the imag part.\n *\n * The input tensors real and imag must have the same shape.\n *\n * ```js\n * const real = tf.tensor1d([2.25, 3.25]);\n * const imag = tf.tensor1d([4.75, 5.75]);\n * const complex = tf.complex(real, imag);\n *\n * complex.print();\n * ```\n *\n * @doc {heading: 'Tensors', subheading: 'Creation'}\n */\nfunction complex_(real, imag) {\n    const $real = convertToTensor(real, 'real', 'complex');\n    const $imag = convertToTensor(imag, 'imag', 'complex');\n    util.assertShapesMatch($real.shape, $imag.shape, `real and imag shapes, ${$real.shape} and ${$imag.shape}, ` +\n        `must match in call to tf.complex().`);\n    const forward = (backend) => {\n        return backend.complex($real, $imag);\n    };\n    const inputs = { real: $real, imag: $imag };\n    return ENGINE.runKernelFunc(forward, inputs, null /* gradient */, Complex);\n}\nexport const complex = op({ complex_ });\n//# sourceMappingURL=complex.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Conv2D } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport * as util from '../util';\nimport * as conv_util from './conv_util';\nimport { op } from './operation';\nimport { reshape } from './reshape';\n/**\n * Computes a 2D convolution over the input x.\n *\n * @param x The input tensor, of rank 4 or rank 3, of shape\n *     `[batch, height, width, inChannels]`. If rank 3, batch of 1 is\n * assumed.\n * @param filter The filter, rank 4, of shape\n *     `[filterHeight, filterWidth, inDepth, outDepth]`.\n * @param strides The strides of the convolution: `[strideHeight,\n * strideWidth]`.\n * @param pad The type of padding algorithm.\n *    - `same` and stride 1: output will be of same size as input,\n *       regardless of filter size.\n *    - `valid`: output will be smaller than input if filter is larger\n *       than 1x1.\n *   - For more info, see this guide:\n *     [https://www.tensorflow.org/api_guides/python/nn#Convolution](\n *          https://www.tensorflow.org/api_guides/python/nn#Convolution)\n * @param dataFormat: An optional string from: \"NHWC\", \"NCHW\". Defaults to\n *     \"NHWC\". Specify the data format of the input and output data. With the\n *     default format \"NHWC\", the data is stored in the order of: [batch,\n *     height, width, channels].\n * @param dilations The dilation rates: `[dilationHeight, dilationWidth]`\n *     in which we sample input values across the height and width dimensions\n *     in atrous convolution. Defaults to `[1, 1]`. If `dilations` is a single\n *     number, then `dilationHeight == dilationWidth`. If it is greater than\n *     1, then all values of `strides` must be 1.\n * @param dimRoundingMode The rounding mode used when computing output\n *     dimensions if pad is a number. If none is provided, it will not round\n *     and error if the output is of fractional size.\n *\n * @doc {heading: 'Operations', subheading: 'Convolution'}\n */\nfunction conv2d_(x, filter, strides, pad, dataFormat = 'NHWC', dilations = [1, 1], dimRoundingMode) {\n    const $x = convertToTensor(x, 'x', 'conv2d');\n    const $filter = convertToTensor(filter, 'filter', 'conv2d');\n    let x4D = $x;\n    let reshapedTo4D = false;\n    if ($x.rank === 3) {\n        reshapedTo4D = true;\n        x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);\n    }\n    util.assert(x4D.rank === 4, () => `Error in conv2d: input must be rank 4, but got rank ${x4D.rank}.`);\n    util.assert($filter.rank === 4, () => `Error in conv2d: filter must be rank 4, but got rank ` +\n        `${$filter.rank}.`);\n    if (dimRoundingMode != null) {\n        util.assert(util.isInt(pad), () => `Error in conv2d: pad must be an integer when using, ` +\n            `dimRoundingMode ${dimRoundingMode} but got pad ${pad}.`);\n    }\n    const inDepth = dataFormat === 'NHWC' ? x4D.shape[3] : x4D.shape[1];\n    util.assert(inDepth === $filter.shape[2], () => `Error in conv2d: depth of input (${inDepth}) must match ` +\n        `input depth for filter ${$filter.shape[2]}.`);\n    util.assert(conv_util.eitherStridesOrDilationsAreOne(strides, dilations), () => 'Error in conv2D: Either strides or dilations must be 1. ' +\n        `Got strides ${strides} and dilations '${dilations}'`);\n    const forward = (backend, save) => {\n        const $dataFormat = conv_util.convertConv2DDataFormat(dataFormat);\n        const convInfo = conv_util.computeConv2DInfo(x4D.shape, $filter.shape, strides, dilations, pad, dimRoundingMode, false, $dataFormat);\n        const res = backend.conv2d(x4D, $filter, convInfo);\n        save([x4D, $filter]);\n        return res;\n    };\n    const inputs = { x: x4D, filter: $filter };\n    const attrs = { strides, pad, dataFormat, dilations, dimRoundingMode };\n    const res = ENGINE.runKernelFunc(forward, inputs, null /* grad */, Conv2D, attrs);\n    if (reshapedTo4D) {\n        return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);\n    }\n    return res;\n}\nexport const conv2d = op({ conv2d_ });\n//# sourceMappingURL=conv2d.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Identity } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Creates a new tensor with the same values and shape as the specified\n * tensor.\n *\n * ```js\n * const x = tf.tensor([1, 2]);\n *\n * x.clone().print();\n * ```\n *\n * @param x The tensor to clone.\n *\n * @doc {heading: 'Tensors', subheading: 'Creation'}\n */\nfunction clone_(x) {\n    const $x = convertToTensor(x, 'x', 'clone', null);\n    const forward = () => ENGINE.makeTensorFromDataId($x.dataId, $x.shape, $x.dtype);\n    const inputs = { x: $x };\n    // Note this op is called tf.identity in python. Hence the kernel name used\n    // here.\n    return ENGINE.runKernelFunc(forward, inputs, null /* grad */, Identity);\n}\nexport const clone = op({ clone_ });\n//# sourceMappingURL=clone.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { DepthwiseConv2dNative } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport * as util from '../util';\nimport * as conv_util from './conv_util';\nimport { op } from './operation';\nimport { reshape } from './reshape';\n/**\n * Depthwise 2D convolution.\n *\n * Given a 4D `input` array and a `filter` array of shape\n * `[filterHeight, filterWidth, inChannels, channelMultiplier]` containing\n * `inChannels` convolutional filters of depth 1, this op applies a\n * different filter to each input channel (expanding from 1 channel to\n * `channelMultiplier` channels for each), then concatenates the results\n * together. The output has `inChannels * channelMultiplier` channels.\n *\n * See\n * [https://www.tensorflow.org/api_docs/python/tf/nn/depthwise_conv2d](\n *     https://www.tensorflow.org/api_docs/python/tf/nn/depthwise_conv2d)\n * for more details.\n *\n * @param x The input tensor, of rank 4 or rank 3, of shape\n *     `[batch, height, width, inChannels]`. If rank 3, batch of 1 is\n * assumed.\n * @param filter The filter tensor, rank 4, of shape\n *     `[filterHeight, filterWidth, inChannels, channelMultiplier]`.\n * @param strides The strides of the convolution: `[strideHeight,\n * strideWidth]`. If strides is a single number, then `strideHeight ==\n * strideWidth`.\n * @param pad The type of padding algorithm.\n *   - `same` and stride 1: output will be of same size as input,\n *       regardless of filter size.\n *   - `valid`: output will be smaller than input if filter is larger\n *       than 1x1.\n *   - For more info, see this guide:\n *     [https://www.tensorflow.org/api_guides/python/nn#Convolution](\n *          https://www.tensorflow.org/api_guides/python/nn#Convolution)\n * @param dilations The dilation rates: `[dilationHeight, dilationWidth]`\n *     in which we sample input values across the height and width dimensions\n *     in atrous convolution. Defaults to `[1, 1]`. If `rate` is a single\n *     number, then `dilationHeight == dilationWidth`. If it is greater than\n *     1, then all values of `strides` must be 1.\n * @param dataFormat: An optional string from: \"NHWC\", \"NCHW\". Defaults to\n *     \"NHWC\". Specify the data format of the input and output data. With the\n *     default format \"NHWC\", the data is stored in the order of: [batch,\n *     height, width, channels]. Only \"NHWC\" is currently supported.\n * @param dimRoundingMode The rounding mode used when computing output\n *     dimensions if pad is a number. If none is provided, it will not round\n *     and error if the output is of fractional size.\n *\n * @doc {heading: 'Operations', subheading: 'Convolution'}\n */\nfunction depthwiseConv2d_(x, filter, strides, pad, dataFormat = 'NHWC', dilations = [1, 1], dimRoundingMode) {\n    const $x = convertToTensor(x, 'x', 'depthwiseConv2d');\n    const $filter = convertToTensor(filter, 'filter', 'depthwiseConv2d');\n    let x4D = $x;\n    let reshapedTo4D = false;\n    if ($x.rank === 3) {\n        reshapedTo4D = true;\n        x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);\n    }\n    util.assert(x4D.rank === 4, () => `Error in depthwiseConv2d: input must be rank 4, but got ` +\n        `rank ${x4D.rank}.`);\n    util.assert($filter.rank === 4, () => `Error in depthwiseConv2d: filter must be rank 4, but got rank ` +\n        `${$filter.rank}.`);\n    util.assert(x4D.shape[3] === $filter.shape[2], () => `Error in depthwiseConv2d: number of input channels ` +\n        `(${x4D.shape[3]}) must match the inChannels dimension in ` +\n        `filter ${$filter.shape[2]}.`);\n    if (dimRoundingMode != null) {\n        util.assert(util.isInt(pad), () => `Error in depthwiseConv2d: pad must be an integer when using, ` +\n            `dimRoundingMode ${dimRoundingMode} but got pad ${pad}.`);\n    }\n    const forward = (backend, save) => {\n        if (dilations == null) {\n            dilations = [1, 1];\n        }\n        util.assert(conv_util.eitherStridesOrDilationsAreOne(strides, dilations), () => 'Error in depthwiseConv2d: Either strides or dilations must be ' +\n            `1. Got strides ${strides} and dilations '${dilations}'`);\n        const convInfo = conv_util.computeConv2DInfo(x4D.shape, $filter.shape, strides, dilations, pad, dimRoundingMode, true /* depthwise */);\n        const res = backend.depthwiseConv2D(x4D, $filter, convInfo);\n        save([x4D, $filter]);\n        return res;\n    };\n    const inputs = { x: x4D, filter: $filter };\n    const attrs = { strides, pad, dataFormat, dilations, dimRoundingMode };\n    const res = ENGINE.runKernelFunc(forward, inputs, null /* grad */, DepthwiseConv2dNative, attrs);\n    if (reshapedTo4D) {\n        return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);\n    }\n    return res;\n}\nexport const depthwiseConv2d = op({ depthwiseConv2d_ });\n//# sourceMappingURL=depthwise_conv2d.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Equal } from '../kernel_names';\nimport { makeTypesMatch } from '../tensor_util';\nimport { convertToTensor } from '../tensor_util_env';\nimport { assertAndGetBroadcastShape } from './broadcast_util';\nimport { op } from './operation';\n/**\n * Returns the truth value of (a == b) element-wise. Supports broadcasting.\n *\n * ```js\n * const a = tf.tensor1d([1, 2, 3]);\n * const b = tf.tensor1d([2, 2, 2]);\n *\n * a.equal(b).print();\n * ```\n *\n * @param a The first input tensor.\n * @param b The second input tensor. Must have the same dtype as `a`.\n *\n * @doc {heading: 'Operations', subheading: 'Logical'}\n */\nfunction equal_(a, b) {\n    let $a = convertToTensor(a, 'a', 'equal');\n    let $b = convertToTensor(b, 'b', 'equal');\n    [$a, $b] = makeTypesMatch($a, $b);\n    assertAndGetBroadcastShape($a.shape, $b.shape);\n    const forward = backend => backend.equal($a, $b);\n    const inputs = { a: $a, b: $b };\n    return ENGINE.runKernelFunc(forward, inputs, null, Equal);\n}\nexport const equal = op({ equal_ });\n//# sourceMappingURL=equal.js.map","/**\n * @license\n * Copyright 2020 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { TensorBuffer } from '../tensor';\nimport * as util from '../util';\n/**\n * Creates an empty `tf.TensorBuffer` with the specified `shape` and `dtype`.\n *\n * The values are stored in CPU as `TypedArray`. Fill the buffer using\n * `buffer.set()`, or by modifying directly `buffer.values`.\n *\n * When done, call `buffer.toTensor()` to get an immutable `tf.Tensor` with\n * those values.\n *\n * ```js\n * // Create a buffer and set values at particular indices.\n * const buffer = tf.buffer([2, 2]);\n * buffer.set(3, 0, 0);\n * buffer.set(5, 1, 0);\n *\n * // Convert the buffer back to a tensor.\n * buffer.toTensor().print();\n * ```\n *\n * @param shape An array of integers defining the output tensor shape.\n * @param dtype The dtype of the buffer. Defaults to 'float32'.\n * @param values The values of the buffer as `TypedArray`. Defaults to\n * zeros.\n *\n * @doc {heading: 'Tensors', subheading: 'Creation'}\n */\nexport function buffer(shape, dtype = 'float32', values) {\n    dtype = dtype || 'float32';\n    util.assertNonNegativeIntegerDimensions(shape);\n    return new TensorBuffer(shape, dtype, values);\n}\n//# sourceMappingURL=buffer.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { BatchToSpaceND } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport * as util from '../util';\nimport { op } from './operation';\n/**\n * This operation reshapes the \"batch\" dimension 0 into `M + 1` dimensions of\n * shape `blockShape + [batch]`, interleaves these blocks back into the grid\n * defined by the spatial dimensions `[1, ..., M]`, to obtain a result with\n * the same rank as the input. The spatial dimensions of this intermediate\n * result are then optionally cropped according to `crops` to produce the\n * output. This is the reverse of `tf.spaceToBatchND`. See below for a precise\n * description.\n *\n * ```js\n * const x = tf.tensor4d([1, 2, 3, 4], [4, 1, 1, 1]);\n * const blockShape = [2, 2];\n * const crops = [[0, 0], [0, 0]];\n *\n * x.batchToSpaceND(blockShape, crops).print();\n * ```\n *\n * @param x A `tf.Tensor`. N-D with `x.shape` = `[batch] + spatialShape +\n * remainingShape`, where spatialShape has `M` dimensions.\n * @param blockShape A 1-D array. Must have shape `[M]`, all values must\n * be >= 1.\n * @param crops A 2-D array.  Must have shape `[M, 2]`, all values must be >= 0.\n * `crops[i] = [cropStart, cropEnd]` specifies the amount to crop from input\n * dimension `i + 1`, which corresponds to spatial dimension `i`. It is required\n * that `cropStart[i] + cropEnd[i] <= blockShape[i] * inputShape[i + 1]`\n *\n * This operation is equivalent to the following steps:\n *\n * 1. Reshape `x` to `reshaped` of shape: `[blockShape[0], ...,\n * blockShape[M-1], batch / prod(blockShape), x.shape[1], ...,\n * x.shape[N-1]]`\n *\n * 2. Permute dimensions of `reshaped`to produce `permuted` of shape `[batch /\n * prod(blockShape),x.shape[1], blockShape[0], ..., x.shape[M],\n * blockShape[M-1],x.shape[M+1], ..., x.shape[N-1]]`\n *\n * 3. Reshape `permuted` to produce `reshapedPermuted` of shape `[batch /\n * prod(blockShape),x.shape[1] * blockShape[0], ..., x.shape[M] *\n * blockShape[M-1],x.shape[M+1], ..., x.shape[N-1]]`\n *\n * 4. Crop the start and end of dimensions `[1, ..., M]` of `reshapedPermuted`\n * according to `crops` to produce the output of shape: `[batch /\n * prod(blockShape),x.shape[1] * blockShape[0] - crops[0,0] - crops[0,1],\n * ..., x.shape[M] * blockShape[M-1] - crops[M-1,0] -\n * crops[M-1,1],x.shape[M+1], ..., x.shape[N-1]]`\n *\n * @doc {heading: 'Tensors', subheading: 'Transformations'}\n */\nfunction batchToSpaceND_(x, blockShape, crops) {\n    const $x = convertToTensor(x, 'x', 'batchToSpaceND');\n    const prod = blockShape.reduce((a, b) => a * b);\n    util.assert($x.rank >= 1 + blockShape.length, () => `input rank is ${$x.rank} but should be > than blockShape.length ${blockShape.length}`);\n    util.assert(crops.length === blockShape.length, () => `crops.length is ${crops.length} but should be equal to blockShape.length  ${blockShape.length}`);\n    util.assert($x.shape[0] % prod === 0, () => `input tensor batch is ${$x.shape[0]} but is not divisible by the product of ` +\n        `the elements of blockShape ${blockShape.join(' * ')} === ${prod}`);\n    const forward = backend => {\n        return backend.batchToSpaceND($x, blockShape, crops);\n    };\n    const inputs = { x: $x };\n    const attrs = { blockShape, crops };\n    return ENGINE.runKernelFunc(forward, inputs, null /* gradient */, BatchToSpaceND, attrs);\n}\nexport const batchToSpaceND = op({ batchToSpaceND_ });\n//# sourceMappingURL=batch_to_space_nd.js.map"],"sourceRoot":""}