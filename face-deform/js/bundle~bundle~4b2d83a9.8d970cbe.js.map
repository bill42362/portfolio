{"version":3,"sources":["webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/mul.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/min.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/gather_nd_util.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/floorDiv.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/logical_and.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/greater_equal.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/mean.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/minimum.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/log1p.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/log_sum_exp.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/leaky_relu.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/loss_ops_utils.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/mat_mul.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/fused/conv2d.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/fused/depthwise_conv2d.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/fused/mat_mul.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/image/flip_left_right.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/image/resize_nearest_neighbor.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/image/resize_bilinear.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/image/rotate_with_offset.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/image/crop_and_resize.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/image/non_max_suppression.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/image/non_max_suppression_async.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/image/non_max_suppression_with_score.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/image/non_max_suppression_with_score_async.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/image/non_max_suppression_padded.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/image/non_max_suppression_padded_async.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/image/threshold.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/image/transform.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/linalg/band_part.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/linalg/gram_schmidt.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/linalg/qr.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/losses/absolute_difference.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/losses/cosine_distance.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/losses/hinge_loss.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/losses/huber_loss.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/losses/log_loss.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/losses/mean_squared_error.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/losses/sigmoid_cross_entropy.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/losses/softmax_cross_entropy.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/fused_util.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/losses/compute_weighted_loss.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/neg.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/max.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/log.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/greater.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/imag.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/fill.js","webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/less_equal.js"],"names":["mul","mul_","a","b","$a","$b","inputs","runKernel","min","min_","x","axis","keepDims","attrs","prepareAndValidate","tensor","indices","tensorRank","shape","length","indicesRank","Error","dtype","indicesShape","sliceRank","nResult","i","inputShape","resultShape","slice","pop","sliceSize","push","strides","map","stride","floorDiv","floorDiv_","logicalAnd","logicalAnd_","greaterEqual","greaterEqual_","mean","mean_","minimum","minimum_","log1p","log1p_","logSumExp","logSumExp_","$x","axes","xMax","c","d","res","newShape","leakyRelu","leakyRelu_","alpha","Reduction","matMul","matMul_","transposeA","transposeB","fusedConv2d_","filter","pad","dataFormat","dilations","dimRoundingMode","bias","activation","preluActivationWeights","leakyreluAlpha","state","gradientDepth","result","add","$filter","x4D","reshapedTo4D","rank","reshape","conv_util","convInfo","$bias","$preluActivationWeights","broadcast_util","outShape","grad","dy","saved","y","dyActivation","der","biasDer","save","value","gradFunc","customOp","customOpWithBias","depthwiseConv2d","fusedDepthwiseConv2d_","xDer","filterDer","fusedMatMul_","innerShapeA","innerShapeB","outerShapeA","outerShapeB","outerDimsA","outerDimsB","batchDimA","batchDimB","concat","a3D","b3D","aDer","bDer","flipLeftRight","flipLeftRight_","image","$image","resizeNearestNeighbor","resizeNearestNeighbor_","images","size","alignCorners","halfPixelCenters","$images","batchImages","resizeBilinear","resizeBilinear_","rotateWithOffset","rotateWithOffset_","radians","fillValue","center","cropAndResize","cropAndResize_","boxes","boxInd","cropSize","method","extrapolationValue","$boxes","$boxInd","numBoxes","nonMaxSuppression","nonMaxSuppression_","scores","maxOutputSize","iouThreshold","scoreThreshold","Number","NEGATIVE_INFINITY","$scores","nonMaxSuppressionAsync","async","boxesAndScores","Promise","all","data","boxesVals","scoresVals","selectedIndices","dispose","nonMaxSuppressionWithScore","nonMaxSuppressionWithScore_","softNmsSigma","params","selectedScores","nonMaxSuppressionWithScoreAsync","nonMaxSuppressionPadded","nonMaxSuppressionPadded_","padToMaxOutputSize","validOutputs","nonMaxSuppressionPaddedAsync","$maxOutputSize","$iouThreshold","$scoreThreshold","threshold","threshold_","inverted","threshValue","totalPixelsInImage","r","g","grayscale","$threshold","$r","$g","histogram","total","classFirst","classSecond","meanFirst","meanSec","weightForeground","weightBack","bestThresh","bestInBetVar","cInBetVar","index","meanFirstDivA","meanSecFill","meanSecAdd","meanSecMul","cInBetVarSubA","cInBetVarSubB","cInBetVarMul","condition","otsu","invCondition","transform","transform_","transforms","interpolation","fillMode","outputShape","$transforms","bandPart","bandPart_","numLower","numUpper","M","N","j","ij","inBand","zero","mat","gramSchmidt","gramSchmidt_","xs","inputIsTensor2D","Array","isArray","dim","ys","xs1d","tidy","proj","qr2d","fullMatrices","m","n","q","one2D","w","iters","rTemp","wTemp","qTemp","rjEnd1","normX","rjj","s","u1","wPre","tau","rjEndAll","tauTimesW","wT","rTimesTau","tawTimesWT","qAllJEnd","qTimesTau","qr","qr_","outerDimsProd","reduce","prev","x2ds","q2ds","r2ds","forEach","x2d","q2d","r2d","absoluteDifference","absoluteDifference_","labels","predictions","weights","reduction","SUM_BY_NONZERO_WEIGHTS","$labels","$predictions","$weights","losses","cosineDistance","cosineDistance_","one","hingeLoss","hingeLoss_","huberLoss","huberLoss_","delta","deltaScalar","error","quadratic","linear","logLoss","logLoss_","epsilon","epsilonScalar","l1","l2","meanSquaredError","meanSquaredError_","sigmoidCrossEntropy","sigmoidCrossEntropy_","multiClassLabels","logits","labelSmoothing","$multiClassLabels","$logits","labelSmoothingScalar","half","maxOutput","outputXTarget","sigmoidOutput","sigmoidCrossEntropyWithLogits_","softmaxCrossEntropy","softmaxCrossEntropy_","onehotLabels","$onehotLabels","numClasses","lse","logResult","costVector","dyShape","softmaxCrossEntropyWithLogits_","getFusedDyActivation","getFusedBiasGradient","reduceAxes","applyActivation","shouldFuse","computeWeightedLoss","computeWeightedLoss_","$losses","weightedLoss","NONE","SUM","MEAN","broadcastFactor","broadcastedWeights","numNonZeros","neg","neg_","max","max_","reductionIndices","log","log_","greater","greater_","imag","imag_","input","fill","lessEqual","lessEqual_"],"mappings":";qJAAA,0EAqDO,MAAMA,EAAM,YAAG,CAAEC,KAPxB,SAAcC,EAAGC,GACb,IAAIC,EAAK,YAAgBF,EAAG,IAAK,OAC7BG,EAAK,YAAgBF,EAAG,IAAK,QAChCC,EAAIC,GAAM,YAAeD,EAAIC,GAC9B,MAAMC,EAAS,CAAEJ,EAAGE,EAAID,EAAGE,GAC3B,OAAO,IAAOE,UAAU,KAAUD,O,iCCnDtC,kEAwDO,MAAME,EAAM,YAAG,CAAEC,KAPxB,SAAcC,EAAGC,EAAO,KAAMC,GAAW,GACrC,MACMN,EAAS,CAAEI,EADN,YAAgBA,EAAG,IAAK,QAE7BG,EAAQ,CAAEF,OAAMC,YAEtB,OAAO,IAAOL,UAAU,KAAKD,EAAQO,O,iCCtDzC,qEASO,SAASC,EAAmBC,EAAQC,GACvC,MAAMC,EAAaF,EAAOG,MAAMC,OAC1BC,EAAcJ,EAAQE,MAAMC,OAClC,GAAIF,EAAa,EACb,MAAM,IAAII,MACN,4EAAqBJ,MAE7B,GAAIG,EAAc,EACd,MAAM,IAAIC,MACN,8EAAqBD,MAE7B,GAAsB,UAAlBJ,EAAQM,MACR,MAAM,IAAID,MACN,yEAAsBL,EAAQM,UAEtC,GAAIN,EAAQE,MAAME,EAAc,GAAKH,EACjC,MAAM,IAAII,MACN,iEAAGL,EAAQE,MAAME,EAAc,UAAUH,KAEjD,GAAoC,IAAhC,YAAcF,EAAOG,OACrB,MAAM,IAAIG,MACN,mEAAiBN,EAAOG,UAEhC,MAAMK,EAAeP,EAAQE,MACvBM,EAAYD,EAAaA,EAAaJ,OAAS,GAGrD,IAAIM,EAAU,EACd,IAAK,IAAIC,EAAI,EAAGA,EAAIH,EAAaJ,OAAS,IAAKO,EAC3CD,GAAWF,EAAaG,GAE5B,MAAMC,EAAaZ,EAAOG,MACpBU,EAAcL,EAAaM,QACjCD,EAAYE,MACZ,IAAIC,EAAY,EAChB,IAAK,IAAIL,EAAIF,EAAWE,EAAIT,IAAcS,EACtCK,GAAaJ,EAAWD,GACxBE,EAAYI,KAAKL,EAAWD,IAEhC,MAAMO,EAAU,IAAI,YAAelB,EAAOG,OAAOgB,KAAIC,GAAUA,EAASJ,IACpE,GAAGF,MAAM,EAAGL,GAChB,MAAO,CAACI,EAAaH,EAASM,EAAWE,K,iCClD7C,0EAsDO,MAAMG,EAAW,YAAG,CAAEC,UAP7B,SAAmBnC,EAAGC,GAClB,IAAIC,EAAK,YAAgBF,EAAG,IAAK,YAC7BG,EAAK,YAAgBF,EAAG,IAAK,aAChCC,EAAIC,GAAM,YAAeD,EAAIC,GAC9B,MAAMC,EAAS,CAAEJ,EAAGE,EAAID,EAAGE,GAC3B,OAAO,IAAOE,UAAU,IAAUD,O,iCCpDtC,0EA2CO,MAAMgC,EAAa,YAAG,CAAEC,YAP/B,SAAqBrC,EAAGC,GACpB,MAAMC,EAAK,YAAgBF,EAAG,IAAK,aAAc,QAC3CG,EAAK,YAAgBF,EAAG,IAAK,aAAc,QACjD,YAA2BC,EAAGc,MAAOb,EAAGa,OACxC,MAAMZ,EAAS,CAAEJ,EAAGE,EAAID,EAAGE,GAC3B,OAAO,IAAOE,UAAU,KAAYD,O,iCCzCxC,kFA6CO,MAAMkC,EAAe,YAAG,CAAEC,cARjC,SAAuBvC,EAAGC,GACtB,IAAIC,EAAK,YAAgBF,EAAG,IAAK,eAAgB,qBAC7CG,EAAK,YAAgBF,EAAG,IAAK,eAAgB,sBAChDC,EAAIC,GAAM,YAAeD,EAAIC,GAC9B,YAA2BD,EAAGc,MAAOb,EAAGa,OACxC,MAAMZ,EAAS,CAAEJ,EAAGE,EAAID,EAAGE,GAC3B,OAAO,IAAOE,UAAU,KAAcD,O,iCC3C1C,kEAuDO,MAAMoC,EAAO,YAAG,CAAEC,MANzB,SAAejC,EAAGC,EAAO,KAAMC,GAAW,GACtC,MACMN,EAAS,CAAEI,EADN,YAAgBA,EAAG,IAAK,SAE7BG,EAAQ,CAAEF,OAAMC,YACtB,OAAO,IAAOL,UAAU,KAAMD,EAAQO,O,iCCrD1C,0FA8DO,MAAM+B,EAAU,YAAG,CAAEC,SAZ5B,SAAkB3C,EAAGC,GACjB,IAAIC,EAAK,YAAgBF,EAAG,IAAK,WAC7BG,EAAK,YAAgBF,EAAG,IAAK,YAChCC,EAAIC,GAAM,YAAeD,EAAIC,GACb,SAAbD,EAAGkB,QACHlB,EAAK,YAAKA,EAAI,SACdC,EAAK,YAAKA,EAAI,UAElB,YAA2BD,EAAGc,MAAOb,EAAGa,OACxC,MAAMZ,EAAS,CAAEJ,EAAGE,EAAID,EAAGE,GAC3B,OAAO,IAAOE,UAAU,KAASD,O,iCC5DrC,kEAsCO,MAAMwC,EAAQ,YAAG,CAAEC,OAL1B,SAAgBrC,GACZ,MACMJ,EAAS,CAAEI,EADN,YAAgBA,EAAG,IAAK,UAEnC,OAAO,IAAOH,UAAU,KAAOD,O,iCCpCnC,0HAuEO,MAAM0C,EAAY,YAAG,CAAEC,WAf9B,SAAoBvC,EAAGC,EAAO,KAAMC,GAAW,GAC3C,MAAMsC,EAAK,YAAgBxC,EAAG,IAAK,aAC7ByC,EAAO,YAAexC,EAAMuC,EAAGhC,OAC/BkC,EAAO,YAAIF,EAAIC,GAAM,GACrBjD,EAAI,YAAIgD,EAAIE,GACZjD,EAAI,YAAID,GACRmD,EAAI,YAAIlD,EAAGgD,GACXG,EAAI,YAAID,GACRE,EAAM,YAAI,YAAQH,EAAME,EAAEpC,OAAQoC,GACxC,GAAI1C,EAAU,CACV,MAAM4C,EAAW,YAAqBD,EAAIrC,MAAOiC,GACjD,OAAO,YAAQI,EAAKC,GAExB,OAAOD,M,iCCrEX,kEA2CO,MAAME,EAAY,YAAG,CAAEC,WAN9B,SAAoBhD,EAAGiD,EAAQ,IAC3B,MACMrD,EAAS,CAAEI,EADN,YAAgBA,EAAG,IAAK,cAE7BG,EAAQ,CAAE8C,SAChB,OAAO,IAAOpD,UAAU,KAAWD,EAAQO,O,gCCzBxC,IAAI+C,EAhBX,kCAiBA,SAAWA,GACPA,EAAUA,EAAgB,KAAI,GAAK,OACnCA,EAAUA,EAAgB,KAAI,GAAK,OACnCA,EAAUA,EAAe,IAAI,GAAK,MAClCA,EAAUA,EAAkC,uBAAI,GAAK,yBAJzD,CAKGA,IAAcA,EAAY,M,gCCtB7B,0EA6CO,MAAMC,EAAS,YAAG,CAAEC,QAR3B,SAAiB5D,EAAGC,EAAG4D,GAAa,EAAOC,GAAa,GACpD,IAAI5D,EAAK,YAAgBF,EAAG,IAAK,UAC7BG,EAAK,YAAgBF,EAAG,IAAK,WAChCC,EAAIC,GAAM,YAAeD,EAAIC,GAC9B,MAAMC,EAAS,CAAEJ,EAAGE,EAAID,EAAGE,GACrBQ,EAAQ,CAAEkD,aAAYC,cAC5B,OAAO,IAAOzD,UAAU,IAAaD,EAAQO,O,+RCiJ1C,MAAM,EAAS,YAAG,CAAEoD,aApG3B,UAAsB,EAAEvD,EAAC,OAAEwD,EAAM,QAAEjC,EAAO,IAAEkC,EAAG,WAAEC,EAAa,OAAM,UAAEC,EAAY,CAAC,EAAG,GAAE,gBAAEC,EAAe,KAAEC,EAAI,WAAEC,EAAa,SAAQ,uBAAEC,EAAsB,eAAEC,IAE5J,GADAF,EAAaA,GAAc,UACgC,IAAvD,YAAW,IAAOG,MAAMC,cAAeJ,GAAuB,CAC9D,IAAIK,EAAS,YAAcnE,EAAGwD,EAAQjC,EAASkC,EAAKC,EAAYC,EAAWC,GAI3E,OAHY,MAARC,IACAM,EAAS,OAAAC,EAAA,GAAID,EAAQN,IAElB,YAAgBM,EAAQL,EAAYC,EAAwBC,GAEvE,MAAMxB,EAAK,YAAgBxC,EAAG,IAAK,UAC7BqE,EAAU,YAAgBb,EAAQ,SAAU,UAClD,IAAIc,EAAM9B,EACN+B,GAAe,EACH,IAAZ/B,EAAGgC,OACHD,GAAe,EACfD,EAAM,OAAAG,EAAA,GAAQjC,EAAI,CAAC,EAAGA,EAAGhC,MAAM,GAAIgC,EAAGhC,MAAM,GAAIgC,EAAGhC,MAAM,MAE7D,IAAyB,IAAb8D,EAAIE,MAAY,IACxB,6DAAGF,EAAIE,UACX,IAA6B,IAAjBH,EAAQG,MAAY,IAC5B,8DAAGH,EAAQG,UACQ,MAAnBZ,GACA,IAAY,IAAWH,IAAM,IACzB,6EAAmBG,iBAA+BH,OAE1D,IAAYa,EAAI9D,MAAM,KAAO6D,EAAQ7D,MAAM,IAAI,IAAM,oCAAoC8D,EAAI9D,MAAM,yCACrE6D,EAAQ7D,MAAM,QAC5C,IAAYkE,EAAA,EAAyCnD,EAASoC,IAAY,IACtE,uEAAepC,oBAA0BoC,OAC7C,IAA2B,SAAfD,GAAuB,IAAM,sCAAsCA,4CAC/E,MAAMiB,EAAWD,EAAA,EAA4BJ,EAAI9D,MAAO6D,EAAQ7D,MAAOe,EAASoC,EAAWF,EAAKG,GAChG,IAAIgB,EAMAC,EALQ,MAARhB,IACAe,EAAQ,YAAgBf,EAAM,OAAQ,iBACrCe,GAAS,YAAeA,EAAOpC,GAChCsC,EAAA,EAA0CH,EAASI,SAAUH,EAAMpE,QAGzC,MAA1BuD,IACAc,EAA0B,YAAgBd,EAAwB,gBAAiB,iBAEvF,MAAMiB,EAAO,CAACC,EAAIC,KACd,MAAOb,EAASC,EAAKa,EAAGP,GAASM,EAC3BE,EAAe,YAAqBH,EAAIE,EAAGrB,GACjD,IAAYY,EAAA,EAA4Bf,IAAY,IAEhD,uHAAsDA,OAC1D,MAEM0B,EAAM,CAFC,YAAoBf,EAAI9D,MAAO4E,EAAcf,EAAS9C,EAASkC,GAC1D,YAAqBa,EAAKc,EAAcf,EAAQ7D,MAAOe,EAASkC,IAElF,GAAa,MAATmB,EAAe,CACf,MAAMU,EAAU,YAAqBV,EAAOQ,GAC5CC,EAAI/D,KAAKgE,GAEb,OAAOD,GAELzF,EAAS,CACXI,EAAGsE,EACHd,OAAQa,EACRR,KAAMe,EACNb,uBAAwBc,GAEtB1E,EAAQ,CACVoB,UACAkC,MACAC,aACAC,YACAC,kBACAE,aACAE,kBAIJ,GAAY,MAARH,EAAc,CAYd,OAXiB,aAAW,CAACS,EAAKd,EAAQ+B,KACtC,IAAI1C,EAEJ,IAAOhD,UAAU,KAAaD,EAAQO,GAMtC,OALAoF,EAAK,CAAC/B,EAAQc,EAAKzB,IACf0B,IAEA1B,EAAM,OAAA4B,EAAA,GAAQ5B,EAAK,CAACA,EAAIrC,MAAM,GAAIqC,EAAIrC,MAAM,GAAIqC,EAAIrC,MAAM,MAEvD,CAAEgF,MAAO3C,EAAK4C,SAAUT,KAE5BU,CAASpB,EAAKD,GAYrB,OATyB,aAAW,CAACC,EAAKd,EAAQK,EAAM0B,KACpD,IAAI1C,EAAM,IAAOhD,UAAU,KAAaD,EAAQO,GAMhD,OALAoF,EAAK,CAAC/B,EAAQc,EAAKzB,EAAKgB,IACpBU,IAEA1B,EAAM,OAAA4B,EAAA,GAAQ5B,EAAK,CAACA,EAAIrC,MAAM,GAAIqC,EAAIrC,MAAM,GAAIqC,EAAIrC,MAAM,MAEvD,CAAEgF,MAAO3C,EAAK4C,SAAUT,KAE5BW,CAAiBrB,EAAKD,EAASO,M,+BCFvC,MAAMgB,EAAkB,YAAG,CAAEC,sBArGpC,UAA+B,EAAE7F,EAAC,OAAEwD,EAAM,QAAEjC,EAAO,IAAEkC,EAAG,WAAEC,EAAa,OAAM,UAAEC,EAAY,CAAC,EAAG,GAAE,gBAAEC,EAAe,KAAEC,EAAI,WAAEC,EAAa,SAAQ,uBAAEC,EAAsB,eAAEC,IACrK,IAA2D,IAAvD,YAAW,IAAOC,MAAMC,cAAeJ,GAAuB,CAC9D,IAAIK,EAAS,YAAuBnE,EAAGwD,EAAQjC,EAASkC,EAAKC,EAAYC,EAAWC,GAIpF,OAHY,MAARC,IACAM,EAAS,OAAAC,EAAA,GAAID,EAAQN,IAElB,YAAgBM,EAAQL,EAAYC,EAAwBC,GAEvE,MAAMxB,EAAK,YAAgBxC,EAAG,IAAK,mBAC7BqE,EAAU,YAAgBb,EAAQ,SAAU,mBAClD,IAAIc,EAAM9B,EACN+B,GAAe,EACH,IAAZ/B,EAAGgC,OACHD,GAAe,EACfD,EAAM,OAAAG,EAAA,GAAQjC,EAAI,CAAC,EAAGA,EAAGhC,MAAM,GAAIgC,EAAGhC,MAAM,GAAIgC,EAAGhC,MAAM,MAE7D,IAAyB,IAAb8D,EAAIE,MAAY,IACxB,sEAAQF,EAAIE,UAChB,IAA6B,IAAjBH,EAAQG,MAAY,IAC5B,uEAAgBH,EAAQG,UAC5B,IAAYF,EAAI9D,MAAM,KAAO6D,EAAQ7D,MAAM,IAAI,IAC3C,6DAAI8D,EAAI9D,MAAM,qDACJ6D,EAAQ7D,MAAM,QACX,MAAbmD,IACAA,EAAY,CAAC,EAAG,IAEpB,IAAYe,EAAA,EAAyCnD,EAASoC,IAAY,IACtE,sFAAqBpC,oBAA0BoC,OAC5B,MAAnBC,GACA,IAAY,IAAWH,IAAM,IACzB,qFAAyBG,iBAA+BH,OAEhE,MAAMkB,EAAWD,EAAA,EAA4BJ,EAAI9D,MAAO6D,EAAQ7D,MAAOe,EAASoC,EAAWF,EAAKG,GAAiB,GACjH,IAAIgB,EAMAC,EALQ,MAARhB,IACAe,EAAQ,YAAgBf,EAAM,OAAQ,iBACrCe,GAAS,YAAeA,EAAOpC,GAChCsC,EAAA,EAA0CH,EAASI,SAAUH,EAAMpE,QAGzC,MAA1BuD,IACAc,EAA0B,YAAgBd,EAAwB,gBAAiB,0BAEvF,MAAMiB,EAAO,CAACC,EAAIC,KACd,IAAYR,EAAA,EAA4Bf,IAAY,IAEhD,mHAAIA,OACR,MAAOU,EAASC,EAAKa,EAAGtB,GAAQqB,EAC1BE,EAAe,YAAqBH,EAAIE,EAAGrB,GAC3CgC,EAAO,YAAmCxB,EAAI9D,MAAO4E,EAAcf,EAAS9C,EAASkC,EAAKE,EAAWC,GACrGmC,EAAY,YAAoCzB,EAAKc,EAAcf,EAAQ7D,MAAOe,EAASkC,EAAKE,EAAWC,GACjH,GAAY,MAARC,EAAc,CAEd,MAAO,CAACiC,EAAMC,EADE,YAAqBnB,EAAOQ,IAGhD,MAAO,CAACU,EAAMC,IAEZnG,EAAS,CACXI,EAAGsE,EACHd,OAAQa,EACRR,KAAMe,EACNb,uBAAwBc,GAEtB1E,EAAQ,CACVoB,UACAkC,MACAC,aACAC,YACAC,kBACAE,aACAE,kBAIJ,GAAY,MAARH,EAAc,CAWd,OAViB,aAAW,CAACS,EAAKd,EAAQ+B,KAEtC,IAAI1C,EAAM,IAAOhD,UAAU,KAAsBD,EAAQO,GAMzD,OALAoF,EAAK,CAAC/B,EAAQc,EAAKzB,IACf0B,IAEA1B,EAAM,OAAA4B,EAAA,GAAQ5B,EAAK,CAACA,EAAIrC,MAAM,GAAIqC,EAAIrC,MAAM,GAAIqC,EAAIrC,MAAM,MAEvD,CAAEgF,MAAO3C,EAAK4C,SAAUT,KAE5BU,CAASpB,EAAKD,GAarB,OAVyB,aAAW,CAACC,EAAKd,EAAQK,EAAM0B,KAEpD,IAAI1C,EAAM,IAAOhD,UAAU,KAAsBD,EAAQO,GAMzD,OALAoF,EAAK,CAAC/B,EAAQc,EAAKzB,EAAKgB,IACpBU,IAEA1B,EAAM,OAAA4B,EAAA,GAAQ5B,EAAK,CAACA,EAAIrC,MAAM,GAAIqC,EAAIrC,MAAM,GAAIqC,EAAIrC,MAAM,MAEvD,CAAEgF,MAAO3C,EAAK4C,SAAUT,KAE5BW,CAAiBrB,EAAKD,EAASO,M,YCxBvC,MAAMzB,EAAS,YAAG,CAAE6C,aA3G3B,UAAsB,EAAExG,EAAC,EAAEC,EAAC,WAAE4D,GAAa,EAAK,WAAEC,GAAa,EAAK,KAAEO,EAAI,WAAEC,EAAa,SAAQ,uBAAEC,EAAsB,eAAEC,IACvH,IAA2D,IAAvD,YAAW,IAAOC,MAAMC,cAAeJ,GAAuB,CAC9D,IAAIK,EAAS,YAAc3E,EAAGC,EAAG4D,EAAYC,GAI7C,OAHY,MAARO,IACAM,EAAS,OAAAC,EAAA,GAAID,EAAQN,IAElB,YAAgBM,EAAQL,EAAYC,EAAwBC,GAEvE,IAAItE,EAAK,YAAgBF,EAAG,IAAK,gBAC7BG,EAAK,YAAgBF,EAAG,IAAK,iBAChCC,EAAIC,GAAM,YAAeD,EAAIC,GAC9B,MAAMsG,EAAc5C,EAAa3D,EAAGc,MAAMd,EAAG8E,KAAO,GAAK9E,EAAGc,MAAMd,EAAG8E,KAAO,GACtE0B,EAAc5C,EAAa3D,EAAGa,MAAMb,EAAG6E,KAAO,GAAK7E,EAAGa,MAAMb,EAAG6E,KAAO,GACtE2B,EAAc9C,EAAa3D,EAAGc,MAAMd,EAAG8E,KAAO,GAAK9E,EAAGc,MAAMd,EAAG8E,KAAO,GACtE4B,EAAc9C,EAAa3D,EAAGa,MAAMb,EAAG6E,KAAO,GAAK7E,EAAGa,MAAMb,EAAG6E,KAAO,GACtE6B,EAAa3G,EAAGc,MAAMW,MAAM,GAAI,GAChCmF,EAAa3G,EAAGa,MAAMW,MAAM,GAAI,GAChCoF,EAAY,IAAmBF,GAC/BG,EAAY,IAAmBF,GACrC,IAAY5G,EAAG8E,MAAQ,GAAK7E,EAAG6E,MAAQ,GAAK9E,EAAG8E,OAAS7E,EAAG6E,MAAM,IAC7D,kFAAsB9E,EAAG8E,YAAY7E,EAAG6E,UAC5C,IAAY,IAAiB6B,EAAYC,IAAa,IAAM,4CAA4CD,WACjGC,6BAAsC5G,EAAGc,aACzCb,EAAGa,sBACV,IAAYyF,IAAgBC,GAAa,IAAM,wCAAwCD,WAChFC,6BAAuCxG,EAAGc,aAC1Cb,EAAGa,wBAAwB6C,oBACXC,kBACvB,MAAMyB,EAAWrF,EAAGc,MAAMW,MAAM,GAAI,GAAGsF,OAAO,CAACN,EAAaC,IACtDM,EAAMrD,EACR,OAAAoB,EAAA,GAAQ/E,EAAI,CAAC6G,EAAWN,EAAaE,IACrC,OAAA1B,EAAA,GAAQ/E,EAAI,CAAC6G,EAAWJ,EAAaF,IACnCU,EAAMrD,EACR,OAAAmB,EAAA,GAAQ9E,EAAI,CAAC6G,EAAWJ,EAAaF,IACrC,OAAAzB,EAAA,GAAQ9E,EAAI,CAAC6G,EAAWN,EAAaE,IACzC,IAAIxB,EAMAC,EALQ,MAARhB,IACAe,EAAQ,YAAgBf,EAAM,OAAQ,iBACrCe,GAAS,YAAeA,EAAOlF,GAChCoF,EAAA,EAA0CC,EAAUH,EAAMpE,QAGhC,MAA1BuD,IACAc,EAA0B,YAAgBd,EAAwB,gBAAiB,iBAEvF,MAAMiB,EAAO,CAACC,EAAIC,KACd,MAAOwB,EAAKC,EAAKxB,EAAGP,GAASM,EAIvBE,EAAe,YAAqB,OAAAX,EAAA,GAAQQ,EAAIE,EAAE3E,OAAQ2E,EAAGrB,GACnE,IAAI8C,EACAC,EAiBJ,GAhBKxD,GAAeC,GAIVD,GAAcC,GACpBsD,EAAO,YAAcxB,EAAcuB,GAAK,GAAO,GAC/CE,EAAO,YAAczB,EAAcsB,GAAK,GAAM,IAEzCrD,IAAeC,GACpBsD,EAAO,YAAcD,EAAKvB,GAAc,GAAO,GAC/CyB,EAAO,YAAcH,EAAKtB,GAAc,GAAO,KAG/CwB,EAAO,YAAcD,EAAKvB,GAAc,GAAM,GAC9CyB,EAAO,YAAczB,EAAcsB,GAAK,GAAM,KAb9CE,EAAO,YAAcxB,EAAcuB,GAAK,GAAO,GAC/CE,EAAO,YAAcH,EAAKtB,GAAc,GAAM,IActC,MAARvB,EAAc,CAEd,MAAO,CAAC+C,EAAMC,EADE,YAAqBjC,EAAOQ,IAI5C,MAAO,CAACwB,EAAMC,IAGhBjH,EAAS,CACXJ,EAAGkH,EACHjH,EAAGkH,EACH9C,KAAMe,EACNb,uBAAwBc,GAEtB1E,EAAQ,CAAEkD,aAAYC,aAAYQ,aAAYE,kBAGpD,GAAY,MAARH,EAAc,CAQd,OAPiB,aAAW,CAAC6C,EAAKC,EAAKpB,KACnC,MAAM1C,EAEN,IAAOhD,UAAU,KAAcD,EAAQO,GAEvC,OADAoF,EAAK,CAACmB,EAAKC,EAAK9D,IACT,CAAE2C,MAAO,OAAAf,EAAA,GAAQ5B,EAAKkC,GAAWU,SAAUT,KAE/CU,CAASgB,EAAKC,GAUrB,OAPyB,aAAW,CAACD,EAAKC,EAAK/B,EAAOW,KAClD,MAAM1C,EAEN,IAAOhD,UAAU,KAAcD,EAAQO,GAEvC,OADAoF,EAAK,CAACmB,EAAKC,EAAK9D,EAAK+B,IACd,CAAEY,MAAO,OAAAf,EAAA,GAAQ5B,EAAKkC,GAAWU,SAAUT,KAE/CW,CAAiBe,EAAKC,EAAK/B,O,iCCzJ1C,yEAoCO,MAAMkC,EAAgB,YAAG,CAAEC,eARlC,SAAwBC,GACpB,MAAMC,EAAS,YAAgBD,EAAO,QAAS,gBAAiB,WAChE,IAA4B,IAAhBC,EAAOzC,MAAY,IAC3B,6DAAgByC,EAAOzC,UAC3B,MAAM5E,EAAS,CAAEoH,MAAOC,GAExB,OADY,IAAOpH,UAAU,IAAeD,EAAQ,Q,iCCjCxD,gFAiEO,MAAMsH,EAAwB,YAAG,CAAEC,uBAzB1C,SAAgCC,EAAQC,EAAMC,GAAe,EAAOC,GAAmB,GACnF,MAAMC,EAAU,YAAgBJ,EAAQ,SAAU,yBAClD,IAA6B,IAAjBI,EAAQhD,MAA+B,IAAjBgD,EAAQhD,MAAY,IAClD,uEAAQgD,EAAQhD,UACpB,IAA4B,IAAhB6C,EAAK5G,QAAc,IAC3B,oEAAG4G,OACP,IAA8B,YAAlBG,EAAQ5G,OAAyC,UAAlB4G,EAAQ5G,OAAmB,IAAM,qDAC5E,KAAiC,IAArB2G,IAA+C,IAAjBD,GAAwB,IAAM,6FAExE,IAAIG,EAAcD,EACdjD,GAAe,EACE,IAAjBiD,EAAQhD,OACRD,GAAe,EACfkD,EAAc,YAAQD,EAAS,CAAC,EAAGA,EAAQhH,MAAM,GAAIgH,EAAQhH,MAAM,GAAIgH,EAAQhH,MAAM,MAEzF,QAAW6G,EACLzH,EAAS,CAAEwH,OAAQK,GACnBtH,EAAQ,CAAEmH,eAAcC,mBAAkBF,QAE1CxE,EAAM,IAAOhD,UAAU,KAAuBD,EAAQO,GAC5D,OAAIoE,EACO,YAAQ1B,EAAK,CAACA,EAAIrC,MAAM,GAAIqC,EAAIrC,MAAM,GAAIqC,EAAIrC,MAAM,KAExDqC,M,iCC/DX,gFA+DO,MAAM6E,EAAiB,YAAG,CAAEC,gBAxBnC,SAAyBP,EAAQC,EAAMC,GAAe,EAAOC,GAAmB,GAC5E,MAAMC,EAAU,YAAgBJ,EAAQ,SAAU,kBAClD,IAA6B,IAAjBI,EAAQhD,MAA+B,IAAjBgD,EAAQhD,MAAY,IAClD,gEAAQgD,EAAQhD,UACpB,IAA4B,IAAhB6C,EAAK5G,QAAc,IAC3B,6DAAG4G,OACP,KAAiC,IAArBE,IAA+C,IAAjBD,GAAwB,IAAM,sFAExE,IAAIG,EAAcD,EACdjD,GAAe,EACE,IAAjBiD,EAAQhD,OACRD,GAAe,EACfkD,EAAc,YAAQD,EAAS,CAAC,EAAGA,EAAQhH,MAAM,GAAIgH,EAAQhH,MAAM,GAAIgH,EAAQhH,MAAM,MAEzF,QAAW6G,EACLzH,EAAS,CAAEwH,OAAQK,GACnBtH,EAAQ,CAAEmH,eAAcC,mBAAkBF,QAE1CxE,EAAM,IAAOhD,UAAU,KAAgBD,EAAQO,GACrD,OAAIoE,EACO,YAAQ1B,EAAK,CAACA,EAAIrC,MAAM,GAAIqC,EAAIrC,MAAM,GAAIqC,EAAIrC,MAAM,KAExDqC,M,iCC7DX,yEA8CO,MAAM+E,EAAmB,YAAG,CAAEC,kBATrC,SAA2Bb,EAAOc,EAASC,EAAY,EAAGC,EAAS,IAC/D,MAAMf,EAAS,YAAgBD,EAAO,QAAS,mBAAoB,WACnE,IAA4B,IAAhBC,EAAOzC,MAAY,IAC3B,gEAAgByC,EAAOzC,UAC3B,MAAM5E,EAAS,CAAEoH,MAAOC,GAClB9G,EAAQ,CAAE2H,UAASC,YAAWC,UAEpC,OADY,IAAOnI,UAAU,KAAkBD,EAAQO,O,iCC3C3D,yEAgEO,MAAM8H,EAAgB,YAAG,CAAEC,eApBlC,SAAwBlB,EAAOmB,EAAOC,EAAQC,EAAUC,EAAS,WAAYC,EAAqB,GAC9F,MAAMtB,EAAS,YAAgBD,EAAO,QAAS,iBACzCwB,EAAS,YAAgBL,EAAO,QAAS,gBAAiB,WAC1DM,EAAU,YAAgBL,EAAQ,SAAU,gBAAiB,SAC7DM,EAAWF,EAAOhI,MAAM,GAC9B,IAA4B,IAAhByG,EAAOzC,MAAY,IAC3B,6DAAgByC,EAAOzC,UAC3B,IAA4B,IAAhBgE,EAAOhE,MAAkC,IAApBgE,EAAOhI,MAAM,IAAU,IAAM,oDAAoDkI,sBAC7FF,EAAOhI,WAC5B,IAA6B,IAAjBiI,EAAQjE,MAAciE,EAAQjI,MAAM,KAAOkI,GAAU,IAAM,qDAAqDA,oBACvGF,EAAOhI,WAC5B,IAAgC,IAApB6H,EAAS5H,QAAc,IAC/B,wEAAU4H,EAAS5H,YACvB,IAAY4H,EAAS,IAAM,GAAKA,EAAS,IAAM,GAAG,IAAM,2CAA2CA,MACnG,IAAuB,aAAXC,GAAoC,YAAXA,GAAsB,IAAM,+CAA+CA,MAChH,MAAM1I,EAAS,CAAEoH,MAAOC,EAAQkB,MAAOK,EAAQJ,OAAQK,GACjDtI,EAAQ,CAAEmI,SAAQC,qBAAoBF,YAE5C,OADY,IAAOxI,UAAU,IAAeD,EAAQO,O,iCC7DxD,0EAiDO,MAAMwI,EAAoB,YAAG,CAAEC,mBAVtC,SAA4BT,EAAOU,EAAQC,EAAeC,EAAe,GAAKC,EAAiBC,OAAOC,mBAClG,MAAMV,EAAS,YAAgBL,EAAO,QAAS,qBACzCgB,EAAU,YAAgBN,EAAQ,SAAU,qBAC5CjJ,EAAS,YAAsB4I,EAAQW,EAASL,EAAeC,EAAcC,GAI7E7I,EAAQ,CAAE2I,cAHhBA,EAAgBlJ,EAAOkJ,cAGQC,aAF/BA,EAAenJ,EAAOmJ,aAEuBC,eAD7CA,EAAiBpJ,EAAOoJ,gBAExB,OAAO,IAAOnJ,UAAU,KAAqB,CAAEsI,MAAOK,EAAQK,OAAQM,GAAWhJ,O,iCC/CrF,qEA8DO,MAAMiJ,EAtBbC,eAAuClB,EAAOU,EAAQC,EAAeC,EAAe,GAAKC,EAAiBC,OAAOC,mBAC7G,MAAMV,EAAS,YAAgBL,EAAO,QAAS,0BACzCgB,EAAU,YAAgBN,EAAQ,SAAU,0BAC5CjJ,EAAS,YAAsB4I,EAAQW,EAASL,EAAeC,EAAcC,GACnFF,EAAgBlJ,EAAOkJ,cACvBC,EAAenJ,EAAOmJ,aACtBC,EAAiBpJ,EAAOoJ,eACxB,MAAMM,QAAuBC,QAAQC,IAAI,CAAChB,EAAOiB,OAAQN,EAAQM,SAC3DC,EAAYJ,EAAe,GAC3BK,EAAaL,EAAe,IAI5B,gBAAEM,GAAoB,YAAwBF,EAAWC,EAAYb,EAAeC,EAAcC,GAOxG,OANIR,IAAWL,GACXK,EAAOqB,UAEPV,IAAYN,GACZM,EAAQU,UAEL,YAASD,EAAiB,W,iCC5DrC,0EAgEO,MAAME,EAA6B,YAAG,CAAEC,4BAd/C,SAAqC5B,EAAOU,EAAQC,EAAeC,EAAe,GAAKC,EAAiBC,OAAOC,kBAAmBc,EAAe,GAC7I,MAAMxB,EAAS,YAAgBL,EAAO,QAAS,qBACzCgB,EAAU,YAAgBN,EAAQ,SAAU,qBAC5CoB,EAAS,YAAsBzB,EAAQW,EAASL,EAAeC,EAAcC,EAAgBgB,GAK7FpK,EAAS,CAAEuI,MAAOK,EAAQK,OAAQM,GAClChJ,EAAQ,CAAE2I,cALhBA,EAAgBmB,EAAOnB,cAKQC,aAJ/BA,EAAekB,EAAOlB,aAIuBC,eAH7CA,EAAiBiB,EAAOjB,eAGqCgB,aAF7DA,EAAeC,EAAOD,cAIhB7F,EAAS,IAAOtE,UAAU,KAAqBD,EAAQO,GAC7D,MAAO,CAAEyJ,gBAAiBzF,EAAO,GAAI+F,eAAgB/F,EAAO,Q,iCC9DhE,qEA2EO,MAAMgG,EA1Bbd,eAAgDlB,EAAOU,EAAQC,EAAeC,EAAe,GAAKC,EAAiBC,OAAOC,kBAAmBc,EAAe,GACxJ,MAAMxB,EAAS,YAAgBL,EAAO,QAAS,0BACzCgB,EAAU,YAAgBN,EAAQ,SAAU,0BAC5CoB,EAAS,YAAsBzB,EAAQW,EAASL,EAAeC,EAAcC,EAAgBgB,GACnGlB,EAAgBmB,EAAOnB,cACvBC,EAAekB,EAAOlB,aACtBC,EAAiBiB,EAAOjB,eACxBgB,EAAeC,EAAOD,aACtB,MAAMV,QAAuBC,QAAQC,IAAI,CAAChB,EAAOiB,OAAQN,EAAQM,SAC3DC,EAAYJ,EAAe,GAC3BK,EAAaL,EAAe,IAI5B,gBAAEM,EAAe,eAAEM,GAAmB,YAAwBR,EAAWC,EAAYb,EAAeC,EAAcC,EAAgBgB,GAOxI,OANIxB,IAAWL,GACXK,EAAOqB,UAEPV,IAAYN,GACZM,EAAQU,UAEL,CACHD,gBAAiB,YAASA,EAAiB,SAC3CM,eAAgB,YAASA,M,iCCxEjC,0EA8DO,MAAME,EAA0B,YAAG,CAAEC,yBAlB5C,SAAkClC,EAAOU,EAAQC,EAAeC,EAAe,GAAKC,EAAiBC,OAAOC,kBAAmBoB,GAAqB,GAChJ,MAAM9B,EAAS,YAAgBL,EAAO,QAAS,qBACzCgB,EAAU,YAAgBN,EAAQ,SAAU,qBAC5CoB,EAAS,YAAsBzB,EAAQW,EAASL,EAAeC,EAAcC,EAAgB,MAI7FpJ,EAAS,CAAEuI,MAAOK,EAAQK,OAAQM,GAClChJ,EAAQ,CACV2I,cALmBmB,EAAOnB,cAM1BC,aALkBkB,EAAOlB,aAMzBC,eALoBiB,EAAOjB,eAM3BsB,sBAGEnG,EAAS,IAAOtE,UAAU,KAAqBD,EAAQO,GAC7D,MAAO,CAAEyJ,gBAAiBzF,EAAO,GAAIoG,aAAcpG,EAAO,Q,iCC5D9D,6EAmEO,MAAMqG,EAvBbnB,eAA6ClB,EAAOU,EAAQC,EAAeC,EAAe,GAAKC,EAAiBC,OAAOC,kBAAmBoB,GAAqB,GAC3J,MAAM9B,EAAS,YAAgBL,EAAO,QAAS,0BACzCgB,EAAU,YAAgBN,EAAQ,SAAU,0BAC5CoB,EAAS,YAAsBzB,EAAQW,EAASL,EAAeC,EAAcC,EAAgB,MAC7FyB,EAAiBR,EAAOnB,cACxB4B,EAAgBT,EAAOlB,aACvB4B,EAAkBV,EAAOjB,gBACxBU,EAAWC,SAAoBJ,QAAQC,IAAI,CAAChB,EAAOiB,OAAQN,EAAQM,UAIpE,gBAAEG,EAAe,aAAEW,GAAiB,YAAwBb,EAAWC,EAAYc,EAAgBC,EAAeC,EAAiBL,GAOzI,OANI9B,IAAWL,GACXK,EAAOqB,UAEPV,IAAYN,GACZM,EAAQU,UAEL,CACHD,gBAAiB,YAASA,EAAiB,SAC3CW,aAAc,YAAOA,EAAc,Y,iCChE3C,qMAkHO,MAAMK,EAAY,YAAG,CAAEC,WA/D9B,SAAoB7D,EAAOsB,EAAS,SAAUwC,GAAW,EAAOC,EAAc,IAC1E,MAAM9D,EAAS,YAAgBD,EAAO,QAAS,aAMzCgE,EAAqB/D,EAAOzG,MAAM,GAAKyG,EAAOzG,MAAM,GAC1D,IACIyK,EAAGC,EAAGzL,EAAG0L,EADTC,EAAa,YAAI,YAAS,CAACL,IAAe,KAU9C,GARA,IAA4B,IAAhB9D,EAAOzC,MAAY,IAC3B,yDAAgByC,EAAOzC,UAC3B,IAAgC,IAApByC,EAAOzG,MAAM,IAAgC,IAApByG,EAAOzG,MAAM,IAAU,IAExD,0EAAWyG,EAAOzG,MAAM,QAC5B,IAA6B,UAAjByG,EAAOrG,OAAsC,YAAjBqG,EAAOrG,OAAqB,IAChE,sEAAiBqG,EAAOrG,WAC5B,IAAuB,SAAX0H,GAAgC,WAAXA,GAAqB,IAAM,0CAA0CA,MAC9E,IAApBrB,EAAOzG,MAAM,GAAU,EACtByK,EAAGC,EAAGzL,GAAK,YAAMwH,EAAQ,CAAC,EAAG,EAAG,IAAK,GACtC,MAAMoE,EAAK,YAAIJ,EAhBQ,OAiBjBK,EAAK,YAAIJ,EAhBU,MAiBnBvL,EAAK,YAAIF,EAhBS,MAiBxB0L,EAAY,YAAI,YAAIE,EAAIC,GAAK3L,QAG7BwL,EAAYnE,EAEhB,GAAe,SAAXsB,EAAmB,CAEnB8C,EAOR,SAAcG,EAAWC,GACrB,IAGIC,EAAYC,EAAaC,EAAWC,EAASC,EAAkBC,EAH/DC,EAAa,YAAS,EAAE,IACxBC,EAAe,YAAS,CAAC,IACzBC,EAAY,YAAS,CAAC,IAE1B,IAAK,IAAIC,EAAQ,EAAGA,EAAQX,EAAUlE,KAAO,EAAG6E,IAAS,CACrDT,EAAa,YAAMF,EAAW,EAAGW,EAAQ,GACzCR,EAAc,YAAMH,EAAWW,EAAQ,GACvCL,EAAmB,YAAI,YAAIJ,GAAaD,GACxCM,EAAa,YAAI,YAAIJ,GAAcF,GACnC,MAAMW,EAAgB,YAAI,YAAIV,EAAY,YAAM,EAAGA,EAAWpE,QAC9DsE,EAAY,YAAIQ,EAAe,YAAIV,IACnC,MAAMW,EAAc,YAAKV,EAAYlL,MAAOiL,EAAWpE,MACjDgF,EAAa,YAAI,YAAM,EAAGX,EAAYrE,MAAO+E,GAC7CE,EAAa,YAAIZ,EAAa,GACpCE,EAAU,YAAI,YAAIU,GAAa,YAAIZ,IACnC,MAAMa,EAAgB,YAAIZ,EAAWC,GAC/BY,EAAgB,YAAIb,EAAWC,GAC/Ba,EAAe,YAAIZ,EAAkBC,GAC3CG,EAAY,YAAI,YAAIQ,EAAcF,GAAgBC,GAClD,MAAME,EAAY,YAAQT,EAAWD,GACrCA,EAAe,YAAMU,EAAWT,EAAWD,GAC3CD,EAAa,YAAMW,EAAW,YAAS,CAACR,IAASH,GAErD,OAAOA,EA/BUY,CADM,YAAS,YAAK,YAAMxB,GAAY,SAAU,YAAO,IAAK,KAC3CH,GAElC,MAAM4B,EAAe9B,EACjB,YAAUK,EAAWC,GAAc,YAAQD,EAAWC,GAE1D,OADe,YAAK,YAAIwB,EAAc,KAAM,a,iCCrFhD,yEAkEO,MAAMC,EAAY,YAAG,CAAEC,WAf9B,SAAoB9F,EAAO+F,EAAYC,EAAgB,UAAWC,EAAW,WAAYlF,EAAY,EAAGmF,GACpG,MAAMjG,EAAS,YAAgBD,EAAO,QAAS,YAAa,WACtDmG,EAAc,YAAgBJ,EAAY,aAAc,YAAa,WAC3E,IAA4B,IAAhB9F,EAAOzC,MAAY,IAC3B,yDAAgByC,EAAOzC,UAC3B,IAAiC,IAArB2I,EAAY3I,OACnB2I,EAAY3M,MAAM,KAAOyG,EAAOzG,MAAM,IACV,IAAzB2M,EAAY3M,MAAM,KACG,IAAzB2M,EAAY3M,MAAM,IAAU,IAAM,qEACtC,IAA2B,MAAf0M,GAA8C,IAAvBA,EAAYzM,QAAc,IACzD,4EAAWyM,OACf,MAAMtN,EAAS,CAAEoH,MAAOC,EAAQ8F,WAAYI,GACtChN,EAAQ,CAAE6M,gBAAeC,WAAUlF,YAAWmF,eACpD,OAAO,IAAOrN,UAAU,KAAWD,EAAQO,O,iCChE/C,oJAiGO,MAAMiN,EAAW,YAAG,CAAEC,UA7B7B,SAAmB7N,EAAG8N,EAAUC,GAC5B,YAAOD,EAAW,GAAM,GAAG,IAAM,gDAAgDA,OACjF,YAAOC,EAAW,GAAM,GAAG,IAAM,gDAAgDA,OACjF,MAAM7N,EAAK,YAAgBF,EAAG,IAAK,YACnC,YAAOE,EAAG8E,MAAQ,GAAG,IAAM,4CAA4C9E,EAAG8E,UAC1E,MAAMhE,EAAQd,EAAGc,OACVgN,EAAGC,GAAK/N,EAAGc,MAAMW,OAAO,GAC/B,KAAMmM,GAAYE,GACd,MAAM,IAAI7M,MAAM,yBAAyB2M,mDACYE,OAEzD,KAAMD,GAAYE,GACd,MAAM,IAAI9M,MAAM,yBAAyB4M,sDACeE,OAExDH,EAAW,IACXA,EAAWE,GAEXD,EAAW,IACXA,EAAWE,GAEf,MAAMzM,EAAI,YAAQ,YAAM,EAAGwM,EAAG,EAAG,SAAU,EAAE,EAAG,IAC1CE,EAAI,YAAM,EAAGD,EAAG,EAAG,SACnBE,EAAK,YAAI3M,EAAG0M,GACZE,EAAS,YAAW,YAAUD,EAAI,aAAQL,EAAU,UAAW,YAAaK,EAAI,aAAQJ,EAAU,WAClGM,EAAO,YAAM,CAACL,EAAGC,GAAI/N,EAAGkB,OAC9B,OAAO,YAAQ,YAAM,YAAQ,YAAQlB,EAAI,EAAE,EAAG8N,EAAGC,KAC5CjM,KAAIsM,GAAO,YAAMF,EAAQE,EAAKD,MAASrN,O,iCC/FhD,4HA8FO,MAAMuN,EAAc,YAAG,CAAEC,aAvChC,SAAsBC,GAClB,IAAIC,EACJ,GAAIC,MAAMC,QAAQH,GAAK,CACnBC,GAAkB,EAClB,YAAa,MAAND,GAAcA,EAAGxN,OAAS,GAAG,IAAM,sEAE1C,MAAM4N,EAAMJ,EAAG,GAAGzN,MAAM,GACxB,IAAK,IAAIQ,EAAI,EAAGA,EAAIiN,EAAGxN,SAAUO,EAC7B,YAAOiN,EAAGjN,GAAGR,MAAM,KAAO6N,GAAK,IAC3B,iEAAIJ,EAAGjN,GAAGR,MAAM,UAAU6N,YAIlCH,GAAkB,EAClBD,EAAK,YAAMA,EAAIA,EAAGzN,MAAM,GAAI,GAAGgB,KAAIxB,GAAK,YAAQA,EAAG,CAAC,MAExD,YAAOiO,EAAGxN,QAAUwN,EAAG,GAAGzN,MAAM,IAAI,IAAM,oCAAoCyN,EAAGxN,yCACpDwN,EAAG,GAAGzN,MAAM,SACzC,MAAM8N,EAAK,GACLC,EAAON,EACb,IAAK,IAAIjN,EAAI,EAAGA,EAAIiN,EAAGxN,SAAUO,EAC7BsN,EAAGhN,KAAK,IAAOkN,MAAK,KAChB,IAAIxO,EAAIuO,EAAKvN,GACb,GAAIA,EAAI,EACJ,IAAK,IAAI0M,EAAI,EAAGA,EAAI1M,IAAK0M,EAAG,CACxB,MAAMe,EAAO,YAAI,YAAI,YAAIH,EAAGZ,GAAI1N,IAAKsO,EAAGZ,IACxC1N,EAAI,YAAIA,EAAGyO,GAGnB,OAAO,YAAIzO,EAAG,YAAKA,EAAG,kBAG9B,OAAIkO,EACO,YAAMI,EAAI,GAGVA,M,iCC3Ff,6MA4GA,SAASI,EAAK1O,EAAG2O,GAAe,GAC5B,OAAO,IAAOH,MAAK,KACf,YAA0B,IAAnBxO,EAAEQ,MAAMC,QAAc,IAAM,0CAA0CT,EAAEQ,MAAMC,oBACrF,MAAMmO,EAAI5O,EAAEQ,MAAM,GACZqO,EAAI7O,EAAEQ,MAAM,GAClB,IAAIsO,EAAI,YAAIF,GACR3D,EAAI,YAAMjL,GACd,MAAM+O,EAAQ,YAAS,CAAC,CAAC,IAAK,CAAC,EAAG,IAClC,IAAIC,EAAI,YAAMD,GACd,MAAME,EAAQL,GAAKC,EAAIA,EAAID,EAC3B,IAAK,IAAIlB,EAAI,EAAGA,EAAIuB,IAASvB,EAAG,CAG5B,MAAMwB,EAAQjE,EACRkE,EAAQH,EACRI,EAAQN,GACbE,EAAG/D,EAAG6D,GAAK,IAAON,MAAK,KAEpB,MAAMa,EAAS,YAAMpE,EAAG,CAACyC,EAAGA,GAAI,CAACkB,EAAIlB,EAAG,IAClC4B,EAAQ,YAAKD,GACbE,EAAM,YAAMtE,EAAG,CAACyC,EAAGA,GAAI,CAAC,EAAG,IAE3B8B,EAAI,YAAM,YAAQD,EAAK,GAAI,YAAS,CAAC,EAAE,KAAM,YAAS,CAAC,CAAC,MACxDE,EAAK,YAAIF,EAAK,YAAIC,EAAGF,IACrBI,EAAO,YAAIL,EAAQI,GAErBT,EADkB,IAAlBU,EAAKlP,MAAM,GACP,YAAMuO,GAGN,YAAO,CACPA,EACA,YAAMW,EAAM,CAAC,EAAG,GAAI,CAACA,EAAKlP,MAAM,GAAK,EAAGkP,EAAKlP,MAAM,MACpD,GAEP,MAAMmP,EAAM,YAAI,YAAI,YAAOH,EAAGC,GAAKH,IAE7BM,EAAW,YAAM3E,EAAG,CAACyC,EAAG,GAAI,CAACkB,EAAIlB,EAAGmB,IACpCgB,EAAY,YAAIF,EAAKX,GACrBc,EAAK,YAAUd,GACrB,GAAU,IAANtB,EACAzC,EAAI,YAAI2E,EAAU,YAAOC,EAAW,YAAOC,EAAIF,SAE9C,CACD,MAAMG,EAAY,YAAIH,EAAU,YAAOC,EAAW,YAAOC,EAAIF,KAC7D3E,EAAI,YAAO,CAAC,YAAMA,EAAG,CAAC,EAAG,GAAI,CAACyC,EAAGmB,IAAKkB,GAAY,GAEtD,MAAMC,EAAa,YAAUH,GACvBI,EAAW,YAAMnB,EAAG,CAAC,EAAGpB,GAAI,CAACkB,EAAGE,EAAEtO,MAAM,GAAKkN,IACnD,GAAU,IAANA,EACAoB,EAAI,YAAImB,EAAU,YAAO,YAAOA,EAAUjB,GAAIgB,QAE7C,CACD,MAAME,EAAY,YAAID,EAAU,YAAO,YAAOA,EAAUjB,GAAIgB,IAC5DlB,EAAI,YAAO,CAAC,YAAMA,EAAG,CAAC,EAAG,GAAI,CAACF,EAAGlB,IAAKwC,GAAY,GAEtD,MAAO,CAAClB,EAAG/D,EAAG6D,MAElB,YAAQ,CAACI,EAAOC,EAAOC,IAM3B,OAJKT,GAAgBC,EAAIC,IACrBC,EAAI,YAAMA,EAAG,CAAC,EAAG,GAAI,CAACF,EAAGC,IACzB5D,EAAI,YAAMA,EAAG,CAAC,EAAG,GAAI,CAAC4D,EAAGA,KAEtB,CAACC,EAAG7D,MAGZ,MAAMkF,EAAK,YAAG,CAAEC,IA9FvB,SAAapQ,EAAG2O,GAAe,GAE3B,GADA,YAAO3O,EAAEwE,MAAQ,GAAG,IAAM,gEAAgExE,EAAEwE,SAC7E,IAAXxE,EAAEwE,KACF,OAAOkK,EAAK1O,EAAG2O,GAEd,CAKD,MAAM0B,EAAgBrQ,EAAEQ,MAAMW,MAAM,EAAGnB,EAAEQ,MAAMC,OAAS,GACnD6P,QAAO,CAAC9K,EAAO+K,IAAS/K,EAAQ+K,IAC/BC,EAAO,YAAQ,YAAQxQ,EAAG,CAC5BqQ,EAAerQ,EAAEQ,MAAMR,EAAEQ,MAAMC,OAAS,GACxCT,EAAEQ,MAAMR,EAAEQ,MAAMC,OAAS,KACzB,GACEgQ,EAAO,GACPC,EAAO,GACbF,EAAKG,SAAQC,IACT,MAAOC,EAAKC,GAAOpC,EAAKkC,EAAKjC,GAC7B8B,EAAKnP,KAAKuP,GACVH,EAAKpP,KAAKwP,MAId,MAAO,CAFG,YAAQ,YAAML,EAAM,GAAIzQ,EAAEQ,OAC1B,YAAQ,YAAMkQ,EAAM,GAAI1Q,EAAEQ,a,iCCxG5C,2FAiDO,MAAMuQ,EAAqB,YAAG,CAAEC,oBAXvC,SAA6BC,EAAQC,EAAaC,EAASC,EAAY,IAAUC,wBAC7E,MAAMC,EAAU,YAAgBL,EAAQ,SAAU,sBAC5CM,EAAe,YAAgBL,EAAa,cAAe,sBACjE,IAAIM,EAAW,KACA,MAAXL,IACAK,EAAW,YAAgBL,EAAS,UAAW,uBAEnD,YAAkBG,EAAQ9Q,MAAO+Q,EAAa/Q,MAAO,iCACrD,MAAMiR,EAAS,YAAI,YAAIH,EAASC,IAChC,OAAO,YAAoBE,EAAQD,EAAUJ,O,iCC/CjD,2GAqCO,MAAMM,EAAiB,YAAG,CAAEC,gBAZnC,SAAyBV,EAAQC,EAAajR,EAAMkR,EAASC,EAAY,IAAUC,wBAC/E,MAAMC,EAAU,YAAgBL,EAAQ,SAAU,kBAC5CM,EAAe,YAAgBL,EAAa,cAAe,kBACjE,IAAIM,EAAW,KACA,MAAXL,IACAK,EAAW,YAAgBL,EAAS,UAAW,mBAEnD,YAAkBG,EAAQ9Q,MAAO+Q,EAAa/Q,MAAO,6BACrD,MAAMoR,EAAM,YAAO,GACbH,EAAS,YAAIG,EAAK,YAAI,YAAIN,EAASC,GAAetR,GAAM,IAC9D,OAAO,YAAoBwR,EAAQD,EAAUJ,O,iCCnCjD,2GAsCO,MAAMS,EAAY,YAAG,CAAEC,WAd9B,SAAoBb,EAAQC,EAAaC,EAASC,EAAY,IAAUC,wBACpE,IAAIC,EAAU,YAAgBL,EAAQ,SAAU,aAChD,MAAMM,EAAe,YAAgBL,EAAa,cAAe,aACjE,IAAIM,EAAW,KACA,MAAXL,IACAK,EAAW,YAAgBL,EAAS,UAAW,cAEnD,YAAkBG,EAAQ9Q,MAAO+Q,EAAa/Q,MAAO,wBACrD,MAAMoR,EAAM,YAAO,GAEnBN,EAAU,YAAI,YAAI,YAAO,GAAIA,GAAUM,GACvC,MAAMH,EAAS,YAAK,YAAIG,EAAK,YAAIN,EAASC,KAC1C,OAAO,YAAoBE,EAAQD,EAAUJ,O,iCCpCjD,oIA2DO,MAAMW,EAAY,YAAG,CAAEC,WAf9B,SAAoBf,EAAQC,EAAaC,EAASc,EAAQ,EAAKb,EAAY,IAAUC,wBACjF,MAAMC,EAAU,YAAgBL,EAAQ,SAAU,aAC5CM,EAAe,YAAgBL,EAAa,cAAe,aACjE,IAAIM,EAAW,KACA,MAAXL,IACAK,EAAW,YAAgBL,EAAS,UAAW,cAEnD,YAAkBG,EAAQ9Q,MAAO+Q,EAAa/Q,MAAO,wBACrD,MAAM0R,EAAc,YAAOD,GACrBE,EAAQ,YAAI,YAAIZ,EAAcD,IAC9Bc,EAAY,YAAQD,EAAOD,GAC3BG,EAAS,YAAIF,EAAOC,GACpBX,EAAS,YAAI,YAAI,YAAO,IAAM,YAAOW,IAAa,YAAIF,EAAaG,IACzE,OAAO,YAAoBZ,EAAQD,EAAUJ,O,iCCzDjD,2HA0DO,MAAMkB,EAAU,YAAG,CAAEC,SAf5B,SAAkBtB,EAAQC,EAAaC,EAASqB,EAAU,KAAMpB,EAAY,IAAUC,wBAClF,MAAMC,EAAU,YAAgBL,EAAQ,SAAU,WAC5CM,EAAe,YAAgBL,EAAa,cAAe,WACjE,IAAIM,EAAW,KACA,MAAXL,IACAK,EAAW,YAAgBL,EAAS,UAAW,YAEnD,YAAkBG,EAAQ9Q,MAAO+Q,EAAa/Q,MAAO,sBACrD,MAAMoR,EAAM,YAAO,GACba,EAAgB,YAAOD,GACvBE,EAAK,YAAI,YAAIpB,EAAS,YAAI,YAAIC,EAAckB,MAC5CE,EAAK,YAAI,YAAIf,EAAKN,GAAU,YAAI,YAAI,YAAIM,EAAKL,GAAekB,KAC5DhB,EAAS,YAAIiB,EAAIC,GACvB,OAAO,YAAoBlB,EAAQD,EAAUJ,O,iCCxDjD,oFAgDO,MAAMwB,EAAmB,YAAG,CAAEC,kBAXrC,SAA2B5B,EAAQC,EAAaC,EAASC,EAAY,IAAUC,wBAC3E,MAAMC,EAAU,YAAgBL,EAAQ,SAAU,oBAC5CM,EAAe,YAAgBL,EAAa,cAAe,oBACjE,IAAIM,EAAW,KACA,MAAXL,IACAK,EAAW,YAAgBL,EAAS,UAAW,qBAEnD,YAAkBG,EAAQ9Q,MAAO+Q,EAAa/Q,MAAO,+BACrD,MAAMiR,EAAS,YAAkBH,EAASC,GAC1C,OAAO,YAAoBE,EAAQD,EAAUJ,O,iCC9CjD,oJAkGO,MAAM0B,EAAsB,YAAG,CAAEC,qBAlBxC,SAA8BC,EAAkBC,EAAQ9B,EAAS+B,EAAiB,EAAG9B,EAAY,IAAUC,wBACvG,IAAI8B,EAAoB,YAAgBH,EAAkB,mBAAoB,uBAC9E,MAAMI,EAAU,YAAgBH,EAAQ,SAAU,uBAClD,IAAIzB,EAAW,KAKf,GAJe,MAAXL,IACAK,EAAW,YAAgBL,EAAS,UAAW,wBAEnD,YAAkBgC,EAAkB3S,MAAO4S,EAAQ5S,MAAO,kCACtD0S,EAAiB,EAAG,CACpB,MAAMG,EAAuB,YAAOH,GAC9BtB,EAAM,YAAO,GACb0B,EAAO,YAAO,IACpBH,EACI,YAAI,YAAIA,EAAmB,YAAIvB,EAAKyB,IAAwB,YAAIC,EAAMD,IAE9E,MAAM5B,EAjEV,SAAwCR,EAAQgC,GAC5C,MAAM3B,EAAU,YAAgBL,EAAQ,SAAU,iCAC5CmC,EAAU,YAAgBH,EAAQ,SAAU,iCAClD,YAAkB3B,EAAQ9Q,MAAO4S,EAAQ5S,MAAO,4CAqBhD,MAAM+S,EAAY,YAAKH,GACjBI,EAAgB,YAAIJ,EAAS9B,GAC7BmC,EAAgB,YAAM,YAAI,YAAI,YAAIL,MACxC,OAAO,YAAI,YAAIG,EAAWC,GAAgBC,GAsC3BC,CAA+BP,EAAmBC,GACjE,OAAO,YAAoB3B,EAAQD,EAAUJ,O,iCChGjD,mLA+HO,MAAMuC,EAAsB,YAAG,CAAEC,qBAlBxC,SAA8BC,EAAcZ,EAAQ9B,EAAS+B,EAAiB,EAAG9B,EAAY,IAAUC,wBACnG,IAAIyC,EAAgB,YAAgBD,EAAc,eAAgB,uBAClE,MAAMT,EAAU,YAAgBH,EAAQ,SAAU,uBAClD,IAAIzB,EAAW,KAKf,GAJe,MAAXL,IACAK,EAAW,YAAgBL,EAAS,UAAW,wBAEnD,YAAkB2C,EAActT,MAAO4S,EAAQ5S,MAAO,kCAClD0S,EAAiB,EAAG,CACpB,MAAMG,EAAuB,YAAOH,GAC9BtB,EAAM,YAAO,GACbmC,EAAa,YAAOD,EAActT,MAAM,IAC9CsT,EACI,YAAI,YAAIA,EAAe,YAAIlC,EAAKyB,IAAwB,YAAIA,EAAsBU,IAE1F,MAAMtC,EAlEV,SAAwCR,EAAQgC,EAAQ5E,GAAM,GAI1D,IAHa,IAATA,IACAA,EAAM4E,EAAOzO,KAAO,GAEpB6J,IAAQ4E,EAAOzO,KAAO,EACtB,MAAM7D,MACF,mGAAuCsS,EAAOzO,oBAC/B6J,KAuBvB,OApBiB,aAAW,CAAC4C,EAAQgC,EAAQ1N,KAIzC,MACMyO,EAAM,YAAUf,EAAQ,CAAC5E,IADd,GAEX4F,EAAY,YAAI,YAAKhB,EAAQ,WAAYe,GAC/CzO,EAAK,CAAC0L,EAAQgD,IACd,MAAMC,EAAa,YAAI,YAAID,EAAWhD,IAUtC,MAAO,CAAEzL,MATK,YAAI0O,EAAY,CAAC7F,IASf5I,SARC,CAACR,EAAIC,KAClB,MAAO+L,EAAQgD,GAAa/O,EACtBiP,EAAU,YAAqBlP,EAAGzE,MAAO,CAAC6N,IAChD,MAAO,CACH,YAAI,YAAQpJ,EAAIkP,GAAU,YAAI,YAAKlD,EAAQ,WAAY,YAAIgD,KAC3D,YAAI,YAAQhP,EAAIkP,GAAU,YAAI,YAAIF,GAAY,YAAKhD,EAAQ,kBAKhEvL,CAASuL,EAAQgC,GAoCTmB,CAA+BN,EAAeV,GAC7D,OAAO,YAAoB3B,EAAQD,EAAUJ,O,gCC7HjD,yOA4BO,SAASiD,EAAqBpP,EAAIE,EAAGrB,GACxC,GAAkB,MAAdA,GAAqC,WAAfA,EACtB,OAAOmB,EAEX,GAAmB,SAAfnB,EACA,OAAO,YAAImB,EAAI,YAAKE,IAExB,MAAM,IAAIxE,MAAM,gDAAgDmD,MAG7D,SAASwQ,EAAqBzQ,EAAMuB,GACvC,IAAIvC,EAAMuC,EACV,MAAMmP,EAAa,IAAgC1Q,EAAKrD,MAAO4E,EAAa5E,OAI5E,OAHI+T,EAAW9T,OAAS,IACpBoC,EAAM,YAAIA,EAAK0R,IAEZ,YAAQ1R,EAAKgB,EAAKrD,OAEtB,SAASgU,EAAgBxU,EAAG8D,EAAYC,EAAwBC,GACnE,GAAmB,WAAfF,EACA,OAAO9D,EAEN,GAAmB,SAAf8D,EACL,OAAO,YAAK9D,GAEX,GAAmB,QAAf8D,EACL,OAAO,YAAI9D,GAEV,GAAmB,UAAf8D,EACL,OAAO,YAAM9D,GAEZ,GAAmB,UAAf8D,EACL,OAAO,YAAM9D,EAAG+D,GAEf,GAAmB,cAAfD,EACL,OAAO,YAAU9D,EAAGgE,GAEnB,GAAmB,YAAfF,EACL,OAAO,YAAQ9D,GAEnB,MAAM,IAAIW,MAAM,4BAA4BmD,MAGzC,MAAM2Q,EAAa,CAACvQ,EAAeJ,MACjBI,EAAgB,IACE,WAAfJ,G,gCCzE5B,+HA0DO,MAAM4Q,EAAsB,YAAG,CAAEC,qBApCxC,SAA8BlD,EAAQN,EAASC,EAAY,IAAUC,wBACjE,MAAMuD,EAAU,YAAgBnD,EAAQ,SAAU,uBAClD,IAAID,EAAW,KACA,MAAXL,IACAK,EAAW,YAAgBL,EAAS,UAAW,wBAEnD,MAAM0D,EAA4B,MAAZrD,EAAoBoD,EAAU,YAAIA,EAASpD,GACjE,GAAIJ,IAAc,IAAU0D,KACxB,OAAOD,EAEX,GAAIzD,IAAc,IAAU2D,IACxB,OAAO,YAAIF,GAEf,GAAIzD,IAAc,IAAU4D,KAAM,CAC9B,GAAgB,MAAZxD,EACA,OAAO,YAAKqD,GAEX,CACD,MAAMI,EAAkBL,EAAQvN,KAAOmK,EAASnK,KAC1ClD,EAAS,YAAI,YAAI0Q,GAAe,YAAIrD,IAC1C,OAAOyD,EAAkB,EAAI,YAAI9Q,EAAQ,YAAO8Q,IAC5C9Q,GAGZ,GAAIiN,IAAc,IAAUC,uBAAwB,CAChD,GAAgB,MAAZG,EACA,OAAO,YAAI,YAAIqD,GAAe,YAAOD,EAAQvN,OAE5C,CACD,MAAM6N,EAAqB,YAAI1D,EAAU,YAAKoD,EAAQpU,QAChD2U,EAAc,YAAK,YAAI,YAASD,EAAoB,YAAO,KAAM,WACvE,OAAO,YAAI,YAAIL,GAAeM,IAGtC,MAAMxU,MAAM,sBAAsByQ,S,gCCxDtC,kEAsCO,MAAMgE,EAAM,YAAG,CAAEC,KALxB,SAAcrV,GACV,MACMJ,EAAS,CAAEI,EADN,YAAgBA,EAAG,IAAK,QAEnC,OAAO,IAAOH,UAAU,KAAKD,O,gCCpCjC,kEAuDO,MAAM0V,EAAM,YAAG,CAAEC,KANxB,SAAcvV,EAAGC,EAAO,KAAMC,GAAW,GACrC,MACMN,EAAS,CAAEI,EADN,YAAgBA,EAAG,IAAK,QAE7BG,EAAQ,CAAEqV,iBAAkBvV,EAAMC,YACxC,OAAO,IAAOL,UAAU,KAAKD,EAAQO,O,gCCrDzC,kEAqCO,MAAMsV,EAAM,YAAG,CAAEC,KALxB,SAAc1V,GACV,MACMJ,EAAS,CAAEI,EADN,YAAgBA,EAAG,IAAK,QAEnC,OAAO,IAAOH,UAAU,KAAKD,O,gCCnCjC,kFA6CO,MAAM+V,EAAU,YAAG,CAAEC,SAR5B,SAAkBpW,EAAGC,GACjB,IAAIC,EAAK,YAAgBF,EAAG,IAAK,UAAW,qBACxCG,EAAK,YAAgBF,EAAG,IAAK,UAAW,sBAC3CC,EAAIC,GAAM,YAAeD,EAAIC,GAC9B,YAA2BD,EAAGc,MAAOb,EAAGa,OACxC,MAAMZ,EAAS,CAAEJ,EAAGE,EAAID,EAAGE,GAC3B,OAAO,IAAOE,UAAU,KAASD,O,gCC3CrC,kEAuCO,MAAMiW,EAAO,YAAG,CAAEC,MALzB,SAAeC,GACX,MACMnW,EAAS,CAAEmW,MADF,YAAgBA,EAAO,QAAS,SAE/C,OAAO,IAAOlW,UAAU,KAAMD,O,gCCrClC,oDAgCA,SAASoW,EAAKxV,EAAOgF,EAAO5E,GACxB,MAAMT,EAAQ,CAAEK,QAAOgF,QAAO5E,SAC9B,OAAO,IAAOf,UAAU,IAAM,GAAIM,K,gCClCtC,kFA6CO,MAAM8V,EAAY,YAAG,CAAEC,WAR9B,SAAoB1W,EAAGC,GACnB,IAAIC,EAAK,YAAgBF,EAAG,IAAK,YAAa,qBAC1CG,EAAK,YAAgBF,EAAG,IAAK,YAAa,sBAC7CC,EAAIC,GAAM,YAAeD,EAAIC,GAC9B,YAA2BD,EAAGc,MAAOb,EAAGa,OACxC,MAAMZ,EAAS,CAAEJ,EAAGE,EAAID,EAAGE,GAC3B,OAAO,IAAOE,UAAU,KAAWD","file":"js/bundle~bundle~4b2d83a9.8d970cbe.js","sourcesContent":["/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Multiply } from '../kernel_names';\nimport { makeTypesMatch } from '../tensor_util';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Multiplies two `tf.Tensor`s element-wise, A * B. Supports broadcasting.\n *\n * We also expose `tf.mulStrict` which has the same signature as this op and\n * asserts that `a` and `b` are the same shape (does not broadcast).\n *\n * ```js\n * const a = tf.tensor1d([1, 2, 3, 4]);\n * const b = tf.tensor1d([2, 3, 4, 5]);\n *\n * a.mul(b).print();  // or tf.mul(a, b)\n * ```\n *\n * ```js\n * // Broadcast mul a with b.\n * const a = tf.tensor1d([1, 2, 3, 4]);\n * const b = tf.scalar(5);\n *\n * a.mul(b).print();  // or tf.mul(a, b)\n * ```\n * @param a The first tensor to multiply.\n * @param b The second tensor to multiply. Must have the same dtype as `a`.\n *\n * @doc {heading: 'Operations', subheading: 'Arithmetic'}\n */\nfunction mul_(a, b) {\n    let $a = convertToTensor(a, 'a', 'mul');\n    let $b = convertToTensor(b, 'b', 'mul');\n    [$a, $b] = makeTypesMatch($a, $b);\n    const inputs = { a: $a, b: $b };\n    return ENGINE.runKernel(Multiply, inputs);\n}\nexport const mul = op({ mul_ });\n//# sourceMappingURL=mul.js.map","/**\n * @license\n * Copyright 2020 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Min } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes the minimum value from the input.\n *\n * Reduces the input along the dimensions given in `axes`. Unless `keepDims`\n * is true, the rank of the array is reduced by 1 for each entry in `axes`.\n * If `keepDims` is true, the reduced dimensions are retained with length 1.\n * If `axes` has no entries, all dimensions are reduced, and an array with a\n * single element is returned.\n *\n * ```js\n * const x = tf.tensor1d([1, 2, 3]);\n *\n * x.min().print();  // or tf.min(x)\n * ```\n *\n * ```js\n * const x = tf.tensor2d([1, 2, 3, 4], [2, 2]);\n *\n * const axis = 1;\n * x.min(axis).print();  // or tf.min(x, axis)\n * ```\n *\n * @param x The input Tensor.\n * @param axis The dimension(s) to reduce. By default it reduces\n *     all dimensions.\n * @param keepDims If true, retains reduced dimensions with size 1.\n *\n * @doc {heading: 'Operations', subheading: 'Reduction'}\n */\nfunction min_(x, axis = null, keepDims = false) {\n    const $x = convertToTensor(x, 'x', 'min');\n    const inputs = { x: $x };\n    const attrs = { axis, keepDims };\n    // tslint:disable-next-line: no-unnecessary-type-assertion\n    return ENGINE.runKernel(Min, inputs, attrs);\n}\nexport const min = op({ min_ });\n//# sourceMappingURL=min.js.map","import { computeStrides, sizeFromShape } from '../util';\n/**\n * Validate gather nd inputs.\n *\n * @param tensor The tensor contains the source values.\n * @param indices The tensor contains the indices to slice the source.\n *\n * @returns [resultShape, numUpdates, sliceSize, strides]\n */\nexport function prepareAndValidate(tensor, indices) {\n    const tensorRank = tensor.shape.length;\n    const indicesRank = indices.shape.length;\n    if (tensorRank < 1) {\n        throw new Error('tf.gatherND() expects the input to be rank 1 or higher,' +\n            ` but the rank was ${tensorRank}.`);\n    }\n    if (indicesRank < 1) {\n        throw new Error('tf.gatherND() expects the indices to be rank 1 or higher,' +\n            ` but the rank was ${indicesRank}.`);\n    }\n    if (indices.dtype !== 'int32') {\n        throw new Error('tf.gatherND() expects the indices to be int32 type,' +\n            ` but the dtype was ${indices.dtype}.`);\n    }\n    if (indices.shape[indicesRank - 1] > tensorRank) {\n        throw new Error('index innermost dimension length must be <= tensor rank; saw: ' +\n            `${indices.shape[indicesRank - 1]} vs. ${tensorRank}`);\n    }\n    if (sizeFromShape(tensor.shape) === 0) {\n        throw new Error('Requested more than 0 entries, but input is empty.' +\n            ` Input shape: ${tensor.shape}.`);\n    }\n    const indicesShape = indices.shape;\n    const sliceRank = indicesShape[indicesShape.length - 1];\n    // The result shape is\n    //   indices.shape[:-1] + params.shape[indices.shape[-1]:]\n    let nResult = 1;\n    for (let i = 0; i < indicesShape.length - 1; ++i) {\n        nResult *= indicesShape[i];\n    }\n    const inputShape = tensor.shape;\n    const resultShape = indicesShape.slice();\n    resultShape.pop();\n    let sliceSize = 1;\n    for (let i = sliceRank; i < tensorRank; ++i) {\n        sliceSize *= inputShape[i];\n        resultShape.push(inputShape[i]);\n    }\n    const strides = [...computeStrides(tensor.shape).map(stride => stride / sliceSize),\n        1].slice(0, sliceRank);\n    return [resultShape, nResult, sliceSize, strides];\n}\n//# sourceMappingURL=gather_nd_util.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { FloorDiv } from '../kernel_names';\nimport { makeTypesMatch } from '../tensor_util';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Divides two `tf.Tensor`s element-wise, A / B. Supports broadcasting.\n * The result is rounded with floor function.\n *\n *\n * ```js\n * const a = tf.tensor1d([1, 4, 9, 16]);\n * const b = tf.tensor1d([1, 2, 3, 4]);\n *\n * a.floorDiv(b).print();  // or tf.div(a, b)\n * ```\n *\n * ```js\n * // Broadcast div a with b.\n * const a = tf.tensor1d([2, 4, 6, 8]);\n * const b = tf.scalar(2);\n *\n * a.floorDiv(b).print();  // or tf.floorDiv(a, b)\n * ```\n *\n * @param a The first tensor as the numerator.\n * @param b The second tensor as the denominator. Must have the same dtype as\n * `a`.\n *\n * @doc {heading: 'Operations', subheading: 'Arithmetic'}\n */\nfunction floorDiv_(a, b) {\n    let $a = convertToTensor(a, 'a', 'floorDiv');\n    let $b = convertToTensor(b, 'b', 'floorDiv');\n    [$a, $b] = makeTypesMatch($a, $b);\n    const inputs = { a: $a, b: $b };\n    return ENGINE.runKernel(FloorDiv, inputs);\n}\nexport const floorDiv = op({ floorDiv_ });\n//# sourceMappingURL=floorDiv.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { LogicalAnd } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { assertAndGetBroadcastShape } from './broadcast_util';\nimport { op } from './operation';\n/**\n * Returns the truth value of `a AND b` element-wise. Supports broadcasting.\n *\n * ```js\n * const a = tf.tensor1d([false, false, true, true], 'bool');\n * const b = tf.tensor1d([false, true, false, true], 'bool');\n *\n * a.logicalAnd(b).print();\n * ```\n *\n * @param a The first input tensor. Must be of dtype bool.\n * @param b The second input tensor. Must be of dtype bool.\n *\n * @doc {heading: 'Operations', subheading: 'Logical'}\n */\nfunction logicalAnd_(a, b) {\n    const $a = convertToTensor(a, 'a', 'logicalAnd', 'bool');\n    const $b = convertToTensor(b, 'b', 'logicalAnd', 'bool');\n    assertAndGetBroadcastShape($a.shape, $b.shape);\n    const inputs = { a: $a, b: $b };\n    return ENGINE.runKernel(LogicalAnd, inputs);\n}\nexport const logicalAnd = op({ logicalAnd_ });\n//# sourceMappingURL=logical_and.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { GreaterEqual } from '../kernel_names';\nimport { makeTypesMatch } from '../tensor_util';\nimport { convertToTensor } from '../tensor_util_env';\nimport { assertAndGetBroadcastShape } from './broadcast_util';\nimport { op } from './operation';\n/**\n * Returns the truth value of (a >= b) element-wise. Supports broadcasting.\n *\n * ```js\n * const a = tf.tensor1d([1, 2, 3]);\n * const b = tf.tensor1d([2, 2, 2]);\n *\n * a.greaterEqual(b).print();\n * ```\n *\n * @param a The first input tensor.\n * @param b The second input tensor. Must have the same dtype as `a`.\n *\n * @doc {heading: 'Operations', subheading: 'Logical'}\n */\nfunction greaterEqual_(a, b) {\n    let $a = convertToTensor(a, 'a', 'greaterEqual', 'string_or_numeric');\n    let $b = convertToTensor(b, 'b', 'greaterEqual', 'string_or_numeric');\n    [$a, $b] = makeTypesMatch($a, $b);\n    assertAndGetBroadcastShape($a.shape, $b.shape);\n    const inputs = { a: $a, b: $b };\n    return ENGINE.runKernel(GreaterEqual, inputs);\n}\nexport const greaterEqual = op({ greaterEqual_ });\n//# sourceMappingURL=greater_equal.js.map","/**\n * @license\n * Copyright 2020 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Mean } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes the mean of elements across dimensions of a `tf.Tensor`.\n *\n * Reduces `x` along the dimensions given in `axis`. Unless `keepDims` is\n * true, the rank of the `tf.Tensor` is reduced by 1 for each entry in `axis`.\n * If `keepDims` is true, the reduced dimensions are retained with length 1.\n * If `axis` has no entries, all dimensions are reduced, and a `tf.Tensor` with\n * a single element is returned.\n *\n * ```js\n * const x = tf.tensor1d([1, 2, 3]);\n *\n * x.mean().print();  // or tf.mean(a)\n * ```\n *\n * ```js\n * const x = tf.tensor2d([1, 2, 3, 4], [2, 2]);\n *\n * const axis = 1;\n * x.mean(axis).print();  // or tf.mean(x, axis)\n * ```\n *\n * @param x The input tensor.\n * @param axis The dimension(s) to reduce. By default it reduces\n *     all dimensions.\n * @param keepDims If true, retains reduced dimensions with size 1.\n *\n * @doc {heading: 'Operations', subheading: 'Reduction'}\n */\nfunction mean_(x, axis = null, keepDims = false) {\n    const $x = convertToTensor(x, 'x', 'mean');\n    const inputs = { x: $x };\n    const attrs = { axis, keepDims };\n    return ENGINE.runKernel(Mean, inputs, attrs);\n}\nexport const mean = op({ mean_ });\n//# sourceMappingURL=mean.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Minimum } from '../kernel_names';\nimport { makeTypesMatch } from '../tensor_util';\nimport { convertToTensor } from '../tensor_util_env';\nimport { assertAndGetBroadcastShape } from './broadcast_util';\nimport { cast } from './cast';\nimport { op } from './operation';\n/**\n * Returns the min of a and b (`a < b ? a : b`) element-wise.\n * Supports broadcasting.\n *\n * We also expose `minimumStrict` which has the same signature as this op and\n * asserts that `a` and `b` are the same shape (does not broadcast).\n *\n * ```js\n * const a = tf.tensor1d([1, 4, 3, 16]);\n * const b = tf.tensor1d([1, 2, 9, 4]);\n *\n * a.minimum(b).print();  // or tf.minimum(a, b)\n * ```\n *\n * ```js\n * // Broadcast minimum a with b.\n * const a = tf.tensor1d([2, 4, 6, 8]);\n * const b = tf.scalar(5);\n *\n * a.minimum(b).print();  // or tf.minimum(a, b)\n * ```\n *\n * @param a The first tensor.\n * @param b The second tensor. Must have the same type as `a`.\n *\n * @doc {heading: 'Operations', subheading: 'Arithmetic'}\n */\nfunction minimum_(a, b) {\n    let $a = convertToTensor(a, 'a', 'minimum');\n    let $b = convertToTensor(b, 'b', 'minimum');\n    [$a, $b] = makeTypesMatch($a, $b);\n    if ($a.dtype === 'bool') {\n        $a = cast($a, 'int32');\n        $b = cast($b, 'int32');\n    }\n    assertAndGetBroadcastShape($a.shape, $b.shape);\n    const inputs = { a: $a, b: $b };\n    return ENGINE.runKernel(Minimum, inputs);\n}\nexport const minimum = op({ minimum_ });\n//# sourceMappingURL=minimum.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Log1p } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes natural logarithm of the input `tf.Tensor` plus one\n * element-wise: `ln(1 + x)`\n *\n * ```js\n * const x = tf.tensor1d([1, 2, Math.E - 1]);\n *\n * x.log1p().print();  // or tf.log1p(x)\n * ```\n * @param x The input tensor.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction log1p_(x) {\n    const $x = convertToTensor(x, 'x', 'log1p');\n    const inputs = { x: $x };\n    return ENGINE.runKernel(Log1p, inputs);\n}\nexport const log1p = op({ log1p_ });\n//# sourceMappingURL=log1p.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { convertToTensor } from '../tensor_util_env';\nimport { parseAxisParam } from '../util';\nimport { add } from './add';\nimport { expandShapeToKeepDim } from './axis_util';\nimport { exp } from './exp';\nimport { log } from './log';\nimport { max } from './max';\nimport { op } from './operation';\nimport { reshape } from './reshape';\nimport { sub } from './sub';\nimport { sum } from './sum';\n/**\n * Computes the log(sum(exp(elements across the reduction dimensions)).\n *\n * Reduces the input along the dimensions given in `axis`. Unless `keepDims`\n * is true, the rank of the array is reduced by 1 for each entry in `axis`.\n * If `keepDims` is true, the reduced dimensions are retained with length 1.\n * If `axis` has no entries, all dimensions are reduced, and an array with a\n * single element is returned.\n *\n * ```js\n * const x = tf.tensor1d([1, 2, 3]);\n *\n * x.logSumExp().print();  // or tf.logSumExp(x)\n * ```\n *\n * ```js\n * const x = tf.tensor2d([1, 2, 3, 4], [2, 2]);\n *\n * const axis = 1;\n * x.logSumExp(axis).print();  // or tf.logSumExp(a, axis)\n * ```\n * @param x The input tensor.\n * @param axis The dimension(s) to reduce. If null (the default),\n *     reduces all dimensions.\n * @param keepDims If true, retains reduced dimensions with length\n *     of 1. Defaults to false.\n *\n * @doc {heading: 'Operations', subheading: 'Reduction'}\n */\nfunction logSumExp_(x, axis = null, keepDims = false) {\n    const $x = convertToTensor(x, 'x', 'logSumExp');\n    const axes = parseAxisParam(axis, $x.shape);\n    const xMax = max($x, axes, true /* keepDims */);\n    const a = sub($x, xMax);\n    const b = exp(a);\n    const c = sum(b, axes);\n    const d = log(c);\n    const res = add(reshape(xMax, d.shape), d);\n    if (keepDims) {\n        const newShape = expandShapeToKeepDim(res.shape, axes);\n        return reshape(res, newShape);\n    }\n    return res;\n}\nexport const logSumExp = op({ logSumExp_ });\n//# sourceMappingURL=log_sum_exp.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { LeakyRelu } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes leaky rectified linear element-wise.\n *\n * See\n * [http://web.stanford.edu/~awni/papers/relu_hybrid_icml2013_final.pdf](\n *     http://web.stanford.edu/~awni/papers/relu_hybrid_icml2013_final.pdf)\n *\n * ```js\n * const x = tf.tensor1d([-1, 2, -3, 4]);\n *\n * x.leakyRelu(0.1).print();  // or tf.leakyRelu(x, 0.1)\n * ```\n * @param x The input tensor.\n * @param alpha The scaling factor for negative values, defaults to 0.2.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction leakyRelu_(x, alpha = 0.2) {\n    const $x = convertToTensor(x, 'x', 'leakyRelu');\n    const inputs = { x: $x };\n    const attrs = { alpha };\n    return ENGINE.runKernel(LeakyRelu, inputs, attrs);\n}\nexport const leakyRelu = op({ leakyRelu_ });\n//# sourceMappingURL=leaky_relu.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nexport var Reduction;\n(function (Reduction) {\n    Reduction[Reduction[\"NONE\"] = 0] = \"NONE\";\n    Reduction[Reduction[\"MEAN\"] = 1] = \"MEAN\";\n    Reduction[Reduction[\"SUM\"] = 2] = \"SUM\";\n    Reduction[Reduction[\"SUM_BY_NONZERO_WEIGHTS\"] = 3] = \"SUM_BY_NONZERO_WEIGHTS\";\n})(Reduction || (Reduction = {}));\n//# sourceMappingURL=loss_ops_utils.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { BatchMatMul } from '../kernel_names';\nimport { makeTypesMatch } from '../tensor_util';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes the dot product of two matrices, A * B. These must be matrices.\n *\n * ```js\n * const a = tf.tensor2d([1, 2], [1, 2]);\n * const b = tf.tensor2d([1, 2, 3, 4], [2, 2]);\n *\n * a.matMul(b).print();  // or tf.matMul(a, b)\n * ```\n * @param a First matrix in dot product operation.\n * @param b Second matrix in dot product operation.\n * @param transposeA If true, `a` is transposed before multiplication.\n * @param transposeB If true, `b` is transposed before multiplication.\n *\n * @doc {heading: 'Operations', subheading: 'Matrices'}\n */\nfunction matMul_(a, b, transposeA = false, transposeB = false) {\n    let $a = convertToTensor(a, 'a', 'matMul');\n    let $b = convertToTensor(b, 'b', 'matMul');\n    [$a, $b] = makeTypesMatch($a, $b);\n    const inputs = { a: $a, b: $b };\n    const attrs = { transposeA, transposeB };\n    return ENGINE.runKernel(BatchMatMul, inputs, attrs);\n}\nexport const matMul = op({ matMul_ });\n//# sourceMappingURL=mat_mul.js.map","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../../engine';\nimport { customGrad } from '../../gradients';\nimport { FusedConv2D } from '../../kernel_names';\nimport { makeTypesMatch } from '../../tensor_util';\nimport { convertToTensor } from '../../tensor_util_env';\nimport * as util from '../../util';\nimport { add } from '../add';\nimport * as broadcast_util from '../broadcast_util';\nimport { conv2d as unfusedConv2d } from '../conv2d';\nimport { conv2DBackpropFilter } from '../conv2d_backprop_filter';\nimport { conv2DBackpropInput } from '../conv2d_backprop_input';\nimport * as conv_util from '../conv_util';\nimport { applyActivation, getFusedBiasGradient, getFusedDyActivation, shouldFuse } from '../fused_util';\nimport { op } from '../operation';\nimport { reshape } from '../reshape';\n/**\n * Computes a 2D convolution over the input x, optionally fused with adding a\n * bias and applying an activation.\n *\n * ```js\n * const inputDepth = 2;\n * const inShape = [2, 2, 2, inputDepth];\n * const outputDepth = 2;\n * const fSize = 1;\n * const pad = 0;\n * const strides = 1;\n *\n * const x = tf.tensor4d( [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15,\n * 16], inShape);\n * const w = tf.tensor4d([-1, 1, -2, 0.5], [fSize, fSize, inputDepth,\n * outputDepth]);\n *\n * tf.fused.conv2d({ x, filter: w, strides, pad, dataFormat: 'NHWC',\n * dilations: [1, 1], bias: tf.scalar(5), activation: 'relu' }).print();\n * ```\n *\n * @param obj An object with the following properties:\n * @param x The input tensor, of rank 4 or rank 3, of shape\n *     `[batch, height, width, inChannels]`. If rank 3, batch of 1 is\n * assumed.\n * @param filter The filter, rank 4, of shape\n *     `[filterHeight, filterWidth, inDepth, outDepth]`.\n * @param strides The strides of the convolution: `[strideHeight,\n * strideWidth]`.\n * @param pad The type of padding algorithm.\n *   - `same` and stride 1: output will be of same size as input,\n *       regardless of filter size.\n *   - `valid` output will be smaller than input if filter is larger\n *       than 1x1.\n *   - For more info, see this guide:\n *     [https://www.tensorflow.org/api_guides/python/nn#Convolution](\n *          https://www.tensorflow.org/api_guides/python/nn#Convolution)\n * @param dataFormat An optional string from: \"NHWC\", \"NCHW\". Defaults to\n *     \"NHWC\". Specify the data format of the input and output data. With the\n *     default format \"NHWC\", the data is stored in the order of: [batch,\n *     height, width, channels]. Only \"NHWC\" is currently supported.\n * @param dilations The dilation rates: `[dilationHeight, dilationWidth]`\n *     in which we sample input values across the height and width dimensions\n *     in atrous convolution. Defaults to `[1, 1]`. If `dilations` is a single\n *     number, then `dilationHeight == dilationWidth`. If it is greater than\n *     1, then all values of `strides` must be 1.\n * @param dimRoundingMode A string from: 'ceil', 'round', 'floor'. If none is\n *     provided, it will default to truncate.\n * @param bias Tensor to be added to the result.\n * @param activation Name of activation kernel (defaults to `linear`) to be\n *     applied\n *      after biasAdd.\n * @param preluActivationWeights Tensor of prelu weights to be applied as part\n *     of a `prelu` activation, typically the same shape as `x`.\n * @param leakyreluAlpha Optional. Alpha to be applied as part of a `leakyrelu`\n *     activation.\n */\nfunction fusedConv2d_({ x, filter, strides, pad, dataFormat = 'NHWC', dilations = [1, 1], dimRoundingMode, bias, activation = 'linear', preluActivationWeights, leakyreluAlpha }) {\n    activation = activation || 'linear';\n    if (shouldFuse(ENGINE.state.gradientDepth, activation) === false) {\n        let result = unfusedConv2d(x, filter, strides, pad, dataFormat, dilations, dimRoundingMode);\n        if (bias != null) {\n            result = add(result, bias);\n        }\n        return applyActivation(result, activation, preluActivationWeights, leakyreluAlpha);\n    }\n    const $x = convertToTensor(x, 'x', 'conv2d');\n    const $filter = convertToTensor(filter, 'filter', 'conv2d');\n    let x4D = $x;\n    let reshapedTo4D = false;\n    if ($x.rank === 3) {\n        reshapedTo4D = true;\n        x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);\n    }\n    util.assert(x4D.rank === 4, () => `Error in fused conv2d: input must be rank 4, but got rank ` +\n        `${x4D.rank}.`);\n    util.assert($filter.rank === 4, () => `Error in fused conv2d: filter must be rank 4, but got rank ` +\n        `${$filter.rank}.`);\n    if (dimRoundingMode != null) {\n        util.assert(util.isInt(pad), () => `Error in fused conv2d: pad must be an integer when using, ` +\n            `dimRoundingMode ${dimRoundingMode} but got pad ${pad}.`);\n    }\n    util.assert(x4D.shape[3] === $filter.shape[2], () => `Error in conv2d: depth of input (${x4D.shape[3]}) must match ` +\n        `input depth for filter ${$filter.shape[2]}.`);\n    util.assert(conv_util.eitherStridesOrDilationsAreOne(strides, dilations), () => 'Error in conv2D: Either strides or dilations must be 1. ' +\n        `Got strides ${strides} and dilations '${dilations}'`);\n    util.assert(dataFormat === 'NHWC', () => `Error in conv2d: got dataFormat of ${dataFormat} but only NHWC is currently supported.`);\n    const convInfo = conv_util.computeConv2DInfo(x4D.shape, $filter.shape, strides, dilations, pad, dimRoundingMode);\n    let $bias;\n    if (bias != null) {\n        $bias = convertToTensor(bias, 'bias', 'fused conv2d');\n        [$bias] = makeTypesMatch($bias, $x);\n        broadcast_util.assertAndGetBroadcastShape(convInfo.outShape, $bias.shape);\n    }\n    let $preluActivationWeights;\n    if (preluActivationWeights != null) {\n        $preluActivationWeights = convertToTensor(preluActivationWeights, 'prelu weights', 'fused conv2d');\n    }\n    const grad = (dy, saved) => {\n        const [$filter, x4D, y, $bias] = saved;\n        const dyActivation = getFusedDyActivation(dy, y, activation);\n        util.assert(conv_util.tupleValuesAreOne(dilations), () => 'Error in gradient of fused conv2D: ' +\n            `dilation rates greater than 1 ` +\n            `are not yet supported in gradients. Got dilations '${dilations}'`);\n        const xDer = conv2DBackpropInput(x4D.shape, dyActivation, $filter, strides, pad);\n        const filterDer = conv2DBackpropFilter(x4D, dyActivation, $filter.shape, strides, pad);\n        const der = [xDer, filterDer];\n        if ($bias != null) {\n            const biasDer = getFusedBiasGradient($bias, dyActivation);\n            der.push(biasDer);\n        }\n        return der;\n    };\n    const inputs = {\n        x: x4D,\n        filter: $filter,\n        bias: $bias,\n        preluActivationWeights: $preluActivationWeights\n    };\n    const attrs = {\n        strides,\n        pad,\n        dataFormat,\n        dilations,\n        dimRoundingMode,\n        activation,\n        leakyreluAlpha\n    };\n    // Depending on the the params passed in we will have different number of\n    // inputs and thus a a different number of elements in the gradient.\n    if (bias == null) {\n        const customOp = customGrad((x4D, filter, save) => {\n            let res = \n            // tslint:disable-next-line: no-unnecessary-type-assertion\n            ENGINE.runKernel(FusedConv2D, inputs, attrs);\n            save([filter, x4D, res]);\n            if (reshapedTo4D) {\n                // tslint:disable-next-line: no-unnecessary-type-assertion\n                res = reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);\n            }\n            return { value: res, gradFunc: grad };\n        });\n        return customOp(x4D, $filter);\n    }\n    else {\n        const customOpWithBias = customGrad((x4D, filter, bias, save) => {\n            let res = ENGINE.runKernel(FusedConv2D, inputs, attrs);\n            save([filter, x4D, res, bias]);\n            if (reshapedTo4D) {\n                // tslint:disable-next-line: no-unnecessary-type-assertion\n                res = reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);\n            }\n            return { value: res, gradFunc: grad };\n        });\n        return customOpWithBias(x4D, $filter, $bias);\n    }\n}\nexport const conv2d = op({ fusedConv2d_ });\n//# sourceMappingURL=conv2d.js.map","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../../engine';\nimport { customGrad } from '../../gradients';\nimport { FusedDepthwiseConv2D } from '../../kernel_names';\nimport { makeTypesMatch } from '../../tensor_util';\nimport { convertToTensor } from '../../tensor_util_env';\nimport * as util from '../../util';\nimport { add } from '../add';\nimport * as broadcast_util from '../broadcast_util';\nimport * as conv_util from '../conv_util';\nimport { depthwiseConv2d as unfusedDepthwiseConv2d } from '../depthwise_conv2d';\nimport { depthwiseConv2dNativeBackpropFilter } from '../depthwise_conv2d_native_backprop_filter';\nimport { depthwiseConv2dNativeBackpropInput } from '../depthwise_conv2d_native_backprop_input';\nimport { applyActivation, getFusedBiasGradient, getFusedDyActivation, shouldFuse } from '../fused_util';\nimport { op } from '../operation';\nimport { reshape } from '../reshape';\n/**\n * Computes depthwise 2D convolution, optionally fused with adding a\n * bias and applying an activation.\n *\n * Given a 4D `input` array and a `filter` array of shape\n * `[filterHeight, filterWidth, inChannels, channelMultiplier]` containing\n * `inChannels` convolutional filters of depth 1, this op applies a\n * different filter to each input channel (expanding from 1 channel to\n * `channelMultiplier` channels for each), then concatenates the results\n * together. The output has `inChannels * channelMultiplier` channels.\n *\n * See\n * [https://www.tensorflow.org/api_docs/python/tf/nn/depthwise_conv2d](\n *     https://www.tensorflow.org/api_docs/python/tf/nn/depthwise_conv2d)\n * for more details.\n *\n * @param obj An object with the following properties:\n * @param x The input tensor, of rank 4 or rank 3, of shape\n *     `[batch, height, width, inChannels]`. If rank 3, batch of 1 is\n * assumed.\n * @param filter The filter tensor, rank 4, of shape\n *     `[filterHeight, filterWidth, inChannels, channelMultiplier]`.\n * @param strides The strides of the convolution: `[strideHeight,\n * strideWidth]`. If strides is a single number, then `strideHeight ==\n * strideWidth`.\n * @param pad The type of padding algorithm.\n *   - `same` and stride 1: output will be of same size as input,\n *       regardless of filter size.\n *   - `valid`: output will be smaller than input if filter is larger\n *       than 1x1.\n *   - For more info, see this guide:\n *     [https://www.tensorflow.org/api_guides/python/nn#Convolution](\n *          https://www.tensorflow.org/api_guides/python/nn#Convolution)\n * @param dilations The dilation rates: `[dilationHeight, dilationWidth]`\n *     in which we sample input values across the height and width dimensions\n *     in atrous convolution. Defaults to `[1, 1]`. If `rate` is a single\n *     number, then `dilationHeight == dilationWidth`. If it is greater than\n *     1, then all values of `strides` must be 1.\n * @param dataFormat: An optional string from: \"NHWC\", \"NCHW\". Defaults to\n *     \"NHWC\". Specify the data format of the input and output data. With the\n *     default format \"NHWC\", the data is stored in the order of: [batch,\n *     height, width, channels]. Only \"NHWC\" is currently supported.\n * @param dimRoundingMode A string from: 'ceil', 'round', 'floor'. If none is\n *     provided, it will default to truncate.\n * @param bias Tensor to be added to the result.\n * @param activation Name of activation kernel (defaults to `linear`).\n * @param preluActivationWeights Tensor of prelu weights to be applied as part\n *     of a `prelu` activation, typically the same shape as `x`.\n * @param leakyreluAlpha Optional. Alpha to be applied as part of a `leakyrelu`\n *     activation.\n */\nfunction fusedDepthwiseConv2d_({ x, filter, strides, pad, dataFormat = 'NHWC', dilations = [1, 1], dimRoundingMode, bias, activation = 'linear', preluActivationWeights, leakyreluAlpha }) {\n    if (shouldFuse(ENGINE.state.gradientDepth, activation) === false) {\n        let result = unfusedDepthwiseConv2d(x, filter, strides, pad, dataFormat, dilations, dimRoundingMode);\n        if (bias != null) {\n            result = add(result, bias);\n        }\n        return applyActivation(result, activation, preluActivationWeights, leakyreluAlpha);\n    }\n    const $x = convertToTensor(x, 'x', 'depthwiseConv2d');\n    const $filter = convertToTensor(filter, 'filter', 'depthwiseConv2d');\n    let x4D = $x;\n    let reshapedTo4D = false;\n    if ($x.rank === 3) {\n        reshapedTo4D = true;\n        x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);\n    }\n    util.assert(x4D.rank === 4, () => `Error in fused depthwiseConv2d: input must be rank 4, but got ` +\n        `rank ${x4D.rank}.`);\n    util.assert($filter.rank === 4, () => `Error in fused depthwiseConv2d: filter must be rank 4, ` +\n        `but got rank ${$filter.rank}.`);\n    util.assert(x4D.shape[3] === $filter.shape[2], () => `Error in fused depthwiseConv2d: number of input channels ` +\n        `(${x4D.shape[3]}) must match the inChannels dimension in ` +\n        `filter ${$filter.shape[2]}.`);\n    if (dilations == null) {\n        dilations = [1, 1];\n    }\n    util.assert(conv_util.eitherStridesOrDilationsAreOne(strides, dilations), () => 'Error in fused depthwiseConv2d: Either strides or dilations must ' +\n        `be 1. Got strides ${strides} and dilations '${dilations}'`);\n    if (dimRoundingMode != null) {\n        util.assert(util.isInt(pad), () => `Error in fused depthwiseConv2d: pad must be an integer when ` +\n            `using dimRoundingMode ${dimRoundingMode} but got pad ${pad}.`);\n    }\n    const convInfo = conv_util.computeConv2DInfo(x4D.shape, $filter.shape, strides, dilations, pad, dimRoundingMode, true /* depthwise */);\n    let $bias;\n    if (bias != null) {\n        $bias = convertToTensor(bias, 'bias', 'fused conv2d');\n        [$bias] = makeTypesMatch($bias, $x);\n        broadcast_util.assertAndGetBroadcastShape(convInfo.outShape, $bias.shape);\n    }\n    let $preluActivationWeights;\n    if (preluActivationWeights != null) {\n        $preluActivationWeights = convertToTensor(preluActivationWeights, 'prelu weights', 'fused depthwiseConv2d');\n    }\n    const grad = (dy, saved) => {\n        util.assert(conv_util.tupleValuesAreOne(dilations), () => 'Error in gradient of fused depthwiseConv2d: dilation rates ' +\n            `greater than 1 are not yet supported. Got dilations ` +\n            `'${dilations}'`);\n        const [$filter, x4D, y, bias] = saved;\n        const dyActivation = getFusedDyActivation(dy, y, activation);\n        const xDer = depthwiseConv2dNativeBackpropInput(x4D.shape, dyActivation, $filter, strides, pad, dilations, dimRoundingMode);\n        const filterDer = depthwiseConv2dNativeBackpropFilter(x4D, dyActivation, $filter.shape, strides, pad, dilations, dimRoundingMode);\n        if (bias != null) {\n            const biasDer = getFusedBiasGradient($bias, dyActivation);\n            return [xDer, filterDer, biasDer];\n        }\n        return [xDer, filterDer];\n    };\n    const inputs = {\n        x: x4D,\n        filter: $filter,\n        bias: $bias,\n        preluActivationWeights: $preluActivationWeights\n    };\n    const attrs = {\n        strides,\n        pad,\n        dataFormat,\n        dilations,\n        dimRoundingMode,\n        activation,\n        leakyreluAlpha\n    };\n    // Depending on the the params passed in we will have different number of\n    // inputs and thus a a different number of elements in the gradient.\n    if (bias == null) {\n        const customOp = customGrad((x4D, filter, save) => {\n            // tslint:disable-next-line: no-unnecessary-type-assertion\n            let res = ENGINE.runKernel(FusedDepthwiseConv2D, inputs, attrs);\n            save([filter, x4D, res]);\n            if (reshapedTo4D) {\n                // tslint:disable-next-line: no-unnecessary-type-assertion\n                res = reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);\n            }\n            return { value: res, gradFunc: grad };\n        });\n        return customOp(x4D, $filter);\n    }\n    else {\n        const customOpWithBias = customGrad((x4D, filter, bias, save) => {\n            // tslint:disable-next-line: no-unnecessary-type-assertion\n            let res = ENGINE.runKernel(FusedDepthwiseConv2D, inputs, attrs);\n            save([filter, x4D, res, bias]);\n            if (reshapedTo4D) {\n                // tslint:disable-next-line: no-unnecessary-type-assertion\n                res = reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);\n            }\n            return { value: res, gradFunc: grad };\n        });\n        return customOpWithBias(x4D, $filter, $bias);\n    }\n}\nexport const depthwiseConv2d = op({ fusedDepthwiseConv2d_ });\n//# sourceMappingURL=depthwise_conv2d.js.map","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../../engine';\nimport { customGrad } from '../../gradients';\nimport { _FusedMatMul } from '../../kernel_names';\nimport { makeTypesMatch } from '../../tensor_util';\nimport { convertToTensor } from '../../tensor_util_env';\nimport * as util from '../../util';\nimport { add } from '../add';\nimport * as broadcast_util from '../broadcast_util';\nimport { applyActivation, getFusedBiasGradient, getFusedDyActivation, shouldFuse } from '../fused_util';\nimport { matMul as unfusedMatMul } from '../mat_mul';\nimport { op } from '../operation';\nimport { reshape } from '../reshape';\n/**\n * Computes the dot product of two matrices with optional activation and bias.\n *\n * ```js\n * const a = tf.tensor2d([-1, -2], [1, 2]);\n * const b = tf.tensor2d([1, 2, 3, 4], [2, 2]);\n * const bias = tf.tensor2d([1, 2], [1, 2]);\n *\n * tf.fused.matMul({a, b, bias, activation: 'relu'}).print();\n * ```\n *\n * @param obj An object with the following properties:\n * - `a` First matrix in dot product operation.\n * - `b` Second matrix in dot product operation.\n * - `transposeA` If true, `a` is transposed before multiplication.\n * - `transposeB` If true, `b` is transposed before multiplication.\n * - `bias` Matrix to be added to the result.\n * - `activation` Name of activation kernel (defaults to `linear`).\n * - `preluActivationWeights` Tensor of prelu weights.\n * - `leakyreluAlpha` Alpha of leakyrelu.\n */\nfunction fusedMatMul_({ a, b, transposeA = false, transposeB = false, bias, activation = 'linear', preluActivationWeights, leakyreluAlpha, }) {\n    if (shouldFuse(ENGINE.state.gradientDepth, activation) === false) {\n        let result = unfusedMatMul(a, b, transposeA, transposeB);\n        if (bias != null) {\n            result = add(result, bias);\n        }\n        return applyActivation(result, activation, preluActivationWeights, leakyreluAlpha);\n    }\n    let $a = convertToTensor(a, 'a', 'fused matMul');\n    let $b = convertToTensor(b, 'b', 'fused matMul');\n    [$a, $b] = makeTypesMatch($a, $b);\n    const innerShapeA = transposeA ? $a.shape[$a.rank - 2] : $a.shape[$a.rank - 1];\n    const innerShapeB = transposeB ? $b.shape[$b.rank - 1] : $b.shape[$b.rank - 2];\n    const outerShapeA = transposeA ? $a.shape[$a.rank - 1] : $a.shape[$a.rank - 2];\n    const outerShapeB = transposeB ? $b.shape[$b.rank - 2] : $b.shape[$b.rank - 1];\n    const outerDimsA = $a.shape.slice(0, -2);\n    const outerDimsB = $b.shape.slice(0, -2);\n    const batchDimA = util.sizeFromShape(outerDimsA);\n    const batchDimB = util.sizeFromShape(outerDimsB);\n    util.assert($a.rank >= 2 && $b.rank >= 2 && $a.rank === $b.rank, () => `Error in fused matMul: inputs must have the same rank of at ` +\n        `least 2, got ranks ${$a.rank} and ${$b.rank}.`);\n    util.assert(util.arraysEqual(outerDimsA, outerDimsB), () => `Error in fused matMul: outer dimensions (${outerDimsA}) and (` +\n        `${outerDimsB}) of Tensors with shapes ${$a.shape} and ` +\n        `${$b.shape} must match.`);\n    util.assert(innerShapeA === innerShapeB, () => `Error in fused matMul: inner shapes (${innerShapeA}) and (` +\n        `${innerShapeB}) of Tensors with shapes ${$a.shape} and ` +\n        `${$b.shape} and transposeA=${transposeA}` +\n        ` and transposeB=${transposeB} must match.`);\n    const outShape = $a.shape.slice(0, -2).concat([outerShapeA, outerShapeB]);\n    const a3D = transposeA ?\n        reshape($a, [batchDimA, innerShapeA, outerShapeA]) :\n        reshape($a, [batchDimA, outerShapeA, innerShapeA]);\n    const b3D = transposeB ?\n        reshape($b, [batchDimB, outerShapeB, innerShapeB]) :\n        reshape($b, [batchDimB, innerShapeB, outerShapeB]);\n    let $bias;\n    if (bias != null) {\n        $bias = convertToTensor(bias, 'bias', 'fused matMul');\n        [$bias] = makeTypesMatch($bias, $a);\n        broadcast_util.assertAndGetBroadcastShape(outShape, $bias.shape);\n    }\n    let $preluActivationWeights;\n    if (preluActivationWeights != null) {\n        $preluActivationWeights = convertToTensor(preluActivationWeights, 'prelu weights', 'fused matMul');\n    }\n    const grad = (dy, saved) => {\n        const [a3D, b3D, y, $bias] = saved;\n        // we reshape dy because the result of the forward is not\n        // necessarily going to be a 3d tensor due to a reshape done at the end of\n        // the customOp.\n        const dyActivation = getFusedDyActivation(reshape(dy, y.shape), y, activation);\n        let aDer;\n        let bDer;\n        if (!transposeA && !transposeB) {\n            aDer = unfusedMatMul(dyActivation, b3D, false, true);\n            bDer = unfusedMatMul(a3D, dyActivation, true, false);\n        }\n        else if (!transposeA && transposeB) {\n            aDer = unfusedMatMul(dyActivation, b3D, false, false);\n            bDer = unfusedMatMul(dyActivation, a3D, true, false);\n        }\n        else if (transposeA && !transposeB) {\n            aDer = unfusedMatMul(b3D, dyActivation, false, true);\n            bDer = unfusedMatMul(a3D, dyActivation, false, false);\n        }\n        else {\n            aDer = unfusedMatMul(b3D, dyActivation, true, true);\n            bDer = unfusedMatMul(dyActivation, a3D, true, true);\n        }\n        if (bias != null) {\n            const biasDer = getFusedBiasGradient($bias, dyActivation);\n            return [aDer, bDer, biasDer];\n        }\n        else {\n            return [aDer, bDer];\n        }\n    };\n    const inputs = {\n        a: a3D,\n        b: b3D,\n        bias: $bias,\n        preluActivationWeights: $preluActivationWeights\n    };\n    const attrs = { transposeA, transposeB, activation, leakyreluAlpha };\n    // Depending on the the params passed in we will have different number of\n    // inputs and thus a a different number of elements in the gradient.\n    if (bias == null) {\n        const customOp = customGrad((a3D, b3D, save) => {\n            const res = \n            // tslint:disable-next-line: no-unnecessary-type-assertion\n            ENGINE.runKernel(_FusedMatMul, inputs, attrs);\n            save([a3D, b3D, res]);\n            return { value: reshape(res, outShape), gradFunc: grad };\n        });\n        return customOp(a3D, b3D);\n    }\n    else {\n        const customOpWithBias = customGrad((a3D, b3D, $bias, save) => {\n            const res = \n            // tslint:disable-next-line: no-unnecessary-type-assertion\n            ENGINE.runKernel(_FusedMatMul, inputs, attrs);\n            save([a3D, b3D, res, $bias]);\n            return { value: reshape(res, outShape), gradFunc: grad };\n        });\n        return customOpWithBias(a3D, b3D, $bias);\n    }\n}\nexport const matMul = op({ fusedMatMul_ });\n//# sourceMappingURL=mat_mul.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../../engine';\nimport { FlipLeftRight } from '../../kernel_names';\nimport { convertToTensor } from '../../tensor_util_env';\nimport * as util from '../../util';\nimport { op } from '../operation';\n/**\n * Flips the image left to right. Currently available in the CPU, WebGL, and\n * WASM backends.\n *\n * @param image 4d tensor of shape `[batch, imageHeight, imageWidth, depth]`.\n */\n/** @doc {heading: 'Operations', subheading: 'Images', namespace: 'image'} */\nfunction flipLeftRight_(image) {\n    const $image = convertToTensor(image, 'image', 'flipLeftRight', 'float32');\n    util.assert($image.rank === 4, () => 'Error in flipLeftRight: image must be rank 4,' +\n        `but got rank ${$image.rank}.`);\n    const inputs = { image: $image };\n    const res = ENGINE.runKernel(FlipLeftRight, inputs, {});\n    return res;\n}\nexport const flipLeftRight = op({ flipLeftRight_ });\n//# sourceMappingURL=flip_left_right.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../../engine';\nimport { ResizeNearestNeighbor } from '../../kernel_names';\nimport { convertToTensor } from '../../tensor_util_env';\nimport * as util from '../../util';\nimport { op } from '../operation';\nimport { reshape } from '../reshape';\n/**\n * NearestNeighbor resize a batch of 3D images to a new shape.\n *\n * @param images The images, of rank 4 or rank 3, of shape\n *     `[batch, height, width, inChannels]`. If rank 3, batch of 1 is assumed.\n * @param size The new shape `[newHeight, newWidth]` to resize the\n *     images to. Each channel is resized individually.\n * @param alignCorners Defaults to False. If true, rescale\n *     input by `(new_height - 1) / (height - 1)`, which exactly aligns the 4\n *     corners of images and resized images. If false, rescale by\n *     `new_height / height`. Treat similarly the width dimension.\n * @param halfPixelCenters Defaults to `false`. Whether to assumes pixels are of\n *      half the actual dimensions, and yields more accurate resizes. This flag\n *      would also make the floating point coordinates of the top left pixel\n *      0.5, 0.5.\n *\n * @doc {heading: 'Operations', subheading: 'Images', namespace: 'image'}\n */\nfunction resizeNearestNeighbor_(images, size, alignCorners = false, halfPixelCenters = false) {\n    const $images = convertToTensor(images, 'images', 'resizeNearestNeighbor');\n    util.assert($images.rank === 3 || $images.rank === 4, () => `Error in resizeNearestNeighbor: x must be rank 3 or 4, but got ` +\n        `rank ${$images.rank}.`);\n    util.assert(size.length === 2, () => `Error in resizeNearestNeighbor: new shape must 2D, but got shape ` +\n        `${size}.`);\n    util.assert($images.dtype === 'float32' || $images.dtype === 'int32', () => '`images` must have `int32` or `float32` as dtype');\n    util.assert(halfPixelCenters === false || alignCorners === false, () => `Error in resizeNearestNeighbor: If halfPixelCenters is true, ` +\n        `alignCorners must be false.`);\n    let batchImages = $images;\n    let reshapedTo4D = false;\n    if ($images.rank === 3) {\n        reshapedTo4D = true;\n        batchImages = reshape($images, [1, $images.shape[0], $images.shape[1], $images.shape[2]]);\n    }\n    const [] = size;\n    const inputs = { images: batchImages };\n    const attrs = { alignCorners, halfPixelCenters, size };\n    // tslint:disable-next-line: no-unnecessary-type-assertion\n    const res = ENGINE.runKernel(ResizeNearestNeighbor, inputs, attrs);\n    if (reshapedTo4D) {\n        return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);\n    }\n    return res;\n}\nexport const resizeNearestNeighbor = op({ resizeNearestNeighbor_ });\n//# sourceMappingURL=resize_nearest_neighbor.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../../engine';\nimport { ResizeBilinear } from '../../kernel_names';\nimport { convertToTensor } from '../../tensor_util_env';\nimport * as util from '../../util';\nimport { op } from '../operation';\nimport { reshape } from '../reshape';\n/**\n * Bilinear resize a single 3D image or a batch of 3D images to a new shape.\n *\n * @param images The images, of rank 4 or rank 3, of shape\n *     `[batch, height, width, inChannels]`. If rank 3, batch of 1 is assumed.\n * @param size The new shape `[newHeight, newWidth]` to resize the\n *     images to. Each channel is resized individually.\n * @param alignCorners Defaults to `false`. If true, rescale\n *     input by `(new_height - 1) / (height - 1)`, which exactly aligns the 4\n *     corners of images and resized images. If false, rescale by\n *     `new_height / height`. Treat similarly the width dimension.\n * @param halfPixelCenters Defaults to `false`. Whether to assume pixel centers\n *     are at 0.5, which would make the floating point coordinates of the top\n *     left pixel 0.5, 0.5.\n *\n * @doc {heading: 'Operations', subheading: 'Images', namespace: 'image'}\n */\nfunction resizeBilinear_(images, size, alignCorners = false, halfPixelCenters = false) {\n    const $images = convertToTensor(images, 'images', 'resizeBilinear');\n    util.assert($images.rank === 3 || $images.rank === 4, () => `Error in resizeBilinear: x must be rank 3 or 4, but got ` +\n        `rank ${$images.rank}.`);\n    util.assert(size.length === 2, () => `Error in resizeBilinear: new shape must 2D, but got shape ` +\n        `${size}.`);\n    util.assert(halfPixelCenters === false || alignCorners === false, () => `Error in resizeBilinear: If halfPixelCenters is true, ` +\n        `alignCorners must be false.`);\n    let batchImages = $images;\n    let reshapedTo4D = false;\n    if ($images.rank === 3) {\n        reshapedTo4D = true;\n        batchImages = reshape($images, [1, $images.shape[0], $images.shape[1], $images.shape[2]]);\n    }\n    const [] = size;\n    const inputs = { images: batchImages };\n    const attrs = { alignCorners, halfPixelCenters, size };\n    // tslint:disable-next-line: no-unnecessary-type-assertion\n    const res = ENGINE.runKernel(ResizeBilinear, inputs, attrs);\n    if (reshapedTo4D) {\n        return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);\n    }\n    return res;\n}\nexport const resizeBilinear = op({ resizeBilinear_ });\n//# sourceMappingURL=resize_bilinear.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../../engine';\nimport { RotateWithOffset } from '../../kernel_names';\nimport { convertToTensor } from '../../tensor_util_env';\nimport * as util from '../../util';\nimport { op } from '../operation';\n/**\n * Rotates the input image tensor counter-clockwise with an optional offset\n * center of rotation. Currently available in the CPU, WebGL, and WASM backends.\n *\n * @param image 4d tensor of shape `[batch, imageHeight, imageWidth, depth]`.\n * @param radians The amount of rotation.\n * @param fillValue The value to fill in the empty space leftover\n *     after rotation. Can be either a single grayscale value (0-255), or an\n *     array of three numbers `[red, green, blue]` specifying the red, green,\n *     and blue channels. Defaults to `0` (black).\n * @param center The center of rotation. Can be either a single value (0-1), or\n *     an array of two numbers `[centerX, centerY]`. Defaults to `0.5` (rotates\n *     the image around its center).\n *\n * @doc {heading: 'Operations', subheading: 'Images', namespace: 'image'}\n */\nfunction rotateWithOffset_(image, radians, fillValue = 0, center = 0.5) {\n    const $image = convertToTensor(image, 'image', 'rotateWithOffset', 'float32');\n    util.assert($image.rank === 4, () => 'Error in rotateWithOffset: image must be rank 4,' +\n        `but got rank ${$image.rank}.`);\n    const inputs = { image: $image };\n    const attrs = { radians, fillValue, center };\n    const res = ENGINE.runKernel(RotateWithOffset, inputs, attrs);\n    return res;\n}\nexport const rotateWithOffset = op({ rotateWithOffset_ });\n//# sourceMappingURL=rotate_with_offset.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../../engine';\nimport { CropAndResize } from '../../kernel_names';\nimport { convertToTensor } from '../../tensor_util_env';\nimport * as util from '../../util';\nimport { op } from '../operation';\n/**\n * Extracts crops from the input image tensor and resizes them using bilinear\n * sampling or nearest neighbor sampling (possibly with aspect ratio change)\n * to a common output size specified by cropSize.\n *\n * @param image 4d tensor of shape `[batch,imageHeight,imageWidth, depth]`,\n *     where imageHeight and imageWidth must be positive, specifying the\n *     batch of images from which to take crops\n * @param boxes 2d float32 tensor of shape `[numBoxes, 4]`. Each entry is\n *     `[y1, x1, y2, x2]`, where `(y1, x1)` and `(y2, x2)` are the normalized\n *     coordinates of the box in the boxInd[i]'th image in the batch\n * @param boxInd 1d int32 tensor of shape `[numBoxes]` with values in range\n *     `[0, batch)` that specifies the image that the `i`-th box refers to.\n * @param cropSize 1d int32 tensor of 2 elements `[cropHeigh, cropWidth]`\n *     specifying the size to which all crops are resized to.\n * @param method Optional string from `'bilinear' | 'nearest'`,\n *     defaults to bilinear, which specifies the sampling method for resizing\n * @param extrapolationValue A threshold for deciding when to remove boxes based\n *     on score. Defaults to 0.\n * @return A 4D tensor of the shape `[numBoxes,cropHeight,cropWidth,depth]`\n *\n * @doc {heading: 'Operations', subheading: 'Images', namespace: 'image'}\n */\nfunction cropAndResize_(image, boxes, boxInd, cropSize, method = 'bilinear', extrapolationValue = 0) {\n    const $image = convertToTensor(image, 'image', 'cropAndResize');\n    const $boxes = convertToTensor(boxes, 'boxes', 'cropAndResize', 'float32');\n    const $boxInd = convertToTensor(boxInd, 'boxInd', 'cropAndResize', 'int32');\n    const numBoxes = $boxes.shape[0];\n    util.assert($image.rank === 4, () => 'Error in cropAndResize: image must be rank 4,' +\n        `but got rank ${$image.rank}.`);\n    util.assert($boxes.rank === 2 && $boxes.shape[1] === 4, () => `Error in cropAndResize: boxes must be have size [${numBoxes},4] ` +\n        `but had shape ${$boxes.shape}.`);\n    util.assert($boxInd.rank === 1 && $boxInd.shape[0] === numBoxes, () => `Error in cropAndResize: boxInd must be have size [${numBoxes}] ` +\n        `but had shape ${$boxes.shape}.`);\n    util.assert(cropSize.length === 2, () => `Error in cropAndResize: cropSize must be of length 2, but got ` +\n        `length ${cropSize.length}.`);\n    util.assert(cropSize[0] >= 1 && cropSize[1] >= 1, () => `cropSize must be atleast [1,1], but was ${cropSize}`);\n    util.assert(method === 'bilinear' || method === 'nearest', () => `method must be bilinear or nearest, but was ${method}`);\n    const inputs = { image: $image, boxes: $boxes, boxInd: $boxInd };\n    const attrs = { method, extrapolationValue, cropSize };\n    const res = ENGINE.runKernel(CropAndResize, inputs, attrs);\n    return res;\n}\nexport const cropAndResize = op({ cropAndResize_ });\n//# sourceMappingURL=crop_and_resize.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../../engine';\nimport { NonMaxSuppressionV3 } from '../../kernel_names';\nimport { convertToTensor } from '../../tensor_util_env';\nimport { nonMaxSuppSanityCheck } from '../nonmax_util';\nimport { op } from '../operation';\n/**\n * Performs non maximum suppression of bounding boxes based on\n * iou (intersection over union).\n *\n * @param boxes a 2d tensor of shape `[numBoxes, 4]`. Each entry is\n *     `[y1, x1, y2, x2]`, where `(y1, x1)` and `(y2, x2)` are the corners of\n *     the bounding box.\n * @param scores a 1d tensor providing the box scores of shape `[numBoxes]`.\n * @param maxOutputSize The maximum number of boxes to be selected.\n * @param iouThreshold A float representing the threshold for deciding whether\n *     boxes overlap too much with respect to IOU. Must be between [0, 1].\n *     Defaults to 0.5 (50% box overlap).\n * @param scoreThreshold A threshold for deciding when to remove boxes based\n *     on score. Defaults to -inf, which means any score is accepted.\n * @return A 1D tensor with the selected box indices.\n *\n * @doc {heading: 'Operations', subheading: 'Images', namespace: 'image'}\n */\nfunction nonMaxSuppression_(boxes, scores, maxOutputSize, iouThreshold = 0.5, scoreThreshold = Number.NEGATIVE_INFINITY) {\n    const $boxes = convertToTensor(boxes, 'boxes', 'nonMaxSuppression');\n    const $scores = convertToTensor(scores, 'scores', 'nonMaxSuppression');\n    const inputs = nonMaxSuppSanityCheck($boxes, $scores, maxOutputSize, iouThreshold, scoreThreshold);\n    maxOutputSize = inputs.maxOutputSize;\n    iouThreshold = inputs.iouThreshold;\n    scoreThreshold = inputs.scoreThreshold;\n    const attrs = { maxOutputSize, iouThreshold, scoreThreshold };\n    return ENGINE.runKernel(NonMaxSuppressionV3, { boxes: $boxes, scores: $scores }, attrs);\n}\nexport const nonMaxSuppression = op({ nonMaxSuppression_ });\n//# sourceMappingURL=non_max_suppression.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { nonMaxSuppressionV3Impl } from '../../backends/non_max_suppression_impl';\nimport { convertToTensor } from '../../tensor_util_env';\nimport { nonMaxSuppSanityCheck } from '../nonmax_util';\nimport { tensor1d } from '../tensor1d';\n/**\n * Performs non maximum suppression of bounding boxes based on\n * iou (intersection over union).\n *\n * This is the async version of `nonMaxSuppression`\n *\n * @param boxes a 2d tensor of shape `[numBoxes, 4]`. Each entry is\n *     `[y1, x1, y2, x2]`, where `(y1, x1)` and `(y2, x2)` are the corners of\n *     the bounding box.\n * @param scores a 1d tensor providing the box scores of shape `[numBoxes]`.\n * @param maxOutputSize The maximum number of boxes to be selected.\n * @param iouThreshold A float representing the threshold for deciding whether\n *     boxes overlap too much with respect to IOU. Must be between [0, 1].\n *     Defaults to 0.5 (50% box overlap).\n * @param scoreThreshold A threshold for deciding when to remove boxes based\n *     on score. Defaults to -inf, which means any score is accepted.\n * @return A 1D tensor with the selected box indices.\n *\n * @doc {heading: 'Operations', subheading: 'Images', namespace: 'image'}\n */\nasync function nonMaxSuppressionAsync_(boxes, scores, maxOutputSize, iouThreshold = 0.5, scoreThreshold = Number.NEGATIVE_INFINITY) {\n    const $boxes = convertToTensor(boxes, 'boxes', 'nonMaxSuppressionAsync');\n    const $scores = convertToTensor(scores, 'scores', 'nonMaxSuppressionAsync');\n    const inputs = nonMaxSuppSanityCheck($boxes, $scores, maxOutputSize, iouThreshold, scoreThreshold);\n    maxOutputSize = inputs.maxOutputSize;\n    iouThreshold = inputs.iouThreshold;\n    scoreThreshold = inputs.scoreThreshold;\n    const boxesAndScores = await Promise.all([$boxes.data(), $scores.data()]);\n    const boxesVals = boxesAndScores[0];\n    const scoresVals = boxesAndScores[1];\n    // We call a cpu based impl directly with the typedarray data  here rather\n    // than a kernel because all kernels are synchronous (and thus cannot await\n    // .data()).\n    const { selectedIndices } = nonMaxSuppressionV3Impl(boxesVals, scoresVals, maxOutputSize, iouThreshold, scoreThreshold);\n    if ($boxes !== boxes) {\n        $boxes.dispose();\n    }\n    if ($scores !== scores) {\n        $scores.dispose();\n    }\n    return tensor1d(selectedIndices, 'int32');\n}\nexport const nonMaxSuppressionAsync = nonMaxSuppressionAsync_;\n//# sourceMappingURL=non_max_suppression_async.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../../engine';\nimport { NonMaxSuppressionV5 } from '../../kernel_names';\nimport { convertToTensor } from '../../tensor_util_env';\nimport { nonMaxSuppSanityCheck } from '../nonmax_util';\nimport { op } from '../operation';\n/**\n * Performs non maximum suppression of bounding boxes based on\n * iou (intersection over union).\n *\n * This op also supports a Soft-NMS mode (c.f.\n * Bodla et al, https://arxiv.org/abs/1704.04503) where boxes reduce the score\n * of other overlapping boxes, therefore favoring different regions of the image\n * with high scores. To enable this Soft-NMS mode, set the `softNmsSigma`\n * parameter to be larger than 0.\n *\n * @param boxes a 2d tensor of shape `[numBoxes, 4]`. Each entry is\n *     `[y1, x1, y2, x2]`, where `(y1, x1)` and `(y2, x2)` are the corners of\n *     the bounding box.\n * @param scores a 1d tensor providing the box scores of shape `[numBoxes]`.\n * @param maxOutputSize The maximum number of boxes to be selected.\n * @param iouThreshold A float representing the threshold for deciding whether\n *     boxes overlap too much with respect to IOU. Must be between [0, 1].\n *     Defaults to 0.5 (50% box overlap).\n * @param scoreThreshold A threshold for deciding when to remove boxes based\n *     on score. Defaults to -inf, which means any score is accepted.\n * @param softNmsSigma A float representing the sigma parameter for Soft NMS.\n *     When sigma is 0, it falls back to nonMaxSuppression.\n * @return A map with the following properties:\n *     - selectedIndices: A 1D tensor with the selected box indices.\n *     - selectedScores: A 1D tensor with the corresponding scores for each\n *       selected box.\n *\n * @doc {heading: 'Operations', subheading: 'Images', namespace: 'image'}\n */\nfunction nonMaxSuppressionWithScore_(boxes, scores, maxOutputSize, iouThreshold = 0.5, scoreThreshold = Number.NEGATIVE_INFINITY, softNmsSigma = 0.0) {\n    const $boxes = convertToTensor(boxes, 'boxes', 'nonMaxSuppression');\n    const $scores = convertToTensor(scores, 'scores', 'nonMaxSuppression');\n    const params = nonMaxSuppSanityCheck($boxes, $scores, maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma);\n    maxOutputSize = params.maxOutputSize;\n    iouThreshold = params.iouThreshold;\n    scoreThreshold = params.scoreThreshold;\n    softNmsSigma = params.softNmsSigma;\n    const inputs = { boxes: $boxes, scores: $scores };\n    const attrs = { maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma };\n    // tslint:disable-next-line: no-unnecessary-type-assertion\n    const result = ENGINE.runKernel(NonMaxSuppressionV5, inputs, attrs);\n    return { selectedIndices: result[0], selectedScores: result[1] };\n}\nexport const nonMaxSuppressionWithScore = op({ nonMaxSuppressionWithScore_ });\n//# sourceMappingURL=non_max_suppression_with_score.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { nonMaxSuppressionV5Impl } from '../../backends/non_max_suppression_impl';\nimport { convertToTensor } from '../../tensor_util_env';\nimport { nonMaxSuppSanityCheck } from '../nonmax_util';\nimport { tensor1d } from '../tensor1d';\n/**\n * Asynchronously performs non maximum suppression of bounding boxes based on\n * iou (intersection over union).\n *\n * This op also supports a Soft-NMS mode (c.f.\n * Bodla et al, https://arxiv.org/abs/1704.04503) where boxes reduce the score\n * of other overlapping boxes, therefore favoring different regions of the image\n * with high scores. To enable this Soft-NMS mode, set the `softNmsSigma`\n * parameter to be larger than 0.\n *\n * @param boxes a 2d tensor of shape `[numBoxes, 4]`. Each entry is\n *     `[y1, x1, y2, x2]`, where `(y1, x1)` and `(y2, x2)` are the corners of\n *     the bounding box.\n * @param scores a 1d tensor providing the box scores of shape `[numBoxes]`.\n * @param maxOutputSize The maximum number of boxes to be selected.\n * @param iouThreshold A float representing the threshold for deciding whether\n *     boxes overlap too much with respect to IOU. Must be between [0, 1].\n *     Defaults to 0.5 (50% box overlap).\n * @param scoreThreshold A threshold for deciding when to remove boxes based\n *     on score. Defaults to -inf, which means any score is accepted.\n * @param softNmsSigma A float representing the sigma parameter for Soft NMS.\n *     When sigma is 0, it falls back to nonMaxSuppression.\n * @return A map with the following properties:\n *     - selectedIndices: A 1D tensor with the selected box indices.\n *     - selectedScores: A 1D tensor with the corresponding scores for each\n *       selected box.\n *\n * @doc {heading: 'Operations', subheading: 'Images', namespace: 'image'}\n */\nasync function nonMaxSuppressionWithScoreAsync_(boxes, scores, maxOutputSize, iouThreshold = 0.5, scoreThreshold = Number.NEGATIVE_INFINITY, softNmsSigma = 0.0) {\n    const $boxes = convertToTensor(boxes, 'boxes', 'nonMaxSuppressionAsync');\n    const $scores = convertToTensor(scores, 'scores', 'nonMaxSuppressionAsync');\n    const params = nonMaxSuppSanityCheck($boxes, $scores, maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma);\n    maxOutputSize = params.maxOutputSize;\n    iouThreshold = params.iouThreshold;\n    scoreThreshold = params.scoreThreshold;\n    softNmsSigma = params.softNmsSigma;\n    const boxesAndScores = await Promise.all([$boxes.data(), $scores.data()]);\n    const boxesVals = boxesAndScores[0];\n    const scoresVals = boxesAndScores[1];\n    // We call a cpu based impl directly with the typedarray data  here rather\n    // than a kernel because all kernels are synchronous (and thus cannot await\n    // .data()).\n    const { selectedIndices, selectedScores } = nonMaxSuppressionV5Impl(boxesVals, scoresVals, maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma);\n    if ($boxes !== boxes) {\n        $boxes.dispose();\n    }\n    if ($scores !== scores) {\n        $scores.dispose();\n    }\n    return {\n        selectedIndices: tensor1d(selectedIndices, 'int32'),\n        selectedScores: tensor1d(selectedScores)\n    };\n}\nexport const nonMaxSuppressionWithScoreAsync = nonMaxSuppressionWithScoreAsync_;\n//# sourceMappingURL=non_max_suppression_with_score_async.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../../engine';\nimport { NonMaxSuppressionV4 } from '../../kernel_names';\nimport { convertToTensor } from '../../tensor_util_env';\nimport { nonMaxSuppSanityCheck } from '../nonmax_util';\nimport { op } from '../operation';\n/**\n * Asynchronously performs non maximum suppression of bounding boxes based on\n * iou (intersection over union), with an option to pad results.\n *\n * @param boxes a 2d tensor of shape `[numBoxes, 4]`. Each entry is\n *     `[y1, x1, y2, x2]`, where `(y1, x1)` and `(y2, x2)` are the corners of\n *     the bounding box.\n * @param scores a 1d tensor providing the box scores of shape `[numBoxes]`.\n * @param maxOutputSize The maximum number of boxes to be selected.\n * @param iouThreshold A float representing the threshold for deciding whether\n *     boxes overlap too much with respect to IOU. Must be between [0, 1].\n *     Defaults to 0.5 (50% box overlap).\n * @param scoreThreshold A threshold for deciding when to remove boxes based\n *     on score. Defaults to -inf, which means any score is accepted.\n * @param padToMaxOutputSize Defalts to false. If true, size of output\n *     `selectedIndices` is padded to maxOutputSize.\n * @return A map with the following properties:\n *     - selectedIndices: A 1D tensor with the selected box indices.\n *     - validOutputs: A scalar denoting how many elements in `selectedIndices`\n *       are valid. Valid elements occur first, then padding.\n *\n * @doc {heading: 'Operations', subheading: 'Images', namespace: 'image'}\n */\nfunction nonMaxSuppressionPadded_(boxes, scores, maxOutputSize, iouThreshold = 0.5, scoreThreshold = Number.NEGATIVE_INFINITY, padToMaxOutputSize = false) {\n    const $boxes = convertToTensor(boxes, 'boxes', 'nonMaxSuppression');\n    const $scores = convertToTensor(scores, 'scores', 'nonMaxSuppression');\n    const params = nonMaxSuppSanityCheck($boxes, $scores, maxOutputSize, iouThreshold, scoreThreshold, null /* softNmsSigma */);\n    const $maxOutputSize = params.maxOutputSize;\n    const $iouThreshold = params.iouThreshold;\n    const $scoreThreshold = params.scoreThreshold;\n    const inputs = { boxes: $boxes, scores: $scores };\n    const attrs = {\n        maxOutputSize: $maxOutputSize,\n        iouThreshold: $iouThreshold,\n        scoreThreshold: $scoreThreshold,\n        padToMaxOutputSize\n    };\n    // tslint:disable-next-line: no-unnecessary-type-assertion\n    const result = ENGINE.runKernel(NonMaxSuppressionV4, inputs, attrs);\n    return { selectedIndices: result[0], validOutputs: result[1] };\n}\nexport const nonMaxSuppressionPadded = op({ nonMaxSuppressionPadded_ });\n//# sourceMappingURL=non_max_suppression_padded.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { nonMaxSuppressionV4Impl } from '../../backends/non_max_suppression_impl';\nimport { convertToTensor } from '../../tensor_util_env';\nimport { nonMaxSuppSanityCheck } from '../nonmax_util';\nimport { scalar } from '../scalar';\nimport { tensor1d } from '../tensor1d';\n/**\n * Asynchronously performs non maximum suppression of bounding boxes based on\n * iou (intersection over union), with an option to pad results.\n *\n * @param boxes a 2d tensor of shape `[numBoxes, 4]`. Each entry is\n *     `[y1, x1, y2, x2]`, where `(y1, x1)` and `(y2, x2)` are the corners of\n *     the bounding box.\n * @param scores a 1d tensor providing the box scores of shape `[numBoxes]`.\n * @param maxOutputSize The maximum number of boxes to be selected.\n * @param iouThreshold A float representing the threshold for deciding whether\n *     boxes overlap too much with respect to IOU. Must be between [0, 1].\n *     Defaults to 0.5 (50% box overlap).\n * @param scoreThreshold A threshold for deciding when to remove boxes based\n *     on score. Defaults to -inf, which means any score is accepted.\n * @param padToMaxOutputSize Defalts to false. If true, size of output\n *     `selectedIndices` is padded to maxOutputSize.\n * @return A map with the following properties:\n *     - selectedIndices: A 1D tensor with the selected box indices.\n *     - validOutputs: A scalar denoting how many elements in `selectedIndices`\n *       are valid. Valid elements occur first, then padding.\n *\n * @doc {heading: 'Operations', subheading: 'Images', namespace: 'image'}\n */\nasync function nonMaxSuppressionPaddedAsync_(boxes, scores, maxOutputSize, iouThreshold = 0.5, scoreThreshold = Number.NEGATIVE_INFINITY, padToMaxOutputSize = false) {\n    const $boxes = convertToTensor(boxes, 'boxes', 'nonMaxSuppressionAsync');\n    const $scores = convertToTensor(scores, 'scores', 'nonMaxSuppressionAsync');\n    const params = nonMaxSuppSanityCheck($boxes, $scores, maxOutputSize, iouThreshold, scoreThreshold, null /* softNmsSigma */);\n    const $maxOutputSize = params.maxOutputSize;\n    const $iouThreshold = params.iouThreshold;\n    const $scoreThreshold = params.scoreThreshold;\n    const [boxesVals, scoresVals] = await Promise.all([$boxes.data(), $scores.data()]);\n    // We call a cpu based impl directly with the typedarray data here rather\n    // than a kernel because all kernels are synchronous (and thus cannot await\n    // .data()).\n    const { selectedIndices, validOutputs } = nonMaxSuppressionV4Impl(boxesVals, scoresVals, $maxOutputSize, $iouThreshold, $scoreThreshold, padToMaxOutputSize);\n    if ($boxes !== boxes) {\n        $boxes.dispose();\n    }\n    if ($scores !== scores) {\n        $scores.dispose();\n    }\n    return {\n        selectedIndices: tensor1d(selectedIndices, 'int32'),\n        validOutputs: scalar(validOutputs, 'int32')\n    };\n}\nexport const nonMaxSuppressionPaddedAsync = nonMaxSuppressionPaddedAsync_;\n//# sourceMappingURL=non_max_suppression_padded_async.js.map","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { tensor1d } from '../tensor1d';\nimport { op } from '../operation';\nimport { cast } from '../cast';\nimport { split } from '../split';\nimport { bincount } from '../bincount';\nimport { lessEqual } from '../less_equal';\nimport { greater } from '../greater';\nimport { sum } from '../sum';\nimport { add } from '../add';\nimport { mul } from '../mul';\nimport { div } from '../div';\nimport { sub } from '../sub';\nimport { round } from '../round';\nimport { where } from '../where';\nimport { fill } from '../fill';\nimport { slice } from '../slice';\nimport { range } from '../range';\nimport { tensor } from '../tensor';\nimport * as util from '../../util';\nimport { convertToTensor } from '../../tensor_util_env';\n/**\n * Performs image binarization with corresponding threshold\n * (depends on the method)value, which creates a binary image from a grayscale.\n * @param image 3d tensor of shape [imageHeight,imageWidth, depth],\n * where imageHeight and imageWidth must be positive.The image color\n * range should be [0, 255].\n * @param method Optional string from `'binary' | 'otsu'`\n * which specifies the method for thresholding. Defaults to 'binary'.\n * @param inverted Optional boolean whichspecifies\n * if colours should be inverted. Defaults to false.\n * @param threshValue Optional number which defines threshold value from 0 to 1.\n * Defaults to 0.5.\n * @return A 3d tensor of shape [imageHeight,imageWidth, depth], which\n * contains binarized image.\n */\nfunction threshold_(image, method = 'binary', inverted = false, threshValue = 0.5) {\n    const $image = convertToTensor(image, 'image', 'threshold');\n    /* 0.2989, 0.5870, 0.1140 are represent luma coefficients in CCIR601.\n    Reference for converting between RGB and grayscale: https://en.wikipedia.org/wiki/Luma_%28video%29  */\n    const RED_INTENCITY_COEF = 0.2989;\n    const GREEN_INTENCITY_COEF = 0.5870;\n    const BLUE_INTENCITY_COEF = 0.1140;\n    const totalPixelsInImage = $image.shape[0] * $image.shape[1];\n    let $threshold = mul(tensor1d([threshValue]), 255);\n    let r, g, b, grayscale;\n    util.assert($image.rank === 3, () => 'Error in threshold: image must be rank 3,' +\n        `but got rank ${$image.rank}.`);\n    util.assert($image.shape[2] === 3 || $image.shape[2] === 1, () => 'Error in threshold: ' +\n        'image color channel must be equal to 3 or 1' +\n        `but got ${$image.shape[2]}.`);\n    util.assert($image.dtype === 'int32' || $image.dtype === 'float32', () => 'Error in dtype: image dtype must be int32 or float32,' +\n        `but got dtype ${$image.dtype}.`);\n    util.assert(method === 'otsu' || method === 'binary', () => `Method must be binary or otsu, but was ${method}`);\n    if ($image.shape[2] === 3) {\n        [r, g, b] = split($image, [1, 1, 1], -1);\n        const $r = mul(r, RED_INTENCITY_COEF);\n        const $g = mul(g, GREEN_INTENCITY_COEF);\n        const $b = mul(b, BLUE_INTENCITY_COEF);\n        grayscale = add(add($r, $g), $b);\n    }\n    else {\n        grayscale = image;\n    }\n    if (method === 'otsu') {\n        const $histogram = bincount(cast(round(grayscale), 'int32'), tensor([]), 256);\n        $threshold = otsu($histogram, totalPixelsInImage);\n    }\n    const invCondition = inverted ?\n        lessEqual(grayscale, $threshold) : greater(grayscale, $threshold);\n    const result = cast(mul(invCondition, 255), 'int32');\n    return result;\n}\nfunction otsu(histogram, total) {\n    let bestThresh = tensor1d([-1]);\n    let bestInBetVar = tensor1d([0]);\n    let cInBetVar = tensor1d([0]);\n    let classFirst, classSecond, meanFirst, meanSec, weightForeground, weightBack;\n    for (let index = 0; index < histogram.size - 1; index++) {\n        classFirst = slice(histogram, 0, index + 1);\n        classSecond = slice(histogram, index + 1);\n        weightForeground = div(sum(classFirst), total);\n        weightBack = div(sum(classSecond), total);\n        const meanFirstDivA = sum(mul(classFirst, range(0, classFirst.size)));\n        meanFirst = div(meanFirstDivA, sum(classFirst));\n        const meanSecFill = fill(classSecond.shape, classFirst.size);\n        const meanSecAdd = add(range(0, classSecond.size), meanSecFill);\n        const meanSecMul = mul(classSecond, (meanSecAdd));\n        meanSec = div(sum(meanSecMul), sum(classSecond));\n        const cInBetVarSubA = sub(meanFirst, meanSec);\n        const cInBetVarSubB = sub(meanFirst, meanSec);\n        const cInBetVarMul = mul(weightForeground, weightBack);\n        cInBetVar = mul(mul(cInBetVarMul, cInBetVarSubA), cInBetVarSubB);\n        const condition = greater(cInBetVar, bestInBetVar);\n        bestInBetVar = where(condition, cInBetVar, bestInBetVar);\n        bestThresh = where(condition, tensor1d([index]), bestThresh);\n    }\n    return bestThresh;\n}\nexport const threshold = op({ threshold_ });\n//# sourceMappingURL=threshold.js.map","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../../engine';\nimport { Transform } from '../../kernel_names';\nimport { convertToTensor } from '../../tensor_util_env';\nimport * as util from '../../util';\nimport { op } from '../operation';\n/**\n * Applies the given transform(s) to the image(s).\n *\n * @param image 4d tensor of shape `[batch, imageHeight, imageWidth, depth]`.\n * @param transforms Projective transform matrix/matrices. A tensor1d of length\n *     8 or tensor of size N x 8. If one row of transforms is [a0, a1, a2, b0\n *     b1, b2, c0, c1], then it maps the output point (x, y) to a transformed\n *     input point (x', y') = ((a0 x + a1 y + a2) / k, (b0 x + b1 y + b2) / k),\n *     where k = c0 x + c1 y + 1. The transforms are inverted compared to the\n *     transform mapping input points to output points.\n * @param interpolation Interpolation mode.\n *     Supported values: 'nearest', 'bilinear'. Default to 'nearest'.\n * @param fillMode Points outside the boundaries of the input are filled\n *     according to the given mode, one of 'constant', 'reflect', 'wrap',\n *     'nearest'. Default to 'constant'.\n *     'reflect': (d c b a | a b c d | d c b a ) The input is extended by\n *     reflecting about the edge of the last pixel.\n *     'constant': (k k k k | a b c d | k k k k) The input is extended by\n *     filling all values beyond the edge with the same constant value k.\n *     'wrap': (a b c d | a b c d | a b c d) The input is extended by\n *     wrapping around to the opposite edge.\n *     'nearest': (a a a a | a b c d | d d d d) The input is extended by\n *     the nearest pixel.\n * @param fillValue A float represents the value to be filled outside the\n *     boundaries when fillMode is 'constant'.\n * @param Output dimension after the transform, [height, width]. If undefined,\n *     output is the same size as input image.\n *\n * @doc {heading: 'Operations', subheading: 'Images', namespace: 'image'}\n */\nfunction transform_(image, transforms, interpolation = 'nearest', fillMode = 'constant', fillValue = 0, outputShape) {\n    const $image = convertToTensor(image, 'image', 'transform', 'float32');\n    const $transforms = convertToTensor(transforms, 'transforms', 'transform', 'float32');\n    util.assert($image.rank === 4, () => 'Error in transform: image must be rank 4,' +\n        `but got rank ${$image.rank}.`);\n    util.assert($transforms.rank === 2 &&\n        ($transforms.shape[0] === $image.shape[0] ||\n            $transforms.shape[0] === 1) &&\n        $transforms.shape[1] === 8, () => `Error in transform: Input transform should be batch x 8 or 1 x 8`);\n    util.assert(outputShape == null || outputShape.length === 2, () => 'Error in transform: outputShape must be [height, width] or null, ' +\n        `but got ${outputShape}.`);\n    const inputs = { image: $image, transforms: $transforms };\n    const attrs = { interpolation, fillMode, fillValue, outputShape };\n    return ENGINE.runKernel(Transform, inputs, attrs);\n}\nexport const transform = op({ transform_ });\n//# sourceMappingURL=transform.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { convertToTensor } from '../../tensor_util_env';\nimport { assert } from '../../util';\nimport { greaterEqual } from '../greater_equal';\nimport { lessEqual } from '../less_equal';\nimport { logicalAnd } from '../logical_and';\nimport { op } from '../operation';\nimport { range } from '../range';\nimport { reshape } from '../reshape';\nimport { scalar } from '../scalar';\nimport { stack } from '../stack';\nimport { sub } from '../sub';\nimport { unstack } from '../unstack';\nimport { where } from '../where';\nimport { zeros } from '../zeros';\n/**\n * Copy a tensor setting everything outside a central band in each innermost\n * matrix to zero.\n *\n * The band part is computed as follows: Assume input has `k` dimensions\n * `[I, J, K, ..., M, N]`, then the output is a tensor with the same shape where\n * `band[i, j, k, ..., m, n] = in_band(m, n) * input[i, j, k, ..., m, n]`.\n * The indicator function\n * `in_band(m, n) = (num_lower < 0 || (m-n) <= num_lower))`\n * `&& (num_upper < 0 || (n-m) <= num_upper)`\n *\n * ```js\n * const x = tf.tensor2d([[ 0,  1,  2, 3],\n *                        [-1,  0,  1, 2],\n *                        [-2, -1,  0, 1],\n *                        [-3, -2, -1, 0]]);\n * let y = tf.linalg.bandPart(x, 1, -1);\n * y.print(); // [[ 0,  1,  2, 3],\n *            //  [-1,  0,  1, 2],\n *            //  [ 0, -1,  0, 1],\n *            //  [ 0, 0 , -1, 0]]\n * let z = tf.linalg.bandPart(x, 2, 1);\n * z.print(); // [[ 0,  1,  0, 0],\n *            //  [-1,  0,  1, 0],\n *            //  [-2, -1,  0, 1],\n *            //  [ 0, -2, -1, 0]]\n * ```\n *\n * @param x Rank `k` tensor\n * @param numLower Number of subdiagonals to keep.\n *   If negative, keep entire lower triangle.\n * @param numUpper Number of subdiagonals to keep.\n *   If negative, keep entire upper triangle.\n * @returns Rank `k` tensor of the same shape as input.\n *   The extracted banded tensor.\n *\n * @doc {heading:'Operations', subheading:'Linear Algebra', namespace:'linalg'}\n */\nfunction bandPart_(a, numLower, numUpper) {\n    assert(numLower % 1 === 0, () => `bandPart(): numLower must be an integer, got ${numLower}.`);\n    assert(numUpper % 1 === 0, () => `bandPart(): numUpper must be an integer, got ${numUpper}.`);\n    const $a = convertToTensor(a, 'a', 'bandPart');\n    assert($a.rank >= 2, () => `bandPart(): Rank must be at least 2, got ${$a.rank}.`);\n    const shape = $a.shape;\n    const [M, N] = $a.shape.slice(-2);\n    if (!(numLower <= M)) {\n        throw new Error(`bandPart(): numLower (${numLower})` +\n            ` must not be greater than the number of rows (${M}).`);\n    }\n    if (!(numUpper <= N)) {\n        throw new Error(`bandPart(): numUpper (${numUpper})` +\n            ` must not be greater than the number of columns (${N}).`);\n    }\n    if (numLower < 0) {\n        numLower = M;\n    }\n    if (numUpper < 0) {\n        numUpper = N;\n    }\n    const i = reshape(range(0, M, 1, 'int32'), [-1, 1]);\n    const j = range(0, N, 1, 'int32');\n    const ij = sub(i, j);\n    const inBand = logicalAnd(lessEqual(ij, scalar(+numLower, 'int32')), greaterEqual(ij, scalar(-numUpper, 'int32')));\n    const zero = zeros([M, N], $a.dtype);\n    return reshape(stack(unstack(reshape($a, [-1, M, N]))\n        .map(mat => where(inBand, mat, zero))), shape);\n}\nexport const bandPart = op({ bandPart_ });\n//# sourceMappingURL=band_part.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../../engine';\nimport { assert } from '../../util';\nimport { div } from '../div';\nimport { mul } from '../mul';\nimport { norm } from '../norm';\nimport { op } from '../operation';\nimport { split } from '../split';\nimport { squeeze } from '../squeeze';\nimport { stack } from '../stack';\nimport { sub } from '../sub';\nimport { sum } from '../sum';\n/**\n * Gram-Schmidt orthogonalization.\n *\n * ```js\n * const x = tf.tensor2d([[1, 2], [3, 4]]);\n * let y = tf.linalg.gramSchmidt(x);\n * y.print();\n * console.log('Othogonalized:');\n * y.dot(y.transpose()).print();  // should be nearly the identity matrix.\n * console.log('First row direction maintained:');\n * const data = await y.array();\n * console.log(data[0][1] / data[0][0]);  // should be nearly 2.\n * ```\n *\n * @param xs The vectors to be orthogonalized, in one of the two following\n *   formats:\n *   - An Array of `tf.Tensor1D`.\n *   - A `tf.Tensor2D`, i.e., a matrix, in which case the vectors are the rows\n *     of `xs`.\n *   In each case, all the vectors must have the same length and the length\n *   must be greater than or equal to the number of vectors.\n * @returns The orthogonalized and normalized vectors or matrix.\n *   Orthogonalization means that the vectors or the rows of the matrix\n *   are orthogonal (zero inner products). Normalization means that each\n *   vector or each row of the matrix has an L2 norm that equals `1`.\n *\n * @doc {heading:'Operations', subheading:'Linear Algebra', namespace:'linalg'}\n */\nfunction gramSchmidt_(xs) {\n    let inputIsTensor2D;\n    if (Array.isArray(xs)) {\n        inputIsTensor2D = false;\n        assert(xs != null && xs.length > 0, () => 'Gram-Schmidt process: input must not be null, undefined, or ' +\n            'empty');\n        const dim = xs[0].shape[0];\n        for (let i = 1; i < xs.length; ++i) {\n            assert(xs[i].shape[0] === dim, () => 'Gram-Schmidt: Non-unique lengths found in the input vectors: ' +\n                `(${xs[i].shape[0]} vs. ${dim})`);\n        }\n    }\n    else {\n        inputIsTensor2D = true;\n        xs = split(xs, xs.shape[0], 0).map(x => squeeze(x, [0]));\n    }\n    assert(xs.length <= xs[0].shape[0], () => `Gram-Schmidt: Number of vectors (${xs.length}) exceeds ` +\n        `number of dimensions (${xs[0].shape[0]}).`);\n    const ys = [];\n    const xs1d = xs;\n    for (let i = 0; i < xs.length; ++i) {\n        ys.push(ENGINE.tidy(() => {\n            let x = xs1d[i];\n            if (i > 0) {\n                for (let j = 0; j < i; ++j) {\n                    const proj = mul(sum(mul(ys[j], x)), ys[j]);\n                    x = sub(x, proj);\n                }\n            }\n            return div(x, norm(x, 'euclidean'));\n        }));\n    }\n    if (inputIsTensor2D) {\n        return stack(ys, 0);\n    }\n    else {\n        return ys;\n    }\n}\nexport const gramSchmidt = op({ gramSchmidt_ });\n//# sourceMappingURL=gram_schmidt.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../../engine';\nimport { dispose } from '../../globals';\nimport { assert } from '../../util';\nimport { clone } from '../clone';\nimport { concat } from '../concat';\nimport { div } from '../div';\nimport { eye } from '../eye';\nimport { greater } from '../greater';\nimport { matMul } from '../mat_mul';\nimport { mul } from '../mul';\nimport { neg } from '../neg';\nimport { norm } from '../norm';\nimport { op } from '../operation';\nimport { reshape } from '../reshape';\nimport { slice } from '../slice';\nimport { stack } from '../stack';\nimport { sub } from '../sub';\nimport { tensor2d } from '../tensor2d';\nimport { transpose } from '../transpose';\nimport { unstack } from '../unstack';\nimport { where } from '../where';\n/**\n * Compute QR decomposition of m-by-n matrix using Householder transformation.\n *\n * Implementation based on\n *   [http://www.cs.cornell.edu/~bindel/class/cs6210-f09/lec18.pdf]\n * (http://www.cs.cornell.edu/~bindel/class/cs6210-f09/lec18.pdf)\n *\n * ```js\n * const a = tf.tensor2d([[1, 2], [3, 4]]);\n * let [q, r] = tf.linalg.qr(a);\n * console.log('Q');\n * q.print();\n * console.log('R');\n * r.print();\n * console.log('Orthogonalized');\n * q.dot(q.transpose()).print()  // should be nearly the identity matrix.\n * console.log('Reconstructed');\n * q.dot(r).print(); // should be nearly [[1, 2], [3, 4]];\n * ```\n *\n * @param x The `tf.Tensor` to be QR-decomposed. Must have rank >= 2. Suppose\n *   it has the shape `[..., M, N]`.\n * @param fullMatrices An optional boolean parameter. Defaults to `false`.\n *   If `true`, compute full-sized `Q`. If `false` (the default),\n *   compute only the leading N columns of `Q` and `R`.\n * @returns An `Array` of two `tf.Tensor`s: `[Q, R]`. `Q` is a unitary matrix,\n *   i.e., its columns all have unit norm and are mutually orthogonal.\n *   If `M >= N`,\n *     If `fullMatrices` is `false` (default),\n *       - `Q` has a shape of `[..., M, N]`,\n *       - `R` has a shape of `[..., N, N]`.\n *     If `fullMatrices` is `true` (default),\n *       - `Q` has a shape of `[..., M, M]`,\n *       - `R` has a shape of `[..., M, N]`.\n *   If `M < N`,\n *     - `Q` has a shape of `[..., M, M]`,\n *     - `R` has a shape of `[..., M, N]`.\n * @throws If the rank of `x` is less than 2.\n *\n * @doc {heading:'Operations',\n *       subheading:'Linear Algebra',\n *       namespace:'linalg'}\n */\nfunction qr_(x, fullMatrices = false) {\n    assert(x.rank >= 2, () => `qr() requires input tensor to have a rank >= 2, but got rank ${x.rank}`);\n    if (x.rank === 2) {\n        return qr2d(x, fullMatrices);\n    }\n    else {\n        // Rank > 2.\n        // TODO(cais): Below we split the input into individual 2D tensors,\n        //   perform QR decomposition on them and then stack the results back\n        //   together. We should explore whether this can be parallelized.\n        const outerDimsProd = x.shape.slice(0, x.shape.length - 2)\n            .reduce((value, prev) => value * prev);\n        const x2ds = unstack(reshape(x, [\n            outerDimsProd, x.shape[x.shape.length - 2],\n            x.shape[x.shape.length - 1]\n        ]), 0);\n        const q2ds = [];\n        const r2ds = [];\n        x2ds.forEach(x2d => {\n            const [q2d, r2d] = qr2d(x2d, fullMatrices);\n            q2ds.push(q2d);\n            r2ds.push(r2d);\n        });\n        const q = reshape(stack(q2ds, 0), x.shape);\n        const r = reshape(stack(r2ds, 0), x.shape);\n        return [q, r];\n    }\n}\nfunction qr2d(x, fullMatrices = false) {\n    return ENGINE.tidy(() => {\n        assert(x.shape.length === 2, () => `qr2d() requires a 2D Tensor, but got a ${x.shape.length}D Tensor.`);\n        const m = x.shape[0];\n        const n = x.shape[1];\n        let q = eye(m); // Orthogonal transform so far.\n        let r = clone(x); // Transformed matrix so far.\n        const one2D = tensor2d([[1]], [1, 1]);\n        let w = clone(one2D);\n        const iters = m >= n ? n : m;\n        for (let j = 0; j < iters; ++j) {\n            // This tidy within the for-loop ensures we clean up temporary\n            // tensors as soon as they are no longer needed.\n            const rTemp = r;\n            const wTemp = w;\n            const qTemp = q;\n            [w, r, q] = ENGINE.tidy(() => {\n                // Find H = I - tau * w * w', to put zeros below R(j, j).\n                const rjEnd1 = slice(r, [j, j], [m - j, 1]);\n                const normX = norm(rjEnd1);\n                const rjj = slice(r, [j, j], [1, 1]);\n                // The sign() function returns 0 on 0, which causes division by zero.\n                const s = where(greater(rjj, 0), tensor2d([[-1]]), tensor2d([[1]]));\n                const u1 = sub(rjj, mul(s, normX));\n                const wPre = div(rjEnd1, u1);\n                if (wPre.shape[0] === 1) {\n                    w = clone(one2D);\n                }\n                else {\n                    w = concat([\n                        one2D,\n                        slice(wPre, [1, 0], [wPre.shape[0] - 1, wPre.shape[1]])\n                    ], 0);\n                }\n                const tau = neg(div(matMul(s, u1), normX));\n                // -- R := HR, Q := QH.\n                const rjEndAll = slice(r, [j, 0], [m - j, n]);\n                const tauTimesW = mul(tau, w);\n                const wT = transpose(w);\n                if (j === 0) {\n                    r = sub(rjEndAll, matMul(tauTimesW, matMul(wT, rjEndAll)));\n                }\n                else {\n                    const rTimesTau = sub(rjEndAll, matMul(tauTimesW, matMul(wT, rjEndAll)));\n                    r = concat([slice(r, [0, 0], [j, n]), rTimesTau], 0);\n                }\n                const tawTimesWT = transpose(tauTimesW);\n                const qAllJEnd = slice(q, [0, j], [m, q.shape[1] - j]);\n                if (j === 0) {\n                    q = sub(qAllJEnd, matMul(matMul(qAllJEnd, w), tawTimesWT));\n                }\n                else {\n                    const qTimesTau = sub(qAllJEnd, matMul(matMul(qAllJEnd, w), tawTimesWT));\n                    q = concat([slice(q, [0, 0], [m, j]), qTimesTau], 1);\n                }\n                return [w, r, q];\n            });\n            dispose([rTemp, wTemp, qTemp]);\n        }\n        if (!fullMatrices && m > n) {\n            q = slice(q, [0, 0], [m, n]);\n            r = slice(r, [0, 0], [n, n]);\n        }\n        return [q, r];\n    });\n}\nexport const qr = op({ qr_ });\n//# sourceMappingURL=qr.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { convertToTensor } from '../../tensor_util_env';\nimport { assertShapesMatch } from '../../util';\nimport { abs } from '../abs';\nimport { Reduction } from '../loss_ops_utils';\nimport { op } from '../operation';\nimport { sub } from '../sub';\nimport { computeWeightedLoss } from './compute_weighted_loss';\n/**\n * Computes the absolute difference loss between two tensors.\n *\n * @param labels The ground truth output tensor, same dimensions as\n *    'predictions'.\n * @param predictions The predicted outputs.\n * @param weights Tensor whose rank is either 0, or the same rank as\n *    `labels`, and must be broadcastable to `labels` (i.e., all dimensions\n *    must be either `1`, or the same as the corresponding `losses`\n *    dimension).\n * @param reduction Type of reduction to apply to loss. Should be of type\n *    `Reduction`\n *\n * @doc {heading: 'Training', subheading: 'Losses', namespace: 'losses'}\n */\nfunction absoluteDifference_(labels, predictions, weights, reduction = Reduction.SUM_BY_NONZERO_WEIGHTS) {\n    const $labels = convertToTensor(labels, 'labels', 'absoluteDifference');\n    const $predictions = convertToTensor(predictions, 'predictions', 'absoluteDifference');\n    let $weights = null;\n    if (weights != null) {\n        $weights = convertToTensor(weights, 'weights', 'absoluteDifference');\n    }\n    assertShapesMatch($labels.shape, $predictions.shape, 'Error in absoluteDifference: ');\n    const losses = abs(sub($labels, $predictions));\n    return computeWeightedLoss(losses, $weights, reduction);\n}\nexport const absoluteDifference = op({ absoluteDifference_ });\n//# sourceMappingURL=absolute_difference.js.map","import { convertToTensor } from '../../tensor_util_env';\nimport { assertShapesMatch } from '../../util';\nimport { Reduction } from '../loss_ops_utils';\nimport { mul } from '../mul';\nimport { op } from '../operation';\nimport { scalar } from '../scalar';\nimport { sub } from '../sub';\nimport { sum } from '../sum';\nimport { computeWeightedLoss } from './compute_weighted_loss';\n/**\n * Computes the cosine distance loss between two tensors.\n *\n * @param labels The ground truth output tensor, same dimensions as\n *    'predictions'.\n * @param predictions The predicted outputs.\n * @param axis The dimension along which the cosine distance is computed.\n * @param weights Tensor whose rank is either 0, or the same rank as\n *    `labels`, and must be broadcastable to `labels` (i.e., all dimensions\n *    must be either `1`, or the same as the corresponding `losses`\n *    dimension).\n * @param reduction Type of reduction to apply to loss. Should be of type\n *    `Reduction`\n *\n * @doc {heading: 'Training', subheading: 'Losses', namespace: 'losses'}\n */\nfunction cosineDistance_(labels, predictions, axis, weights, reduction = Reduction.SUM_BY_NONZERO_WEIGHTS) {\n    const $labels = convertToTensor(labels, 'labels', 'cosineDistance');\n    const $predictions = convertToTensor(predictions, 'predictions', 'cosineDistance');\n    let $weights = null;\n    if (weights != null) {\n        $weights = convertToTensor(weights, 'weights', 'cosineDistance');\n    }\n    assertShapesMatch($labels.shape, $predictions.shape, 'Error in cosineDistance: ');\n    const one = scalar(1);\n    const losses = sub(one, sum(mul($labels, $predictions), axis, true));\n    return computeWeightedLoss(losses, $weights, reduction);\n}\nexport const cosineDistance = op({ cosineDistance_ });\n//# sourceMappingURL=cosine_distance.js.map","import { convertToTensor } from '../../tensor_util_env';\nimport { assertShapesMatch } from '../../util';\nimport { Reduction } from '../loss_ops_utils';\nimport { mul } from '../mul';\nimport { op } from '../operation';\nimport { relu } from '../relu';\nimport { scalar } from '../scalar';\nimport { sub } from '../sub';\nimport { computeWeightedLoss } from './compute_weighted_loss';\n/**\n * Computes the Hinge loss between two tensors.\n *\n * @param labels The ground truth output tensor, same dimensions as\n *    'predictions'.\n * @param predictions The predicted outputs.\n * @param weights Tensor whose rank is either 0, or the same rank as\n *    `labels`, and must be broadcastable to `labels` (i.e., all dimensions\n *    must be either `1`, or the same as the corresponding `losses`\n *    dimension).\n * @param reduction Type of reduction to apply to loss. Should be of type\n *    `Reduction`\n *\n * @doc {heading: 'Training', subheading: 'Losses', namespace: 'losses'}\n */\nfunction hingeLoss_(labels, predictions, weights, reduction = Reduction.SUM_BY_NONZERO_WEIGHTS) {\n    let $labels = convertToTensor(labels, 'labels', 'hingeLoss');\n    const $predictions = convertToTensor(predictions, 'predictions', 'hingeLoss');\n    let $weights = null;\n    if (weights != null) {\n        $weights = convertToTensor(weights, 'weights', 'hingeLoss');\n    }\n    assertShapesMatch($labels.shape, $predictions.shape, 'Error in hingeLoss: ');\n    const one = scalar(1);\n    // Convert binary labels to (-1, 1)\n    $labels = sub(mul(scalar(2), $labels), one);\n    const losses = relu(sub(one, mul($labels, $predictions)));\n    return computeWeightedLoss(losses, $weights, reduction);\n}\nexport const hingeLoss = op({ hingeLoss_ });\n//# sourceMappingURL=hinge_loss.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { convertToTensor } from '../../tensor_util_env';\nimport { assertShapesMatch } from '../../util';\nimport { abs } from '../abs';\nimport { add } from '../add';\nimport { Reduction } from '../loss_ops_utils';\nimport { minimum } from '../minimum';\nimport { mul } from '../mul';\nimport { op } from '../operation';\nimport { scalar } from '../scalar';\nimport { square } from '../square';\nimport { sub } from '../sub';\nimport { computeWeightedLoss } from './compute_weighted_loss';\n/**\n * Computes the huber loss between two tensors.\n *\n * @param labels The ground truth output tensor, same dimensions as\n *    'predictions'.\n * @param predictions The predicted outputs.\n * @param weights Tensor whose rank is either 0, or the same rank as\n *    `labels`, and must be broadcastable to `labels` (i.e., all dimensions\n *    must be either `1`, or the same as the corresponding `losses`\n *    dimension).\n * @param delta Point where huber loss changes from quadratic to linear.\n * @param reduction Type of reduction to apply to loss. Should be of type\n *    `Reduction`.\n *\n * @doc {heading: 'Training', subheading: 'Losses', namespace: 'losses'}\n */\nfunction huberLoss_(labels, predictions, weights, delta = 1.0, reduction = Reduction.SUM_BY_NONZERO_WEIGHTS) {\n    const $labels = convertToTensor(labels, 'labels', 'huberLoss');\n    const $predictions = convertToTensor(predictions, 'predictions', 'huberLoss');\n    let $weights = null;\n    if (weights != null) {\n        $weights = convertToTensor(weights, 'weights', 'huberLoss');\n    }\n    assertShapesMatch($labels.shape, $predictions.shape, 'Error in huberLoss: ');\n    const deltaScalar = scalar(delta);\n    const error = abs(sub($predictions, $labels));\n    const quadratic = minimum(error, deltaScalar);\n    const linear = sub(error, quadratic);\n    const losses = add(mul(scalar(0.5), square(quadratic)), mul(deltaScalar, linear));\n    return computeWeightedLoss(losses, $weights, reduction);\n}\nexport const huberLoss = op({ huberLoss_ });\n//# sourceMappingURL=huber_loss.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { convertToTensor } from '../../tensor_util_env';\nimport { assertShapesMatch } from '../../util';\nimport { add } from '../add';\nimport { log } from '../log';\nimport { Reduction } from '../loss_ops_utils';\nimport { mul } from '../mul';\nimport { neg } from '../neg';\nimport { op } from '../operation';\nimport { scalar } from '../scalar';\nimport { sub } from '../sub';\nimport { computeWeightedLoss } from './compute_weighted_loss';\n/**\n * Computes the log loss between two tensors.\n *\n * @param labels The ground truth output tensor, same dimensions as\n *    'predictions'.\n * @param predictions The predicted outputs.\n * @param weights Tensor whose rank is either 0, or the same rank as\n *    `labels`, and must be broadcastable to `labels` (i.e., all dimensions\n *    must be either `1`, or the same as the corresponding `losses`\n *    dimension).\n * @param epsilon A small increment to avoid taking log of zero\n * @param reduction Type of reduction to apply to loss. Should be of type\n *    `Reduction`\n *\n * @doc {heading: 'Training', subheading: 'Losses', namespace: 'losses'}\n */\nfunction logLoss_(labels, predictions, weights, epsilon = 1e-7, reduction = Reduction.SUM_BY_NONZERO_WEIGHTS) {\n    const $labels = convertToTensor(labels, 'labels', 'logLoss');\n    const $predictions = convertToTensor(predictions, 'predictions', 'logLoss');\n    let $weights = null;\n    if (weights != null) {\n        $weights = convertToTensor(weights, 'weights', 'logLoss');\n    }\n    assertShapesMatch($labels.shape, $predictions.shape, 'Error in logLoss: ');\n    const one = scalar(1);\n    const epsilonScalar = scalar(epsilon);\n    const l1 = neg(mul($labels, log(add($predictions, epsilonScalar))));\n    const l2 = mul(sub(one, $labels), log(add(sub(one, $predictions), epsilonScalar)));\n    const losses = sub(l1, l2);\n    return computeWeightedLoss(losses, $weights, reduction);\n}\nexport const logLoss = op({ logLoss_ });\n//# sourceMappingURL=log_loss.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { convertToTensor } from '../../tensor_util_env';\nimport { assertShapesMatch } from '../../util';\nimport { Reduction } from '../loss_ops_utils';\nimport { op } from '../operation';\nimport { squaredDifference } from '../squared_difference';\nimport { computeWeightedLoss } from './compute_weighted_loss';\n/**\n * Computes the mean squared error between two tensors.\n *\n * @param labels The ground truth output tensor, same dimensions as\n *    'predictions'.\n * @param predictions The predicted outputs.\n * @param weights Tensor whose rank is either 0, or the same rank as\n *    `labels`, and must be broadcastable to `labels` (i.e., all dimensions\n *    must be either `1`, or the same as the corresponding `losses`\n *    dimension).\n * @param reduction Type of reduction to apply to loss. Should be of type\n *    `Reduction`\n *\n * @doc {heading: 'Training', subheading: 'Losses', namespace: 'losses'}\n */\nfunction meanSquaredError_(labels, predictions, weights, reduction = Reduction.SUM_BY_NONZERO_WEIGHTS) {\n    const $labels = convertToTensor(labels, 'labels', 'meanSquaredError');\n    const $predictions = convertToTensor(predictions, 'predictions', 'meanSquaredError');\n    let $weights = null;\n    if (weights != null) {\n        $weights = convertToTensor(weights, 'weights', 'meanSquaredError');\n    }\n    assertShapesMatch($labels.shape, $predictions.shape, 'Error in meanSquaredError: ');\n    const losses = squaredDifference($labels, $predictions);\n    return computeWeightedLoss(losses, $weights, reduction);\n}\nexport const meanSquaredError = op({ meanSquaredError_ });\n//# sourceMappingURL=mean_squared_error.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { convertToTensor } from '../../tensor_util_env';\nimport { assertShapesMatch } from '../../util';\nimport { abs } from '../abs';\nimport { add } from '../add';\nimport { exp } from '../exp';\nimport { log1p } from '../log1p';\nimport { Reduction } from '../loss_ops_utils';\nimport { mul } from '../mul';\nimport { neg } from '../neg';\nimport { op } from '../operation';\nimport { relu } from '../relu';\nimport { scalar } from '../scalar';\nimport { sub } from '../sub';\nimport { computeWeightedLoss } from './compute_weighted_loss';\nfunction sigmoidCrossEntropyWithLogits_(labels, logits) {\n    const $labels = convertToTensor(labels, 'labels', 'sigmoidCrossEntropyWithLogits');\n    const $logits = convertToTensor(logits, 'logits', 'sigmoidCrossEntropyWithLogits');\n    assertShapesMatch($labels.shape, $logits.shape, 'Error in sigmoidCrossEntropyWithLogits: ');\n    /**\n     * Implementation Details:\n     *\n     * For brevity, let `x = logits`, `z = labels`.  The logistic loss is\n     *     z * -log(sigmoid(x)) + (1 - z) * -log(1 - sigmoid(x))\n     *   = z * -log(1 / (1 + exp(-x))) + (1 - z) * -log(exp(-x) / (1 + exp(-x)))\n     *   = z * log(1 + exp(-x)) + (1 - z) * (-log(exp(-x)) + log(1 + exp(-x)))\n     *   = z * log(1 + exp(-x)) + (1 - z) * (x + log(1 + exp(-x))\n     *   = (1 - z) * x + log(1 + exp(-x))\n     *   = x - x * z + log(1 + exp(-x))\n     *\n     *   For x < 0, to avoid overflow in exp(-x), we reformulate the above\n     *     x - x * z + log(1 + exp(-x))\n     *   = log(exp(x)) - x * z + log(1 + exp(-x))\n     *   = - x * z + log(1 + exp(x))\n     *\n     * Hence, to ensure stability and avoid overflow, the implementation uses\n     * this equivalent formulation:\n     *     max(x, 0) - x * z + log(1 + exp(-abs(x)))\n     */\n    const maxOutput = relu($logits);\n    const outputXTarget = mul($logits, $labels);\n    const sigmoidOutput = log1p(exp(neg(abs($logits))));\n    return add(sub(maxOutput, outputXTarget), sigmoidOutput);\n}\n/**\n * Computes the sigmoid cross entropy loss between two tensors.\n *\n * If labelSmoothing is nonzero, smooth the labels towards 1/2:\n *\n *   newMulticlassLabels = multiclassLabels * (1 - labelSmoothing)\n *                         + 0.5 * labelSmoothing\n *\n * @param multiClassLabels The ground truth output tensor of shape\n * [batch_size, num_classes], same dimensions as 'predictions'.\n * @param logits The predicted outputs.\n * @param weights Tensor whose rank is either 0, or the same rank as\n *    `labels`, and must be broadcastable to `labels` (i.e., all dimensions\n *    must be either `1`, or the same as the corresponding `losses`\n *    dimension).\n * @param labelSmoothing If greater than 0, then smooth the labels.\n * @param reduction Type of reduction to apply to loss. Should be of type\n *    `Reduction`\n *\n * @doc { heading: 'Training', subheading: 'Losses', namespace: 'losses' }\n */\nfunction sigmoidCrossEntropy_(multiClassLabels, logits, weights, labelSmoothing = 0, reduction = Reduction.SUM_BY_NONZERO_WEIGHTS) {\n    let $multiClassLabels = convertToTensor(multiClassLabels, 'multiClassLabels', 'sigmoidCrossEntropy');\n    const $logits = convertToTensor(logits, 'logits', 'sigmoidCrossEntropy');\n    let $weights = null;\n    if (weights != null) {\n        $weights = convertToTensor(weights, 'weights', 'sigmoidCrossEntropy');\n    }\n    assertShapesMatch($multiClassLabels.shape, $logits.shape, 'Error in sigmoidCrossEntropy: ');\n    if (labelSmoothing > 0) {\n        const labelSmoothingScalar = scalar(labelSmoothing);\n        const one = scalar(1);\n        const half = scalar(0.5);\n        $multiClassLabels =\n            add(mul($multiClassLabels, sub(one, labelSmoothingScalar)), mul(half, labelSmoothingScalar));\n    }\n    const losses = sigmoidCrossEntropyWithLogits_($multiClassLabels, $logits);\n    return computeWeightedLoss(losses, $weights, reduction);\n}\nexport const sigmoidCrossEntropy = op({ sigmoidCrossEntropy_ });\n//# sourceMappingURL=sigmoid_cross_entropy.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { customGrad } from '../../gradients';\nimport { convertToTensor } from '../../tensor_util_env';\nimport { assertShapesMatch } from '../../util';\nimport { add } from '../add';\nimport { expandShapeToKeepDim } from '../axis_util';\nimport { cast } from '../cast';\nimport { div } from '../div';\nimport { exp } from '../exp';\nimport { logSumExp } from '../log_sum_exp';\nimport { Reduction } from '../loss_ops_utils';\nimport { mul } from '../mul';\nimport { neg } from '../neg';\nimport { op } from '../operation';\nimport { reshape } from '../reshape';\nimport { scalar } from '../scalar';\nimport { sub } from '../sub';\nimport { sum } from '../sum';\nimport { computeWeightedLoss } from './compute_weighted_loss';\n/**\n * Computes softmax cross entropy between logits and labels.\n *\n * Measures the probability error in discrete classification tasks in which\n * the classes are mutually exclusive (each entry is in exactly one class).\n * For example, each CIFAR-10 image is labeled with one and only one label: an\n * image can be a dog or a truck, but not both.\n *\n * `NOTE`: While the classes are mutually exclusive, their probabilities need\n * not be. All that is required is that each row of labels is a valid\n * probability distribution. If they are not, the computation of the gradient\n * will be incorrect.\n *\n * `WARNING`: This op expects unscaled logits, since it performs a softmax on\n * logits internally for efficiency. Do not call this op with the output of\n * softmax, as it will produce incorrect results.\n *\n * logits and labels must have the same shape, e.g. [batch_size, num_classes]\n * and the same dtype.\n * @param labels The labels array.\n * @param logits The logits array.\n * @param dim The dimension softmax would be performed on. Defaults to `-1`\n *     which indicates the last dimension.\n */\nfunction softmaxCrossEntropyWithLogits_(labels, logits, dim = -1) {\n    if (dim === -1) {\n        dim = logits.rank - 1;\n    }\n    if (dim !== logits.rank - 1) {\n        throw Error(`Softmax cross entropy along a non-last dimension is not yet ` +\n            `supported. Labels / logits was rank ${logits.rank} ` +\n            `and dim was ${dim}`);\n    }\n    // Use a custom gradient for numerical stability.\n    const customOp = customGrad((labels, logits, save) => {\n        // Reference:\n        //   1. http://cs231n.github.io/linear-classify/#softmax\n        //   2. https://blog.feedly.com/tricks-of-the-trade-logsumexp/\n        const keepDims = true;\n        const lse = logSumExp(logits, [dim], keepDims);\n        const logResult = sub(cast(logits, 'float32'), lse);\n        save([labels, logResult]);\n        const costVector = neg(mul(logResult, labels));\n        const value = sum(costVector, [dim]);\n        const gradFunc = (dy, saved) => {\n            const [labels, logResult] = saved;\n            const dyShape = expandShapeToKeepDim(dy.shape, [dim]);\n            return [\n                mul(reshape(dy, dyShape), sub(cast(labels, 'float32'), exp(logResult))),\n                mul(reshape(dy, dyShape), sub(exp(logResult), cast(labels, 'float32'))),\n            ];\n        };\n        return { value, gradFunc };\n    });\n    return customOp(labels, logits);\n}\n/**\n * Computes the softmax cross entropy loss between two tensors.\n *\n * If labelSmoothing is nonzero, smooth the labels towards 1/2:\n *\n *   newOnehotLabels = onehotLabels * (1 - labelSmoothing)\n *                         + labelSmoothing / numClasses\n *\n * @param onehotLabels One hot encoded labels\n *    [batch_size, num_classes], same dimensions as 'predictions'.\n * @param logits The predicted outputs.\n * @param weights Tensor whose rank is either 0, or 1, and must be\n *    broadcastable to `loss`  of shape [batch_size]\n * @param labelSmoothing If greater than 0, then smooth the labels.\n * @param reduction Type of reduction to apply to loss. Should be of type\n *    `Reduction`\n *\n * @doc { heading: 'Training', subheading: 'Losses', namespace: 'losses' }\n */\nfunction softmaxCrossEntropy_(onehotLabels, logits, weights, labelSmoothing = 0, reduction = Reduction.SUM_BY_NONZERO_WEIGHTS) {\n    let $onehotLabels = convertToTensor(onehotLabels, 'onehotLabels', 'softmaxCrossEntropy');\n    const $logits = convertToTensor(logits, 'logits', 'softmaxCrossEntropy');\n    let $weights = null;\n    if (weights != null) {\n        $weights = convertToTensor(weights, 'weights', 'softmaxCrossEntropy');\n    }\n    assertShapesMatch($onehotLabels.shape, $logits.shape, 'Error in softmaxCrossEntropy: ');\n    if (labelSmoothing > 0) {\n        const labelSmoothingScalar = scalar(labelSmoothing);\n        const one = scalar(1);\n        const numClasses = scalar($onehotLabels.shape[1]);\n        $onehotLabels =\n            add(mul($onehotLabels, sub(one, labelSmoothingScalar)), div(labelSmoothingScalar, numClasses));\n    }\n    const losses = softmaxCrossEntropyWithLogits_($onehotLabels, $logits);\n    return computeWeightedLoss(losses, $weights, reduction);\n}\nexport const softmaxCrossEntropy = op({ softmaxCrossEntropy_ });\n//# sourceMappingURL=softmax_cross_entropy.js.map","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport * as broadcast_util from './broadcast_util';\nimport { elu } from './elu';\nimport { leakyRelu } from './leaky_relu';\nimport { mul } from './mul';\nimport { prelu } from './prelu';\nimport { relu } from './relu';\nimport { relu6 } from './relu6';\nimport { reshape } from './reshape';\nimport { sigmoid } from './sigmoid';\nimport { step } from './step';\nimport { sum } from './sum';\n// Returns gradient for fused activation.\nexport function getFusedDyActivation(dy, y, activation) {\n    if (activation == null || activation === 'linear') {\n        return dy;\n    }\n    if (activation === 'relu') {\n        return mul(dy, step(y));\n    }\n    throw new Error(`Cannot compute gradient for fused activation ${activation}.`);\n}\n// Returns gradient for fused bias.\nexport function getFusedBiasGradient(bias, dyActivation) {\n    let res = dyActivation;\n    const reduceAxes = broadcast_util.getReductionAxes(bias.shape, dyActivation.shape);\n    if (reduceAxes.length > 0) {\n        res = sum(res, reduceAxes);\n    }\n    return reshape(res, bias.shape);\n}\nexport function applyActivation(x, activation, preluActivationWeights, leakyreluAlpha) {\n    if (activation === 'linear') {\n        return x;\n    }\n    else if (activation === 'relu') {\n        return relu(x);\n    }\n    else if (activation === 'elu') {\n        return elu(x);\n    }\n    else if (activation === 'relu6') {\n        return relu6(x);\n    }\n    else if (activation === 'prelu') {\n        return prelu(x, preluActivationWeights);\n    }\n    else if (activation === 'leakyrelu') {\n        return leakyRelu(x, leakyreluAlpha);\n    }\n    else if (activation === 'sigmoid') {\n        return sigmoid(x);\n    }\n    throw new Error(`Unknown fused activation ${activation}.`);\n}\n// Whether we should call fused ops.\nexport const shouldFuse = (gradientDepth, activation) => {\n    const gradientMode = gradientDepth > 0;\n    return !gradientMode || activation === 'linear';\n};\n//# sourceMappingURL=fused_util.js.map","import { convertToTensor } from '../../tensor_util_env';\nimport { cast } from '../cast';\nimport { div } from '../div';\nimport { Reduction } from '../loss_ops_utils';\nimport { mean } from '../mean';\nimport { mul } from '../mul';\nimport { notEqual } from '../not_equal';\nimport { ones } from '../ones';\nimport { op } from '../operation';\nimport { scalar } from '../scalar';\nimport { sum } from '../sum';\n/**\n * Computes the weighted loss between two tensors.\n *\n * @param losses Tensor of shape `[batch_size, d1, ... dN]`.\n * @param weights Tensor whose rank is either 0, or the same rank as\n *    `losses`, and must be broadcastable to `losses` (i.e., all\n *    dimensions must be either `1`, or the same as the corresponding\n *    `losses` dimension).\n *\n * @doc {heading: 'Training', subheading: 'Losses', namespace: 'losses'}\n */\nfunction computeWeightedLoss_(losses, weights, reduction = Reduction.SUM_BY_NONZERO_WEIGHTS) {\n    const $losses = convertToTensor(losses, 'losses', 'computeWeightedLoss');\n    let $weights = null;\n    if (weights != null) {\n        $weights = convertToTensor(weights, 'weights', 'computeWeightedLoss');\n    }\n    const weightedLoss = ($weights == null) ? $losses : mul($losses, $weights);\n    if (reduction === Reduction.NONE) {\n        return weightedLoss;\n    }\n    if (reduction === Reduction.SUM) {\n        return sum(weightedLoss);\n    }\n    if (reduction === Reduction.MEAN) {\n        if ($weights == null) {\n            return mean(weightedLoss);\n        }\n        else {\n            const broadcastFactor = $losses.size / $weights.size;\n            const result = div(sum(weightedLoss), sum($weights));\n            return broadcastFactor > 1 ? div(result, scalar(broadcastFactor)) :\n                result;\n        }\n    }\n    if (reduction === Reduction.SUM_BY_NONZERO_WEIGHTS) {\n        if ($weights == null) {\n            return div(sum(weightedLoss), scalar($losses.size));\n        }\n        else {\n            const broadcastedWeights = mul($weights, ones($losses.shape));\n            const numNonZeros = cast(sum(notEqual(broadcastedWeights, scalar(0))), 'float32');\n            return div(sum(weightedLoss), numNonZeros);\n        }\n    }\n    throw Error(`Unknown reduction: ${reduction}`);\n}\nexport const computeWeightedLoss = op({ computeWeightedLoss_ });\n//# sourceMappingURL=compute_weighted_loss.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Neg } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes `-1 * x` element-wise.\n *\n * ```js\n * const x = tf.tensor2d([1, 2, -2, 0], [2, 2]);\n *\n * x.neg().print();  // or tf.neg(x)\n * ```\n *\n * @param x The input tensor.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction neg_(x) {\n    const $x = convertToTensor(x, 'x', 'neg');\n    const inputs = { x: $x };\n    return ENGINE.runKernel(Neg, inputs);\n}\nexport const neg = op({ neg_ });\n//# sourceMappingURL=neg.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Max } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes the maximum of elements across dimensions of a `tf.Tensor`.\n *\n * Reduces the input along the dimensions given in `axes`. Unless `keepDims`\n * is true, the rank of the `tf.Tensor` is reduced by 1 for each entry in\n * `axes`. If `keepDims` is true, the reduced dimensions are retained with\n * length 1. If `axes` has no entries, all dimensions are reduced, and an\n * `tf.Tensor` with a single element is returned.\n *\n * ```js\n * const x = tf.tensor1d([1, 2, 3]);\n *\n * x.max().print();  // or tf.max(x)\n * ```\n *\n * ```js\n * const x = tf.tensor2d([1, 2, 3, 4], [2, 2]);\n *\n * const axis = 1;\n * x.max(axis).print();  // or tf.max(x, axis)\n * ```\n *\n * @param x The input tensor.\n * @param axis The dimension(s) to reduce. By default it reduces\n *     all dimensions.\n * @param keepDims If true, retains reduced dimensions with size 1.\n *\n * @doc {heading: 'Operations', subheading: 'Reduction'}\n */\nfunction max_(x, axis = null, keepDims = false) {\n    const $x = convertToTensor(x, 'x', 'max');\n    const inputs = { x: $x };\n    const attrs = { reductionIndices: axis, keepDims };\n    return ENGINE.runKernel(Max, inputs, attrs);\n}\nexport const max = op({ max_ });\n//# sourceMappingURL=max.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Log } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes natural logarithm of the input `tf.Tensor` element-wise: `ln(x)`\n *\n * ```js\n * const x = tf.tensor1d([1, 2, Math.E]);\n *\n * x.log().print();  // or tf.log(x)\n * ```\n * @param x The input tensor.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction log_(x) {\n    const $x = convertToTensor(x, 'x', 'log');\n    const inputs = { x: $x };\n    return ENGINE.runKernel(Log, inputs);\n}\nexport const log = op({ log_ });\n//# sourceMappingURL=log.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Greater } from '../kernel_names';\nimport { makeTypesMatch } from '../tensor_util';\nimport { convertToTensor } from '../tensor_util_env';\nimport { assertAndGetBroadcastShape } from './broadcast_util';\nimport { op } from './operation';\n/**\n * Returns the truth value of (a > b) element-wise. Supports broadcasting.\n *\n * ```js\n * const a = tf.tensor1d([1, 2, 3]);\n * const b = tf.tensor1d([2, 2, 2]);\n *\n * a.greater(b).print();\n * ```\n *\n * @param a The first input tensor.\n * @param b The second input tensor. Must have the same dtype as `a`.\n *\n * @doc {heading: 'Operations', subheading: 'Logical'}\n */\nfunction greater_(a, b) {\n    let $a = convertToTensor(a, 'a', 'greater', 'string_or_numeric');\n    let $b = convertToTensor(b, 'b', 'greater', 'string_or_numeric');\n    [$a, $b] = makeTypesMatch($a, $b);\n    assertAndGetBroadcastShape($a.shape, $b.shape);\n    const inputs = { a: $a, b: $b };\n    return ENGINE.runKernel(Greater, inputs);\n}\nexport const greater = op({ greater_ });\n//# sourceMappingURL=greater.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Imag } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Returns the imaginary part of a complex (or real) tensor.\n *\n * Given a tensor input, this operation returns a tensor of type float that is\n * the imaginary part of each element in input considered as a complex number.\n * If input is real, a tensor of all zeros is returned.\n *\n * ```js\n * const x = tf.complex([-2.25, 3.25], [4.75, 5.75]);\n * tf.imag(x).print();\n * ```\n *\n * @doc {heading: 'Tensors', subheading: 'Creation'}\n */\nfunction imag_(input) {\n    const $input = convertToTensor(input, 'input', 'imag');\n    const inputs = { input: $input };\n    return ENGINE.runKernel(Imag, inputs);\n}\nexport const imag = op({ imag_ });\n//# sourceMappingURL=imag.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Fill } from '../kernel_names';\n/**\n * Creates a `tf.Tensor` filled with a scalar value.\n *\n * ```js\n * tf.fill([2, 2], 4).print();\n * ```\n *\n * @param shape An array of integers defining the output tensor shape.\n * @param value The scalar value to fill the tensor with.\n * @param dtype The type of an element in the resulting tensor. Defaults to\n * 'float'.\n *\n * @doc {heading: 'Tensors', subheading: 'Creation'}\n */\nfunction fill(shape, value, dtype) {\n    const attrs = { shape, value, dtype };\n    return ENGINE.runKernel(Fill, {}, attrs);\n}\nexport { fill };\n//# sourceMappingURL=fill.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { LessEqual } from '../kernel_names';\nimport { makeTypesMatch } from '../tensor_util';\nimport { convertToTensor } from '../tensor_util_env';\nimport { assertAndGetBroadcastShape } from './broadcast_util';\nimport { op } from './operation';\n/**\n * Returns the truth value of (a <= b) element-wise. Supports broadcasting.\n *\n * ```js\n * const a = tf.tensor1d([1, 2, 3]);\n * const b = tf.tensor1d([2, 2, 2]);\n *\n * a.lessEqual(b).print();\n * ```\n *\n * @param a The first input tensor.\n * @param b The second input tensor. Must have the same dtype as `a`.\n *\n * @doc {heading: 'Operations', subheading: 'Logical'}\n */\nfunction lessEqual_(a, b) {\n    let $a = convertToTensor(a, 'a', 'lessEqual', 'string_or_numeric');\n    let $b = convertToTensor(b, 'b', 'lessEqual', 'string_or_numeric');\n    [$a, $b] = makeTypesMatch($a, $b);\n    assertAndGetBroadcastShape($a.shape, $b.shape);\n    const inputs = { a: $a, b: $b };\n    return ENGINE.runKernel(LessEqual, inputs);\n}\nexport const lessEqual = op({ lessEqual_ });\n//# sourceMappingURL=less_equal.js.map"],"sourceRoot":""}